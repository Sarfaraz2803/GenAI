{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f2306b-6b74-44e5-b1b1-b427c7df5d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: chromadb in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (0.5.23)\n",
      "Requirement already satisfied: langchain-chroma in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.3.31)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (0.115.7)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (3.9.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (0.13.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.27.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-huggingface) (3.4.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-huggingface) (4.46.3)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-groq) (0.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.45.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.1.21)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarfarazuddin.s\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~enacity (C:\\Users\\sarfarazuddin.s\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~enacity (C:\\Users\\sarfarazuddin.s\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~enacity (C:\\Users\\sarfarazuddin.s\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain chromadb langchain-chroma langchain-huggingface langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bf3164-878e-4920-89b5-66c8089f40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36974869-97c9-4543-9a06-4153de6b9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3cdc80-6ea3-42a9-b5bd-ba6e5bd490f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = r\"C:\\Users\\sarfarazuddin.s\\Downloads\\The Data Science Handbook.pdf\"\n",
    "if not os.path.exists(pdf_file_path):\n",
    "    raise FileNotFoundError(f\"The file {pdf_file_path} does not exist.\")\n",
    "\n",
    "# Load and split the PDF document into chunks\n",
    "document_loader = PyPDFLoader(pdf_file_path)\n",
    "# documents = document_loader.load_and_split()\n",
    "documents = document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d62e71-7b67-4f09-89ff-5b33305780da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 0}, page_content='THE\\nDATA SCIENCE  \\nHANDBOOK\\nADVICE A ND I NSIGHTS FROM   \\n25 AMAZING DA TA SCIEN TISTS\\nDJ Patil, Hilary Mason, Pete Skomoroch, Riley Newman, Jonathan Goldman, Michael Hochster, \\n George Roumeliotis, Kevin Novak, Jace Kohlmeier, Chris Moody, Erich Owens, Luis Sanchez, \\n Eithon Cadag, Sean Gourley, Clare Corthell, Diane Wu, Joe Blitzstein, Josh Wills, Bradley Voytek, \\n Michelangelo D’Agostino, Mike Dewar, Kunal Punera, William Chen, John Foreman, Drew Conway\\nBY M AX  S ONGHE N RY  W ANG WI LL IA M  C HENCA R L  SHAN\\nFOREWORD BY JAKE K LAMKA\\nSold to\\nmenogetusername@gmail.com\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 1}, page_content='To our family, friends and mentors. \\nYour support and encouragement is the fuel for our fire.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 2}, page_content='CONTENTS\\nPreface by Jake Klamka, Insight Data Science     1 \\nIntroduction            4\\nChapter 1: DJ Patil, VP of Product at RelateIQ\\nThe Importance of Taking Chances and Giving Back    6\\nChapter 2: Hilary Mason, Founder at Fast Forward Labs\\nOn Becoming a Successful Data Scientist      17\\nChapter 3: Pete Skomoroch, Data Scientist at Data Wrangling\\nSoftware is Eating the World, and It’s Replacing it With Data  27\\nChapter 4: Mike Dewar, Data Scientist at New York Times\\nData Science in Journalism        40\\nChapter 5: Riley Newman, Head of Data at AirBnB\\nData Is The Voice Of Your Customer       49\\nChapter 6: Clare Corthell, Data Scientist at Mattermark\\nCreating Your Own Data Science Curriculum     56\\nChapter 7: Drew Conway, Head of Data at Project Florida\\nHuman Problems Won’t Be Solved by Root-Mean-Squared Error 64\\nChapter 8: Kevin Novak, Head of Data Science at Uber\\nData Science: Software Carpentry, Engineering and Product  76\\nChapter 9: Chris Moody, Data Scientist at Square\\nFrom Astrophysics to Data Science       84\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 3}, page_content='CONTENTS\\nChapter 10: Erich Owens, Data Engineer at Facebook\\nThe Importance of Software Engineering in Data Science  95\\nChapter 11: Eithon Cadag, Principal Data Scientist at Ayasdi\\nBridging the Chasm: From Bioinformatics to Data Science  102\\nChapter 12: George Roumeliotis, Senior Data Scientist at Intuit\\nHow to Develop Data Science Skills       115\\nChapter 13: Diane Wu, Data Scientist at Palantir\\nThe Interplay Between Science, Engineering and Data Science 123\\nChapter 14: Jace Kohlmeier, Dean of Data Science at Khan Academy\\nFrom High Frequency Trading to Powering Personalized Education  130\\nChapter 15: Joe Blitzstein, Professor of Statistics at Harvard University\\nTeaching Data Science and Storytelling      140\\nChapter 16: John Foreman, Chief Data Scientist at MailChimp\\nData Science is not a Kaggle Competition     151\\nChapter 17: Josh Wills, Director of Data Science at Cloudera\\nMathematics, Ego Death and Becoming a Better Programmer 169\\nChapter 18: Bradley Voytek, Computational Cognitive Science Professor \\nat UCSD\\nData Science, Zombies and Academia      181\\nChapter 19: Luis Sanchez, Founder and Data Scientist at ttwick\\nAcademia, Quantitative Finance and Entrepreneurship   191\\nChapter 20: Michelangelo D’Agostino, Lead Data Scientist at Civis Analytics\\nThe U.S. Presidential Elections as a Physical Science   202\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 4}, page_content='CONTENTS\\nChapter 21: Michael Hochster, Director of Data Science at LinkedIn\\nThe Importance of Developing Data Sense    213\\nChapter 22: Kunal Punera, Co-Founder/CTO at Bento Labs\\nData Mining, Data Products, and Entrepreneurship   227\\nChapter 23: Sean Gourley, Co-founder and CTO at Quid\\nFrom Modeling War to Augmenting Human Intelligence  245\\nChapter 24: Jonathan Goldman, Dir. of Data Science & Analytics at Intuit\\nHow to Build Novel Data Products and Companies   266\\nChapter 25: William Chen, Data Scientist at Quora\\nFrom Undergraduate to Data Science     272\\nAbout the Authors          279\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 5}, page_content='PREFACE\\nIn the past five years, data science has made an impact in almost every major area of \\nhuman endeavour. From commerce, to education, to energy, and of course, software and \\nthe Internet, data science has created immense value across the world. In fact, in early \\n2015 the President of the United States announced the new role of Chief Data Scientist \\nto the White House and appointed DJ Patil, one of the interviewees in this book, to the \\nposition.\\nLike many innovations in the world, the birth of this industry was started by a few \\nmotivated people. Over the last few years, they founded, developed and advocated for \\nthe value that data analytics can bring to every industry. In The Data Science Handbook, \\nyou will have the opportunity to meet many of these founding data scientists, hear first \\nhand accounts of the incredible journeys they took, and read where they believe the field \\nis headed.\\nThe road to becoming a data scientist is not always an easy one. When I tried to transition \\nfrom experimental particle physics to industry, resources were few and far between. In \\nfact, although a need for data science existed in companies, the job title had not even \\nbeen created. I spent a lot of time teaching myself, working on various startup projects, \\nand later saw many of my friends from academia run into the same challenges.\\nI observed a groundswell of incredibly gifted and highly trained researchers who were \\nexcited about moving into data-driven roles, yet were missing key pieces of knowledge \\nabout how to do so. As a result, they had trouble transferring their incredible quantitative \\nand data analysis research skills to a career in industry. Meanwhile, having lived and \\nworked in Silicon Valley, I also saw that there was very strong demand from technology \\ncompanies who wanted to hire these exact people. \\nTo help others bridge the gap between academia and industry, I founded the Insight Data \\nScience Fellows Program in 2012. Insight is a training fellowship that helps quantitative \\nPhDs transition from academia to industry. Over the last few years, we’ve helped hundreds \\nof Insight Fellows, from fields like physics, computational biology, neuroscience, math, \\nand engineering, transition from a background in academia to become leading data \\nscientists at companies like Facebook, Airbnb, LinkedIn, The New York Times, Memorial \\nSloan Kettering Cancer Center and nearly a hundred other companies.\\nIn my personal journey to both entering the technology field as well as creating a \\ncommunity for others to do the same, one key resource I found to be tremendously useful \\nwas conversations with those who had successfully made the transition. As I developed \\nInsight, I have had the chance to engage with some of Silicon Valley’s best data scientists \\nwho are mentors to the program: \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 6}, page_content='2PREFACE\\nJonathan Goldman created one of the first data products at LinkedIn—People You May \\nKnow—which transformed the growth trajectory of the company. DJ Patil built and grew \\nthe data science team at LinkedIn into a powerhouse and co-coined the term “Data \\nScientist.” Riley Newman worked on developing product analytics that was instrumental \\nin Airbnb’s growth. Jace Kohlmeier led the data team at Khan Academy that helped \\noptimize learning for millions of students.\\nUnfortunately, it’s hard to get face-to-face time with these remarkable people. At Insight, \\nto maintain an exceptionally high quality and personal time with these mentors, we \\nselect only a small group of talented scientists and engineers three times per year. \\nHowever, The Data Science Handbook provides readers with a way to have these in-\\ndepth conversation at scale.\\nBy reading the interviews in The Data Science Handbook, you will have the experience \\nof learning from the leaders in data science at your own pace, no matter where you are \\nin the world. Each interview is an in-depth conversation, covering the personal stories of \\nthese data scientists from their initial experiences that helped them find their own path \\nto a career in data science.\\nIt’s not just the early data science leaders who can have a big impact on the field. There \\nis also new talent entering, with the opportunity for each and every new member to push \\nthe field forward. When I met the authors of this book, they were still college students \\nand aspiring data scientists, full of the same questions that those beginning in data \\nscience have. \\nThrough 18 months of hard work, they have done the legwork in seeking out some of the \\nbest data scientists around the country, and asking them for their advice and guidance. \\nThis book is the result of that work, containing over 100 hours of collected wisdom with \\npeople otherwise inaccessible to most of us (imagine having to compete with President \\nObama to talk with DJ Patil!).\\nBy reading these extended, informal interviews, you will get to sit down with industry \\ntrailblazers like DJ Patil, Jonathan Goldman and Pete Skomoroch, who were all part \\nof the early, core LinkedIn data science teams. You will meet with Hilary Mason and \\nDrew Conway, who were instrumental in creating the thriving New York data science \\ncommunity. You will hear advice from the next generation of data science leaders, like \\nDiane Wu and Chris Moody, both Insight Alumni, who are now blazing new trails at \\nMetaMinds and Stitch Fix. \\nYou will meet data scientists who are having a big impact in academia, including Bradley \\nVoytek from UC San Diego and Joe Blitzstein from Harvard. You will meet data scientists \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 7}, page_content='3\\nin startups, such as Clare Corthell from Mattermark and Kunal Punera of Bento Labs, \\nwho will share how they use data science as a core competitive advantage.\\nThe data scientists in the Data Science Handbook, along with dozens of others, have \\nhelped create the very industry that is now having such a tremendous impact on the \\nworld. Here in this book, they discuss the mindset that allowed them to create this \\nindustry, address misconceptions about the field, share stories of specific challenges and \\nvictories, and talk about what they look for when building their teams. \\nI hope that by reading their stories, hearing how they think, and learning their vision for \\nthe future of data science, you will come to think of ways you can have an impact, and \\nperhaps even advance the field yourself.\\nJake Klamka\\nFounder\\nInsight Data Science Fellows Program\\nInsight Data Engineering Fellows Program\\nInsight Health Data Science Fellows Program\\nPREFACE\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 8}, page_content='INTRODUCTION\\nWelcome to The Data Science Handbook!\\nIn the following pages, you will find in-depth interviews with 25 remarkable data \\nscientists. They hail from a wide selection of backgrounds, disciplines, and industries. \\nSome of them, like DJ Patil and Hilary Mason, were part of the trailblazing wave of data \\nscientists who catapulted the field into national attention. Others are at the start of their \\ncareers, such as Clare Corthell, who made her own path to data science by creating the \\nOpen Source Data Science Masters, a self-guided curriculum built on freely available \\ninternet resources. \\nHow We Hope You Can Use This Book\\nIn assembling this book, we wanted to create something that could both last the test of \\ntime as well as address your interest in data science no matter what background you may \\nhave. We crafted our book so that it can be something you come back to again and again, \\nto re-read at different stages in your career as a data professional. \\nBelow, we’ve listed the knowledge our book can offer. While each interview is fascinating \\nin its own right, and covers a large portion of the knowledge spectrum, we’ve highlighted \\na few interviews to give you a quick start: \\n• As an aspiring data scientist  - you’ll find concrete examples and advice of how to \\ntransition into the industry.\\n• Suggested interviews: William Chen, Clare Corthell, Diane Wu\\n• As a working data scientist - you’ll find suggestions on how to become more effective \\nand grow in your career.\\n• Suggested interviews: Josh Wills, Kunal Punera, Jace Kohlmeier\\n• As a leader of a data science team - you’ll find time-tested advice on how to hire \\nother data scientists, build a team, and work with product and engineering. \\n• Suggested interviews: Riley Newman, John Foreman, Kevin Novak\\n• As an entrepreneur or business owner - you’ll find insights on the future of data \\nscience and the opportunities on the horizon.\\n• Suggested interviews: Sean Gourley, Jonathan Goldman, Luis Sanchez\\n• As a data-curious citizen  - you’ll find narratives and histories of the field, from \\nsome of the first data pioneers.\\n• Suggested interviews: DJ Patil, Hilary Mason, Drew Conway, Pete Skomoroch\\nIn collecting, curating and editing these interviews, we focused on having a deep and \\nstimulating conversation with each data scientist. Much of what’s inside is being told \\npublicly for the first time. You’ll hear about their personal backgrounds, worldviews, \\ncareer trajectories and life advice. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 9}, page_content='5INTRODUCTION\\nIn the following pages, you’ll learn how these data scientists navigated questions such \\nas:\\n• Why is data science so important in today’s world and economy?\\n• How does one master the triple disciplines of programming, statistics and domain \\nexpertise to become an effective data scientist? \\n• How do you transition from academia, or other fields, to a position in data science?\\n• What separates the work of a data scientists from a statistician, and a software \\nengineer? How can they work together? \\n• What should you look for when evaluating data science roles at companies?\\n• What does it take to build an effective data science team? \\n• What mindsets, techniques and skills distinguishes a great data scientist from the \\nmerely good?\\n• What lies in the future for data science?\\nAfter you read these interviews, we hope that you will see the road to becoming a data \\nscientist is as diverse and varied as the discipline itself. Good luck on your own journey, \\nand and feel free to get in touch with us at contact@thedatasciencehandbook.com!\\n— Carl, Henry, William and Max\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 10}, page_content='DJ PATIL VP of Product at RelateIQ\\nSomething that touched a lot of people from your presentations is your speech \\non failure. It’s surprising to see someone as accomplished as yourself talk about \\nfailure. Can you tell us a bit more about that?\\nSomething most people struggle with when starting their career is how they enter the \\njob market correctly. The first role you have places you in a “box” that other people \\nuse to infer what skills you have. If you enter as a salesperson you’re into sales, if you \\nenter as a media person you’re into media, if you enter as a product person you’re into \\nproducts etc. Certain boxes make more sense to transition in or out of than other ones. \\n \\nThe academic box is a tough one because automatically, by definition, you’re an \\nacademic. The question is: Where do you go from there? How do you jump into a different \\nbox? I think we have a challenge that people and organizations like to hire others like \\nDJ Patil is co-coiner of the term ‘Data Scientist’ and co-\\nauthor of the Harvard Business Review article: “Data \\nScientist: Sexiest Job of the 21st Century.”\\n \\nFascinated by  math at an  early age, DJ completed a B.A. \\nin Mathematics at University of California, San Diego and \\na PhD in Applied Mathematics at University of Maryland \\nwhere he studied nonlinear dynamics, chaos theory, and \\ncomplexity. Before joining the tech world, he did nearly a \\ndecade of research in meteorology, and consulted for the \\nDepartment of Defense and Department of Energy. During \\nhis tech career, DJ has worked at eBay as a Principal \\nArchitect and Research Scientist, and at LinkedIn as Head of Data Products, where he \\nco-coined the term “Data Scientist” with Jeff Hammerbacher and built one of the premier \\ndata science teams. He is now VP of Product at RelateIQ, a next generation, data-driven \\ncustomer relationship management (CRM) software.  Most recently RelateIQ was acquired \\nby Salesforce.com for its novel data science technology.\\n \\nIn his interview, DJ talks about the importance of taking chances, seeking accelerations in \\nlearning, working on teams, rekindling curiosity, and giving back to the community that \\ninvests in you. \\nSince we interviewed him, DJ has gone on to be appointed by President Barack Obama as the \\nfirst United States Chief Data Scientist.\\nThe Importance of Taking Chances and Giving Back\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 11}, page_content='7\\nthemselves. For example, at Ayasdi (a topological machine learning company) there’s a \\ndisproportionate amount of mathematicians and a surprising number of topologists.\\n \\nFor most people who come from academia, the first step is that someone has to take a \\nrisk on you. Expect that you’re going to have to talk to lots and lots of people. It took me \\n6 months before eBay took a chance on me. Nobody just discovers you at a cafe and says \\n“Hey, by the way you’re writing on that piece of napkin, you must be smart!” That’s not \\nhow it works, you must put yourself in positions where somebody can actually take a risk \\non you, before they can give you that opportunity.\\n \\nAnd to do that, you must \\nhave failed many times, \\nto the point where some \\npeople are not willing to \\ntake a risk on you. You \\ndon’t get your lucky break \\nwithout seeing a lot of \\npeople slamming doors in \\nyour face. Also, it’s not like \\nthe way that you describe yourself is staying the same; your description is changing and \\nevolving every time you talk to someone.  You are doing data science in that way. You’re \\niterating on how you are presenting yourself and you’re trying to figure out what works.\\n \\nFinally someone takes a chance on you, but once you’ve found somebody, the question \\nis how do you set yourself up for success once you get in? I think one of the great things \\nabout data science is it’s ambiguous enough now, so that a lot of people with extra \\ntraining fit the mold naturally. People say, “Hey, sure you can be a data scientist! Maybe \\nyour coding isn’t software engineering quality coding, but your ability to learn about a \\nproblem and apply these other tools is fantastic.”\\n \\nNobody in the company actually knows what these tools are supposed to be, so you get \\nto figure it out. It gives you latitude. The book isn’t written yet, so it’s really exciting.\\nWhat would you suggest as the first step to putting yourself out there and figuring \\nout what one should know? How does one first demonstrate one’s value?\\n \\nIt first starts by proving you can do something, that you can make something.\\n \\nI tell every graduate student to do the following exercise: when I was a grad student I \\nwent around to my whole department and said, “I want to be a mathematician. When I say \\nthe word mathematician, what does that mean to you? What must every mathematician \\nknow?”\\nDJ PATIL\\nNobody just discovers you at a cafe and says “Hey, \\nby the way you’re writing on that piece of napkin, you \\nmust be smart!” That’s not how it works, you must \\nput yourself in positions where somebody can actually \\ntake a risk on you, before they can give you that \\nopportunity.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 12}, page_content='8\\nI did it, and the answers I got were all different. What the hell was I supposed to do? \\nNo one had a clear definition of what a mathematician is! But I thought, there must \\nbe some underlying basis. Of course, there’s a common denominator that many people \\ncame from. I said, okay, there seem to be about three or four different segmentations. \\nThe segmentation I thought was the most important was the segmentation that gave \\nyou the best optionality to change if it ended up being a bad idea.\\n \\nAs a result of that, I took a lot of differential equations classes, and a bunch of probability \\nclasses, even though that wasn’t my thing. I audited classes, I knew how to code, I was \\nlearning a lot about physics — I did everything I could that was going to translate to \\nsomething that I could do more broadly.\\n \\nMany people who come out of academia are very one-dimensional. They haven’t proven \\nthat they can make anything, all they’ve proven is that they can study something that \\nnobody (except maybe their advisor and their advisor’s past two students) cares about. \\nThat’s a mistake in my opinion. During that time, you can solve that hard PhD caliber \\nproblem AND develop other skills. \\n \\nFor example, aside from your time in the lab, you can be out interacting with people, \\ngoing to lectures that add value, attending hackathons, learning how to build things. It’s \\nthe same reason that we don’t tell someone, \\n“First, you have to do research and then you \\nlearn to give a talk.”  These things happen \\ntogether. One amplifies the other.\\n \\nSo my argument is that people right now \\ndon’t know how to make things. And once \\nyou make it, you must also be able to tell the story, to create a narrative around why you \\nmade it.\\n \\nWith that comes the other thing that most academics are not good at. They like to tell you, \\nrather than listen to you, so they don’t actually listen to the problem. In academia, the \\nfirst thing you do is sit at your desk and then close the door. There’s no door anywhere in \\nSilicon Valley; you’re out on the open floor. These people are very much culture shocked \\nwhen people tell them, “No you must be working, collaborating, engaging, fighting, \\ndebating, rather than hiding behind the desk and the door.”\\n \\nI think that’s just lacking in the training, and where academia fails people. They don’t \\nget a chance to work in teams; they don’t work in groups.\\nUndergrad education, however is undergoing some radical transformations. We’re seeing \\nthat shift if you just compare the amount of hackathons, collaboration, team projects \\nDJ PATIL\\nIt first starts by proving you can \\ndo something, that you can make \\nsomething.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 13}, page_content='9\\nthat exist today versus a few years ago. It’s really about getting people trained and ready \\nfor the work force. The Masters students do some of that as well but the PhDs do not. \\nI think it’s because many academics are interested in training replicas of themselves \\nrather than doing what’s right for society and giving people the optionality as individuals \\nto make choices.\\n \\nHow does collaboration change from academic graduate programs to working in \\nindustry?\\n \\nPeople make a mistake by forgetting that \\ndata science is a team sport. People might \\npoint to people like me or Hammerbacher or \\nHilary or Peter Norvig and they say, oh look \\nat these people! It’s false, it’s totally false, \\nthere’s not one single data scientist that does it all on their own. data science is a team \\nsport, somebody has to bring the data together, somebody has to move it, someone needs \\nto analyse it, someone needs to be there to bounce ideas around.\\n \\nJeff couldn’t have done this without the rest of the infrastructure team at Facebook, \\nthe team he helped put together. There are dozens and dozens of people that I could \\nnot have done it without, and that’s true for everyone! Because it’s a bit like academia, \\npeople see data scientists as solo hunters. That’s a false representation, largely because \\nof media and the way things get interpreted.\\nDo you think there’s going to be this evolution of people in data science who work \\nfor a few years, then take those skills and then apply them to all sorts of different \\nproblem domains, like in civics, education and health care?\\n \\nI think it’s the beginning of a trend. I hope it becomes one. Datakind is one of the first \\nexamples of that, and so is data science for Social Good. One of the ones that’s personally \\nclose to my heart is something called Crisis Text Line. It comes out of DoSomething.org \\n— they started this really clever texting campaign as a suicide prevention hotline and \\nthe result is we started getting these text messages that were just heart wrenching.\\nThere were calls that said “I’ve been raped by my father,” “I’m going to cut myself,” “I’m \\ngoing to take pills,” really just tragic stuff. Most teens nowadays do not interact by voice \\n- calling is tough but texting is easy. The amount of information that is going back and \\nforth between people who need help and people who can provide help through Crisis \\nText Line is astonishing.\\n \\nHow do we do it? How does it happen? There are some very clever data scientists there \\nwho are drawn to working on this because of its mission, which is to help teens in crisis. \\nDJ PATIL\\nPeople make a mistake by forgetting \\nthat data science is a team sport.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 14}, page_content='10\\nThere’s a bunch of technology that is allowing us to do things that couldn’t be done \\nfive, six years ago because you’d need this big heavyweight technology that cost a lot of \\nmoney. Today, you can just spin up your favorite technology stack and get going.\\n \\nThese guys are doing phenomenal work. They are literally saving lives. The sophistication \\nthat I see from such a small organization in terms of their dashboards rivals some of the \\nmuch bigger, well-funded types of places. This is because they’re good at it. They have \\naccess to the technology, they have the brain power. We have people jumping in who \\nwant to help, and we’re seeing this as not just a data science thing but as a generational \\nthing where all technologists are willing to help each other as long as it’s for a great \\nmission.\\n \\nJennifer Aaker just wrote about this in a New York Times op-ed piece — that the millennial \\ngeneration is much more mission driven. What defines happiness for them is the ability \\nto help others. I think that there is a fundamental shift happening. In my generation it’s \\nruled by empathy. In your generation, it’s about compassion. The difference between \\nempathy and compassion is big. Empathy is understanding the pain. Compassion is \\nabout taking away the pain away from others, it’s about solving the problem. That small \\nsubtle shift is the difference between a data scientist that can tell you what the graph \\nis doing versus telling you what action you need to do from the insight. That’s a force \\nmultiplier by definition.\\n \\nCompassion is also critical for designing beautiful and intuitive products, by solving \\nthe pain of the user. Is that how you chose to work in product, as the embodiment \\nof data?\\n \\nI think the first thing that people don’t recognize is that there are a number of people \\nwho have started very hard things who also have very deep technical backgrounds.\\nTake Fry’s Electronics for example. John Fry, the founder, is a mathematician. He built \\na whole castle for one of the mathematical associations out in Morgan Hill, that’s how \\nmuch of patron of the arts he is for them. Then you can look at Reed Hastings of Netflix, \\nhe’s a mathematician. My father and his generation, all of the old Silicon Valley crew \\nwere all hardcore scientists. I think it just goes on to show - you look in these odd places \\nand you see things you would not have guessed.\\nI think there’s two roles that have been interesting to me in companies: the first is you’re \\nstarting something from scratch and the second is you’re in product. Why those two \\nroles? If you start the company you’re in product by definition, and if you’re in product \\nyou’re making. It’s about physically making something. Then the question is, how do \\nyou make? There’s a lot of ways and weapons you can use to your advantage. People \\nDJ PATIL\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 15}, page_content='11\\nsay there is market assessment, you can do this detailed market assessment, you can \\nidentify a gap in the market right there and hit it.\\n \\nThere’s marketing products, where you build something and put a lot of whizbang \\nmarketing, and the marketing does phenomenally. There are engineering products which \\nare just wow — you can say this is just so well engineered, this is phenomenal, nobody \\ncan understand it, but it’s great, pure, raw engineering. There is designing products, \\ncreating something beautifully. And then, there’s data.\\n \\nThe type of person I like best is the one who has two strong suits in these domains, not \\njust one. Mine, personally, are user experience (UX) and data. Why user experience and \\ndata? Most people say you have to be one or the other, and that didn’t make sense to me \\nbecause the best ways to solve data problems are often with UX. Sometimes, you can be \\nvery clever with a UX problem by surfacing data in a very unique way.\\n \\nFor example, People You May Know (a viral \\nfeature at LinkedIn that connected the social \\ngraph between professionals) solved a design \\nproblem through data. You would join the \\nsite, and it would recommend people to you \\nas you onboard on the website. But People \\nYou May Know feels creepy if the results are \\ntoo good, even it it was just a natural result of an algorithm called triangle closing. They’d \\nask, “How do you know that? I just met this person!” To fix this, you could say something \\nlike “You both know Jake.” Then it’s obvious. It’s a very simplistic design element that \\nfixes the data problem. My belief is that by bringing any two elements together, it’s no \\nlonger a world of one.\\n \\nAnother way to say this is, how do you create versatility? How do you make people \\nwith dynamic range, which is the ability to be useful in many different contexts? The \\nassumption is our careers are naturally changing at a faster rate than we’ve ever seen \\nthem change before. Look at the pace at which things are being disrupted. It’s astonishing. \\nWhen I first got here eBay was the crazy place to be and now they’re on a turnaround. \\nYahoo went from being the mammoth place to now attempting a turnaround. We’ve had \\ncompanies that just totally disappeared.\\nI see a spectrum of billion dollar companies coming and going. We’re seeing something \\nvery radical happening. Think about Microsoft. Who wouldn’t have killed for a role in \\nMicrosoft ten years ago? It was a no brainer. But not anymore.\\n \\nBecause of the pace at which the world changes, the only way to prepare yourself is by \\nDJ PATIL\\nBecause of the pace at which the \\nworld changes, the only way to \\nprepare yourself is by having that \\ndynamic range.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 16}, page_content='12\\nhaving that dynamic range. I think what we’re realizing also is that different things give \\nyou different elements of dynamic range. Right now data is one of those because it’s \\nso scarce. People are getting the fact that this is happening. It gives a disproportionate \\nadvantage to those who are data savvy.\\n \\nYou mentioned earlier that when you were looking to become a mathematician you \\npicked a path that optimized for optionality. As a data scientist, what type of skills \\nshould one be building to expand or broaden their versatility?\\n \\nI think what data gives you is a unique excuse to interact with many different functions \\nof a business. As a result, you tend to be more in the center and that means you get \\nto understand what lots of different functions are, what other people do, how you can \\ninteract with them.  In other words, you’re constantly in the fight rather than being \\nrelegated to the bench. So you get a lot of time on the field. That’s what changes things.\\n \\nThe part here I think people often miss is \\nthat they don’t know how much work this is. \\nTake an example from RelateIQ. I’m in the \\nproduct role (although they say I’m supposed \\nto be the head of product here, I think of \\nthese things as team sports and that we’re \\nall in it together), and I work over a hundred \\nhours a week easily. If I had more time I’d go \\nfor longer hours. I think one of the things that people don’t recognize is how much net \\ntime you just have to put in. It doesn’t matter how old you are or how good you are, you \\nhave to put in your time.\\n \\nYou’re not putting in your time because of some mythical ten thousand hours thing (I \\ndon’t buy that argument at all, I think it’s false because it assumes linear serial learning \\nrather than parallelized learning that accelerates). You put in your time because you can \\nlearn a lot more about disparate things that fit into the puzzle together. It’s like a stew, \\nit only becomes good if it’s been simmering for long time.\\n \\nOne of the first things I tell new data scientists when they get into the organization is \\nthat they better be the first ones in the building and the last ones out. If that means four \\nhours of sleep, get used to it. It’s going to be that way for the first six months, probably \\na year plus.\\nThat’s how you accelerate on the learning curve. Once you get in there, you’re in the \\nconversations. You want to be in those conversations where people are suffering at two \\nin the morning. You’re worn down. They are worn down. All your emotional barriers \\ncome down and now you’re really bonding. There’s a reason they put Navy Seals through \\nDJ PATIL\\nOne of the first things I tell new data \\nscientists when they get into the \\norganization is that they better be \\nthe first ones in the building and the \\nlast ones out.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 17}, page_content='13\\ntraining hell. They don’t put them in hell during their first firefight. You go into a firefight \\ncompletely unprepared and you die. You make them bond before the firefight so you can \\nrely on each other and increase their probability of survival in the firefight. It’s not about \\nbonding during the firefight, it’s about bonding before.\\nThat’s what I would say about the people you talked to at any of the good data places. \\nThey’ve been working 10x harder than most places, because it is do or die. As a result, \\nthey have learned through many iterations. That’s what makes them good.\\nWhat can you do on a day-to-day basis that can make you a good data scientist?\\nI don’t think we know. I don’t \\nthink we have enough data on it. I \\ndon’t think there’s enough clarity \\non what works well and what \\ndoesn’t work well. I think you can \\ndefinitely say some things increase \\nthe probability of personal success. \\nThat’s not just about data science, \\nit’s about listening hard, being a good team player, picking up trash, making sure balls \\ndon’t get dropped, taking things off people’s plates, being there for the team rather than \\nas an individual, and focusing on delivering value for somebody or something.\\n \\nWhen you do that, you have a customer (could be internal, external, anybody). I think \\nthat’s what gives you the lift. Besides the usual skills, the other thing that’s really \\nimportant is the ability to make, storytell, and create narratives. Also, never losing the \\nfeeling of passion and curiosity.\\n \\nI think people that go into academia early, go in with passion. You know that moment \\nwhen you hear a lecture about something, and you’re saying, “Wow! That was mind \\nblowing!” That moment on campus when you’re saying, “Holy crap, I never saw it \\ncoming.” Why do we lose that?\\n \\nHere is a similar analogy. If you watch kids running around a track, and the parents want \\nto leave, the kids always answer, “One more! One more!” You watch an adult run laps, \\nand they are thinking, “How many more do I have to do?” You count down the minutes \\nto the workout, instead of saying, “Wow, that was awesome!”\\n \\nI feel that once you flip from one to the other you’ve lost something inherently. You have \\nto really fight hard to fill your day with things that are going to invigorate you on those \\nfronts. One more conversation, one more fight, one more thing. When you find those \\nDJ PATIL\\nIf you watch kids running around a track, and \\nthe parents want to leave, the kids always \\nanswer, “One more! One more!” You watch \\nan adult run laps, and they are thinking, “How \\nmany more do I have to do?”\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 18}, page_content='14\\nenvironments, that’s rare. When you’re around people who are constantly inspiring you \\nwith tidbits of information, I feel like that’s when you’re lucky.\\n \\nIs all learning the same? What value can you bring as a young data scientist to \\npeople who have more knowledge than yourself?\\n \\nThere’s a difference between knowledge and wisdom. I think that’s one of the classic \\nchallenges with academia. You can take a high school kid who can build an app better than \\na person with a doctorate who works in algorithms, and it’s because of their knowledge \\nof the app ecosystem. Wisdom also goes the other way: if you’re working on a very hard \\nacademic problem, you can look at it and say, “That’s going to be O(n2)”.\\n \\nI was very fortunate when I was at eBay, as I happened \\nto get inserted in a team where there was a lot of \\nwisdom. Even though eBay was moving very slowly in \\nthings we were doing, I was around a lot of people who \\nhad a disproportionate amount of wisdom, so I was the \\nstupidest guy with the least amount of tours of duty. But at the same time, I was able to \\nadd value because I saw things in ways that they had never seen. So we had to figure out \\nwhere that wisdom aligned and where it didn’t.\\n \\nThe other side of that was at LinkedIn, when you’re on that exponential curve trajectory \\nwith a company. People say, “Well you were only at the company for three plus years,” \\nbut I happened to be there when it grew from couple hundred to a couple thousand \\npeople. Being in a place where you see that crazy trajectory is what gives you wisdom, \\nand that’s the type of thing that I think compounds massively.\\n \\nMany young people today are confronted with this problem related to knowledge \\nand wisdom. They have to decide: Do they do what they’re deeply passionate \\nabout in the field they care most about? Or do they do the route that provides \\nthem with the most immediate amount of growth? Do they go compound the \\nknowledge of skills, or do they build wisdom in that domain? \\n \\nIt’s a good and classic conundrum. I’ve gone with it as a non-linear approach: you go \\nwhere the world takes you. The way I think about it is, wherever you go, make sure you’re \\naround the best people in the world.\\n \\nI’m a firm believer in the apprentice model, I was very fortunate that I got to train with \\npeople like James Yorke who coined with the term “chaos theory.” I was around Sergey \\nBrin’s dad. I was around some really amazing people and their conversations are some of \\nthe most critical pieces of input in my life, I think I feel very grateful and fortunate to be \\nDJ PATIL\\nI’m a firm believer in the \\napprentice model\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 19}, page_content='15\\naround these people. Being around people like Reid Hoffman, Jeff Weiner is what makes \\nyou good and that gives you wisdom.\\nSo for that tradeoff, if you’re going to be around somebody that’s phenomenal at \\nGoogle, great! If you’re going to be around someone super phenomenal in the education \\nsystem, great! Just make sure whatever you are doing, you’re accelerating massively. The \\nderivative of your momentum better be changing fast in the positive direction. It’s all \\nabout derivatives.\\nWhat do you think about risk taking, and defining oneself?\\n \\nEveryone needs  to chart their own destiny. The only I thing I think is for certain is \\nthat as an individual, you get to ask the questions, and by asking the questions and \\ninterpreting the answers, you decide the narrative that is appropriate for you. If the \\nnarrative is wrong, it’s your narrative to change. If you don’t like what you’re doing, you \\nget to change it.\\n \\nIt may be ugly, maybe hard or painful but the best thing is when you’re younger, you \\nget to take crazy swings at bats that you don’t get to take later on. I couldn’t do half the \\nstuff I was doing before, and I’m very envious of people who get to. And that’s a part of \\nlife, there’s the flip side of when you do have \\nfamily, or responsibilities, that you’re paying \\nfor that next generation. Your parents put a \\nlot on the line to try to stay in a town with \\ngreat schools, and they may not have taken \\nthe risk that they would’ve normally taken to \\ndo these things.\\n \\nThat’s part of the angle by which you play. It’s also the angle which is the difference \\nbetween what it means as an individual and team player. Sometimes you can’t do the \\nthings that you want to do. It’s one of the reasons I’ve become less technical. Take \\nsomeone like Monica Rogati or Peter Skomoroch, two amazing data scientists and \\nengineers at LinkedIn. What’s a better use of my time? Taking a road block out of their \\nway or me spending time debugging or coding something on my own?\\nIn the role I have, in the position and what was expected of me, my job was to remove \\nhurdles from people, my job was to construct the narrative to give other people runway \\nto execute, their job was to execute and they did a hell of a good job at it.\\n \\nYou have talked about your research as a way to give back to the public that \\ninvested in you. Is there an aspect of the world that you feel like could really use \\nDJ PATIL\\nIf the narrative is wrong, it’s your \\nnarrative to change. If you don’t \\nlike what you’re doing, you get to \\nchange it.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 20}, page_content='16\\nthe talent and skills of data scientists to improve it for the better?\\n \\nI think we’re starting to see elements of it. \\nThe Crisis Text Line is a huge one. That’s why \\nI put a lot of my time and energy into that \\none. But there are so many others: national \\nsecurity, basic education, government, Code \\nfor America. I think about our environment, \\nunderstanding weather, understanding those elements, I would love to see us tackle \\nharder problems there.\\n \\nIt’s hard to figure out how you can get involved in these things, they make it intentionally \\nclosed off. And that’s one of the cool things about data, it is a vehicle to open things up. I \\nfell into working on weather because the data was available and I said to myself, “I can do \\nthis!” As a result, you could say I was being a data scientist very early on by downloading \\nall this crazy data and taking over the computers in the department. The data allowed \\nme to become an expert in the weather, not because I spent years studying it, because I \\nwas playing around and that gave me the motivation to spend years studying it.\\nFrom rekindling curiosity, to exploring data, to exploring available venues, it seems \\nlike a common thread in your life is about maximizing your exposure to different \\nopportunities. How do you choose what happens next?\\n \\nYou go where the barrier of entry is low. I don’t like working on things where it’s hard. \\nMy PhD advisor gave me a great lesson — he said only work on simple things; simple \\nthings become hard, hard things become intractable.\\n \\nSo work on simple things?\\nJust simple things.\\nDJ PATIL\\nOnly work on simple things; simple \\nthings become hard, hard things \\nbecome intractable.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 21}, page_content='HILARY MASON Founder at Fast Forward Labs\\nWhat do you do as a data scientist in residence?\\nI do three things. First, I occasionally help the partners talk through an interesting \\ntechnology or company. Second, I work with companies in the Accel portfolio. I help \\nthem when they run into an interesting or challenging data question. Finally, I help \\nAccel think through what the next generation of data companies might look like.\\n \\nDo you expect this to be a growing trend, the fact that VC firms are hiring data \\nscientists in residence?\\n \\nWe’re at a point where there are very few people who’ve spent years building data science \\norganizations in a company or building data-driven products. Having people with even \\njust a few years of expertise in doing that is valuable.\\n \\nI don’t expect that this will be nearly as difficult in the future as it is now. Because data \\nscience is so new — there are only a few people who have been doing this for a long time. \\nTherefore it really helps a VC firm to have access to someone who they can send to one \\nof their companies when that company has some questions. Right now, the expertise \\nis fairly hard to come by, but it’s not impossible. In the coming years, I think more and \\nmore people will take this expertise for granted.\\n \\nWhat can you tell our readers about the data community in New York City?\\n \\nWe’re not a tech city. We are a city of finance, publishing, media, fashion, food and more. \\nIt’s a city of everything else. We see data in everything here. We have people in New York \\nHilary is the Founder of Fast Forward Labs, a machine \\nintelligence research company, and the Data Scientist in \\nResidence at Accel. Previously, she was the Chief Scientist \\nat bitly, where she led a team that studied attention on the \\ninternet in realtime, doing a mix of research, exploration, and \\nengineering. She also co-founded HackNY and DataGotham, \\nand is a member of NYCResistor.\\nOn Becoming a Successful Data Scientist\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 22}, page_content='HILARY MASON\\n18\\ndoing data work across every domain you can imagine. It’s absolutely fascinating.\\n \\nYou’ll see people who talk about their work in the Mayor’s office, people talking about \\ntheir academic work, people in health care using data to cure cancer, and people talking \\nabout journalism. You can see both startups and big companies all talking about how \\nthey use data.\\n \\nDataGotham is our attempt to highlight this diversity. We started it as a public flag that \\nwe planted and said, “ Whatever you do, if you care about data, come here and meet other \\npeople who also feel the same way.” I think we’ve done a good job with that. The best way \\nto get a sense of New York’s data community is to come.\\nHow else do you think data science will change? What will happen to data science \\nin the next five years?\\n \\nFive years is a long time. If you think back five years, data science barely existed, and it’s \\nstill evolving rapidly. It will change a lot in these next five. I’m not going to say what is \\ncertain to happen in the next five years, but I’ll make a few guesses.\\n \\nOne change is that some of the \\ndelightful chaos will go away. I know \\nfantastic data scientists who have \\ndegrees in computer science, physics, \\nmath, statistics, economics, psychology, \\npolitical science, journalism and more. \\nPeople have switched to data science \\nwith a passion and an interest. They didn’t come from an academic program. That’s \\nalready changing — you can enroll in Master’s degree programs in data science now.\\n \\nPerhaps some of the creativity that happens when you have people from so many different \\nbackgrounds will result in a more rigid understanding of what a data scientist actually is. \\nThat’s both a good and bad thing.\\n \\nThe second change is, well, let’s just say that if I’m still writing Java code in five years \\nI’m going to punch a wall! Our tooling has to get a lot better, and it already is starting to. \\nThis is a fake prediction because I know things are already happening in this area.\\nFive years ago, the most interesting data companies were building infrastructure, \\ndifferent kinds of databases. They were working on special tools for managing time \\nseries data. Now, the base infrastructure is mature and we’re seeing companies that are \\nmaking it easier to work with those pieces of infrastructure. So you get a great dashboard \\nWe see data in everything here. We have \\npeople in New York doing data work \\nacross every domain you can imagine. \\nIt’s absolutely fascinating.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 23}, page_content='HILARY MASON\\n19\\nand you can plug in your queries, which go behind the scenes and run map-reduce jobs. \\nYou won’t be spending 40 hours manually parallelizing algorithms and hating your life \\nanymore. I think that will continue to expand.\\n \\nCulture is also a big part of the practice. I think data culture will continue to grow, even \\namong people who aren’t data scientists. This means that within lots of companies, \\nyou will begin to see people whose job titles don’t say “data scientist,” but they will be \\ndoing very similar things. They won’t need to ask a statistician to count something in a \\ndatabase anymore — they can do it themselves. That’s exciting to me. I do believe that \\ndata gives people the power to make better decisions, so the more people who have \\naccess to it, the better.\\n \\nHow do you think the role of a data scientist will change in a world where every \\ncompany has data-minded people?\\n \\nData scientists will keep asking the questions. It’s not always entirely obvious what \\nyou should be counting, even for fairly trivial business problems. It’s also not entirely \\nobvious how to interpret the results. Data scientists can become the coach, the person \\nwho really understands the problem they’re trying to solve.\\n \\nData scientists and data teams do a variety of things beyond just business intelligence. \\nThey also do algorithmic engineering, build new features, collect new data sets, and \\nopen up potential futures for the product or business. I don’t think data scientists will \\nbe out of work anytime soon.\\n \\nYou emphasize communication and storytelling a lot when you talk about data \\nscience. Can you elaborate more on this?\\nA data scientist is someone who sits down with a question and gathers some data to \\nanswer it, or someone who starts with a data set and asks questions to learn more about \\nit. They do some math, write some code, do the analysis, and then come to a conclusion. \\nThen what?\\n \\nThey need to take what they’ve learned and communicate it to people who were not \\ninvolved in the analytical process. Creating a story that’s compelling and exciting for \\npeople, while still respecting the truth of the data, is hard to do. This skill gets neglected \\nin many technical programs, as it’s taken for granted that if you can do something you \\ncan explain it. However, I don’t think it’s that easy.\\nWhy isn’t it easy? Why is explaining something in a simple manner so difficult?\\n \\nIt’s hard because it requires a lot of empathy. You have to understand something that’s \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 24}, page_content='HILARY MASON\\n20\\nvery technical and complex, then explain it to someone who doesn’t come from the same \\nbackground. You have to know how they think so you can translate it into something \\nthey can understand. You also have to do it for people who generally have short attention \\nspans, who are impatient, and who are not ready to spend hours studying.\\n \\nSo you need to come up with a solution \\nthat uses language or a visualization \\nto facilitate their understanding after \\nyou’ve invested all of this time building a \\ncomplex model. When you think about it, \\nit’s amazing that we can take our complex \\ntechnical understanding of something \\nand then write it down in such a short, concise way to communicate it to someone who \\ndoesn’t share the same knowledge or interests. That’s amazing.\\n \\nWhen you think of it that way, it’s not a surprise at all that storytelling is hard. It’s like \\nart. You’re trying to take a really intense emotion or complex phenomenon and express \\nit in a way that people will understand intuitively.\\n \\nYou’ve said before that some of the most exciting data science opportunities are in \\nstartups. Given your experience with Bitly and advising startups, can you elaborate \\nmore on that?\\n \\nI’ll explain with the disclaimer that I’m obviously slightly biased. The most exciting data \\nopportunity is when you have the flexibility to collect data. Often you’re collecting data \\naccidentally as a side effect of another product you were trying to build.\\n \\nBitly is the classic example of this — short URLs make it easy to share on social networks. \\nYou end up collecting this amazing data set about what people are sharing and what \\npeople are clicking on across all these social networks. But nobody really set out in the \\nbeginning to build the world’s greatest URL shortener to discover how popular Kim \\nKardashian is. Bitly’s founder John Borthwick calls this accidental side effect “data \\nexhaust,” which is a lovely phrase for it.\\n \\nThat said, if you’re in academia, you don’t have the benefit of having a product there \\nalready collecting data. There’s an extra project to do before you even do the work you \\nactually care about. You have to struggle to collect your own data, or go to a company \\nand beg for their data. That’s really difficult, because most companies have no incentive \\nto share data at all. In fact, they have a very strong disincentive given privacy liability. \\nSo, as an academic, you find yourself in a difficult position unless you’re one of those \\npeople who are able to build good partnerships (which some people are).\\n \\nI do believe that data gives people the \\npower to make better decisions, so the \\nmore people who have access to it, the \\nbetter.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 25}, page_content='HILARY MASON\\n21\\nIf you’re at a larger company, the data you have is probably either stuck in a bunch of \\nincompatible databases or so highly controlled that it will take a huge political effort to \\nget the data into a place where it becomes useful.\\n \\nStartups are the perfect place where you have a product that’s generating it’s own data. \\nAs a data scientist you have input into how the product changes, so you can ask, “Can we \\ncollect this other thing?” or “Do you think if we tried this we might learn something else?” It’s \\nvery open as to what you do with it.\\n \\nI love that aspect that we can learn something interesting from the data. It’s a fun process \\nand a good place to be.\\nWhat advice would you give our readers who are interested in joining a data science \\nstartup? How should one choose where to work at?\\n \\nTry to learn more about the startup \\nculture. Startups generally have great \\ncultures — one reason is because \\nstartups are much more free to have wide \\nvariability in those cultures. You’ll find \\nthat some startups might be a great fit for \\nyou, while some of them might feel uncomfortable. There’s nothing wrong with you, it’s \\njust a company that’s not a good match.\\n \\nThis is just good advice in general. When you’re looking at working in a small company, \\nmake sure it’s a group of people that you’re comfortable working with and that the social \\nenvironment is one that you’re going to feel happy and comfortable in.\\n \\nThat said, a lot of companies are hiring their first data scientists. Most data scientists \\nhave no experience in a job, so it’s very hard to find someone who can come in and do a \\njob well that nobody has done before. I would make sure that whoever you’re working for \\n— whether it’s your COO, CTO or CEO — has a pretty clear understanding of what they \\nwant you to do. At least they should be someone you think you could collaborate with in \\nfiguring out where you should invest your time.\\n \\nCan you elaborate more on prioritization and investing time?\\n \\nYou’ve got an infinite list of questions you can look into — how do you pick the ones \\nthat are going to have the biggest impact? How do you do that in an environment where \\nyou might have your CEO demanding slides for a board meeting, your head of sales \\ndemanding data, etc., and you have a project that you think is really exciting — but no \\nStartups are the perfect place where \\nyou have a product that’s generating \\nit’s own data.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 26}, page_content='HILARY MASON\\n22\\none else quite gets it yet because they haven’t really sat with you and gone into the data?\\n \\nIf you’re looking for your first job as a data scientist, I would make sure you have a \\nmanager who can manage that process with you. If you’re going to be that manager, it’s \\nnot as easy as it looks from the outside. That is a skill you have to develop. If you’re going \\nto be a manager, I’d recommend that you think about those sets of problems -- how to \\nprocess them and how to communicate them in a way that fits with the process that the \\nrest of the company is using.\\n \\nWhat other advice do you have?\\n \\nLook for good data sets. When I interview people for a data science job, they will already \\nhave spent a few hours with people on the team. I’ll say, ‘Y ou know what we do now. \\nWhat is the first thing that comes to your mind when you’re thinking ‘why haven’t these guys \\neven thought about this?’” I don’t really care what the answer is, but I want to know that \\nthey’re capable of thinking about what the data set is and coming up with ideas on their \\nown for what they would like to see.\\n \\nMost of the answers I’ve have to that question were things we had already thought of. I \\ndon’t expect people to come up with genius ideas in the interview, but just to show that \\nthey have that creative ability can be really helpful. If you’re looking at a company or \\nproduct to potentially work for and you can’t come up with things you would want to \\nwork on, that’s a problem. You should find something you’re a little more excited about.\\n \\nDo you have more advice on prioritization and making an impact within a company?\\n \\nDuring my time at Bitly and in general, \\nwe have a series of questions we ask \\nabout every data project we work on. \\nThe questions would help not just with \\npersonal prioritization but also with \\nhelping other people in the company \\nunderstand what was going on.\\n \\nThe first question is, can we define the question we’re interested in? You’d think it would \\nbe obvious that it’s helpful to write down the question in plain language so that anyone \\ncan understand what you’re trying to do.\\n \\nThe second question is, how do we know when we’ve won? What are the error metrics by \\nwhich we evaluate our solution to this question? If we’re working on an algorithm where \\nthere are no quantitative error metrics, you at least have to write down that there are \\nnone.\\n \\nYou’ve got an infinite list of questions \\nyou can look into — how do you pick \\nthe ones that are going to have the \\nbiggest impact?\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 27}, page_content='HILARY MASON\\n23\\nThe third question is, assuming we can solve this perfectly, what’s the first thing we \\nwill do with it? I ask that question to ensure that every project is immediately relevant \\nto the business or product. It’s not just an irrelevant exercise because we’re curious \\nabout something. The first thing you’ll do with it should also have some longer term \\nimplications about what you understand about the data.\\n \\nFor each data project you’re working on, you need to ask yourself these questions: what \\nare you working on? How will I know when it’s done? What does it impact? If you ask \\nyourself these questions, you always know you’re making a good decision about how \\nyou’re spending your time.\\n \\nDo you have an example of using these questions to understand a project?\\n \\nOne project you might be working on might be, “ Does our user behavior in Turkey differ \\nfrom user behavior in the United States?” That might be an immediately relevant question, \\nmaybe because of a sales deal with someone in Turkey.\\n \\nThe longer term goal would be to understand if geography affects user behaviour, and \\nif so, how? You should always be balancing those near-term and long-term rewards, \\nbuilding your library of information of what you know from your data.\\n \\nThe last question is, assuming that everything works perfectly and everyone in the world \\nuses our solution, how does it change human behavior? That question is important \\nbecause I want to make sure that people are always working on the highest-impact \\nproblems.\\n \\nAnother question I ask sometimes is, what is the most evil thing that could be done \\nwith this? If I were an evil mad scientist in my volcano lair and I had this technology or \\nknowledge, what could I do with it? You get way more creative ideas for what to actually \\ndo with it, very few of which are evil. That’s a fun thought experiment to do. \\n \\nYou’ve given great advice on how data scientists can choose a startup. I wanted to \\nflip that question around — what general advice would you give to new startups \\nthat are building their data science team?\\nThis is always a challenge, and often, people have different ideas of what a data scientist \\ncoming into the company will do. So this means that first the founders and management \\nteam should really understand what they need now.\\n \\nYou’re sure that you want some business analytics, product analytics, and metrics. \\nMaybe you have an idea to do something cool with the data — perhaps something that’s \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 28}, page_content='HILARY MASON\\n24\\nFor each data project you’re working \\non, you need to ask yourself these \\nquestions: what are you working on? \\nHow will I know when it’s done? What \\ndoes it impact?\\nwell understood like a recommendation engine, or maybe even something that’s more \\ncreative. But it’s hard to find someone who can do all of these things and potentially can \\ngrow to manage a team of people.\\n \\nThe things you can do when you’re hiring is look for people who learn quickly, are really \\ncreative, are flexible, and who can work with your engineering team because that’s \\nwhere they’re going to sit. They need to \\nbe best friends with whoever is running \\nthe infrastructure that holds the data, \\nand they need to be able to work with the \\nproduct and business side as well.\\n \\nThat means that you might want to hire \\nsomebody who doesn’t have 20 years of \\ndata experience but who you think can \\nlearn really quickly and grow with the product, with the understanding for that person \\nthat eventually a team might come around them or they might hire a manager.\\n \\nSo much of hiring well in small companies is finding the right person at the right time \\nfor that company. There’s no one formula that really describes it — it has to be a good \\nmatch on both sides.\\n \\nWhat advice do you have for students who are choosing between smaller companies \\nand larger companies?\\n \\nI would say it’s worth looking at the smaller companies. The advice I have there is find \\nsomeone who you’ll work for who you think would be a great mentor for a year. Don’t \\njust go to a small company because it sounds good. Go to one where you think, “ This is \\nsomewhere I can learn from for a year. I think I’ll be happy here for about that long.”\\n \\nThen after a year, you can re-evaluate. Am I still learning? Am I doing work that I love? \\nAnd if not, you can move on to your next learning opportunity. But the first few years out \\nof school will help you learn the skills you’ll need later. Go to places where you can learn \\nthings. That’s the best way to think about it.\\n \\nWhat other advice do you have for students choosing between companies?\\n \\nI know when you look at job offers, it’s really easy to evaluate them based on how much \\nmoney you’re going to make and where you’re going to live. I’m a big fan of living \\nsomewhere you like, because otherwise you’re miserable all the time, because it’s not all \\nabout the money. It’s most important to be working in an environment where you have \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 29}, page_content='HILARY MASON\\n25\\nchallenging work with people you can learn from.\\n \\nFor example, I once did an internship in AT&T Labs Research, and I loved working there. \\nIt was an amazing place full of really amazing people. But I hated living in New Jersey \\nand commuting on the Garden State Parkway. You need to find that right balance of \\nmaking sure you’re in a place where you’re going to be happy, but also learning a lot.\\n \\nWhether you’re making 10 or 20 grand more now, versus years later, it doesn’t make \\na difference. As long as you’re making enough to have a decent place to live, eat well, \\nenjoy your life when you’re not at work, I wouldn’t pay too much attention to the salary.\\n  \\nWhat advice would you give to aspirational data scientists?\\nA lot of people are afraid to get started because they’re afraid they’re going to do \\nsomething stupid and people will make fun of them. Yes, you will do something stupid, \\nbut people are actually nicer than you think and the ones who make fun of you don’t \\nmatter.\\n \\nMy recommendation is that if you’re interested in data science, try it! There are a lot \\nof data sets out there. I have a Bitly list of about 100 public research-quality datasets, \\nwhich you can see here: bitly.com/bundles/hmason/1. You also have access to a bunch of \\npublic APIs. You can be creative.\\n \\nTry to do a project that plays to your strengths. In \\ngeneral, I divide the work of a data scientist into three \\nbuckets: Stats, Code, and Storytelling/Visualization. \\nWhichever one of those you’re best at, do a project \\nthat highlights that strength. Then, do a project \\nusing whichever one of those you’re worst at. This helps you grow, learn something new, \\nand figure out what you need to learn next. Keep going from there.\\n \\nThis has a bunch of advantages. For one thing, you know what data science is actually \\nlike. A lot of data scientists spend their time cleaning data and writing Hadoop scripts. \\nIt’s not all fun — you should experience that.\\n \\nSecond, it gives you something to show people. You can tell people what cool things \\nyou’re trying out — people get really excited about that. They’re not going to say you \\ntried and you suck, they’re going to say, “Wow, you actually did something. That’s cool!” \\nThis can help you get a job.\\n \\nA great example of this is my friend Hilary Parker who works at Etsy on their analytics \\nGo to places where you can \\nlearn things.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 30}, page_content='HILARY MASON\\n26\\nteam. Before she got the job there, she did this fantastic analysis of how Hilary is the \\nmost poisoned baby name in U.S. history. The popularity of the name Hilary was growing \\nuntil Bill Clinton got elected, when it just plummeted. Slowly now it’s getting more and \\nmore popular again (obviously I love this example because my name is also Hilary). She \\nput it on her blog and ended up getting published in  New York Magazine — I believe it \\nreally helped her land a job by showing that she really knew what she was doing.\\n \\nI really just encourage people to start putting things up on their blogs and on Github, \\nand not to be discouraged. It takes optimism and stubbornness to do this well.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 31}, page_content='PETE SKOMOROCH\\nPrincipal Data Scientist at Data Wrangling\\nYou’re one of the people who’ve been around data science since the beginning. \\nHow have you seen it evolve?\\nThe creation of the data scientist role was originally intended to address some challenges \\nat large social networks. Many software companies at the time had separate teams. \\nThere were production engineers, research scientists writing papers and developing \\nprototypes, and data analysts working with offline data warehouses. The classic R&D \\nmodel required a lot of overhead as ideas were passed from one team to another to be \\nre-implemented. The latency to get an idea into production and iteratively improve it in \\nthis way was too high, especially for startups.\\n \\nThe data scientist role was intended to bridge the gap between theory and practice \\nby having scientists who could write code and collaborate with engineering teams to \\nbuild new product features and systems. At LinkedIn, we wanted to hire scientists and \\nengineers who could develop products and work with large production datasets, not just \\nhand off prototypes. I think the original concept has evolved over the last few years as \\norganizations found it difficult to hire candidates with the full skill set. Simultaneously, \\nas data science became more popular, it evolved into an umbrella term that describes \\na large number of very different roles. In my case, I was a Research Engineer at AOL \\nEver since he was young, Pete Skomoroch was interested \\nin science. This led him to double major in mathematics \\nand physics at Brandeis University, where he discovered \\nhe enjoyed tinkering with mathematical models and \\nengineering. After graduating, Pete honed his technical skills \\nat Juice Analytics, MIT Lincoln Laboratory and AOL Search.\\nPete eventually ended up as a Principal Data Scientist at \\nLinkedIn, where he led teams of Data Scientists focused \\non Reputation, Inferred Identity and Data Products. He \\nwas lead Data Scientist and creator of LinkedIn Skills & \\nEndorsements, one of the fastest growing new products in \\nLinkedIn’s history.\\n \\nHe is also the founder of Data Wrangling, which offers consulting services for data mining \\nand predictive analytics. \\nSoftware is Eating the World, and It’s Replacing it With Data\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 32}, page_content='PETE SKOMOROCH\\n28PETE SKOMOROCH\\nSearch and was originally hired as a Research Scientist at LinkedIn before my job title \\nwas changed to Data Scientist. In the following years, many business analysts and \\nstatisticians also rebranded as data scientists.\\n \\nToday, depending on the company, a data scientist could be a person who fits that \\noriginal hybrid scientist-engineer role, or they could be statisticians, business analysts, \\nresearch scientists, infrastructure engineers, marketers, or data visualization experts. \\nIn some organizations, things have come full circle as these skills are held by separate \\nspecialized individuals that work together on a data team.\\n \\nThere is nothing wrong with \\nany of these roles and you need \\nall of them for a large modern \\norganization to get the most \\nout of data. That said, I think \\nthere is value in having people \\nwho fit the original definition, \\nwho are interdisciplinary, and \\ncan cross boundaries to build \\nnew products and platforms. \\nConfusion often arises when companies either don’t know which type of role they need \\nfor their organization or which type of data scientist they are interviewing.\\nCan you talk about your story, and how you ended up where you are?\\nI was really interested in science from an early age. When I started at LinkedIn, I was a \\nresearch scientist, and before that, I had been a research engineer at AOL Search. The \\nflavor of that role was more like the R&D labs that were doing machine learning research \\nand crunching search query data, but there was a strong pull for us to do more production \\ncoding involving product.\\n \\nI remember a talk that Jeff Hammerbacher gave in which he mentioned that what he \\nreally wanted on his team was a MacGyver of Data Analysis who could work with data, \\nwrite code in Java and actually implement the algorithms, do some statistics, and really \\nhave a good intuition of what would drive strategic objectives.\\n \\nI think that was the kernel of the idea that Data Scientist is a different role.  When we \\nare interviewing, we don’t want to select for people who are just business analysts who \\ncan’t code, and we don’t want people who are pure engineers who don’t have any science \\nor math background. We want people at that intersection. I think that was really the \\ngenesis of data science, it is cross-disciplinary.\\nWhat [Jeff Hammerbacher] really wanted on his \\nteam was a MacGyver of Data Analysis who could \\nwork with data, write code in Java and actually \\nimplement the algorithms, do some statistics, \\nand really have a good intuition of what would \\ndrive strategic objectives.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 33}, page_content='PETE SKOMOROCH\\n29\\nSome of your undergrad research was about neuroscience, can you tell us a bit \\nmore about that?\\n \\nI was really interested in neuroscience, and physics and electronics. When I went to \\nBrandeis, I found that I actually liked mathematical modeling, data crunching, cracking \\ncodes, building models and programming versus doing lots of bio lab work. I felt my real \\naptitude was digging into the data and coming up with theoretical models, which is what \\ndrew me to physics.\\n \\nI graduated college in 2000 while the \\ndotcom boom was still happening. My \\nfamily was just scraping by financially, \\nso it was really compelling for me to \\ngo into industry although I ultimately \\nplanned to go back to grad school. I had \\nused Matlab, Mathematica, some C, and \\nAssembly in physics classes and learned Visual Basic in an internship, but I wasn’t a \\nstrong programmer at that point. In retrospect, that is one thing I would have done \\ndifferently in undergrad. If I had taken more computer science classes, I probably would \\nhave ramped up faster at startups.\\n \\nWhen giving advice on undergraduate coursework, I’d echo Yann Lecun, who is now \\nheading AI Research at Facebook and did pioneering work in neural networks. I agree \\nwith his advice to take as many physics and math classes as you can, but also learn some \\ncomputer science.\\n \\nHow did computer science play into your post-college job?\\n \\nA big piece of what a data scientist is really doing is creating models. It’s not just about \\ntaking data and loading into a black box machine learning algorithm and running it, \\nbut actually modeling something about an organization, a company or a product. It’s \\ndifficult to find the underlying factors and phenomena that are really predictive and \\nprescriptive vs. something that is just a correlation.\\nSo, when I was looking at jobs coming out of college in 2000, I interviewed at a few \\nplaces, and one that looked really interesting was a small startup in Kendall Square \\ncalled Technology Strategy Inc., which eventually rebranded as ProfitLogic, Inc. Our \\nearly clients included casinos and some of my coworkers were working on interesting \\nprojects optimizing slot machines or spotting cheaters. In the early days we did a lot of \\nconsulting work and as it turned out there was a lot of interest from fashion retailers, \\nwho wanted things like better inventory allocation and markdown price optimization.\\n \\nWhen giving advice on undergraduate \\ncoursework... [I’d say] take as many \\nphysics and math classes as you can, but \\nalso learn some computer science.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 34}, page_content='PETE SKOMOROCH\\n30\\nWhat we were doing was essentially an early version of data science. We would get tapes \\ndelivered weekly from big retailers like Macy’s or JC Penny or Walmart, and the data \\nwould be loaded into our own data warehouses. Then we would run statistical models \\nusing a combination of C++ and Python to adjust prices and build predictive sales \\nforecasts at the item level. The ultimate idea was that you could save a lot of time and \\nmaximize profit by automatically setting prices using a data driven approach. By taking \\nthese optimal price trajectories instead of relying only on intuition, you could make \\nmore profit and get more inventory through the system.\\n \\nMy initial role there was similar to a grad student in a research lab. Eventually, I \\nbecame a hybrid product manager and engineer on the data and algorithm side. I would \\noften be in the office all night, making sure that the weekly model run was working, \\nscrutinizing thousands of charts and logs for model issues. Over time, I started to see \\nareas for improvement and develop my own algorithms for seasonality and other forecast \\nimprovements. I was working with people across the engineering teams, the database \\nteam and research scientists. That’s where I first encountered this pain point of bridging \\nbetween those areas.\\n \\nIn my case, what I found was that I needed to build up my programming and computer \\nscience skills to become more self sufficient. I started out as an analyst building models \\nand then moved into the software engineering organization. \\nHow did you get good at these things? Did you take your own time to learn, or is \\nit more like you just embedded yourself within the groups at the company that you \\nwere doing these things at?\\n \\nI think the only way to excel is to take the extra time. I would go home and read every \\nO’Reilly book I could get my hands on, working through textbooks and side projects. \\nI would do what I could to learn at work, and I was always pushing to work on areas \\nbeyond what I was doing before. I’d advise people to take the time to level up early on in \\ntheir careers, maybe sleep a couple hours less while you can handle it.  \\n \\nAs I was reading and building models, it \\nseemed like machine learning was a better \\nanswer than heuristics or other approaches \\ncommonly used in forecast models. I was \\nlearning that on my own, but I felt like the \\nonly way to level up was to do real coursework \\nand be around people who were actually doing it. There was a job opportunity at MIT’s \\nLincoln Lab working in biodefense, and a big benefit for me was that I could also take \\ngraduate courses in that role. I took a fantastic neural networks course with Sebastian \\nThe only way to level up was to \\ndo real coursework and be around \\npeople who were actually doing it.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 35}, page_content='PETE SKOMOROCH\\n31\\nSeung, the author of Connectome, and a machine learning course with Leslie Kaelbling, \\nalong with some math courses and an optimization theory course. \\n \\nMy story during that time period is a bit of an unusual one. I would often wake up, go \\nto work in Lexington, go to the MIT library, stay up all night eating from the vending \\nmachines and working on problem sets, and go back to work the next day without \\nsleeping. Then I would go home and crash, and then I would repeat that process. I was a \\nzombie for a couple of years and if I could do anything differently, I would balance that \\nmuch better. Yes, you have to put in your time, but try to balance it. Staying up all night \\ncoding is the same thing. Sometimes you maybe have to do it but if you’re doing it all \\nthe time, you are eventually going to burn out and you are nowhere near as effective as \\nyou think you are.\\n \\nThat said, I don’t want to make it seem like there is a magic path through this. To get to \\nthe point where you can gain the right skills this field does take a lot of hard work and I \\nwouldn’t minimize that.\\nThe amount of stuff you have done is unbelievable. I think telling the story of how \\nhard everything was, it’s not that you had everything handed to you. That is critical \\nin communicating how people think.\\nI think there are two parts. Being smart only gets you so far. You have to work hard \\nbecause anything worth doing is worth doing well and you’re better off just digging in. \\nThere is this psychological factor of grit that is important.\\n \\nThat is what I would encourage people \\nto think about. Stretch yourself, \\nbecause if you only work on things \\nthat you know well, you’re going to \\nplateau. That is part of what makes \\ndoing a new startup so appealing. If \\nyou go into management, I advise not giving up coding completely. Own a feature or \\nsomething that keeps you in the loop, so that you’re up to speed with the development \\ntools, the build process, the code base, the latest tricks and languages. All these things \\nare important because the further you get from the nuts and bolts, the harder it is to \\nmake intelligent decisions. The technology changes rapidly, especially in data science.\\n \\nCan you talk about your experience at Lincoln Lab? What was it like, especially as \\nyou were moving there from the private sector?\\n \\nThere was a mixture of biologists, physicists, hardware engineers and software engineers. \\nIf you go into management, I advise not \\ngiving up coding completely. Own a feature \\nor something that keeps you in the loop.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 36}, page_content='PETE SKOMOROCH\\n32\\nI’ve always been drawn to the intersection of fields.  One project involved a machine \\nlearned model for a biosensor. It started as a simple threshold alarm algorithm, and I \\ntook it a step further to mathematically model the biochemical processes statistically \\nand apply machine learning on top of that parameterized model.\\n \\nAnyway, I thought it was interesting that machine learning doesn’t just have to be a \\nblack box. You can get better results if you have a more intuitive sense or physical sense \\nof what you are modeling and build those features into the model. Often, a custom model \\nis what you need to really nail it. On the other hand, if the answer only has to be 80% \\naccurate, you may want to do something more lightweight.\\n \\nAfterwards, I moved to DC while my wife was in grad school, but after a few years in \\ndefense I wanted to try a job in consumer internet.  The most interesting role around \\nDC in terms of machine learning at the time was at AOL Search. The experience working \\nwith large datasets at MIT helped me land a role on a great team there mining search \\nquery data, and many of my coworkers from that team went on to work at Twitter via \\nthe Summize acquisition. There were a lot of management changes at AOL during that \\ntime, and I did my best to adapt while things were uncertain, installing an early Hadoop \\ncluster there and experimenting with mapreduce techniques.\\n \\nThere were all these interesting things developing around the same time in the startup \\nworld, including the early development of Amazon EC2 and Hadoop, and so I viewed \\nthat lack of direction as an opportunity. AOL was very much a content company and I \\nwanted to look at how they could do better in terms of content based on data: Based on \\nsearch data, what can we decipher about what people are actually interested in, what’s \\ntrending? And so the first step is to assess, how are you doing versus your competitors? \\nAOL grew through acquisitions, so it wasn’t like everything was on a central system.  I \\nactually had to crawl internal AOL properties and external sites as well.\\n \\nExternally, there were signs that data was going to be a big deal, but internally they were \\ndismantling the R&D team, so I knew that wasn’t a good place to stay. Another company \\nthat I had been talking to in the area was called Juice Analytics. They were primarily \\nknown for data visualization, but it was an appealing opportunity to me because I could \\napply this intersection of skills I’d been developing to product development. So I joined \\nJuice, and we built and shipped a SaaS software product built on Django and EC2. It \\ntook about a year, and we were crunching search queries and doing some clustering and \\npattern recognition to come up with a better picture of your site’s search topics instead \\nof just the top ten queries or whatever you got at the time in Google Analytics. That was \\na great experience of end-to-end product development.  \\nUltimately, I think it was a failure in terms of product-market fit, but I learned a lot from \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 37}, page_content='PETE SKOMOROCH\\n33\\nthat process. As a data scientist in an engineering driven company, you probably go \\nthrough engineering boot camp, get up to speed with the tech stack, and then you can \\nactually do some engineering to solve your own data problems. When you think about it, \\nthat’s the way you get leverage in the world that we live in now.\\nWhat do you mean when you talk about leverage?\\n \\nImagine you have an idea on how to improve your company’s product. Say you come in \\nand say, I have this great idea. Everybody will love it and it will make billions of dollars \\nand improve the lives of millions of people. But if you are just describing the idea and you \\ncan’t implement at least some rough version of it, you are at a disadvantage. That’s why \\nI think one of the highest leverage things you can do right now is gain some engineering \\nand computer science skills.\\nSo how did you move from Lincoln Lab to Silicon Valley?\\n \\nAfter the experience at ProfitLogic, I was bit by the startup bug and ultimately planned to \\nmove out to California. After my wife completed her master’s in 2009, we said okay, we’re \\njust going out there. The previous year \\nin DC, I became increasingly active on \\nTwitter and I found it really fantastic \\nfor finding people with similar \\ninterests, especially when you were \\noutside the Bay Area. For data, one of \\nthe key people I met was named Mike \\nDriscoll. He’s the CEO at Metamarkets, but at the time he had a blog called Dataspora \\nand he did data-related consulting. We contemplated doing an O’Reilly book back then \\ncalled Big Data Power Tools to a) survey these different tools that you should know and \\nb) offer case studies with tips and tricks for practitioners. My vision was that you would \\nhand that book to a new hire and just have them read through it and be ready to hit the \\nground running. Fast forward to today, and it’s really great to see that this is actually \\nhappening through a variety of courses, textbooks, meetups and data science bootcamps \\nlike the Insight Data Science Fellows program.\\nI think that now a lot of large Fortune 500 companies see the success of consumer \\ninternet companies like Google, Facebook, Twitter, Amazon, etc., and they say, “I’m not \\nsure what they are doing, but it seems to be working. I want that. How do I innovate and \\nbuild products like that?” I think there is a bit of a misconception out there that building \\ndashboards of business metrics like Google will turn you into Google, when really it was \\na huge amount of engineering infrastructure and algorithmic product development that \\ngot them to where they are today. I think a lot of the people who want to get into data \\nOne of the highest leverage things you can \\ndo right now is gain some engineering and \\ncomputer science skills.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 38}, page_content='PETE SKOMOROCH\\n34\\nscience say, “That is really amazing, how does Google know everything?”.\\nOr, perhaps “How does Target know I’m pregnant?”\\n \\nThat’s a darker version of that question, but even there it’s interesting to note that the \\nalgorithms were really just detecting people following instructions from other software \\nsystems. If you are pregnant, there are tons of websites and medical guides that tell you \\nexactly what to purchase and which vitamins to take each week. When you know that, \\nit’s not so surprising that such regimented purchase patterns are detectable. \\nThat said, a lot of data science does seem like magic. How do they create these magical \\nexperiences? Even Uber seems like magic (I know that isn’t all necessarily data science), \\nbut there is something impressive about getting the cars there fast enough when you \\npush a button that it feels like magic. Fortune 500 companies and big organizations want \\nthat magic. And they have some sense that it is happening through data, but they’re not \\nquite sure how. I wasn’t sure either when I started in the field, but it was just clear to me \\nthat we were just scratching the surface of what we can do involving engineering and \\ndata.\\nWhat sort of opportunities did you find at LinkedIn that took advantage of your \\nquantitative background?\\n \\nThe younger a company is, the easier it is to propose new things. When I started working \\nthere, LinkedIn had some structured data around titles and companies and company \\npages, but they didn’t really have any notion of topics or skills. I had just done a bunch \\nof Wikipedia topic mining to build a site called trendingtopics.org, and I thought, with \\nall of these member profiles, I should be able to do some topic mining of the skills that \\npeople have. And then I’ll have that structured data set. I thought you should be able to \\ntag people like websites in del.icio.us (which I was a big fan of) and then we would have \\nall this rich data to do better recommendations and matching.\\n \\nI made a quick proposal to my manager DJ Patil, and I got a time window of six to seven \\nweeks to crank out a prototype. This was back in 2009 and at first, I didn’t think that \\nLinkedIn would have enough data in the connection graph to say how good somebody \\nwas at something. But even in early versions, there was a lot of signal in the data and \\nthe project was green lighted based on that prototype. At that point, my picture of where \\nthis thing was going evolved and I thought that the ultimate value was going to be in the \\nreputation data tied to each skill.\\n \\nWhat ultimately led to further enhancements like endorsements was the overarching \\ngoal to develop products that fulfilled strategic goals to get people back on the site, \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 39}, page_content='PETE SKOMOROCH\\n35\\ngrow engagement, grow profile data, and help improve job matching, ad matching, and \\nother algorithms. The ultimate goal for me was to add a layer of links anchored by skills \\nacross profiles, and do for the social and professional graph what Google had done for \\nweb pages, allowing people to find and by found.\\nCan you talk more about what it’s like developing new features or products at \\nlarger established companies, versus the startups you’ve worked at in the past?\\n \\nThere was a formal process to bringing new ideas to production at LinkedIn because there \\nmay be a big difference between the technologies you used to prototype your idea, and \\nthose that LinkedIn is built with. The same thing likely applies for any big tech company \\nat this point. You have to get projects approved and they have to get a budget because \\nyou need specialized people on the projects in different organizations: web designers, \\nweb developers, frontend engineers, ops people. It takes more of cross-team village to \\nbuild a product versus a startup where you are a small group wearing a bunch of different \\nhats doing a bunch of different things.\\n \\nThe spirit at the time during when we built the first \\nversion of skills was still that we would try to wear many \\nhats. That said, we wanted to ship product quickly and \\nthe way to get that done is to get the right resources \\nlined up so you can really execute. I think one of the \\nworst things you can do is sign up for a project when \\nyou know you are not set up for success and you are not resourced properly.\\nAnother important reality to face is that you need to hit product-market fit. You could \\nhave a very smart idea as a data scientist, but there is more to succeeding than just having \\na smart idea.  One common problem is that the idea might not align with the company \\nobjectives. Another is that many startups that just fail because they are a technology \\nin search of a problem. When you hear there is a shortage of data scientists, I actually \\nbelieve the most difficult people to find are those that have a more human, intuitive \\nsense of the customer and knack for getting to product-market fit.\\nHow do you develop this “intuition” for product-market fit?\\n \\nWhen I interview people, it often manifests itself in somebody who is driven and who \\nhas done some novel, creative side projects. When you are building stuff on your own, \\nyou often see that your original idea doesn’t actually have enough thought put into it. \\nI also like to see when people have worked either in different disciplines or in different \\nareas of domain expertise. An example of a concrete question that would come up in an \\ninterview to test for this intuition would be: “If you had access to all of our data, what \\nwould you do?”\\n \\nThe younger a company is, \\nthe easier it is to propose \\nnew things.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 40}, page_content='PETE SKOMOROCH\\n36\\nI think that rather than going from the bottom up and thinking, “What is something cool \\nI can do with this data?” it is sometimes a better approach to think strategically from the \\ntop down. “What are the top priorities for this company and what are we going after? \\nWhat technology or product trends are opening up new opportunities? Who are our \\ncustomers? What is the market, and how could I do this differently with data?”\\nThis seems to capture the sentiment expressed by Steve Jobs when he said, “People \\nthink focus means saying yes to the thing you’ve got to focus on. But that’s not \\nwhat it means at all. It means saying no to the hundred other good ideas that there \\nare.”\\n \\nRight, and the same thing goes for managing a data team. In the same way, when you’re \\nstaffing or building a product, think about how well it matches the priorities of the \\ncompany. LinkedIn could do a million different things, but you want to focus on things \\nthat actually align with the strategic goals of the company. There are many things that \\nwould align with the vision, but that doesn’t mean it’s the right thing to do. So you \\nneed to prioritize, and you need to do it in the context of all the other things you could \\npossibly do.\\nIt sounds like a great deal of understanding the ins-and-outs of data science is \\nlearning how to focus.\\n \\nYes. It may not take seven years of focus like a PhD, but you probably need at least a \\nyear to do anything of really significant value. If you are coming out of school and you \\nwant to work on a data team, you need to find good mentors. You need people who are \\ntraining you up on the engineering stack, who are sharing the common tools, and helping \\npush projects through management layers. I hear a lot of complaints where lone data \\nscientists feel like they have no support structure. It is really hard to operate without a \\nteam on your side, because I think the personality type of scientists is often not the most \\nassertive when dealing with business stakeholders.\\nCan you talk more about the growing importance of data science within companies?\\n \\nI think data teams are building really important things. They are actually going about \\nit in a very deliberate way and they’re using reason, theory and evidence. People from \\nscience backgrounds are well suited for this, because you’re building up a theory of what \\nyou think will happen if you were to make certain changes to the product. I think that \\nthat is really at the core of the skillset that you want in engineering product development \\nand data science to make informed decisions.\\n \\nI think that data science is going to become this discipline that drives decision-making \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 41}, page_content='PETE SKOMOROCH\\n37\\nand product development. In order for data to have the biggest impact, it needs to be in \\nthe early phases of product development rather than just added as an afterthought.\\n \\nIt also involves giving feedback to the product and engineering team about the quality, type \\nand quantity of data that will be collected and affected given certain product decisions. \\nIt’s incredibly important to have someone sitting in the room and advocating for the \\ndata team every time a new product \\nfeature is proposed. That may be easier \\nif data science itself rolls up within the \\nengineering or product organization, \\nor has an advocate reporting to the \\nCEO like a Chief Scientist or Chief Data \\nOfficer.\\nOf the people we have talked to, you can offer a unique perspective on how to \\neffectively manage a data science team because you are so engineering focused as \\nwell. There are a lot of managers who are very people focused or they sort of try \\nto massage the politics of the company to get things done, but you seem to want \\nto stick very closely to the nuts and bolts of a company. So what do you find to be \\neffective in creating a data science team?\\n \\nJeff Weiner had this framework for prioritizing decisions around vision, strategy, mission \\nand objectives. He used it as a leadership framework and a way to rally people behind a \\nvision. Of the things that I think an effective engineering manager needs to have, one \\nof them is expertise. If you don’t understand what the people on your team are doing, \\nyou’re going to have a hard time making the right calls. Beyond that, you need to be an \\nadvocate for what is right for the company and by proxy what’s right for your team.\\n \\nA good leader for a data science team understands some data science, has some vision \\nto see what the right path is, brings the right people in, gets the resources, and then gets \\nout of the way and gets other people out of their way. If your team is being thrashed \\naround and pulled in different directions, it will be hard to stay focused.\\n   \\nThere’s a great talk by an MIT professor named Fred Kofman who has a book on business \\nstrategy called Conscious Business. He says when most people are asked what their job \\nis, they reply with their job title. But that’s a very limited way to think about the role \\nyou play within a team or company. If you use the analogy of a soccer team, the various \\nplayers all may have different roles. For example, as the goalie your job is to simply stop \\nthe ball. As an attacker your goal is to score the most number of points. But if you are \\ncompletely optimizing for these local metrics, your team still might not win! So I think \\nthat what can really make teams successful is everyone really believes in what they’re \\ndoing, believes in the mission and feels like they’re enabled to accomplish that.\\nIf you are coming out of school and you \\nwant to work on a data team, you need to \\nfind good mentors.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 42}, page_content='PETE SKOMOROCH\\n38\\nHow did your perspective change throughout your own life?\\n \\nEarlier in my career, I thought what was blocking me from more success was not having \\nthe engineering skills. Over time, as LinkedIn went from 300 to 5000 employees, what’s \\noften difficult for organizations at that scale is communication and coordination issues. \\nWhat I often would see blocking people was of that nature. It was less pure engineering \\nability, and more: “How do you get stuff to ship? How do you get resources? How do you \\nget priority?” If I were given total freedom, I would actually just enjoy building stuff \\nand building algorithms, but when you want to maximize impact and success at the \\ncompany, I think more of what was blocking me at that stage was having to navigate \\nstructure within the company.\\n \\nMy two cents of advice on that \\nwould be engineering, engineering, \\nengineering. Because in that \\nenvironment, or at Facebook or \\nGoogle, optimizing and getting that \\nright is really going to enable you \\nmuch more than other alternatives.\\nIn a larger company, you’re always going to have challenges of organization and your \\nthroughput isn’t going to be as high by definition. That’s why startups exist.\\nI really like what you said about the fact that even if you wanted to build, build, \\nbuild, it would be more effective for a team to unblock their processes. That tied \\nin very closely with the analogy you have with soccer players. Some soccer players \\nwant the personal glory but the best soccer players are the one who realize it’s the \\nteam winning that is more important than fulfilling their own goals.\\n \\nI think it’s a balancing act, and I would add one other thing. My opinion has been the best \\nway to show the way is just to do good work. But it’s not enough to just do good work; \\nyou also have to talk about it. That’s something else you can pull from science because \\na big part of science is communicating. There’s value in that, both from a recruiting \\nrespective, but also for training the next generation. I think that’s the way we build and \\nweave on top of each other’s experiences, it’s all connected. I would balance talking \\nabout your projects with building. I would say work hard, work for a long time, and then \\ntalk about what you did and go on to the next step.\\nGiven all of your experience and perspective, what do you think is going to be the \\nfuture of how data is used in the world?\\n \\nFour to five years ago, I think investors were a good proxy for the future. They might not \\nHe says when most people are asked what \\ntheir job is, they reply with their job title. \\nBut that’s a very limited way to think about \\nthe role you play within a team or company.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 43}, page_content='PETE SKOMOROCH\\n39\\ncome up with all the ideas, but they hear a lot about what people think and are cued into \\nwhere things are headed. It was very early for the data space and people were building \\nlow-level backend technologies. Over time, interest started to shift to what gets built on \\ntop of these backend technologies.\\n   \\nI think what people are really thinking about now is how to replicate the Google and \\nNetflix approach and map it onto the rest of the world. There is a much bigger wave \\ncoming of building tools and applications on top of all of this data and infrastructure. \\nThere now exist data companies in oil & gas, and health care and other areas, taking on \\nsorts of different verticals.\\n \\nI’m looking forward to seeing a set of data companies like this. I think all the data \\ncompanies that are building better platforms and better tools are making everyone’s life \\neasier and I want to see more of that, but I also want to see more industries disrupted in \\na way where it makes society more efficient and people’s lives better.\\n \\nI think the other wave we’re hitting is that of social data. All the social data that is \\nbeing generated is really instrumenting the world and people’s behaviors in an entirely \\nnew way. Everyone has a Facebook account, a LinkedIn account or a Twitter account, \\nwhich provides immediate context about the person. We’re never lived in a time where \\nthere’s so much context about you readily available to make your daily experience better. \\nThe other key component of this is that we all have mobile computers in our pockets, \\ngenerating all this ambient data.\\n \\nWe’re going to see more smart software at the intersection of those two trends. For \\nexample, why does it take four hours to book a flight right now? There are all these \\nworkflows, suboptimal systems, and paperwork which could be much easier using mobile \\nand social data. In movies like Her, you are starting to see where the rise of Google Now, \\nSiri and things like that could be headed. One thing I think is really interesting is this \\nentire field of intelligent systems. That’s a common thread in things I’ve worked on.\\n \\nI think that having these techniques and this intelligence in that sea of data acting on \\nyour behalf is the next stage. You have context, you have alerting, you have all these \\ndisaggregated unbundled verticals like Pandora, but I think next you’re going to see this \\nreally cool future where you’re going to express a desire and intent and something else \\nis going to make it happen. I think that’s what I’m most excited about, and why I think \\nfor data scientists, the world is your oyster.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 44}, page_content='MIKE DEWAR \\nData Scientist at The New York Times R&D Lab\\nCan you trace your career path for our readers? What got you interested in data \\nscience? What got you interested in bitly and The New York Times, and what \\nprojects have you done that you can share with our readers?\\nI got my PhD in Modelling Complex Systems from the University of Sheffield in the UK. \\nThe department is called Automatic Control and Systems Engineering, which in the US \\nis sometimes called Controls or Cybernetics — it’s the study of feedback, modelling, and \\ncontrol.\\nMy PhD looked at modelling spatial-temporal systems. The idea is that you would collect \\ndata from the physical space and then build dynamic models of how the system evolved \\nthrough time using the data you collected.\\nThen I did a few postdoctoral positions. I did a post-doc at the University of Sheffield for \\na year. We worked with Unilever and I looked at modelling how people were brushing \\ntheir teeth. By attaching sensors to a toothbrush with accelerometers and positional \\nsensing, they collected all this data about how people brushed their teeth — it was a very \\nstrange gig.\\nI did that for a year, spent some time writing up the papers for the PhD, and then I \\ndecamped to Edinburgh University, where I worked in the School of Informatics, studying \\nMike Dewar is a Data Scientist at the New York Times R&D \\nLab. Mike holds a PhD from the University of Sheffield, UK, \\nwhere he studied the modelling of complex systems using \\ndata. His current work now focuses on building tools to \\nstudy behaviour.\\nBefore joining The New York Times, Mike worked at the \\nNew York tech company bit.ly, and completed postdoctoral \\npositions at Sheffield, Edinburgh and Columbia Universities. \\nIn this interview, you’ll read Mike’s stories about fruit fly \\nnecrophilia, how The New York Times looks into the future \\nand ways that data science is affecting journalism.\\nMike is a data ambassador for the non-profit organization DataKind, and has published \\nwidely on signal processing, machine learning and data visualization.\\nData Science in Journalism\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 45}, page_content='MIKE DEWAR 41\\nthe behaviour of fruit flies. The biologists would alter the brain of the fruit fly and observe \\ntheir changes in behaviour. In courtship behavior, specifically, the changes were easy to \\nsee. If you place a male fruit fly in a small space with a female fruit fly, even the dead \\nbody of a female fruit fly, it will mate with her. Well, it will definitely try at least, which \\nis a bit grim.\\nSo, there were loads of fun modelling of sequences and some nice machine learning. I even \\ngot to learn how to prepare mutant fruit flies. Most of this work was done at Edinburgh but \\nalso included a little bit of work at Harvard, at the Longwood Campus. Then I got the gig \\nat Columbia, which was in the Applied \\nPhysics and Applied Math Department. \\nThat was with Professor Chris Wiggins, \\nwho you might have come across in your \\nstudies of data science.\\nHe and Hilary Mason wrote a blog post \\nwhich outlined various steps of data \\nscience, namely: “Obtain, scrub, explore, \\nmodel, interpret.” The steps outlined this idea of a data science flow being practical and \\nproducing tangible outputs. Chris was thinking a lot about that with Hilary while I was \\nstudying T-cells.\\nThere are lots of different types of T-cells - the population of these different T-cells \\nin your body changes before, during and after an infection (this is how immunization \\nworks). So after an infection, you have “memory” T-cells in your body. The group at \\nColumbia was very interested in how T-cells change to this “memory” state.\\nThey collected lots of genetic data and looked for different genes that were responsible \\nfor changing the state of these populations of cells. You’d be working with 8 microarrays, \\nbut each microarray would have 25,000 genes on it. You had a very strange machine \\nlearning problem, whereby you had very little data to go on but it felt like you had a lot \\nbecause of all the features.\\nIt was through Chris Wiggins that I met Hilary Mason, who was my boss at Bitly. I had also \\nbecome engaged to a girl who lives in New York, so when it came time to start thinking \\nabout what was next after my post doctorate at Columbia, it was important to me to \\nstay in New York. But life as a postdoctoral student in New York sucks because it’s quite \\nexpensive here. At the same time, the idea of “big data” was just coming to the forefront. \\nThere were numerous social media companies that were just starting to think about \\nwhat they might do with all their data. I was interested in behaviour and making tools \\nfor studying behaviour, so Hilary showed up at just the right moment when I wanted to \\nEssentially, leaving academia is a moment \\nwhere you have to decide if you want \\nto be a professor or not, and I think I’d \\nalready decided that was not quite what \\nI wanted to do.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 46}, page_content='MIKE DEWAR\\n42\\npay the rent, stay in New York, study behaviour, and use lots of data while doing it.\\nSo I jumped ship and went to Bitly as a data scientist. I think I’m probably amongst the \\nfirst people who had that title. I made tools at Bitly for studying very large numbers of \\npeople’s behaviour and trying to build interesting, potentially profitable streams.\\nBitly ran its course. I was there for about a year and a half. We did lots of interesting \\nthings, but it became time to move on. About that time, a position at The New York Times \\nR&D Lab showed up, which was somewhere I’d wanted to work for years, so I moved over \\nto the lab where I’ve been now for about two years doing all sorts of interesting things.\\nEssentially, leaving academia is a moment where you have to decide if you want to be a \\nprofessor or not, and I think I’d already decided that was not quite what I wanted to do. I \\nlike coding and making things, but I don’t enjoy talking all day, so that was the decision \\nI made.\\nWe’ve been talking to a lot of people who decided to jump ship from academia. \\nIt seems like a lot of them have been citing reasons such as the lack of dynamism. \\nThey felt that data science was much more interesting and fast paced. Did you feel \\nthat as well?\\nNo, not really. Academia was very fast paced and very intense, with cutting edge \\nresearch. The stuff I got to work on was amazing. Watching the very modern imaging of \\nT-cells changing and learning about viruses was overwhelmingly fascinating. When the \\npractical wasn’t going quickly, the theoretical was going quickly, and there were always \\nten different things to do.\\nI had a very interesting time in academia. Postdoctoral positions are great fun. Lecturing, \\nhowever, didn’t look like so much fun. I wanted to hold onto the fun bits of academia and \\nget paid, which is no small thing when you are starting a family. When staying in New \\nYork, which is a bizarrely expensive place, a certain set of constraints comes your way. In \\nshort, academia was amazing.\\nIt seems like from your academic background you learned a lot from looking at a \\ncomplex system, a mass of data, and extracting stories and hypotheses from that. \\nYou talk about how the unifying theme in data science is actually just identifying \\nmassive behavioural phenomena. What is your advice for identifying the questions, \\ntelling the stories, and identifying the hypotheses in the data set; especially since \\nyou say data science is all about abductive reasoning, finding stories, and learning \\nfrom data? What is your advice for learning which story to tell with data and what \\nto look at?\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 47}, page_content='MIKE DEWAR\\n43\\nThe key piece of advice is always to draw lots of pictures and draw them very quickly. \\nDraw pictures of how things work, even just flow diagrams or engineering block diagrams. \\nMake very rough, quick visualizations of what’s in the data, starting with time series \\nand histograms. Thinking hard about graphical modelling and really trying to get to \\ngrips with the system and data set that’s in front of you helps you think about how the \\nprobabilities fit together.\\nThe danger that I see people getting \\ninto is that the drawing of the picture \\nbecomes the last thing you do, like when \\nyou’re reading an academic paper. The \\nresults and pictures are always at the end \\nof an academic paper, which is a terrible \\nshame. I think the paper should start with pictures of time series and distributions, and \\ngo from there into the theory. That’s often how we work.\\nThat would be my very general advice: to fail early and to fail often. It’s okay to draw lots \\nand lots of pictures that might all be rubbish, but if you draw pictures quickly and really \\nstart to understand what’s actually going on, you begin to get much deeper ideas of what \\nthe right questions are, than if you just start with a classifier.\\nCan you elaborate on drawing pictures a bit more?\\nI learned a lot at Edinburgh about graphical modelling, which is a very simple technique \\nfor exploring conditional probabilities and trying to explore how random variables in a \\nsystem affect one another. The beautiful thing about graphical models is that if you start \\ndrawing them, you are, at the very same time, beginning to explain your assumptions \\nabout the system. Also, you’re starting to do quite a mathematical task of imposing \\nsome structure that you can then test. I really enjoy quickly trying to show whoever I’m \\nworking with a graphical model of how I think things work. The conversation gets going \\nvery quickly and it leads to testable hypotheses, which is great.\\nThe other interpretation of drawing things quickly is to get immediately into the data \\nset. As soon as someone hands you a data set or gives you access to a stream, the very first \\nthing to do is to find an interesting variable in the data set and plot it. If it’s over time, \\nplot a time series. If you’ve got lots of samples of that variable then plot a distribution. If \\nit’s both then plot both. You can do that using Python, or R, or Tableau, or Excel. Do that \\nfirst and don’t waste time. It takes five minutes to make some plots.\\nThe reason is that it gets you thinking about your assumptions in the same way that \\ngraphical models do. The distributions and the time series get you thinking about the \\nMake very rough, quick visualizations \\nof what’s in the data, starting with time \\nseries and histograms. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 48}, page_content='MIKE DEWAR\\n44\\ndata. Both of those together are the beginning of a modelling process that will see you \\nin good stead. It’s quite an iterative process. If all you’ve got is a Bash terminal, then I \\nwould sort my data and then pipe that to “uniq –c” to get a really cheap histogram.\\nYou say that visualization and communicating data is very important because it \\nhelps other people generate hypotheses and trust the data. What advice do you \\nhave for the best way to approach making visualizations to an internal company \\naudience?\\nOne thing we’ve been doing lately is trying hard to show all the data. I would normally \\nstart by thinking about how a system is working and what I’m trying to get out of a data \\nset. Then I would draw some aggregate visualisations, for example, a histogram if I’m \\ninterested in how things are distributed, or a line plot if I’m interested in a time series.\\nOne thing we’ve tried to do more recently \\nis to draw every single data point in a \\nvisualisation, rather than aggregating, \\njust like in a scatter plot. This is something \\nmade much easier as I now get to work \\nregularly with Nik Hanselmann, who is \\na creative technologist in the lab and is \\nextremely adept at this sort of thing. If \\nyou can make a scatter plot of a large data set interpretable, then that act of showing all \\nof the data points allows people to see a zoomed out view of the whole thing and allows \\nthem to pick on individual data points. They see the outliers and wonder why there’s an \\noutlier there.\\nClusters are another good example. If you’ve done your scatter plot well and people can \\nstart to pick out different features of the scatter plot by looking directly at the bit of data \\nthat you want to show them, then they start to ask questions and start to wonder. That \\nhelps you as the analyst or the data scientist. It helps you in trying to understand what \\nyour audience is actually interested in and how you might help them make decisions. It’s \\nan incredibly difficult thing to do without some sort of interaction like that. Trying to \\nshow all the data points is quite challenging sometimes, but that’s been oddly effective \\nover the last year or so. \\nOther than that, axis labels. I feel old saying it but lots of people don’t put axis labels on \\nthings. You read lots of blog posts about lying with statistics and all that sort of stuff and \\nall the tricks people play, which is fine, but it’s very difficult to get away with those tricks \\nif you label your axes properly. You shouldn’t trust any graph that doesn’t have their axis \\nlabelled properly.\\nAs soon as someone hands you a data \\nset or gives you access to a stream, \\nthe very first thing to do is to find an \\ninteresting variable in the data set and \\nplot it.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 49}, page_content='MIKE DEWAR\\n45\\nHow do you think this whole explosion of data, as well as computational power \\nand analysis on top of that, is going to affect the nature of journalism?\\nThe reason that I ask this question is that where I went to school at UC Berkeley, \\nthere were actually quite a few workshops held for students who wanted to go \\ninto journalism, but these workshops weren’t at all about journalism. They were \\nall about D3, Javascript, Python, and R. To somebody who doesn’t have as much \\nbackground knowledge, how would you describe what’s going on regarding big \\ndata and journalism?\\nThere are a few parts to your question. There have been computer-assisted reporting \\n(CAR) journalists for a long time now. Our computer-assisted reporting desk has been \\naround for many years so the idea that data has been affecting journalism is not a new \\none.\\nThis is how I came to grips with the term “big data.” A friend of mine pointed out that \\nwe should think about big data like we think about punk — a cultural moment that was \\nmeaningfully hyped for a period, which then led to a lasting change in society.\\nI like this idea of “big data” as a cultural \\nmoment because there’s been a definite \\nchange in the amount of data we can \\ncollect and the expectation of collecting \\ndata in the first place. The standard costs \\nof storage, processing, and transmission \\nhave all gone down. There has been, over the last few years, a dramatic cultural shift in \\nand around data storage. That hasn’t gone by journalists — it’s quite the opposite. What \\nthey’re faced with are huge data sets that they think might contain stories. Or it’ll be the \\nother way round where they believe that there is a story and will use the FOIA (Freedom \\nof Information Act) to get data sets.\\nWhen they’re telling a story, or they believe that there’s data associated with the story, \\nthey will search government organizations or FOIA organizations that have worked with \\nthe government and are subject to the Freedom of Information Act. I think the rise of \\nthe FOIA is an interesting response to big data in the sense that a journalist will often \\nassume that there is data associated with a story and will demand to see it.\\nRather than the WikiLeaks style, where there is a huge data dump for one reason or \\nanother, journalists will believe that there is data associated with their story and will \\nuse FOIA data in order to support the story. This is a lot more work, and that work is a \\nlot more laborious. The impact of big data is a culture where we expect there to be data.\\nA journalist will often assume that there \\nis data associated with a story and will \\ndemand to see it.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 50}, page_content='MIKE DEWAR\\n46\\nThe other side of that, which I think is probably a bit sexier, is the WikiLeaks side of \\nthings, where there is a huge pile of data that is being made available - like the Medicare \\ndata. There’s a huge data set that’s been released around how Medicare dollars are spent \\nwith personal information about doctors that receive Medicare funding. There have \\nbeen a lot of stories out of that data set that are very interesting. That’s the other mode \\nthat journalism works in. That’s when people want to use R, or Python, to clean and \\nanalyse the data and d3, ggplot, or matplotlib to build visualizations of that data set. D3 \\nis especially interesting because it’s used to make web and print graphics, which is why \\nyou see it a lot. \\nWhat can you share with us about what you do at the R&D Lab, especially since \\nmost of the people we’ve been talking to work at technology companies, instead \\nof a journalism company with a very strong technology component?\\nThe R&D Lab was set up in 2006 to fulfill a number of roles. Specifically, it tries to think \\nthree to five years into the future, tracking social, cultural and technological trends \\nrelevant to The NYT. That gives us quite a range of possible projects.\\nThe other function of the R&D Lab is \\nessentially to listen. That takes two \\nforms. One is a futurist approach where \\nwe try and watch what’s going on in the \\nblogosphere and watch what’s going on \\nin new technologies. We try and keep an ear out for anything that looks like it might \\nhave something to do with the future. \\nWe also act as a gateway. If someone is developing a new, interesting business software  \\nthat they think The New York Times might be interested in, but there’s not an immediately \\nclear use case, often we’ll speak to them. We’ll ask them some questions and try and \\nunderstand what they think the future looks like. We can think about how that fits in \\nwith how The New York Times thinks about the future.\\nIn terms of projects, it’s quite varied. We’re thinking a lot lately about how to extract \\ninformation from article data. Given an article, can you extract all of the statistics, the \\nquotes, facts and events? This is a tired old problem, so we’re trying to think about other \\nways we might accomplish that. Can we capture information like that during the writing \\nprocess or the editing process or the production process, rather than approaching the \\narticles with an extractive, natural language processing view? It would be much more \\ninteresting to see what metadata we could generate in the first place.\\nThat’s an example of journalistic stuff. Then, we think about how the news might be \\nWe’re thinking a lot lately about how to \\nextract information from article data.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 51}, page_content='MIKE DEWAR\\n47\\npresented in the future. One example is a good idea that the lab had regarding the \\nfuture of tablets. The New York Times R&D Lab had thought about what a tablet reader \\napplication would be like well before the iPad came out. When the iPad did come out, \\nThe New York Times had a head start in understanding how people might interact with \\ntheir tablet and what would be interesting to show on it.\\nWhat advice do you have for other PhD students and people in academia transitioning \\nto data science, especially since you’ve been through this already? What advice \\nwould you give someone interested in transitioning to data science?\\nCode in public, that’s number one. If you’re going to \\nbe a data scientist, you’re probably going to have to be \\nable to program in one way or another. There are lots \\nof different options, but you’re probably going to have \\nto be quantitative and be able to write non-trivial programs on the computer. As you \\ncode, as you practice, as you go to hackathons, as you code for your post doctorate or for \\nyour PhD or for your graduate degree, make sure you do it in public. Put it on Github. \\nTo a certain extent I’m on the other side of it now where I put every thing I think of on \\nGithub, so it’s a bit of a mess.\\nEspecially with PhDs, one of the problems we see is that although they come from \\nimpressive universities, they have impressive resumes, and they’ve written these nice \\npapers, but we still have no idea if they can actually write code. That makes them more \\ndifficult to hire.\\nCoding in public also encourages you to engage with communities that you work with. \\nThere are programming communities that share your languages; academic communities \\nthat might want to use your code to test out your claims; and companies that want to \\nevaluate you and reduce the risk in hiring you.\\nThe other thing is networking. It’s more or less the same thing, but it’s important. In \\nmajor cities it’s very easy for you to get out of your office or house and visit meetups \\nand user groups to give a talk. Giving talks about your academic work to lay people is an \\nincredibly interesting and enlightening experience, one that you should go through. It \\nalso exposes you to the business communities and the various kinds of people that you \\nmight want to get jobs from in the future. It also shows you what other people are up to; \\nit knocks your academic naivety very quickly, which is great.\\nOther than coding in public and networking, try to apply all your work to something. \\nI wrote three papers for my PhD, and they were all about the EM algorithm. There’s a \\nload of spatial-temporal models that I put a lot of work in to. Over 3-4 years, I wrote \\nCode in public.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 52}, page_content='MIKE DEWAR\\n48\\nsome papers, and nobody cared, nobody at all. However, when we applied this theory to \\nmodelling troop movements in Afghanistan, lots of people cared. We won awards. We \\nwrote a book. We were in the news. The idea of taking the advanced things that you learn \\nat school and applying them to something important and meaningful exposes you to a \\nworld that’s difficult to see from the incremental science of being a good student.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 53}, page_content='RILEY NEWMAN Head of Data at Airbnb\\nCan you explain a bit about your background and how you came to Airbnb?\\n \\nI went to college in Seattle where I majored in international politics and economics. \\nHalfway through my time there, I realized the value of statistics for understanding social \\ntrends better. This was something I deepened in grad school, and wanted to pursue in a \\nPhD, but I had joined the Coast Guard in undergrad to pay for school and they called me \\nback from the UK after my master’s. So I came home to the Bay Area with the plan to get \\nsome experience working with data while completing my Coast Guard obligation and \\nthen planned to head back to the UK for the PhD.\\n \\nI spent three intensive years working with a group of economists that were modeling \\nthe 2008 recession. One of them had a degree in computer science and taught me the \\nvalue of automating analytical processes, which I found intriguing. When the time came \\nto leave for the PhD, I was torn — I only wanted to do it for the technical training; my \\nheart wasn’t in academia, and I was a bit tired of consulting. Serendipitously, I met the \\nfounders of Airbnb through a mutual friend, right as I was struggling with this.\\n \\nThere are a couple of things about Airbnb that resonated with me. First and foremost, \\nthe concept behind the company. In undergrad, I read a lot about globalization and the \\ngrowing interconnectedness of the world; also about the fundamental sustainability \\nissues associated with this trend. Airbnb struck me as a solution — it would facilitate more \\ntravel and bring international communities together without requiring the construction \\nof additional structures.\\nRiley Newman paid his way through college at the University \\nof Washington by being part of the US Coast Guard. After \\ngraduating with degrees in economics and international \\nstudies, Riley pursued graduate studies in the UK at the \\nUniversity of Cambridge, before he was called back to the \\nUS by the Coast Guard.\\nAfter working for a few years in economics consulting, \\nRiley met the founders of Airbnb, and was drawn to their \\nvision and focus on culture. He ended up joining Airbnb as \\none of the early employees.\\nNow, Riley is the Head of Data Science for Airbnb where he data science teams using data \\ndata to listen to customers’ voices and desires.\\nData is the Voice of Your Customer\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 54}, page_content='RILEY NEWMAN\\n50\\n \\nI was also attracted to the founders’ focus on culture. This is something I hadn’t \\nexperienced in previous roles. They placed so much value on the sense of camaraderie \\non the team — more so than high school and college lacrosse teams, Coast Guard units, \\nor the consulting firm — and the impact that brings to our work. Looking back, I think \\nthis is the “secret sauce” of Airbnb’s success.\\n \\nFinally, I was excited about helping to build \\nsomething. As a consultant, I had exposure \\nto a wide variety of problems but, at best, we \\ncould convince the client that our work was \\nactionable. At Airbnb, I would be able to follow \\nthe analysis all the way through to impact. And \\nstartups are fast-paced environments where \\nyou can see the impact of your work on a daily basis. That was really exciting to me.\\n \\nHow does this tie into the industry buzz around ”Big Data”?\\n \\n“Big Data” is such a common term these days. I heard a joke recently, “What do big data \\nand teenage sex have in common? — Everybody is talking about it. Nobody knows what \\nit is. All their friends say that they do it, so they say that they do it too.”\\n \\nLike all buzzwords, Big Data is getting tiring. But I met with a more seasoned data \\nscientist recently who described the field in the ‘80s and ‘90s — there was much less \\ndata so they needed to use advanced statistical methods to identify simple trends. These \\ndays, with the volumes of activity web companies are able to generate, and the depth \\nof storage facilitated by technologies like Hadoop, we’re able to gather and make use of \\nmuch more data. So it’s more of a question about how to sift through it all. I think this \\nhas made computer science degrees that much more valuable.\\n \\nI have a data scientist friend whose resume begins with three things he firmly believes: \\nmore data beats better models; better data beats more data; and the 80/20 rule. I couldn’t \\nagree more.\\n \\nI think that is a really good introduction as to what you think data science is. I want \\nto go back to something that you mentioned earlier; your Master’s degree was in \\nEconomics, is that right?\\n \\nYes, I was in the applied economics department at Cambridge. My research was in the \\nfield of economic geography/spatial econometrics.\\n \\nThey placed so much value on the \\nsense of camaraderie on the team. \\nLooking back, I think this is the \\n“secret sauce” of Airbnb’s success.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 55}, page_content='RILEY NEWMAN\\n51\\nMany people we’ve interviewed have their PhD or Masters in physics, statistics, \\nmath, or computer science. You’re one of the few data scientists we’ve talked to \\nwith an economics background. Do most people on your team tend to come from \\nbackgrounds in the hard sciences or are the social sciences represented as well?\\n \\nEveryone on the team has some degree of \\nquantitative training but I like having a wide \\nvariety of backgrounds because this brings \\ndifferent skill sets and approaches to solving \\nproblems. For example, computer scientists \\nare great at scripting automated solutions and \\nproductionizing models; statisticians ensure our models are rigorous; physicists are \\nvery detail-oriented; and economists can build frameworks for understanding problems. \\nAirbnb is particularly interesting to economists because of our two-sided marketplace, \\nwhich lends itself to modeling supply and demand, and looking for ways to make our \\nmarkets more efficient.\\n \\nBut the key thing is that everyone on the team is able to drive impact in the company \\nthrough the cultivation of insights drawn from data. I’m less interested in what people \\nstudied in undergrad than in their ability to do this successfully. However, this requires \\na solid grasp of statistics, experience in coding, and great communication and problem-\\nsolving. Our interview process exposes these skills very well, so we’re able to consider \\npeople from less traditional backgrounds.\\n \\nI agree with you that there isn’t necessarily one particular field that data scientists \\ncome from. However, it does seem like most people come from certain fields that \\ntend to teach some of the most relevant skills. Building on that, what would you \\nsay are some of the most valuable or relevant skills that someone in academia \\nshould build right now?\\n \\nMany people coming into data science from academia have honed their ability to think \\nmathematically or statistically and, to some extent, work with data. The big division that \\nI see is the ability to lend those skills towards problems that will result in an actionable \\nsolution. In other words, the types of questions they ask are as important, or more, than \\nthe methodology behind solving them. In their research, they focus on why something \\nis the way it is or how it works; in industry we’re more interested in what we should do. \\nIf the how or why lends itself to answering this, great. But if nothing changes as a result \\nof your work, then it wasn’t that valuable.\\n \\nWhen we ask other data scientists that question, we hear about technical skills like \\nPython and programming. We don’t hear as much about extracting actionable insights.\\n \\nMore data beats better models; \\nbetter data beats more data; and \\nthe 80/20 rule.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 56}, page_content='RILEY NEWMAN\\n52\\nI’m not saying that those aren’t relevant; I’m presupposing that anyone hoping to \\ngenerate actionable insights from data has the ability to work with the tools of the trade. \\nAt Airbnb, we mostly use Hive, R, Python, and Excel.\\n \\nWhen we interview people, our process is \\nvery transparent (see Quora post on this, \\nhere). We give candidates a day to solve a \\nproblem similar to something we’ve faced, \\nusing real (but anonymized) data. They \\nspend the day seated with the team and \\nare treated like anyone else, meaning they \\ncan collaborate with anyone. At the end of \\nthe day, we have them walk us through what they found and tell us what we should be \\ndoing differently as a result. This is too tight of a timeframe for someone to learn a tool \\nwhile trying to use it to solve the problem. Their time needs to be completely focused on \\ngetting to that actionable insight.\\n \\nContinuing along that vein, you’ve been talking a lot about data scientists coming \\nfrom a Master’s or a PhD. I’m also wondering about your opinion of people coming \\nin with a Bachelor’s in a quantitative field or similar?\\n \\nPeople can absolutely break in with just a Bachelor’s. We shifted to the interview model \\nI described earlier because we realized our image of a data scientist was yielding false \\nnegatives. If you have the right mindset, a decent understanding of statistics, and can \\nuse SQL and R, you’ll be able to get a job.\\n \\nThis is particularly true in younger startups. When I think back to the early days of \\nAirbnb, we were able to squeeze a lot of growth out of a simple ratio. If I spent a month \\nbuilding a perfect model, I would have wasted 29 days. As a company matures, so does \\n(hopefully) its understanding of its ecosystem. So there’s a need for more sophisticated \\napproaches.\\n \\nYou started at Airbnb when it was in a really early stage. Now you’re at the point \\nwhere it’s growing very fast — it’s become a large company. What are some of the \\nways you’ve seen that transitioning into the work that you actually do?\\n \\nI see this transition shaping our work in two ways. First, the team is big enough now that \\nwe’re able to go much deeper into problems. In the past, we were jumping from one fire \\nto the next, so we weren’t able to invest large amounts of time into a single problem. \\nAnd that’s natural for a startup. But as the team has grown, we’ve been able to focus on \\nsome of the key topics for the business and understand them more deeply. We also now \\nWhen we ask other data scientists that \\nquestion, we hear about technical skills \\nlike Python and programming. We \\ndon’t hear as much about extracting \\nactionable insights.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 57}, page_content='RILEY NEWMAN\\n53\\nhave people on the team building data products, which is exciting.\\n \\nSecond is the democratization of information. We’re not the only team that has grown \\nover the last few years and everyone is hungry for data to guide their work. So we have \\nto find ways to remove ourselves from the process of answering basic questions. The last \\nthing you want to be is the gatekeeper of information because you’ll spend all of your \\ntime responding to ad hoc requests. So we’ve invested a lot in the structure of our data \\nwarehouse and the tools used for accessing it so that it’s intuitive to people with less \\nexperience working with data.\\n \\nWhat do you think are some of the most fundamental ways in which data science \\ncan add value to the company?\\n \\nI think data can add value everywhere. It’s the voice of your customer — data is effectively \\na record of an action someone in your community performed, which represents a decision \\nthey made about what to do (or not do) with your product. Data scientists can translate \\nthose decisions to stories that others can understand.\\n \\nWe spend a lot of time with our product \\nteam, which is the most traditional place \\nfor a data scientist. There’s a wide range \\nof work happening here. For example, \\nour trust and safety team builds machine \\nlearning models to predict risk and fraud \\nbefore it takes place. They also have to \\nthink about ways to measure intangible \\nthings, like the strength of trust between people in our community so we can identify \\nways to improve this.\\n \\nWe have other people working on matching guests and hosts, improving the model \\nbehind our search algorithm and uncovering new features to improve the match. A while \\nback we published a blog post about this here.\\n \\nWith our mobile team, we try to uncover opportunities for improving the app. One guy \\non the team looked at the probability of performing an action on the app relative to how \\nfar away that feature is from the homepage. This obviously showed that the more buried \\nsomething is, the less likely it is to happen — but it’s a framework the mobile team can \\nnow use to think through the structure of the app.\\n \\nBut we don’t just work with product. We think about user lifetime value and growth \\nopportunities with our marketing team, operational efficiency with our customer support \\nteam, and we’ve even been chatting with our HR team about how they can leverage data \\nWhen I think back to the early days of \\nAirbnb, we were able to squeeze a lot of \\ngrowth out of a simple ratio. If I spent a \\nmonth building a perfect model, I would \\nhave wasted 29 days.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 58}, page_content='RILEY NEWMAN\\n54\\nto better understand recruiting and career growth.\\n \\nI try not to segment our work by stakeholder; rather I look at the key drivers of the \\nbusiness and try to figure out what problems need to be solved in order for Airbnb to be \\nbetter, and then figure out who is in the best position to use that information.\\n \\nAirbnb is a transactional business so \\nthere’s a funnel we can break apart and \\nanalyze. And getting back to the concept \\nof data being the voice of the customer, we \\nalways start by looking to our community \\nfor advice on what to do next. At the top of \\nthe funnel we try to understand how people \\nare hearing about Airbnb. We can use \\nonline and offline marketing to drive this, emphasizing growth where we think there’s \\na strategic opportunity or where we’re seeing positive ROI (return on investment). For \\nthis, we begin by looking to our community for ideas; for example, where many people \\nare searching for places to stay but we don’t have enough supply to accommodate them. \\nIf this isn’t an anomaly (e.g. one-off event), it represents an opportunity for growth.\\n \\nNext is the experience people have when they come to our site. There’s a lot of A/B \\ntesting here, looking for ways to make it more intuitive and satisfying to a person of any \\ndemographic, anywhere in the world.\\n \\nAfter that is the offline experience, which is tricky because the data behind this isn’t \\nas rich as site usage. But we can get a lot from the reviews people leave each other - a \\ncombination of quantifiable ratings and NLP we can perform on the text of the review.\\n \\nFinally, we look at what we can do to get people to come back and try it again. Mostly, \\nthis means improving each of the steps above, but we think about experiences people \\nhave with customer support or community groups as a way of staying connected.\\n \\nThe final thing I would love to get your perspective on is just looking towards the \\nfuture.  Where do you think the future of data science is and where do you think \\nwe are relative to what data science could be in the future?\\n \\nI think we’ll see a lot of growth on the tools front. It’s amazing how quickly Hadoop \\nand Hive have matured just over the last few years and there are new and exciting \\ntechnologies emerging almost daily. So I’m hopeful that we’ll eventually have lightning-\\nfast tools that can work with data of any size.\\n \\nI also think data logging will develop a lot, because people are aware that you only focus \\nSo we’ve invested a lot in the \\nstructure of our data warehouse and \\nthe tools used for accessing it so \\nthat it’s intuitive to people with less \\nexperience working with data.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 59}, page_content='RILEY NEWMAN\\n55\\non what you can measure, and you only measure what you can log. So questions like we \\nhave about the offline experience will hopefully get easier to answer as data becomes \\nmore ubiquitous.\\n \\nEvery now and then I see an article about \\nthe field of data science disappearing to \\nautomation. In effect, the tools get so good \\nthat you don’t even need to analyze data; \\nthe insights are just there waiting for you. \\nWhile this may be partially true with the \\ngrowth of machine learning, I don’t think it will ever fully be the case. Good data science \\nis more about the questions you pose of the data rather than data munging and analysis.\\n \\nBut with that in mind, I can imagine the field of data science opening up to people that \\nare less technical. As tools get more sophisticated and easy to use, we’ll see more people \\ngetting excited to work with data. We’ve already observed this at Airbnb, where we train \\neveryone in the company to use SQL. As I mentioned earlier, you don’t want your data \\nscience team to be the gatekeepers of all information. We want everyone to be able to \\ninteract. I love watching people with no background in statistics or CS wrapping their \\nminds around the basics of working with data. They get so excited, then they get curious. \\nAnd that frees us up to focus on interesting problems that will impact the business.\\n \\nThis sounds like the democratization of data science.\\n \\nExactly. It’s happening today at Airbnb, and I bet we see a lot more of it in the future.\\nGood data science is more about the \\nquestions you pose of the data rather \\nthan data munging and analysis.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 60}, page_content='CLARE CORTHELL Data Scientist at Mattermark\\nWhat was your background, before you began the Open Source Data Science \\nMasters and before your role at Mattermark?\\nI’m a product person and an entrepreneur. I fell in love with startups long before I \\nattended Stanford, where I designed a degree in a then-obscure program called Science, \\nTechnology & Society. You get to marry two engineering tracks, so I ended up designing \\na degree in product design and digital development, which then got me started working \\non product with early stage companies.\\nBefore the OSDSM (Open Source Data Science Masters), I was designing and prototyping \\nproducts for an early stage education technology company in Germany. Designing from \\nuser anecdotes alone became difficult when you only pull from anecdotes, so I started \\ndigging deeper into analytics and customer profiling. I started thinking about observing \\nmeta-trends among users instead of studying their behavior with a clipboard from \\nbehind a one-way window. What if I just ran several tests on two different prototypes? \\nThen we would have data to tell us which one to develop! But as with many European \\nstartups, the company didn’t get funded, so I had a few weeks to think about how this \\nnew perspective fit in. On a long layover in Barcelona, I ordered an espresso and wrote \\nAfter graduating from Stanford, Clare Corthell embarked on \\na self-crafted journey to acquire the knowledge and skills \\nto understand and analyze macro-behavioral trends. One \\nthing led to another, and her collection of resources turned \\ninto the Open Source Data Science Masters - a curriculum \\nof online courses, books and other resources that one could \\nuse to learn the mathematical and programming foundation \\ncrucial to a data scientist.\\nClare took a risky move by crafting her own degree program, \\noutside of traditional educational institutions. She faced \\nskepticism of a self-taught individual in a job that is typically \\ninhabited by PhDs, but also found a community of supportive colleagues.\\nOvercoming these challenges, Clare completed her Open Source Data Science Masters and \\nfound herself as a data scientist at Mattermark, a venture-backed data startup working with \\nlarge datasets to help professional investors quantify and discover signals of potentially \\nhigh-growth companies.\\nCreating Your Own Data Science Curriculum\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 61}, page_content='57CLARE CORTHELL\\ndown the technical skills I would need to dissect meta-trends and understand user data. \\nThat list laid out 6 months of full-time work, after which I’d really be able to do some \\ndamage. This became the Open Source Data Science Masters.\\nAs with any story, it \\nis now retrospectively \\nclear that I would \\nsecretly fall in love with \\nan applied statistics \\nclass I cheekily called \\n“Exceltastic.” We \\nworked with Bayes’ \\nTheorem and Markov Chains in the business context, figuring out things like how many \\ncars can pass through two toll booths per hour. Everyone else sulked and moaned through \\nmunging spreadsheets while I harbored a dirty secret: I loved Excel models! Even so, I \\ndidn’t know when my toll booth throughput calculations would be demanded of me, nor \\nwhat class logically comes next. It took getting into industry to shed light on the value \\nof keeping metrics. Things like my Exceltastic class don’t seem to fit into an overarching \\npuzzle, but we believe they shape our path. That’s the power of confirmation bias. One \\nof my favorite designers has this phrase that he prints in various media: “Everything I do \\nalways comes back to me.” I’ve always found that fitting.\\nWhat is the Open Source Data Science Masters? What does its curriculum look like?\\nIt’s a collection of open-source resources that help a programmer acquire the skills \\nnecessary to be a competent entry-level data scientist. The first version included \\nintroductory linear algebra, statistics, databases, algorithms, graph analysis, data mining, \\nnatural language processing, and machine learning. I wrote the curriculum for myself, \\nthen I realized that people all over the internet were asking for it, so I published it on \\nGitHub.\\nIn August, I opened the curriculum for pull requests on GitHub. Without feedback it’s \\ndifficult to know whether you’ve covered the right things. Further, it was an effort to get \\nfeedback on the idea of an institution-free degree, a kind of home-school for advanced \\ndegrees. The internet was astonishingly supportive and excited — and that excitement \\nis addictive. It makes you want to be more transparent, and to become part of other \\npeoples’ wonder in learning new things.\\nHow did you get started with the Open Source Data Science Masters?\\nI knew that a traditional Masters program would take at least the next three years of \\nI started thinking about observing meta-trends among \\nusers instead of studying their behavior with a clipboard \\nfrom behind a one-way window. What if I just ran several \\ntests on two different prototypes? Then we would have \\ndata to tell us which one to develop!\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 62}, page_content='58CLARE CORTHELL\\nmy life, but even more importantly it wouldn’t focus on what is core to the profession \\nI wanted to enter. I knew what I wanted and I was willing to take the risk of a non-\\ninstitution education.\\nI set out for the curriculum \\nto take 6 months to complete \\n(March - August 2013), with a \\nsmall project at the end and \\nvarious programming mini-\\nprojects focusing on scraping, \\nmodeling, and analysis. It was \\namazing how difficult it was \\nto manage myself. School gives you this structure that you don’t have to question or \\ndesign, which you don’t really see until you have to manage your own curriculum and \\ndeadlines. There’s a lot of product management that goes into an educational track like \\nthe OSDSM. I’m grateful to all the people who supported me and helped me throughout, \\neven if they didn’t quite understand the strange and uncharted waters I was braving to \\nget there.\\nHow did you find the resources?\\nI reverse-engineered most of it from job descriptions that interested me. This meant \\ncompanies I believed would grow quickly and provide the most opportunity: mid-stage \\nstartups, 100-200 people, existing data science teams and reverence for the methodology. \\nI didn’t want to be the lone wolf and knew I needed mentorship.\\nPeople tend to frown on centering the goals of the classroom on applicability in the \\nreal world, but a classic liberal educational approach in a technical career pivot won’t \\nserve you. This is a technical vocational degree, so the goal was very concrete. I should \\nbe employable and employed on a data science (or Analytics Engineering) team after \\ncompleting the curriculum.\\nThere was another realization that coalesced very quickly: the act of designing from \\ninsights of single users does not scale. I was also hankering for something more technically \\nand algorithmically challenging. I’d bought this book before I moved to Germany, \\nProgramming Collective Intelligence . I just bought it, I really had no reason to. When I \\nfirst opened it up, I understood next to nothing. But I carried it with me in Germany, and \\nevery time I opened it, something new jumped out and I understood more about scaling \\nuser insight. The book became my cornerstone, how I measured my progress. It’s a bible \\nfor Data Scientists.\\nIt took getting into industry to shed light on the \\nvalue of keeping metrics. Things like my Exceltastic \\nclass don’t seem to fit into an overarching puzzle, \\nbut we believe they shape our path.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 63}, page_content='59\\nI also used the following resources/websites:\\n• Quora: This is a great resource for the Valley — it’s truly navel-gazing, but if that’s \\nwhat you’re doing, it’s useful. People like DJ have answered questions about what a \\nData Scientist does on a daily basis. You can start to discern the technical capacities \\nthat are required of you, mathematical foundations that are necessary, and so forth. \\n• Blogs: Zipfian Academy, a data science bootcamp, had a blog. They had a great post \\non the resources they saw as core to becoming a data scientist: A Practical Intro to \\nData Science\\n• Coursera: I’m Coursera’s biggest fanboy. They’re part of this quietly-brewing \\neducational revolution, which will soon be less quiet. My story is a tremor before the \\nearthquake, I’m just waiting for the ground to start shaking.\\nHow much math (probability, statistics, ML) did you try to learn? How much math \\ndo you think a data scientist needs to know?\\nYou don’t have to know everything. That’s why I’ve tried to keep the curriculum so \\ntightly focused on its goal. Programmers are great at “just-in-time” learning because it’s \\nimpossible to know everything. That’s a great trait. If you have a core set of competencies \\nand understand how to “debug” problems and learn what you need to solve them, you \\ncan do damage. And naturally, you improve over time by recognizing new problems as \\nchunks of old problems you’ve already seen and solved.\\nSo much of this curriculum \\nis abstract, and that’s where \\npeople get scared. People are \\nscared of math because it’s not \\napplied in our education system. \\nBut those scary elements of \\nmath and abstraction diminish \\nwith concrete examples and \\nconversations with others. I had a few phone-a-friend lifelines, and I ate up Khan Academy \\nand Coursera videos. There’s something magical about how much more communicative \\nspoken English can be, especially when you can rewind and digest a concept for the \\nsecond, third, or even fourth time. You can always talk through a problem with someone \\nelse, even if they’re not an expert. Talking through things is synonymous with debugging. \\nOne of my mentors calls this “the rubber ducky method,” because if you talk a problem \\nthrough to a plastic duck, sometimes you start to find the holes in your assumptions. \\nThen you can plug them up.\\nIf you think about people as having different levels of competency in these different \\nrealms, it doesn’t take long to understand that working as a team allows you to stack \\nCLARE CORTHELL\\nThe internet was astonishingly supportive and \\nexcited — and that excitement is addictive. It \\nmakes you want to be more transparent, and to \\nbecome part of other peoples’ wonder in learning \\nnew things.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 64}, page_content='60CLARE CORTHELL\\nyour respective skills on top of one another. Having specialties among the team is really \\nessential to getting things done in a small organization. I was lucky enough to join a \\ncompany where I get mentorship in verticals where I’m middling or even an amateur. It’s \\namazing to learn with other people. Finding a job where you have mentors and training \\nis essential to continue to grow and improve. And if you’re not improving and growing, \\nyou’re dead in the water. So that’s a long-winded way of saying: Working with other \\npeople is essential to working with more complex concepts and systems. Rome wasn’t \\nbuilt by some guy, and probably not at a weekend hackathon.\\nWhat would you do differently if you could redo the Masters?\\nAs Patient Zero of a new type of \\ninternet-based institution-free \\neducation, I didn’t know what \\nto expect. It was impossible to \\nknow how I would be judged and \\nwhether I would benefit from my \\nexperiment. This type of ambiguity \\nusually makes people extremely \\nuncomfortable. It’s like leaving a six-year-old in the library by herself instead of putting \\nher in class with a teacher. What is she going to do? Pull a bunch of books onto the floor \\nand see how high she can stack them? Watch birds at the window and think about how \\nwings work? Or is she going to find something interesting and gather books that will \\nhelp her form her own ideas about the world?\\nI knew that it would be a risk, but I took a leap of faith and left myself alone in the \\nlibrary. In the end, the greatest reward didn’t come from the curriculum, it came from \\nwhat taking a risk demonstrated about me. It led me to a tribe that respected the risk \\nI had taken, and valued the grit that it required to follow through. Many people were \\ndispleased that I let myself into the library without an adult. But I’m not interested in \\ntaking the recommended path and clinging to a librarian. I have no interest in small \\nambition.\\nWhat’s the difference between data science job descriptions & day-to-day role at \\nMattermark?\\nOur CEO Danielle was once asked how many data scientists we have at Mattermark. \\nWe’re all data scientists, she thought — we all use, manipulate, and analyze data on a \\ndaily basis to make our customers happier and more profitable. We even all write SQL! \\nThat’s not something you see every day at a company, but it’s essential when you’re \\nbuilding and selling a data product. I build products as an engineer, anything from fitting \\nYou don’t have to know everything. That’s why \\nI’ve tried to keep the curriculum so tightly \\nfocused on its goal. Programmers are great at \\n“just-in-time” learning because it’s impossible \\nto know everything.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 65}, page_content='61\\nclustering algorithms, building automated analyses, designing UIs, acquiring new data \\n— it’s a startup. It’s all hands on deck.\\nIt’s not clear that data science is a job title to stay yet. For example, do we know if growth \\nhacking is a subset of data science? We don’t. There will always be a top-level salary for a \\nperson who can turn chaos into insights. That won’t change. Data Scientist is a title we’ll \\ncontinue to use while we figure it out.\\nWhat could someone in school, or otherwise without too much background in \\nindustry learn from your experience?\\nThe ability to evolve my own career with a self-designed curriculum begins to outline \\nthe immense cracks in the foundation of higher education*. The deconstruction of this \\nsystem was very long in coming, but it’s happening now. The lesson is the following: if \\nyou take initiative and acquire skills that increment your value, the market is able and \\nwilling to reward you.\\nThough people continue to believe and \\nespouse old patterns of education and \\nsuccess, these patterns do not represent \\nrequirements or insurance. The lack of \\nany stamp of approval is a false barrier. \\nThere are no rules.\\nIt’s important to understand the behavior of the market and institutions with regard to \\nyour career. When breaking out of the patterns of success, know that people will judge \\nyou differently than others who have followed the rules.\\nThere are two very discrete things that I learned: The market is requiring people to \\nperform tryouts for jobs instead of interviews, and most companies don’t hire for your \\npotential future value.\\nTryouts as Interviews: The economy has set a very high bar for people coming into a \\nnew profession. Job descriptions always describe a requirement for previous experience, \\nwhich is paradoxical because you need experience to get it. Don’t let that scare you, \\nnot for a minute. Pull on your bootstraps and get in the door by giving yourself that \\nexperience — design and execute on a project that demonstrates your ability to self-\\nlead. Demonstrate that you can take an undefined problem and design a solution. It \\nwill give you the confidence, the skills, and the background to merit everything from \\nthe first interview to the salary you negotiate.\\nCLARE CORTHELL\\nThe ability to evolve my own career \\nwith a self-designed curriculum begins \\nto outline the immense cracks in the \\nfoundation of higher education\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 66}, page_content='62CLARE CORTHELL\\nEven more concretely, work with a non-profit organization (or another organization \\nthat doesn’t have the economic power to hire programmers or data scientists) to create \\na project that is meaningful for the organization and also shows off your skills. It’s a \\ngreat way to do demonstrative and meaningful work while also aiding an organization \\nthat could use your help, and likely has problems people are paying attention to \\nsolving. Win-win.\\nCurrent Value vs Potential: Look for \\ncompanies that will hire you for your \\npotential. It’s important to be upfront \\nabout your grit, self-sufficiency, and \\nability to hit the ground running. \\nLuckily, with disciplines like data \\nscience, the market is on your side. \\nSometimes companies can spring for a Junior Data Scientist and invest in your growth, \\nwhich is really what you wanted from the beginning.\\nEveryone will tell you this, but I work on product so I’ll underline it even more \\nstrongly: Learn to write production-level code. The more technical you are, the more \\nvaluable you are. Being able to write production code makes you imminently hirable \\nand trainable.\\n[*NB: Don’t think for a minute that I don’t believe in the tenets of a true liberal education - \\nquite the contrary. I continue to read philosophy and history, in part because we cannot draw \\nfully upon the knowledge of man without doing so. These are essential elements to being a \\npurposed, ethical, and effective person - but they don’t directly accelerate a career. The true \\nliberal education has nothing to do with market forces, and never should. Higher Education \\nas it exists today and Liberal Education should be held as wholly uniquely-motivated \\ninstitutions.]\\nHow was your self-taught path to becoming a data scientist received by company \\nrecruiters? What advice would you share with entrepreneurial individuals who are \\ninterested in the field?\\nTalk with people who can recognize hustle and grit, and not necessarily those who are \\nlooking to match a pattern drawn from your previous experience. Often, these kinds of \\npeople run startups.\\nRecruiters gave me a very real response: They didn’t see my course of self-study as \\nlegitimate. It’s hard to give yourself a stamp of approval and be taken seriously. I wouldn’t \\nrecommend that just anyone do what I did — it will take a while for autodidactism to \\nTalk with people who can recognize \\nhustle and grit, and not necessarily those \\nwho are looking to match a pattern \\ndrawn from your previous experience.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 67}, page_content='63\\nbecome more accepted, and maybe it will never be a primary pattern. But maybe people \\nlike me can help expose this as a viable way to advance professionally. I know that great \\ncompanies like Coursera will continue to innovate on these new forms of education, \\nkeep quality high, and democratize access.\\ntl;dr\\nIf you want to get to the next level, wherever your next level may be, it’s possible to pave \\nyour own road that leads you there. It’s a monstrously tough road, but it’s your road.\\nCLARE CORTHELL\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 68}, page_content='DREW CONWAY Head of Data at Project Florida\\nYour data science Venn diagram has been widely shared and has really helped \\nmany people get an initial sense of what data science is. You created it a long time \\nago, back in 2010. If you had the chance to create it again today, would you change \\nany part of it?\\nQuite a lot. I can speak a little bit about the history of it which I think is probably less \\nglorious than people know. \\nI was a graduate student at NYU and was a teaching assistant for an undergraduate class \\nin Comparative Politics. As a teaching assistant in those classes, your mind wanders \\nbecause you already know the material. \\nIt was 2010, and the idea of data science was much more primordial. People had less of a \\nsense of what data science was. At that time I was thinking about the definition of data \\nscience. I had been speaking to people like Mike Dewar, Hilary Mason and some other \\npeople in New York and was influenced by their ideas and some of my own and came up \\nwith the definition while sitting there in class.\\nThe original Venn diagram I made on data science, which ended up becoming quite well-\\nknown, was drawn using GIMP as the editor — the simplest, cheapest program in the \\nworld. But I’m very happy that it seems people have attached themselves to it and it \\nmake sense to them. \\nAfter graduating with degrees in both computer science \\nand political science, Drew found himself working at the \\nintersection of both fields as an analyst in the U.S. intelligence \\ncommunity, where he tried to mathematically model the \\nnetworks of terrorist organizations.\\nAfter spending a few years in DC, Drew enrolled in a political \\nscience PhD at New York University. It was here that he \\ndrew up his famous Data Science Venn Diagram. It was also \\nduring this time that he co-founded Data Kind, a nonprofit \\norganization which connects data experts with those who \\nneed help. After a stint at IA Ventures as their Data Scientist \\nin Residence, Drew joined Project Florida as Head of Data, where he uses data science to give \\nindividuals better insights into their health.\\nDrew is also the co-author of the O’Reilly book, Machine Learning for Hackers.\\nHuman Problems Won’t Be Solved by Root Mean-Squared Error\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 69}, page_content='65\\nWhat has become more apparent to me as the years have passed is that the thing missing \\nfrom it is the ability to convey a finding, or relevant information once an analysis is \\ncomplete, to a non-technical audience. A large amount of the hard work that most data \\nscientists do is not necessarily all data wrangling and modeling and coding. Instead, \\nonce you have a result, it’s about figuring out how to explain that result to people who \\nare not necessarily technical or who are either making business decisions or making \\nengineering decisions. \\nReally, it’s all about conveying a \\nfinding. You can use words to do \\nthat, you can use visualization \\nto do that, or you can develop \\na presentation to do it. A well-\\nrounded data science team \\nwill have someone who is \\nvery competent at this. If your \\norganization is making decisions \\nbased on your analysis, you need to be sure they understand why.\\nThis echoes parts of what we’ve heard when we talked with Hilary Mason and \\nMike Dewar. Both of them emphasized the storytelling part and how to carefully \\ncommunicate the analysis part.\\nIt’s something that receives the least amount of thought, but turns out to be one of the \\nmost important things once you’re doing this in the wild. Even the people who have had \\nsuccess in data science up to this point have just been naturally good at it, whether they \\nwere blogging about it or giving good presentations. Both Mike and Hilary are examples \\nof people who are good at doing that. They are naturally good at it. People who are not \\nnaturally good at it can learn about it through coaching, and mentorship.\\nIn just the same way, if you’re not a good coder you can become a better coder through \\ncoaching and mentorship.\\n \\nYou said on a Strata panel: “Human problems won’t be solved by root mean square \\nerror.” What did you mean by that?\\n \\nI think when people think about data science, or even machine learning applied to data \\nscience, people think that we have a well-defined problem, and we have our data set. We \\nneed to find a way of taking that problem and that data set and producing an answer that \\nis better than the one that we currently have.\\nDREW CONWAY\\nA large amount of the hard work that most data \\nscientists do is not necessarily all data wrangling \\nand modeling and coding. Instead, once you have \\na result, it’s about figuring out how to explain \\nthat result to people.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 70}, page_content='66\\nFor example, Kaggle does a really good job of finding a problem definition, finding the \\ndata set, saying that it’s connected to that problem and ramping up to a competition. That \\nway people can try and achieve a very specific thing such as having a better predictor, or \\nhaving a better classifier so your errors are small.\\nBut the really hard problems are ones for which we don’t have good well-defined \\ndefinitions for yet. Or we recognize the problem but it’s not obvious how to find the \\nrelevant data that goes with it. Those are really hard problems to me. I’m a social scientist \\nby training, so I think about how human behavior could be observed, what it is that I \\nwant to learn about institutions or policies or government and interventions to help \\nkeep a lid on our lives.\\nThose problems are very hard to model. So they require more creative thinking. \\nParticularly at first, or at the onset where you have no idea if there’s even any relevant \\ndata out there. You might have to go on and run an experiment, run a data collection \\nexperiment. Then try from there. “Ok, what are the models and methods that might work \\nin this context?” At the end, you’re going to spend a lot more time thinking, “ Alright, \\nwhat are the intended and unintended consequences that might result by implementing \\nmy idea?”\\n \\nTake New York City, for example. Let’s say you wanted to optimize the snow removal \\nroutes in New York City when there’s a snowstorm. Those who were in New York when \\nthere was a big snowstorm might remember — there were a lot of people who complained \\nbecause the snow ploughs couldn’t get to certain neighborhoods fast enough.\\nSo technically it’s probably a pretty easy problem to solve. It’s like a rough optimization \\nproblem. You could do that. But if you take a snow plough that’s expected to be in one \\nplace and reroute it to another place, the people who live in that block will have a negative \\neffect on optimization. Or at least there will be a perceived negative effect.\\n \\nThis is a long-winded answer, but it’s much easier if you’re only thinking about minimizing \\nerror. If you have a broader perspective on how your application or your problem or \\nthe solution to it actually impacts people, it becomes harder and therefore much more \\ninteresting and useful to the discipline of data science.\\nHow have you found working at the intersection of social science and data science? \\nWhat are the problems that you’ve really chewed on and how did you come to \\narrive at those sorts of problems?\\n \\nFor me, it started where you are, in my undergraduate times. I was a computer science \\nstudent but I went to a liberal arts college so I got to take lots of other classes. I always \\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 71}, page_content='67\\nfound questions that were being asked in my political science or sociology classes to \\nbe the ones I was really interested in: “How do groups of people make choices? How do \\nmarkets move? Why is one group of people making different choices than another group \\nof people? What motivates people to do bad things? What motivates people to do good \\nthings?” These sorts of questions were much more interesting to me at the time than \\nwriting a faster compiler or a different programming language.\\n \\nAt that stage I actually \\nended up double majoring \\nin Computer Science and \\nPolitical Science so I had to \\nwrite two theses. My political \\nscience thesis was back in \\n2004. Keep in mind that when I \\nwent to college, 9/11 was a big \\npart of my experience. So I became really interested in terrorism and terrorist groups. I \\nwas reading trying to learn more about it. At the time peer-to-peer file sharing networks \\nwere still prominent. I was reading about how those file-sharing networks were used \\nand the way data went through them and I observed that they were structured in very \\nsimilar ways to nefarious networks or terrorist networks. I wrote my thesis on mirrors \\nbetween these two things. There are weaknesses in the file-sharing network. If it was \\npossible to replicate those weaknesses in a human network, maybe you could exploit the \\nsame weaknesses that people use to try to intercept communications on a file-sharing \\nnetwork.\\n \\nI actually got invited to present that paper at West Point when I was a senior. This set me \\non the first part of my career path. I started my career in the intelligence community and \\nthere were people at the conference from various intelligence agencies who were really \\ninterested in the idea that you could model human behavior in the same way you model \\ncomputer traffic.\\nPart of it for me was that I felt a connection to the 9/11 event and I was interested \\nin learning more about why people would do that. So between the knowledge that I \\nhad learned in Computer Science and my interest in Social Sciences, I landed a job \\nas a computational social scientist working inside the intelligence community. The \\nproblems I was working on there were exactly an extension of the work that got me \\nthere: understanding networks, working out how people make choices in non command-\\nand-control structures.\\n \\nEver since then, I’ve always been fascinated by computer science, math, and statistics as \\na tool belt. I find these technical things really interesting to apply to human problems. \\nDREW CONWAY\\nIf you have a broader perspective on how your \\napplication or your problem or the solution to it \\nactually impacts people, it becomes harder and \\ntherefore much more interesting and useful to the \\ndiscipline of data science.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 72}, page_content='68\\nI’m not working in the intelligence community any more, but since then, I’ve worked on \\nmy Ph.D. and have done research in the space, and have even started an organization \\nlike Data Kind, which tries to scope out the intersection of where the human problems \\nare, where the technical talent is and then put them together. And now at Project Florida, \\nI’ve always wanted to do take these learnings and apply them within the sensor market \\nand with healthcare. It’s always been the classic problem that’s excited and motivated \\nme.\\n \\nHow is it that you were able to come straight out of undergrad and begin working \\nin this domain?\\n \\nFor me, I’m not sure my career path is one that I would recommend for other people. I \\nloved my career, I can’t complain about any step. But we’ll call it an outlier situation. \\nI was working with a lot of “reformed” academics. The people who were mentors to \\nme had been professors at big research universities and it was very multidisciplinary. \\nI had colleagues and bosses who were PhDs in math, computer science, economics and \\nsociology. I was working with a large group of really smart people.\\n \\nI started my career as a very junior analyst. The way that DC works, in a sense, is that \\nin order to reach the next “level” you have to have at least a Masters degree. Well, I got \\nto that point around 2007, so I was thinking about what I wanted to do. I was reaching \\nout to my colleagues and mentors for advice. They sat me down and they said I had two \\nchoices: “You can do the typical DC thing which is to go to night school, get your Masters \\ndegree and then do the next thing. Or you could think about becoming a professional \\nresearcher. Go back to school full-time, see if you’re interested and do a doctorate.”\\nFor me they were saying, “We know you, we know what you like doing. You should really \\nconsider the Ph.D. because we think it would be good for you.”\\n \\nTo be honest, I didn’t really want to do it. It’s such a huge opportunity cost. If I did it, \\nthat was five years I could have been making money and building a career. However, on \\ntheir counsel I started looking around at some programs. I knew I didn’t want to go back \\nto school for a computer science degree or a math degree, because I definitely wasn’t the \\ngreatest computer scientist or mathematician that ever lived. And also, at the end those \\nare not the problems I want to solve. If you’re going to do a PhD., you have to contribute \\nback to the discipline. I wasn’t interested in contributing back to those two disciplines, \\nso I thought about various Political Science programs. I wanted to find one that was very \\nquantitative. I ended up at NYU Political Science, which was one of three or four political \\nscience departments in the world that was heavily quantitative right from the start.\\n \\nIt was also in New York.\\n \\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 73}, page_content='69\\nI felt that being in New York and in a large urban area opened up a lot of different things \\nand wouldn’t limit me to focusing specifically on my academic endeavor. I could be \\nexposed to other things while I was there.\\n \\nI also decided that I wanted to talk more publicly about the work I was doing. Part of this \\nis colored by the fact that for years, by being in the intelligence community, I couldn’t \\ntalk at all about the work I was doing. So moving on from there, I was really eager to start \\nblogging or going to the media to talk about the work.\\n \\nAs soon as I got to graduate school, I started doing those things. That helped balance \\nthe work I was doing as a graduate student with running the Meetup in New York, giving \\ntalks, advising start-ups and getting involved. That doubled my work but it was all fun \\nwork and I really loved it.\\nThe decision to go back to school was basically, “Well, I think this would be good for my \\ncareer.” I didn’t even really know if I wanted to be a professor. It was something I was \\ninterested in, but I knew if I was going to become a professor I was going to be the kind \\nof professor that had one-and-a-half foot in the university, and the other half foot out \\ndoing stuff.\\n \\nFrom my experience at graduate school I decided I definitely didn’t want to be a professor. \\nMy father was a professor so I’m sort of a university brat. I know the lifestyle is fantastic \\n— there’s nothing wrong with it. However, the realm of a university is teaching and \\npublishing and not building software or data science.\\n \\nGiven that you had the experience of working in industry before going back to \\ngraduate school, do you feel that you had a significantly different perspective? \\nWere you looking at the academic problems you were facing in grad school \\ndifferently because you’ve had a chance to dig your teeth into them already in the \\n“real world”?\\n \\nOne thing I always say, and I tell this to people all the time, is that I highly recommend \\nnot going directly from undergraduate to graduate school. Even if it’s just to work for a \\nyear, I think it provides you so much more insight and experience in the kind of problems \\nthat are interesting to industry versus the problems that are interesting to researchers.\\n \\nMy early industry experience was unique in that the work I was doing in the intelligence \\ncommunity was split between two halves. One half was the classic intelligence aspect: \\nstudying people for short-term projects that have to be turned around in a very narrow \\ntime window.\\n \\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 74}, page_content='70\\nI highly recommend not going \\ndirectly from undergraduate to \\ngraduate school.\\nThe other half of my job looked much more academic. These were long-term research \\nprojects; we were working with specific agencies that had the capacity to do high-risk \\nresearch. Through that experience I decided that I really enjoyed and was interested \\nin solving hard problems. One of the problems we worked on is how to enable non \\ncommand-and-control structures (e.g., organizations without coherent org charts) to \\nmake choices.\\n \\nFor example, in a command-and-control \\norganization like the army, if you’re \\nLieutenant Colonel and you’re promoted to \\nfull Colonel, everybody understands how \\nthat works. However, when you’re in a non \\ncommand-and-control structure, different \\npeople in each part of the network have different responsibilities. One does fundraising, \\none does surveillance, and one does operations. Suddenly there’s a person from the \\noperations cell who gets captured; how does that operations cell make a choice about \\nwho will become the new leader? Or does someone get taken from another cell and \\nworked through the system that way?\\n \\nWe’ve thought a lot about how to solve that problem and we didn’t solve it at all. \\nHowever, I got really excited about the thought of solving longer-term problems. So I \\nhad another reason to go to graduate school. There was a lot of freedom to think about \\nsolving problems that I found interesting.\\n \\nI think the basic difference there is in industry is that it’s about always solving someone \\nelse’s problem for them. Now, that’s not an absolute truth, but certainly when you’re \\nstarting your career you’re almost always solving someone else’s problem. Then when \\nyou get to graduate school, you get to think of those problems on your own. The issue \\nis sometimes those problems are really boring or they’re not interesting because you \\ndon’t have enough experience or enough knowledge to recognize good problems. That’s \\nwhere mentorship as a graduate student becomes important.\\n \\nIf you’re going to go to graduate school, you’ve got to trust in and work really hard with \\nyour advisor because if you don’t, you’re probably going to produce bad research. It’s \\nway easier to produce bad research than it is to produce good research. In industry the \\nobjective function is set by someone else; that objective function typically is profit and \\nthe problems are usually smaller and more attainable.\\nSo if you have experience on either side of that, you can be more reflective about how \\nit might be on the other side. I think that there is a certain strictness versus a freedom \\ncomponent and there’s positives and negatives on both sides. It’s really about what \\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 75}, page_content='71\\nmotivates the person doing the work, what kind of stuff you like to do, and how you see \\nyour own self-worth measured in terms of what you’re contributing. Because in either \\ncase, you’re never truly independent. That’s a fallacy that’s built in at graduate school.\\n \\nIn reality, you’re the furthest possible from being autonomous during graduate school. \\nYou’re certainly more autonomous than you would be working for a big company on a \\nteam. But you have many masters as a graduate student, the least of which is yourself, \\nand you have to be really good at maintaining your own schedule and solving a problem \\non your own.\\nYour book “Machine Learning for Hackers” is in the canon of data science now. \\nGiven that, can we talk about the tools that you have found to be useful in your \\ncareer and also while doing data science? How do you discover useful tools for \\ndata science work?\\nPersonally, I am not as much a lover of languages as some computer scientists are. Have \\nyou ever heard of the Strange Loop Conference in St Louis? It’s in St Louis every year; it’s \\na fantastic conference and I highly recommend it. But it’s for people who love tools and \\nlove programming. So I went there and was doing an introduction to machine learning \\nprogramming. I found I was very much a fish out of water there. I was surrounded by \\npeople who I respect and who do interesting work and all they cared about talking about \\nwas the hot new programming language.\\nSo my approach to tools is: is the cost-benefit of me taking the time to learn the tool going \\nto have a significant impact on getting my work done more efficiently or effectively?\\n \\nFor example, I’m now known as an R programmer because my book heavily uses R. \\nThe truth is, I’d never written a line of R code before I got to graduate school. I was a \\nJava, Python, command line programmer from undergraduate, along with a little bit of \\nMATLAB. When I went to graduate school all the statistics classes were taught in Stata. \\nIt’s a point-and-click statistics program and you have to play by the rules. Eventually \\nwhat the program allows you to do is, you have to use this highly stylized, domain-\\nspecific language for Stata called Mata. During graduate school, we were writing our own \\noptimization functions in Mata. I was looking at the syntax and I didn’t know how I was \\ngoing to do it. It was so far afield from any relevant training I’d had in computer science. \\nSo I raised my hand and asked, “Can we do our problems in R?” And the guy teaching the \\nclass said, “Sure, I don’t care.”\\n \\nSince I’d never programmed anything in R, I set out to teach myself how to program in R \\nsimply so I could finish my problem sets for my Intro to Statistics class. For me, once I’m \\ncommitted to doing it I really want to learn it all and go really deep.\\n \\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 76}, page_content='72\\nI want to point out that I’m building up a little bit and giving you a false sense of the \\nbinary nature of this tool choice. I’d known for a while that R was a language that had \\na lot of things in it that would be very useful for me. But it has a very tricky syntax \\nand it’s not designed well as a language. So it’s a little bit of a steep learning curve at \\nthe beginning, but once you get over the hump you can do these wonderful things very \\nquickly.\\n \\nIt was the same thing for me with \\nJavaScript. No one in their right \\nmind will ever ask me to build a \\nwebsite. I don’t do that, it’s not \\nwhat I’m good at. But, I got to \\nlearning it eventually when I was \\nblogging more often. I was so \\ntired of posting an image file of a graph I’d drawn; it would be much more interesting \\nto have some interactivity where the image or the graph wouldn’t just answer the first \\norder question: what is the structure of the data? But that it could also answer the second \\norder questions: Who is this point? Why do we see what we see? \\n \\nMy entire motivation for learning JavaScript was so that I could use d3. All I cared about \\nwas being able to create interactive visualization. There’s a useful tool out there that I \\ndon’t understand how to use, so I’m going to learn it so that I can use it. And now, for \\nme, — the worst JavaScript programmer in the world — everything to me is a d3 problem. \\nYou could ask me to create a simple online form where I’m collecting your address and I \\nwould use d3. I don’t really understand any other way.\\nI learn something through trying to solve a problem. In that process I brute-force my \\nway into having a better understanding.\\n \\nI’m the same way with mathematics and statistics: I learned probability theory, calculus \\nand linear algebra. I was interested in solving a problem and those were the tools I needed \\nto learn. I didn’t have a pure love for those things. Some people love math and love to \\nlearn about math. I think it is beautiful, but I’m not an artist. I’m more of a mechanic.\\n \\nI think that’s powerful and pertinent for people who feel they can’t get started doing \\nthe things they want because they haven’t checked all the technical boxes. It seems like \\nanother way to do it is actually go into what is the problem you want to solve. Since we \\ncannot solve the problem because of a particular tool or medium of expression, then go \\nand learn how to do a particular part. You’re always told to solve the problem first.\\n \\nThat was our motivation for “Machine Learning for Hackers” too. People who are sitting \\nDREW CONWAY\\nIn New York, the anchor industry has always \\nbeen finance, media, advertising, entertainment \\nand to a certain extent, higher education. Those \\nanchor industries have always been about data.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 77}, page_content='73\\nin a job who are now being asked to run a classifier are asking themselves: What’s a \\nclassifier? One way to learn what a classifier is, is to go and read Hastie and Tibshirani, or \\nsome classic machine learning text, and try and beat yourself up over all the notation in \\nthat book. 90% of people don’t have the time or don’t want to have to read that. A better \\nway would be to say, “Here’s a problem you’re trying to solve. Here’s how you solve it. \\nHere’s a tool that will help. Let’s open up that black box a little bit. Explain to you a little \\nbit. Not talk about the math. If you care to learn there are other references, you can go \\nto. But it’s not a must. So “Machine Learning For Hackers” is written around 12 problems \\nthat we try to solve. That was the motivation. It was like writing a book that I wish I’d \\nhad before I went to graduate school.\\n \\nI will say it’s an exciting time. There’s a lot of opportunity for people to build that \\nlandscape. It’s very early days; people still don’t know what we’re talking about when we \\nsay data science exactly so there’s a lot of opportunity.\\n \\nWhat are the exciting data-related things that you’re seeing right now in NYC? \\nHow’s the data ecosystem evolving in New York, and what are the parts of it that \\nyou find exciting?\\n \\nI’m very biased in thinking that New York is the best place in the world to be doing \\nthis work. The reason I think that is, if you look at the history of any big city, they have \\nanchor industries that by and large define the city itself. You can look through a list of \\nAmerican cities and see that. If you look at Silicon Valley — the technology industry \\nhas always been the anchor for Silicon Valley. There, the focus has been on innovation, \\nsoftware engineering, hardware engineering and how to build better machines, better \\npieces of software.\\n \\nIn New York, the anchor industry has always been finance, media, advertising, \\nentertainment and to a certain extent, higher education. Those anchor industries have \\nalways been about data. As a result, what started as a nascent community in New York \\nhas gotten bigger and bigger and has been heavily influenced by the fact that everything \\naround you that’s happening is pivoting off of data; that’s how everyone in the city \\nmakes their money. So there’s billions and billions of dollars that go through New York \\nCity every day that are really a function of data science.\\n \\nThus, the data science community in New York benefits incredibly from its history. Now \\nwe have people who care about writing software, which is different from the same anchor \\nindustries that have existed in New York. However, these people still benefit from the \\nhuge talent pool and the huge amount of money in the city. Therefore it’s no surprise \\nto me that the data science community is growing very, very quickly. People are moving \\nhere to do this work because in a sense it’s always been here, it’s just now that people \\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 78}, page_content='74\\nare paying attention to it more, because it’s not the boring anchor industry that we’ve \\nalways known about.\\n \\nThe other piece that I’ll say for New York as opposed to other places is that we benefit \\ntremendously from our geography. For better or worse, Manhattan is a tiny island that \\nseven million of us live on. It was easy for me when I was in NYU to take a subway up \\nto Columbia or walk up to Union Square. It really galvanized our community because \\npeople were just close to each other. I could have lunch with Mike Dewar if I wanted. \\nThat’s great.\\n \\nWhereas if you go to other places, particularly Silicon Valley, it’s just so geographically \\nspread out that if I worked in San Francisco and I wanted to go out for lunch with someone \\nfrom Mountain View, it’s an hour-long drive.\\n \\nLikewise, if I wanted to go to a meetup \\nin San Jose but I worked in the Mission \\ndistrict, it’s a pain in the ass. You can’t \\ndo that. So it becomes much more \\ndisparate out there. If you look at the \\ncommunity as it exists out there, it is \\nvery broken up. I think that hurts them \\nbecause community for data science is really all about sharing ideas.\\n \\nIt’s much more collaborative in that way. I think New York has had a history of that \\nthrough different industries.\\n \\nRight. The density of the networks that you are interacting with is a huge factor in \\nterms of the information exchange of ideas and how cross-disciplinary you can be.\\n \\nWe tried to institutionalize that with Data Gotham in a sense. Data Gotham is the \\nconference that Hillary and I were doing, and people seemed to like that. Now there are \\nother geographies that are trying to do a similar thing. For example, DC has got one. \\nSimilarly, there are big data science conferences in Silicon Valley.\\nYou gave a talk recently where you made people stand up and promise to hire \\nmore social scientists. What advice do you have for people who have both a social \\nscience and a computer science background and who want to go into data science?\\n \\nThe piece of advice that I would have would be to continue following this track. You’re \\na social scientist and you care about human problems and the specific genre of those \\nproblems that triggers your interest. If you have a desire to solve a problem from the \\nSometimes others say to me, “You’re \\nso unique, no one else can make the \\ntransition from social science to data \\nscience today?” That’s absolutely wrong.\\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 79}, page_content='75\\nworld of social science using the skills of your computer science, you need to dive pretty \\ndeep into whatever the technical tool is that you care about. I talk to a lot of social \\nscientists who are thinking about learning Python or R and they’re not sure which one \\nto pick up, but just dive deeply into one of them.\\n \\nIt doesn’t make any difference. Just pick one, use it and learn from your mistakes, but \\nmake sure you’re asking intelligent questions.\\n \\nYou’re either trying to learn something new or you have an interview or a question that \\nyou ask that you don’t know the answer to and you can say, “I tried this, but I wasn’t \\nquite sure so I went back and tried something different.”\\n \\nA piece of motivation I would give people is that sometimes others say to me, “You’re so \\nunique, no one else can make the transition from social science to data science today?”\\n \\nThat’s absolutely wrong.\\n \\nThe problems that you care about, people will pay you lots of money to work on. Every \\nway that an internet company makes money is by humans making choices; the choice \\nto buy something, the choice to click on something, to share something, to connect with \\nsomeone.\\n \\nAll those things are questions that are fundamental to the social sciences. So you already \\nhave all of the training necessary to identify the problems that are out there in the real \\nworld. Now all you have to do is figure out how to solve them using the tools from an \\nindustry.\\n \\nDon’t think you can’t do it because, the reality is that you’re already way ahead of the \\ngame. Now you have to learn the easy stuff. The hard stuff you already know. Go learn \\nthese things, and then get better at it.\\nDREW CONWAY\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 80}, page_content='KEVIN NOVAK Head of Data Science at Uber\\nLet’s start off by talking a little bit about your background.\\nI am a Senior Data Scientist at Uber and run the dynamic pricing group today. I have \\nworn a lot of hats during my time at Uber and have been with the company for about 2.5 \\nyears. I’m the second full-time data person and 20th employee at Uber.\\n \\nWhat were you doing before Uber?\\nBefore Uber, I was a Ph.D. candidate in nuclear physics at Michigan State University. \\nI was there working on the cyclotron in the theoretical physics department. Anything \\ntheoretical, but especially physics, requires a lot of computer programming.\\n \\nIt’s a whole, long involved process, but essentially involves using statistical methods \\nto evaluate theoretical models for nuclear interactions. We then evaluated the models \\nbased on the output data from the particle accelerator.\\n \\nWe evaluated if models can be confirmed by experimental data.\\n \\nWhat got you interested in data science?\\nI always have been the bad physicist. I have always used computing tools versus using \\nan experimental setup. In undergraduate studies, I wrote a program to build computer-\\nKevin trained as a theoretical nuclear physicist where he \\nused statistical methods to evaluate theoretical models for \\nnuclear interactions. It was during graduate school that \\nKevin realised that he liked solving difficult problems, but \\nnot in an academic environment. A friend from undergrad \\ncame calling and soon Kevin found himself applying his \\nskill-set to solving the mathematics of logistics.\\nToday, Kevin is the head of data science at Uber, where he \\nleads a team collecting and analysing a vast array of data \\nwithin the Uber global network to inform product decisions \\nand better serve clients. He talks about the importance of a \\nrelentless curiosity to solve problems, and the need to develop a well-rounded suite of skills \\nacross engineering, data, and product.\\nData Science: Software Carpentry, Engineering and \\nProduct\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 81}, page_content='KEVIN NOVAK 77\\ngenerated holograms. As a physicist, I was always a bit different and did a mix of theory \\nand computer science.\\n \\nWhen I went to graduate school, I quickly realized that academia wasn’t the best fit for me. \\nAcademia wasn’t what I wanted to do for a career. I wanted to do something different, but \\nmy background was weird during those times when I had a highly specialized focus and \\na wide suite of computer programming skills. It \\nwas hard for the middle 80% of companies to \\nfind a good fit for the skillset that I brought.\\n \\nI got a call from a roommate in undergrad, \\nwho was an early engineer at Uber. The job \\ndescription required the ability to write \\nproduction code and to be good at mathematics. \\nIt was the perfect fit for someone with my \\nbackground and so I decided to join immediately in June 2011.\\n \\nYou mentioned earlier that the role at Uber required a mix of computer science \\nand mathematics, and that other companies simply didn’t know where to put you. \\nCould you elaborate on this?\\n \\nIt was hard for most mainstream companies to justify hiring a nuclear physicist for a \\njob that is not nuclear physics. That’s true in most specialties. I didn’t even know it was \\ncalled data science when I started out, and realized that data science was a buzzword \\nthat was rapidly growing up.\\n \\nData science encapsulates a skill set and a style of background. Almost everyone at the \\nUber data team is from a nontraditional background. Everyone here was doing something \\ndifferent at some point in their lives.\\n \\nThis unconventional transition for most data scientists may change in the future, but \\njust having the hackerish mentality and flexibility is very relevant for aspiring data \\nscientists. This ability to cross-pollinate ideas is especially relevant for startups where \\nyou are expected to wear different hats.\\n \\nSo you mentioned a little about what you think data science really is. If you had to \\nboil down the role and purpose of a data scientist, what would that be?\\n \\nData science is rapidly becoming a buzzword with all the positives and negatives \\nassociated with that. It helps to encapsulate a series of broad ideas as a rallying point for \\nindividuals like myself.\\n \\nIt was hard for most mainstream \\ncompanies to justify hiring a \\nnuclear physicist for a job that is \\nnot nuclear physics. That’s true in \\nmost specialties.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 82}, page_content='KEVIN NOVAK\\n78\\nAt the same time it can be easy to hype a concept without actually having a strong \\nunderstanding of what it is. In my opinion, the field of data science really has two main \\nspecialties. One is the concept of “big data”, where large amounts of information are \\nprocessed to derive mathematical insights. For example, Twitter and Facebook are \\nfamous for the products they’ve developed using this work style. \\nThe opposite specialization in data \\nscience (probably closer to my job) is \\na more highly specialized predictive \\nmodeler, where there is a need to \\nmake quantifiable decisions based on \\nheterogeneous pieces of information. \\nFor instance, predictions based on \\nincomplete information from a sales \\nrepresentative and information from another company which had done this before. \\nThese sort of predictions require a considerable amount of programming, statistics, and \\nmathematical intuition.\\n \\nHow much of your time is spent cleaning data vs. doing actual analysis?\\n \\nCleaning data is very different for the two branches of data science that I just mentioned. \\nOn the larger end, some statistical errors are negated by the virtue of having a lot of \\ninformation — the Law of Large Numbers. Everything converges on a normalized \\ndistribution; statistical anomalies will very rapidly disappear.\\n \\nOn the other end, when you are trying to do predictive modeling based on a small set of \\nincomplete information, one outlier can quickly throw your prediction off if you do not \\nhave a solid understanding of the process or problem that generated it.\\n \\nThe cleaning process is very different between these two regimes. On the smaller end, it \\nis more a matter of evaluating the confidence one has in one’s data, while on the bigger \\nscale, it is more about building up a more homogeneous data set to feed into algorithms.\\n \\nOne of the most rapidly changing areas of the field is cleaning data. There are more data \\nscience and numerical computation toolkits out there than there were 18 months ago. \\nWhere these toolkits shine is in their simplicity in allowing large amounts of information \\nto be thrown at them.\\n \\nThe operations are fairly simple in terms of cleaning data, but what’s challenging is \\nscaling these solutions to very large data sets.\\n \\nThis unconventional transition for most \\ndata scientists may change in the future, \\nbut just having the hackerish mentality \\nand flexibility is very relevant for aspiring \\ndata scientists.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 83}, page_content='KEVIN NOVAK\\n79\\nWhat are some of the most valuable tools and the most valuable skills that someone \\nshould have if he/she wants to work in data science?\\n \\nA lot of people have this biased emphasis on algorithms and programming languages. A \\nlot of the programming languages and problems that we worked on 20 years ago are very \\nsimilar to the problems that we face today. In the big data regime, algorithms that can \\nscale to massive data sets to deliver quick \\nfeedback already exist in closed form. So \\nthe algorithmic solutions already exist. \\nWhere you get paid as a data scientist is \\nthe skill in constructing a data pipeline \\nto feed into algorithms and knowing \\nhow to apply those algorithms in specific \\ncontexts. These skills are all derived from \\nmathematical and statistical intuition.\\n \\nSo a rudimentary understanding of mathematics and statistics will get you 85% of the \\nway there, while the last 15% will come from basic coding skills. A statistical background \\nand intuition will get you a long way. We’re not in academia anymore and can just skip \\nquickly to the solution.\\n \\nYou just mentioned this 85/15 split and for a lot of people that we’ve spoken with \\nthat have the adequate background, there’s this fear that they are not adequately \\nprepared in terms of programming and work experience. A lot of people are \\nconcerned that they don’t have the relevant practical skills to transition into data \\nscience. Could you speak a little to their experience?\\n \\nDifferent companies have a different opinion about what engineering and statistics \\nbackground is required for data scientists. At Uber, the data team is fairly engineering-\\noriented and we do a lot more implementation than a typical data science team. At a lot \\nof companies, data scientists are part of the business or product team and as a result \\ntheir work is a lot more qualitative, which obviously informs the job requirements.\\n \\nWe have to be able to write computer code in order to solve mathematical problems \\non a computer. Having the ability to write professionally organized software code is a \\nsecondary skill for data scientists at Uber.\\n \\nWhenever I talk to other data teams, I always ask where the data team is on the organization \\nchart, and that will tell you a huge amount about the implicit skillsets they expect you to \\nhave. Software engineering is a non-trivial part of our job as a data scientist.\\n \\nSo a rudimentary understanding of \\nmathematics and statistics will get you \\n85% of the way there, while the last \\n15% will come from basic coding skills. \\nA statistical background and intuition \\nwill get you a long way.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 84}, page_content='KEVIN NOVAK\\n80\\nBoth a statistical and programming background are valuable in different ways. You are \\nhired for the programming, but the statistical background is relevant for elevating you to \\nthe next level. So it’s really a tradeoff between these two skills which are both valuable.\\n \\nYou recommended for people to take a look at where data science sits in the \\ncompany structure. So here at Uber, what is it that you do that creates value to the \\ncompany?\\nWe are at our core an engineering team. In most startups, that setup is fairly common. \\nA lot of what we do technologically is backstopped by data. At the end of the day, Uber \\nis a company about logistics, about \\ngetting stuff to people quickly; all \\nof that is a math problem.\\n \\nOn the flip side, the data scientists \\nat Facebook or LinkedIn are a part \\nof their product teams. At the \\nend of the day Facebook is about \\nconnecting people and while the \\ndata component is a nice add-on, it \\nis not a core functionality of the company. Data informs how they scale the company, but \\nit’s not an engineering problem. So the requirements for a data scientist are different \\nbetween a company like Uber and a company like Facebook.\\n \\nSo how do you define personal success?\\n \\nI’m a data scientist and I’m also an engineer. At the end of the day I want to solve problems. \\nSo if I can solve problems today better than I could yesterday, then that’s a success.\\n \\nFor somebody who gets into data science and realizes that it’s not for them, what \\ncan these people transition into?\\n \\nA solid understanding of what’s not working will inform the direction of transition \\nbetter. Data science is at the confluence of computer programming, mathematics and \\ncommunication as part of the work structure.\\n \\nIf you don’t like mathematics, a better and more obvious role is to get into business \\ndevelopment of product.\\n \\nOn the other hand, if you like the mathematics but don’t like programming, an analyst \\nposition may be more suitable. Some people are arguing that a data scientist is an evolution \\nWhenever I talk to other data teams, I always \\nask where the data team is on the organization \\nchart, and that will tell you a huge amount \\nabout the implicit skillsets they expect you \\nto have. Software engineering is a non-trivial \\npart of our job as a data scientist.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 85}, page_content='KEVIN NOVAK\\n81\\nof the analyst, but I believe these two roles are on fundamentally divergent paths. An \\nanalyst is someone who is answering more financial or quantitative information using \\nan existing toolkit. A data scientist is more of a mix of software carpentry, engineering \\nand product.\\n \\nIf you are good at mathematics and engineering, but not good at communication, I \\nwould recommend becoming an engineer. There are a lot of organizational charts in a \\nlot of companies where the engineers are isolated from the other departments. A lot of \\ncompanies can offer that sort of environment where an engineer can just focus on the \\nproblem at hand.\\n \\nSo you’ve been at Uber for more than two years now and you mentioned this \\ndivergent path between the data science and the analyst roles. It sounds like you’ve \\nhad a lot of time to see how it evolves. Broadly speaking, what are the qualities \\nthat separate the amazing data scientists from the rest?\\n \\nI’m amazed by people who are intuitive about problems they have just heard about. For \\nexample, Josh Wills is a guy who has never seen my data set, and has only ever heard of \\nmy problems through media sources. Josh is someone who can come in and, off the top \\nof his head, reverse engineer the statistics of how people are behaving.\\n \\nHaving that sort of intuitive problem \\nskill is very important and on top of the \\napproximation skills will get you 90% \\nof the way there to being a top data \\nscientist. The other interesting skill set is \\nthe ability to work and execute on largely \\nopen green-field projects which would \\ntake an average team much longer to do.\\n \\nAgain, a solid understanding of what’s important and how to build your toolkit is the \\nbase for making you a rock-star data scientist.\\n \\nThe open green-field approach sounds a lot like the way in which academic \\nresearchers approach open-ended problems. What is the difference here in data \\nscience versus academia?\\n \\nThe perceived limitation of academia is that they don’t have the flexibility to go ahead \\nand do it. At the end of the day, academia is about understanding problems whereas data \\nscience is about solving problems and moving on.\\n \\nHaving that sort of intuitive problem \\nskill is very important and on top of the \\napproximation skills will get you 90% \\nof the way there to being a top data \\nscientist.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 86}, page_content='KEVIN NOVAK\\n82\\nWhat attracts me to data science is the ability to step on the gas and just go. I can \\nsolve a problem and move on as long as the relevant people involved in the decision-\\nmaking understand the solution. The approach is more like ready, fire, aim versus a more \\nmethodical process in academia.\\n \\nIn academia, one can work on open-ended problems indefinitely with no expectation \\nof results. How have you made the transition from the academia mindset to a more \\nresults-driven environment?\\n \\nThere are deadlines and very non-trivial \\nones. I have personally been blessed by \\nhaving one of the most leading CEOs in \\nthe industry. Travis is a data-nut, he loves \\ntalking about all sorts of problems. Early \\non he instilled a very experimental culture \\ntowards data science implementations.\\n \\nOne of the examples of this was an \\nexperiment we wanted to run where I \\nwanted to build a test bed to test out \\ndifferent hypotheses. Travis told me to put it into production to test it. That to me \\nexemplifies the entrepreneurial attitude compared to academia and speaks to the whole \\nready, fire, aim concept in entrepreneurial environments.\\n \\nIn academia, the approach would have been to spend a large amount of time doing \\nmeticulous contingency testing in order to come up with the best solution.\\n \\nMore forward looking, for you personally, what would you say are your personal \\ngoals as a data scientist over the course of the next year?\\n \\nI think we are at a pretty cool time in data science, where data science is on everyone’s \\nradar and we are over the initial wave of hype associated with the industry. We’re still at \\nthis phase where 80% of the promise of data science is still unfulfilled.\\n \\nThe leading companies in data, at least in terms of public perception, are still involved \\nin the social space. In my case it is the problem of “how do I give you a car faster?” In the \\ngrand scheme of things, the problem space that is being tackled with data science is still \\nvery open and expanding.\\n \\nAt Uber, we are solving the mathematics of logistics, but one can easily port the same \\nsolutions to solving the logistics problems of the world. For instance, what if one could \\nWhat attracts me to data science is the \\nability to step on the gas and just go. \\nI can solve a problem and move on as \\nlong as the relevant people involved \\nin the decision-making understand the \\nsolution. The approach is more like \\nready, fire, aim versus a more methodical \\nprocess in academia.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 87}, page_content='KEVIN NOVAK\\n83\\nuse data science to give you an ambulance to your location much faster than before? \\nSo when one takes a step back there are immense opportunities in the direction we’re \\nmoving in for data problems.\\n \\nSo the promise of data science is still very much the tip of the iceberg and that to me \\nis very exciting. To me the first part of unleashing this promise is to start building a \\ncommunity of data scientists to enable sharing of ideas.\\n \\nYou mentioned that we are on the tip of the iceberg in terms of applying data \\nscience to solving problems. What are some developments in the field that you \\nthink are emblematic of this trend?\\n \\nEvery person in data has their own pet project — something they love which they \\nalways talk about. I was talking to someone about genomics. There’s a really exciting \\ndevelopment with algorithms where we can analyze genomes literally as quick as they \\ncome out of the machine. The speedup in analyzing genomes is hugely exciting in terms \\nof the possibility of understanding our world.\\n \\nProblems in the healthcare space represent a \\nhuge data promise. It would be amazing if a doctor \\ncould just diagnose a patient without waiting for \\na lab test that takes two weeks.\\n \\nAnother exciting area is logistics, we touched \\nupon it with the ambulance example, but what if \\none could get an instant delivery without having \\nto wait 3-5 weeks for it to get shipped?\\n \\nAre there any other final pieces of advice which you would share with people \\nlooking to transition from academia to the data science industry?\\n \\nNothing convinces like success. If you can find a problem and solve it, or even implement \\nyour own solution to common problems, that is how you get people excited. Trying to \\npigeonhole it to specific problems is not the point.\\n \\nJust solve problems. Start applying data to real life and the rest will follow.\\nNothing convinces like success. \\nIf you can find a problem and \\nsolve it, or even implement \\nyour own solution to common \\nproblems, that is how you get \\npeople excited.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 88}, page_content='CHRIS MOODY Data Scientist at Square\\nThank you very much for being with us, Chris. Can you tell us a little bit about your \\nbackground?\\n \\nI went to Caltech as an undergrad to study Physics. There, I had projects that were largely \\ncomputational. \\nFor example, a project I was involved in was looking at dark matter simulations. Basically, \\nwe don’t know that much about dark matter, but we can guess at things that it could \\npossibly do. One of those things is that it could decay. If it decays, the dark matter particle \\ngets a kick, and it goes off in a random direction at a random speed. Galaxies are sitting \\nat the bottom of a gravity well; they’re like bread crumbs in a big bowl of dark matter. If \\nthe dark matter were spontaneously decaying and getting lots of extra energy, it could \\npopcorn out, and totally change the profiles of galaxies in an essential way. This was a \\nstrongly computational project that taught me many skills.\\n \\nAfter Caltech, I came to Santa Cruz for graduate studies, still working in computational \\nastrophysics. While I was there, I was doing all sorts of things pertaining to galaxies. We \\nwould look through the Hubble Space Telescope at the youngest galaxies in the universe \\nand notice that they were not at all like the galaxies today. Galaxies today are beautiful \\nspiral structures. But when you look back at the youngest galaxies, they are lumpy and \\nclumpy... they look like soup.\\n \\nSo, one of the questions was: Does that mesh well with our ideas of how our universe \\nChris Moody started off his journey towards data science \\nby peering off into distant galaxies, studying computational \\nastrophysics at UC Santa Cruz as a graduate student.\\nAs the data revolution hit the fields of science, however, \\nChris found himself having to learn how to use more \\nsophisticated tools that could process more data. He dove \\ninto programming and contributing towards open-source \\nastrophysics projects.\\nAll this culminated in a data science fellowship at Insight \\nData Science. After completing his Fellowship, Chris joined \\nSquare’s Data Science team. After leaving Square, Chris is now a data scientist at Stitch Fix, \\na fashion startup.\\nAstrophysics to Data Science\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 89}, page_content='CHRIS MOODY 85\\nformed? We started to look at the simulations and realized that what we observed through \\nthe telescope is what we were seeing in our simulations. We were super surprised at \\nthese theoretical predictions coming true!\\n \\nThe next part followed the \\nstandard trajectory of a lot \\nof businesses. We got one or \\ntwo really positive examples \\nof galaxies matching our \\npredictions, and were very \\nexcited about the progress. But \\nit was only one or two examples; \\nwe wanted to know if this was statistically significant, and so we started to scale up our \\ndata. We exploded from 100 gigabytes to hundreds of terabytes of data. This all started \\nat the NASA Ames supercomputer.\\n \\nIt turns out that it’s really hard to answer simple questions when those questions don’t \\nfit onto one computer. So we had to scale up a lot of our algorithms, and build our own \\ninfrastructure and framework. It was at that point that we started to get really interesting \\nresults. We started to see that this is generally true, and this attracted a lot of people \\nto our project, scaling up our people power. So we’d get other new graduate student \\nastronomers and explain, ‘This is how we work; this is how you can be efficient.’\\n \\nI think the romantic, public idea of a scientist is that you jump into a cave and then \\nfive months later, you have a ”Eureka” moment and you come out. Then it’s glorious. \\nBut that’s not really how it works. The reality is: you have lots of bugs, you make lots \\nof errors, and you have to work as a team, which means you have to be able to work \\nefficiently. You have to know how a pull request works. You have to know how commits \\nwork. You have to know how to document. You have to file bugs and report to issue \\ntrackers. You have to do all of these things.\\n \\nAt the end of all that, I realized that I most liked working with data. I liked working with \\nalgorithms. Actually, I absolutely loved working with algorithms. \\nI spent more time reading about how the algorithms worked and how they found all this \\ntruth, despite all the noise and red herrings in the data. I loved doing that and working \\nwith people on a project together. It was great. I thought galaxies were cool, don’t get me \\nwrong, but I liked algorithms more.\\n \\nIt sounds like you spotted a project, saw that it was interesting and used your \\nexperience of working on it to explore your interests. How did your background in \\nI think the romantic, public idea of a scientist is \\nthat you jump into a cave and then five months \\nlater, you have a ”Eureka” moment and you come \\nout. Then it’s glorious. But that’s not really how \\nit works.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 90}, page_content='CHRIS MOODY\\n86\\nscience inform your work as a data scientist?\\n \\nScience is getting harder to do. It’s harder to do it individually and it has to happen as \\npart of a team; a collaborative effort, so we can measure different things. Looking at \\npapers from 50 years ago: having a paper with 50 authors on it was ridiculous, that just \\nnever happened. Half the papers out there were published with only one or two authors \\non them. \\nNow, that’s ridiculously absurd. I \\ncan’t remember the last time I read \\na paper with only one author on it.\\nIt’s just because the instruments \\nyou have to use are larger. We end \\nup having to use supercomputer \\nresources or we have to use the \\nHubble Space Telescope to get somewhere. This means that the data and ideas are \\nstarting to grow much larger than one person can manage. In turn, it means that you \\nhave to learn how to work with other people. So that’s a paradigm shift of science, and \\nalso something that I think industry has been familiar with for a much longer period of \\ntime.\\nAt the same time, a lot of my exposure to things like software engineering best practices, \\nor even computer science, was completely self-taught. I didn’t take any formal classes \\nin these fields.\\n \\nThat’s really interesting that it worked out so well, and also that that didn’t hinder \\nyou.\\n \\nI think that’s actually pretty normal. Look at some start-ups. They’re really interested in \\nfinding someone who can actually do the work; someone who is trying to find and build \\na whole community and foster that growth. Take that person from the 90th percentile \\nand just teach them the remaining 10% of the small skills needed. These startups are \\nbasically instilling habits; thinking about what you’re going to do and how it’s going to \\nreflect on everyone else in the network, instead of being an isolated person.\\n \\nSometimes, that has to happen as a feedback reflex. You have to think of how you’re \\ngoing to fit in with everything else. You have to think about how your code is going to be \\nused by others. I was lucky in that I had a community leader in my project who was really \\ninterested in teaching everyone else how to work together, and I learned a lot from him.\\n \\nThis means that the data and ideas are \\nstarting to grow much larger than one person \\ncan manage. In turn, it means that you have \\nto learn how to work with other people. So \\nthat’s a paradigm shift of science.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 91}, page_content='CHRIS MOODY\\n87\\nOf your friends and peers from Caltech, many of whom have also gone on to do \\nheavy computational physics research, have you found that a substantial portion of \\nthem are heading towards industry?\\n \\nYes, especially in astrophysics. I can’t tell you how many plots I have seen in the last year \\nwith the number of faculty jobs remaining constant, or maybe even slightly decreasing \\nwith time, compared with the sky-high number of post doctorates. That means that the \\nlikelihood of a post doctorate job opening is going down at a ridiculous rate. Even when \\nI was in graduate school, the expected number of postdoctoral candidates went from two \\nto three. If it kept going at that rate, by the time I’d finished my first post doctorate, the \\nexpected rate would be four postdocs to every one position.\\n \\nClearly, there’s a huge supply of post doctorates and not that many positions within \\nacademia.\\n \\nHow much did those academic job statistics influence your decision on what you \\nwanted to do after graduate school? Did you feel you could get the same intellectual \\nstimulation from problems in industry as you received in academia?\\n \\nYes, it was a hard decision, but you look at it and think, ‘How many times do I really \\nwant to roll the dice? How much do I really like this?’ That fear of not finding a job really \\ndestroys a lot of the romance of science. I feel like a lot of people start doing science \\nbecause they have this romantic notion of becoming the best scientist, or contributing \\nin a noble way. But the truth is that science is a shitty ride.\\n \\nYou can do a lot of the same things that science will let you do, but you don’t have to do \\nthese things in the world of academia. You can work on science in industry. When I made \\nthat realization, and understood I could do a lot of the science, and be involved in a lot of \\nthe cool stuff I’d tried to do in the first place, it made me realize that I could switch to a \\nnew job outside of academia. At the same time, I didn’t feel that I was giving up on what \\ndrove me initially. There are a lot of startups that are changing the world, so instead of \\ntrying to define clumps and galaxies, I could try to actually work with somebody, and try \\nto change the world. I thought this was really cool and super exciting.  \\nSo then you joined Insight — a six week long Fellowship for PhDs looking to enter \\nthe field of data science. How much of what the Fellowship taught you would you \\nsay was new to you?\\n \\nAll of it. There’s a paradigm shift from science and industry. Everything in science is about \\na fully detailed presentation of an idea; exhaustively explicating all of the caveats. All \\nof the communication is bordered on fully defined facts, or at least as much as possible. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 92}, page_content='CHRIS MOODY\\n88\\nYou look at the borders of your project, the borders of the results, and you know the \\ndownsides and you know the upsides, and that’s because you’re terrified that someone \\nwill find a deficit in your project, and then nail you for it.\\n \\nBut then the opposite is true in business. The biggest problem is that people have very \\nlimited bandwidth. It takes a lot of effort, and there are a lot of people demanding it. So \\nthe crux of everything in business is actually being able to move all of your results in as \\nterse and precise a fashion as possible.\\n \\nYou don’t need to delineate all of the possibilities, you just need to say what is the major \\npoint, and you can go on from there. So, a lot of what Insight taught me was that you \\nneed to condense all of your results down as quickly as possible. You get someone’s \\nattention and you go; that’s the hardest part. As scientists, we were taught to give an \\nhour-long lecture on our project. We didn’t have to consider whether our audience was \\nbeing entertained or not. If they’re not interested, you don’t care. They’re not your \\naudience if they weren’t interested in the first place.\\n \\nIt’s the opposite idea during the Insight Data \\nScience Fellowship. You have to go out and \\nyou have to make every single connection for \\nyourself. You have to boil it down and make it \\ncompletely convincing that everything you’re \\nsaying is relevant to them, and you have to do it in \\n5 seconds. Everything is an elevator pitch. Every \\nYC Company has to give demos in 180 seconds. So Insight is all about building a demo in \\nthose 6 weeks, and then pitching it in 180 seconds. You’re basically pitching yourself as \\na candidate to those companies. You’re saying, ‘Don’t look at me like a graduate student. \\nI’m actually super goal-orientated, or systems-orientated. I can take all this data, apply \\nthese algorithms, and give you some amazing results.’ That’s what those three minutes \\nare for, and that’s the whole paradigm shift. Now, the focus is not so much on the new \\nidea or how much you’ve added to the body of knowledge. The focus is what can you tell \\nme in 100 seconds. That’s all the CEO has time for.\\nIn scientific lectures, you’re not trying to reach a super-broad audience. In the case of \\nscience, you’re trying to deliver an idea, and then you try to back it up in 15,000 words. \\nYou need to do that in business as well. You need to be able to take your idea and defend \\nit. The thing is that, here, you’re no longer trying to defend it to the CEO, you’re no \\nlonger trying to defend it to anyone else. You just need to defend it to yourself, and then \\nyou need to give them the ideas; there’s an implicit trust there.\\n \\nNo one else is going to check your work and no one else should check your work. You \\nEverything in science is about a \\nfully detailed presentation of an \\nidea. But then the opposite is \\ntrue in business.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 93}, page_content='CHRIS MOODY\\n89\\nneed to be an independent party and you need to break it down as to what is important.\\n \\nYou have to build up small kernels of truth, and that’s all you can deliver. A lot of the \\ntime, people find it distressing, but I thought it was great. I thought it was an awesome \\nchallenge to be able to compress my message down and figure out what all the tidbits \\nare. It’s like a whole design philosophy. I liked the idea of throwing out everything except \\nfor what you need to function. I like it from a designer standpoint and also from an \\nalgorithms and data analysis standpoint. I think that embodying that philosophy was \\nthe single most successful part of the Insight Fellowship. \\n“Data science” has now become a very common phrase in many business sectors. \\nYet, it’s still nebulous and no one is really sure what it means. So, what does data \\nscience mean to you? How would you break it down?\\n \\nIt means a lot. It always means to measure data, being able to make sense of that data, \\ncreate models of that data, and most importantly, to be able to communicate what that \\ndata means.\\n \\nI think data science splits into two fields, and I believe a lot of hiring companies are \\nstarting to reflect this. Data science is starting to break off into descriptive analytics and \\npredictive analytics.\\n \\nDescriptive analytics is, ‘we saw this trend.’ Or, for example, ‘We saw this spike or dip… is \\nthat because our service crashed? We saw this huge spike…is it a multiplicity of things?’ \\nIt’s always asking questions of dynamics, and then asking what is going on. So the raw \\ndata comes back, and then you make something useful — actionable business intelligence \\n– from that data. That’s descriptive analytics, taking data that has been produced and \\ntrying to make head or tails out of it, to drive some decisions out of it. So that might \\nmean, ‘We saw some really exciting events in Bulgaria, but why is our site exploding in \\nBulgaria and nowhere else?’ You may find out that it’s not really from Bulgaria, or that \\nit’s raining everywhere else, or a volcano just went off and everybody’s Tweeting about \\nit, or something ridiculous like that.\\n \\nThe other side of data science is predictive analytics; being ahead of the game. This is \\nwhere you’re shifting towards machine learning algorithms. You’re looking at things \\nsuch as fraud, where you’re trying to predict whether a transaction is fraudulent or not. \\nOr, you’re trying to figure out security applications: is this malevolent activity? But \\nthat’s what it is, fundamentally. It’s pattern finding within all the data, in real-time, \\nwhich adds additional constraints on computational complexity.\\n \\nData science rapidly becoming something concrete, especially as it becomes a more well-\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 94}, page_content='CHRIS MOODY\\n90\\ndefined field. But it’s definitely splitting off into those two directions of data, analyzing \\nit and figuring out underlying trends. If there are multiple trends, maybe it’s multiple \\nelements stacking up to produce the signal you’re looking at. Maybe it’s not really a \\nsignal at all, and it’s a bug somewhere, so you have to look at the data.\\n \\nThe other side is not just trying to make heads or tails of the data, but also making \\npredictions. Which city are we going to open up in next? What are the relevant quantities? \\nA lot of business is driven by intuition and gut feelings, and this scares a lot of people. \\nCEOs are trying to pitch entire companies on feelings, essentially. They’re trying to drive \\nhome their points on a colloquial basis. The whole field of data science is trying to turn \\nthat feeling into something a little more rigorous; trying to deliver on something that’s \\nnot intuition, and finding something \\nthat you can ground yourself on. \\nThat gives your business a lot of \\nstability, especially when there’s a lot \\nof startups and they’re all thinking \\nof great ideas, but only some of them \\nare really as great as they believe, \\nand most of them won’t pan out.\\n \\nYou engage a data scientist at the point when you’re looking to add an incremental \\nvalue. That’s not going to make your business take off, it’s not guaranteed. But at least it \\nwill give you something that’s not solely based on a feeling.\\n \\nOf the two different types of data science you articulated, do they also require \\ndifferent skills?\\n \\nFor the most part, they require a lot of the same core skills. Predictive data science \\nrequires a little more machine learning type skills, and descriptive probably requires a \\nlot more statistical skills. But then, in predictive data analysis, you might be using a lot \\nmore random forests or neural networks – all these really cool algorithms.\\n \\nWhich side of data science, from your physics background, seems more intuitive \\nwith you?\\n \\nI started learning programming In high school, because I wanted to play around with \\ngenetic algorithms. So that’s been a long running interest. Even though I went off and did \\nexperimental physics and computational astrophysics, I’ve always had this background \\nof really wanting to do machine learning. That appeals more to the predictive side than \\nthe descriptive side. Both of them have a lot of overlap. There’s not a wall between the \\ntwo, but you can start to see the continuum of data science. So, I think I’m far more \\nI think data science splits into two fields, \\nand I believe a lot of hiring companies are \\nstarting to reflect this. Data science is starting \\nto break off into descriptive analytics and \\npredictive analytics.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 95}, page_content='CHRIS MOODY\\n91\\nattracted to the predictive side. Neural networks I just think are really cool because \\nyou’re essentially training artificial intelligence. You’re taking these tiny artificial brains \\nand making a decision with them. You’re actually turning a whole company based on \\nthat.\\n \\nWhat do you feel are the defining qualities of a top-notch data scientist, compared \\nwith someone who is merely good?\\n \\nI think it deals with communication. I think that’s the difference between the good \\nscientists and the great. Both are going to know a lot about statistics, the techniques \\nthey can use, and how to design, implement, and execute an experiment. Those things \\nare all important. The biggest thing, though, is that you need to be able to communicate \\nthose results. That’s a lot harder than it looks.\\n \\nI think the easiest thing for a graduate student to do, coming into this field, is to gloss \\nover it, but that’s the single most important thing. Most people complain that graduate \\nstudents don’t have a great programming background. All of their other intuitions, well \\ndesigned experiments, caveated results, are sound. But I think that a lot of people believe \\nthat a programming background is not necessary.\\n \\nSo, maybe it is programming for a lot of people, but if you’re already pretty good, then \\nyou’re probably already a good programmer. The last step is just communication. People \\nneed to sense the passion inside of you. This defines the most successful people. It’s the \\nrealization that you are working with other people, and for a lot of scientists, I think \\nthat’s quite a shock. It really goes against this notion of romantic science.\\n \\nIsaac Newton spent three years in a shack during the plague. He didn’t want to get the \\nplague and he hated talking to everyone. Granted, he was possibly autistic in some ways, \\nbut I think a lot of people follow that archetype of going back and living by themselves, \\nand then they emerge with all of their findings. But in reality, it needs to be a much \\nmore continuous process. It needs to be a much smoother process than just coming back \\nand reeling off a list of accomplishments. So it’s always communication, but that’s the \\neasiest part to skip over.\\n \\nWhat do you see as the promise with data science, and also the interplay between \\nmathematics and computer science, that really speaks to you? Where does your \\npassion lie?\\n \\nWe’re living in a really exciting time because I think what were formerly highly theoretical \\nprinciples are finally having an impact on the world. Before, I was looking at clumps and \\ngalaxies. To do that I needed to run clustering algorithms. I needed to be able to run \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 96}, page_content='92CHRIS MOODY\\ndistributed frameworks on thousands of nodes to answer basic questions.\\n \\nNow, I can do almost the same stuff, and I can tweak a learning algorithm that teaches \\nstudents in the best way they can learn. There’s a whole feedback system that says, “you \\nshould answer these questions, and then five minutes from now, we’ll come back and \\nrepeat it, and then we’ll come back a week later and repeat it again.”\\n \\nThe wonderful thing is that those \\nalgorithms, that whole pattern, is \\nbeing replicated from galaxies to \\npsychology and cognition. All of \\nthese high topics of knowledge are \\nbeginning to trickle down, and they’re \\nactually making a real impact on day-\\nto-day interactions. There is not a single company on NASDAQ that doesn’t use some \\naspect of this. Your Facebook Newsfeed is highly tweaked to give you everything that \\nyou think is relevant, and new content to test your preferences.\\n \\nLinkedIn is using all kinds of graph networks. Square is using all these fraud detection \\ntechniques. HealthTap is fielding all of these questions, and training a computer to \\nunderstand what these questions are. And there really are doctors who will be answering \\na lot of those medical questions.\\n \\nThe cool thing here is that they can take a doctor and clone him virtually. He can answer \\na question, and that might reduce patient time in a hospital somewhere. And when you \\ntake that power, and you multiply it by the number of patients in the whole world — it’s \\na huge number. These are real things. We’re not limited to theoretical worlds. You really \\ncan go out and have awesome effects immediately, and they’re tangible. We’re collecting \\nmore and more data, to the point that there are not that many aspects of life that aren’t \\nbecoming data driven. So it’s super exciting.\\n \\nImagine if you were able to go back to the beginning of your graduate school \\ncareer, and you meet yourself coming in the corridors and you have a five minute \\nwindow to speak to yourself. Would you tell yourself to do anything differently?\\n \\nA lot of it would have centered on working more with people. I joined an open source \\nproject, and that was the single best decision in all of graduate school. I learned how to \\ncode in a collaborative way.\\n \\nThe second most important thing probably would have been communication. Every \\nweek, I would deliver a presentation on my results during the past week, and usually, it \\nI joined an open source project, and \\nthat was the single best decision in all of \\ngraduate school. I learned how to code in a \\ncollaborative way.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 97}, page_content='CHRIS MOODY\\n93\\nwould boil down to giving a two or three minute feedback session at the end of that. So I \\nwas already doing a lot of communication and I wouldn’t have changed that.\\n \\nMy programming context was great; maybe I should have started that earlier and taken \\nmore formal programming classes. If you were to design the curriculum, I’d say you have \\nto have a lot of programming. A lot of classes are like, ‘go and do this assignment.’ The \\nreal world is, ‘go do this assignment but you only have to do this module, and someone \\nelse will do the next module. You guys need to be working collaboratively.’\\n \\nThey should also be doing lots of statistics, and they should be able to do it as quickly \\nas possible. People love to talk about this Pareto Principle, where 80% of the outcomes \\nresult from 20% of the effort. The hard part is trying to figure out where that 80% line \\nactually is, and once you realize you’re at it, stop.\\n \\nHow can people find open source projects to participate in?\\n \\nA lot of the time, they already exist. You probably already know what they are because \\nyou hear about them. The biggest thing is not to be shy about it, and not to be scared \\noff. It took me a long time to work up the courage to actually push code back out and \\nbe able to take the criticism. No matter where you’re working, there are other people \\nworking with similar problems. Just go out and search for them. If they haven’t solved \\nyour specific niche problem, join the effort. It’s a worthwhile process. It’s really hard to \\nconvince graduate students about this, who are already overwhelmed with a lot of other \\nthings, but it is definitely the best part of those five years.\\n \\nYour advisor is going to be \\npushing you for results, and \\nmy advisor said it had been \\nyears since he’d written any \\ncode. So you might not realize \\nhow important this is. But in \\na world that is becoming way \\nmore team-based, both in \\nindustry and science, it’s super important to push everything into a team-based context.\\n \\nAlso, if you’re in science, you’re all about trying to communicate your results. One of the \\nbest ways to do that is through your open source network. They have an audience there, \\nwaiting for you, and they might be really interested. A lot of it is, ‘I built this feature onto \\nthis project.’ They’ll go try it out and maybe they’ll write a paper about it, and then you \\nget an extra citation.\\n \\nIt’s a little unfortunate that the primary currency \\nof science is citations and not source code, even \\nthough that’s a big infrastructure push. I think \\nthat will have to change going forward because \\neverything is being done in a team-based context.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 98}, page_content='CHRIS MOODY\\n94\\nThere are a lot of extra indirect effects. The direct effect is that you’ll be better. The \\nindirect effects are that there are a lot of other people who will benefit, and that will \\nreflect very well on you.\\n \\nIt’s a little unfortunate that the primary currency of science is citations and not source \\ncode, even though that’s a big infrastructure push. I think that will have to change going \\nforward because everything is being done in a team-based context. To do science more \\nefficiently, it has to be that way. There’s no other alternative.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 99}, page_content='ERICH OWENS Data Engineer at Facebook\\nPlease talk a little about your background and how you ended up at Facebook?\\nI studied mathematics and applied mathematics during college. I started with a focus on \\nmathematics and physics at a small liberal arts college called Albion. I then transferred \\nto Columbia University where I obtained a bachelor of science in applied mathematics.\\n \\nI worked at the Stanford Linear Accelerator and the Nasa Jet Propulsion Lab doing basic \\nresearch in materials science and systems engineering. I then transitioned to a Ph.D. \\nprogram in applied mathematics at Brown University, but dropped out after two years \\nwith a masters degree as I couldn’t see myself spending seven years on partial differential \\nequations.\\n \\nI moved out to California to work for startups. I realized that the most exciting thing for \\nme was data science and machine learning. I spent two years at startups called Quid and \\nNewsle and then joined Facebook four months ago as a software engineer with a bent \\ntowards machine learning and data science.\\n \\nIt sounds like you have this background in mathematics and you mentioned that \\nyou wanted to do more machine learning. Could you talk a little bit about how you \\npicked data science versus the other things you could’ve done in industry?\\nI guess when you’re a student at Columbia or Brown and you’re looking at what kind of \\njobs there are, finance is a recurring theme. You go and interview for quant jobs and you \\nErich sits at the intersection of data science and engineering, \\na role derived from his unique experiences across academia, \\nquantitative analysis and software engineering. After \\ntraining as an applied mathematician at Brown, Erich cut \\nhis teeth at Quid analysing an eclectic set of data. From \\nQuid, he moved on to Facebook where he currently works \\nas as data-centric software engineer — combining his \\ndeep theoretical understanding of mathematics with good \\nsoftware engineering skills.\\nHe stresses the importance of coalescing different silos of \\nknowledge and working with a business owner mindset to \\nprioritise important pieces of work.\\nThe Importance of Software Engineering in Data Science\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 100}, page_content='ERICH OWENS\\n96ERICH OWENS 96\\nrealize how there is this massive glut of smart people learning how to game arbitrage \\nwith marginal returns. In the grand scheme of things, finance just seemed fruitless.\\n \\nCompare that to the Bay area, where you have people learning how to build recommender \\nsystems, teaching systems to learn and that to me is very exciting. I think personally that \\nmove seemed accessible to someone with a mathematics background. It required heavy \\nuse of high dimensional vector spaces, linear programs, kernel methods, etc., which was \\na language I spoke already.\\n \\nOn the contrary, server client protocols and the more computer science concepts were \\nforeign to me.\\n \\nYou mentioned this a little bit earlier concerning your move into machine learning \\nand data science. Now that you’re at Facebook, what would you say is the value \\nthat you add as a data scientist?\\nIn the case of Quid, they had a whole team of data analysts who were interested in having \\nhumans label training data. For them to scale, it wasn’t about hiring hundreds of more \\npeople, but it was about teaching an algorithm to do what the analysts did. Their move is \\nlargely emblematic of the growth potential of Silicon Valley, where you get exponential \\nreturns by scaling hardware instead of people.\\n \\nI think finding people who could play around in Python and C++ and build these learning \\nsystems was hard.\\n \\nBriefly going back to your previous experience in academia, what would you say \\nwere your biggest challenges in doing research positions at SLAC or your Ph.D. \\nprogram to your roles at Quid, Newsle or Facebook?\\nAcademics don’t really learn to code \\nthe way engineers in the Bay Area \\ndo. You learn as an academic to hack \\ntogether code to produce results for \\nyour research. There is no incentive \\nto learn to code well or maintainably. \\nYou don’t think about object orientation, functional programming or other techniques \\nin the academic environment, which can be an impediment.\\n \\nWearing a business hat also provides a higher-level end goal which is sometimes not \\npresent in the academic environment.\\n \\nWearing a business hat also provides a \\nhigher-level end goal which is sometimes \\nnot present in the academic environment.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 101}, page_content='ERICH OWENS\\n97\\nHow did you overcome these challenges?\\nI first joined Quid as a quantitative analyst and I had a very basic level of Python skills \\nfrom academia. Fortunately some engineers at Quid took me under their wings and \\ntaught the basics of good software engineering.\\n \\nI think when you are a student in mathematics or physics, you think vector is a vector or \\na matrix is a matrix, but you don’t really think about how those representations tie into \\nthe computer. You don’t think about sparsity, run-time, etc., which are very important \\nin industry.\\n \\nThroughout our conversations we’ve talked to many people about their data \\nscience background because there is such a diverse set of ways for people to get \\ninto the field. What would you have done differently through school and work \\ngiven the experiences you’ve acquired?\\nI wish I plunged in more to build things, building websites or projects. When you’re \\ncomfortable writing things on a whiteboard, you get scared of code. I think iterating a \\nlot on a prototype is really empowering and lets you learn programming and languages.\\n \\nI wish I had programmed more, \\nbecause when I first moved to Silicon \\nValley, lack of coding skills was a big \\nstumbling block. I think my roles at \\nthe earlier startups also demanded \\na lot of iteration and prototyping, \\nwhich helped me learn a lot. The pressure to see results in industry made the learning \\nprocess a lot quicker compared to if I were learning in school.\\n \\nWhat would you say is the value that you bring to Facebook as a data scientist?\\nThe value I bring is not so much as a data scientist, but as a software engineer. Although \\nI borrow the tools of data science in terms of clustering , data analysis and classifiers, \\nI have the ability to build a scalable full-stack system. So I am not just building stand-\\nalone models which are pretty to look at which I’ll write a paper about, but where I add \\nreal value is by incorporating that model into a scalable system.\\n \\nIt’s really interesting that you say that because we’ve talked to people who say \\nthat their main value is not software engineering, but rather their quantitative \\nskills. Of the people you’ve worked with, how many tend to come from the math \\nto engineering transition and vice-versa?\\nI wish I had programmed more, because \\nwhen I first moved to Silicon Valley, lack of \\ncoding skills was a big stumbling block.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 102}, page_content='ERICH OWENS\\n98\\nFacebook has its own data science team which is full of brilliant academics. I talk to \\nthem to get advice on what features to build and what algorithms.\\n \\nHaving that isolated academic data science team is really useful for an engineer like me. \\nWe wouldn’t be as successful without them.\\n \\nI sit at the intersection of data science and engineering.\\n \\nCan you talk a little bit about where data science in Facebook sits in the organizational \\nchart or the product pipeline?\\nI’m on the public content ranking team. We want \\nto connect you to content that you may like. So in a \\nsense we’re working on a content delivery system.\\n \\nIn order for that to work, you really have to \\nunderstand how newsfeed-ranking algorithms \\nwork and what the goal for that team is. It’s one thing to rank and display your friends’ \\ncontent which is quite a finite problem, it’s another to aggregate all content on Facebook \\nat a given time to enable content discovery. The problem is much broader than that.\\n \\nData science at Facebook is a stand-alone organization, but I’ve met several data \\nscientists who have been embedded in different groups. So the structure depends on the \\nproduct. On some teams, data is used to inform product decisions, on others data is a \\ncore component.\\n \\nIn some ways these silos of data science remind one of Bell Labs, where you build great \\nthings and are not so worried from week to week about the details of short-term projects \\nor metric gains.\\n \\nSo you’re more insulated from the hard product deadlines and have more freedom \\nto explore?\\nThat would be my guess, but I am a software engineer. I think that would be accurate as \\nthe data science team does publish a lot of papers with the data Facebook collects.\\n \\nYou’ve been in a lot of roles from startups to Facebook, and you’ve surely met a \\nlot of data scientists along the way. What would you say are some of the qualities \\nthat separate the best data scientists from the rest?\\nThe brilliant ones I’ve seen at the few companies I’ve worked at were the ones who \\nThe value I bring is not so \\nmuch as a data scientist, but as \\na software engineer.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 103}, page_content='ERICH OWENS\\n99\\ncould read papers, prototype and then turn it into a scalable system. I’ve met quite a few \\npeople who would have a great idea, but would then take forever to implement it even \\nin Matlab.\\n \\nSo I think strong programming skills \\ncoupled with systems-level thinking \\nis very important. Building scalable \\nsystems may limit your ideas, but \\nit makes them that much more \\npowerful in terms of impact. At Quid, \\nfor instance, there were engineers \\nwho could build systems on their \\nown and think theoretically. In my opinion, the combination of strong theory and the \\nability to implement that in a scalable manner are makes a data scientist stand out.\\n \\nAre there any developments in the field of data science and machine learning that \\nreally excite you?\\nI like the idea of wearable computing, for instance Google Glass. Say you’re in this \\nneighborhood and you want coffee, but Glass could recommend a nearby art gallery. I \\nlike the idea of life recommendations, the idea of personal assistance, the idea of picking \\nup on personal signals and making recommendations.\\n \\nMore advanced algorithms based off linear separations like support vector machines \\n(SVMs) or deep neural networks that could learn intermediary steps or do automated \\nfeature engineering are very exciting.\\n \\nSay at some point that you would like to move on; do you think that your background \\nwould facilitate an easy transition to another field?\\nI’ve thought about hypotheticals, where say in 10 years I’ve built a great career at \\nFacebook and might go back to school to study quantum computers or some exciting \\ntechnology at the time.\\n \\nHaving a strong mathematical background really emboldens you to do these things. \\nThe nature of hiring at that age is different as you would no longer be a fresh college \\ngraduate, but an experienced hire. At that point, you may also have enough experience \\nto start your own company in an adjacent field.\\n \\nHow do you approach problems? What’s a mathematical way of approaching data \\nscience problems and how do you use that framework to solve other problems?\\nI think strong programming skills coupled \\nwith systems-level thinking is very important. \\nBuilding scalable systems may limit your \\nideas, but it makes them that much more \\npowerful in terms of impact.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 104}, page_content='ERICH OWENS\\n100\\nI’ll give you an example. When looking at time series of data, one usually opts for \\nanalyzing the entire data set which requires a large amount of memory to store, which \\nwill impede actual analysis.\\n \\nHaving learned mathematics and signal theory, I could use a low-pass filter and just keep \\na small buffer to learn the exponential moving average at any given time. You see how \\nan analog-to-digital converter can be useful in analyzing social data. I think spotting \\nanalogous metaphors between fields is the most useful thing someone from a rigorous \\nbackground can do.\\n \\nJust building off analogous metaphors — simulated annealing was inspired by \\nmetallurgy. How have you found your background in mathematics useful in cross-\\npollinating ideas to your current role at Facebook?\\nWhen it comes to recommendation systems, people will often use singular value \\ndecomposition (SVD) to do dimensionality reduction. For me that makes sense from \\na mathematical background, but I’ve seen stumbling blocks when talking to engineers \\nabout why that concept would be useful.\\n \\nThe ability to read a paper and understand \\nit is also very useful. For instance there is \\nthis beautiful technique called random \\nprojections where you populate a random \\nprojection matrix using ones, zeros and \\nminus ones, scaled by some normalization \\nterm. You can throw such a projection \\nmatrix against a high-dimensional vector and map it to a lower-dimensional space. \\nAccording to the Johnson Lindenstrauss lemma, you can guarantee with high probability \\nthat the interpoint distances will be mostly consistent. It’s a remarkable property because \\nyou basically scatter your data into the wind, but it’s still useful with the added benefits \\nof easier implementations and lower runtimes. It makes sense in terms of probability, \\nbut it seems really non-intuitive otherwise.\\n \\nWhat advice or feedback would you give to people who are just starting out on \\ntheir transition to the industry?\\nI think the most useful thing about being in college and graduate school for so many \\nyears was that I was learning for the sake of it and it was just very interesting. When I \\nwas doing applied mathematics I ironically wasn’t that interested in applications. When \\nI asked myself what I wanted during graduate school, I would say that I wanted the \\nI think spotting analogous metaphors \\nbetween fields is the most useful thing \\nsomeone from a rigorous background \\ncan do.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 105}, page_content='ERICH OWENS\\n101\\nautonomy to work on some really big and hard problems. That was as concrete as my \\ncareer goals were.\\n \\nI’m really lucky that the whole data science and machine learning industry existed when \\nI got out of school. I worry that if I were pragmatically focused on learning certain things, \\nI might miss more abstract concepts which have greater implications later.\\n \\nSo I guess I would encourage people to study what they like, but the way that worked out \\nfor me may not work for others. It’s difficult to give very specific advice.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 106}, page_content='EITHON CADAG Principal Data Scientist at Ayasdi\\nCan you talk a little bit about your background?\\n \\nI double degreed at the University of Washington in Business and Informatics; the latter \\nis a specialized degree that focuses on data architecture and how people interact with \\ndata and information. \\nI originally thought of Computer Science as a major, but took a few classes and realized \\nI didn’t want to be coding all at the time. So I opted for an option that potentially didn’t \\ninvolve significant programming, but did involve many things that you would typically \\nsee when working on applied technical problems.\\n \\nMy undergrad focus was on Ubiquitous Computing, and my undergrad capstone project \\nwas on embedded barcoding and handheld computing. I can attribute this to my first job \\nduring college, which was at Intel Research in Seattle. At the time, the Lab’s stated focus \\nwas on ubiquitous computing; this means embedding computing into your environment \\nor finding ways of using computing in ways well-integrated to the environment.\\n \\nI worked on two research projects there: LabScape and PlaceLab. LabScape asked the \\nquestion, “How can we embed computing systems within research laboratories to help \\nscientists?” Basically, we’d develop studies on how scientists actually use software in \\nthe lab. PlaceLab, the second project, asked “Can we utilize WiFi devices to triangulate \\nposition and provide location-specific information to a user?” Have you ever heard of \\nAfter dual degrees at the University of Washington followed \\nby a PhD in Biomedical Informatics, Eithon came to data \\nscience through a focus on machine learning applied \\nto biology. Although initially disinterested in low level \\nprogramming, Eithon came to see the powerful application \\nareas during his research and wrote a pipeline that is still used \\nto identify pathogenic proteins for structure crystallization. \\nAfter graduating, he worked on defense projects for various \\nUS government agencies, before striking into the heart of \\nSilicon Valley. At the time of this interview, Eithon was a \\nmanager and principal data scientist at topological machine \\nlearning company Ayasdi, where he led analytical efforts in \\nthe healthcare and pharmaceutical space. In this interview, Eithon talks about his personal \\njourney to data science mastery, and the joy of being insatiably curious. \\nBridging the Chasm: From Biomedical Informatics to \\nData Science\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 107}, page_content='EITHON CADAG\\n103\\n“wardriving”? Wardriving is basically driving around town with a computer whose Wifi  \\nscanner is on. You combine that with GPS, so you know the strengths of various signals \\naround your current location; this can be coupled with contextual information, such as \\nstores or services nearby. Then you triangulate that information that so when you or \\nsomeone else is in that area again, you can provide information on what’s nearby purely \\nfrom Wifi signal. Both of these were fun projects and I got to work with some really smart \\npeople at the lab.\\n \\nDid you learn how to write code during these projects?\\nI wrote very little code initially. I wasn’t a really good programmer at the time, and was \\nnot terribly attracted to coding, and for both projects I worked on the user side of the \\nresearch, such as usability and user testing. I didn’t become interested in programming \\nuntil a later experience in biomedical science where I saw code development as another \\ntool to accomplishing my goals.\\n \\nLater as an undergraduate, I interned at Seattle Biomedical Research Institute under \\nPeter Myler. My lab worked on infectious diseases, and my first project was to build \\nsoftware to identify genes. This experience got me really interested in biology and \\nresearch in general. \\n \\nThere’s a problem in biology which is pretty fundamental: you have a series of sequences, \\nDNA, and want to identify the location of genes. At a simple level you can find stop \\ncodons, which are short sequences that suggest the end of a gene. One challenge is \\nworking out where these stop codons start, as they sometimes have many potential \\nstarting points. Over the course of a summer, I built software that used a combination \\nof different methods to determine optimal starting position. I then used additional \\nbiological information specific to the species of parasitic genomes we were studying, to \\nfurther enhance the technique. \\n \\nWas that project the catalyst for you going to graduate school?\\n \\nYes, it’s also the project where I realized that coding wasn’t as bad as I thought, and \\nbegan to appreciate the importance of computer science in modern biological research. \\nAt the time, all the computer science classes I took were taught in C, which is probably \\none reason I was a little turned off to the field; I wasn’t great at pointers or deallocating \\nmemory. But this was a great project because it had an application. I got to see what \\nwas going on, how it had an effect, and it made me interested in learning more about \\nsoftware engineering as applied to science.\\n \\nI had a good understanding of the computational aspects because I’d encountered a \\nproject like that very early on.\\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 108}, page_content='EITHON CADAG\\n104\\nHow did you choose graduate school and also how did you choose what projects \\nyou wanted to work on?\\n \\nI started with a Masters. I was very interested in just learning more about computing \\nand biology, and I knew my school actually had a degree that was specific for this kind of \\nfocus so I opted to stay there. I went to the University of Washington for my Masters in \\nBiomedical and Health Informatics.\\n \\nMy focus was actually just the next step in the procedure of finding the genes. Now that \\nwe’ve found the genes, can we make a best guess about what it is actually doing in the \\nbiological system it operates?\\n \\nI used logic and data integration to annotate the genes; biology is full of databases that \\nhave information about genes. The problem is they’re so disconnected and fragmented \\nthat it’s difficult for someone to make sense of it. What we had was essentially a system \\nfor collecting this information wholesale and then federating them under some uniform \\nschema. This schema says: “Here’s a gene. It translates to a protein. Here is some \\ninformation associated with the gene.” \\n \\nI worked on this with my advisor Peter Myler and the head of my department, Peter \\nTarczy-Hornoch. Essentially, our solution was to treat these sources as a large database. \\nWe mapped the information of data sources in an automatic fashion to the contents \\nof the schema. Now you can start to ask things like, “What are the functions to which \\nthis gene maps?” We used logical inference to resolve these questions. Part of this was \\ndoing some shallow NLP , allowing us to parse the gene functions and other descriptors. \\nIt worked pretty well in comparison with human scientists doing manual annotation.\\n \\nThat was my Masters thesis. After that I wanted to work on something a little bit different \\nfor my PhD.\\n \\nWhile there is a lot of biology in your research, there also seems to be a strong \\ntheme of building and engineering systems. Did you continue this intermixing of \\nbiology and engineering in your PhD?\\n \\nWhile there was a heavy component of engineering, I wasn’t the only person working \\non the software platform on which my Masters project was built. There were a number \\nof other folks in the lab that were working on variations of the same data integration \\nmethodology to solve different kinds of problems. In my PhD, I thought what I was doing \\nwith logic was great but there was something unsatisfying about doing something that’s \\na series of conditional rules. I wanted something more unified.\\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 109}, page_content='EITHON CADAG\\n105\\nI started to read a lot about newer statistical methods. I thought we could apply some \\nof them to federated data for protein characterization. Data integration generated a ton \\nof information, and statistical techniques seemed to provide a more efficient way of \\nmaking sense of that information without requiring curated logic. So that’s essentially \\nwhat I did for my PhD. I took proteins and developed and applied a way of assigning \\nfunction to them using data integration and statistical learning. Luckily, William Noble, \\none of the early researchers who helped pioneer machine learning techniques in biology \\nwas a professor at UW so I was able to get his help.\\n \\nI focused primarily on pathogenic \\nproteins; these are proteins \\nin bacteria that tend to cause \\ndisease. An example would be one \\nthat facilitates the invasion of a \\nbacterium into the host cell; another \\ncould be a protein that helps the bacteria attach to the host cell. All these functions were \\nparticularly critical for a consortium run by my advisor, the Seattle Structural Genomics \\nCenter for Infectious Disease. The Center’s mandate was to characterize and crystallize \\nas many new proteins as possible from neglected pathogens.\\n \\nThe overall result was an approach that gathered heterogeneous and noisy data from \\nmyriad biological sources, unified them, and then used statistical methods to determine \\nthe likeliest protein functional class. We used the method that I developed to help \\nprioritize and classify proteins for wet lab investigation. Even now, I will get an email \\nfrom my old collaborators every so often saying, “One of those proteins that you selected \\nin your system was just crystallized, it has a structure we’ve never seen before.” It’s \\nwonderful and gratifying to see that my work is having a direct effect on the advancement \\nof life science.\\nGraduate school was a really fulfilling time for me, because I was able to spend time \\nexploring and found the specific niche in which I was really interested. If you have a \\ngood advisor and you have good support, it’s easy to do have this type of experience. The \\nproblem is that a lot of it depends on the luck of the draw. Did you pick the right advisor? \\nDid you pick the right project? It’s especially true in the sciences where if you pick the \\nwrong project, it might not bear fruit and you feel like you lost time. So I was lucky in the \\nsense that I had great advisors and really great research projects to work on.\\n \\nIt seems like although you didn’t necessarily concentrate in CS in undergraduate, \\nwhat you did for your master’s project and also your PhD was just as extensive \\nof an education in data integration, software engineering and machine learning \\nalgorithms. How did you learn these topics without a background in them?\\n \\nI took proteins and developed and applied \\na way of assigning function to them using \\ndata integration and statistical learning.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 110}, page_content='EITHON CADAG\\n106\\nI think I was fortunate at the very least. Even though I did not start with a lot of hardcore \\nprogramming skills, I did have a component of them from classes an undergrad.\\n \\nBut I think the biggest thing that contributed to my skill set was doing graduate school. \\nTypically, graduate school is taking a few core classes followed by going deep into \\nsomething you’re really interested in. As you go deep you are forced to learn the things \\nyou need to know along the way. So you end up taking extra classes, reading a lot, and \\nmeeting people who are experts in their fields because the goal is eventually to become \\nan expert in your own field; you have to know quite a bit to advance science even just a \\nlittle. At the time, as I learned more technical and analytical skills, it wasn’t learning just \\nfor learning sake, but as a means to an end. For me, this perspective made the learning \\nmuch more interesting.\\n \\nFor example, one of the things I ended up doing as an aside with some colleagues was \\nNatural Language Processing (NLP). We ended up organizing an NLP conference and \\nworkshop in my last year of graduate school. My role there was developing a quick software \\nsystem for annotating medical notes used by workshop participants, and designing the \\nstatistical technique to evaluate results. \\nIt was a competition. We had people from across the country submit their programs \\nand their methods to pull out information from natural language text, which is actually \\npretty hard. Not only did they have to extract the medication, but they had to report \\nthe route and dose for the medication, all from transcribed medical narratives. This was \\na nice opportunity for me to work more on both my software skills and my statistical \\ncapabilities. These are the sorts of opportunities available in research, and especially in \\ngrad school, that helped hone my skills in research execution.\\n \\nDid you also enroll in graduate coursework, or were you completely self-taught?\\n \\nI took quite a few CS and other classes where there was some significant programming \\ninvolved. Also, in my Masters program I worked a lot on a large code base. It was a fairly \\nsignificant repo, with multiple people checking in/out code. So I had to really know my \\nway around code and know that other people were going to be reading my work; I had \\nto write decent comments and know what’s going on. Also, it was all in Java, which is a \\nlanguage that somewhat enforces structured overhead to begin with.\\n \\nIn addition, I worked very briefly for Cerner Corporation; they make one of the largest \\nelectronic medical record systems (EMR) in the US. I actually got to work on pretty \\ncool R&D projects for their medical informatics group, and I had to keep the code well \\ncommented. Part of the exercise there was learning what is standard acceptable practice \\nfor software engineering. So that was a good opportunity to get an understanding of how \\nengineering is done in a much larger ecosystem.\\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 111}, page_content='EITHON CADAG\\n107\\nI think the nice thing about software development in general is that you don’t necessarily \\nhave to focus on it to pick it up. Reading is a pretty important component, both online and \\nin books. There’s a canonical book on software engineering with regards to generating \\nprogramming patterns. I read the whole book during the summer while I was working \\nfor that company. However, I don’t think there’s any better way than actually looking at \\nother people’s code and writing code yourself. I had some really brilliant colleagues who \\nwrote awesome code. So getting to see what they did and learning from them was a huge \\nbenefit.\\n \\nWe talked to several other people and it seems like your graduate experience was \\nvery extensive. Not only did you work on these two awesome projects but also \\nyou just found time to do extra bits.\\n \\nI hardly slept in my last year! You realize when you’re in graduate school that as soon as \\nyou’re finished, it’s the real world. So I wanted to cram as much opportunity to learn as \\npossible within the last couple of years there.\\n \\nThe other thing was that I got a scholarship \\nfrom the Department of Defense to finish \\nwithin a certain amount of time, because \\nafter that I’d get a job with the government \\nas a civil servant. So if I didn’t graduate in \\ntime I’d get a penalty of more time in the \\ngovernment, which was not necessarily bad, but I wanted the option to leave whenever \\nI wanted. My Masters was two years, a standard Masters. My PhD was about three and a \\nhalf. When the US government can come after you for not finishing your degree when \\nyou said you would, that’s pretty good motivation to finish on time!\\n \\nSo immediately after graduating, did you have any thoughts about staying in \\nacademia?\\n \\nYes, I always considered it. But I had this obligation to the government to finish first. \\nBecause they paid for my last half year so I owed them the same amount in service.\\n \\nOne of the things that come up when people are thinking of leaving academia is that \\nthey feel isolated, whereas the draw of industry is that it’s intensely collaborative. \\nWhat was your experience like?\\n \\nA computational biologist will often work in conjunction with other scientists. If you \\nthink about a modern biological lab, you have a Principal Investigator, a number of \\ntechnicians, wet lab scientists, people doing data management and then you might have \\nI don’t think there’s any better way than \\nactually looking at other people’s code \\nand writing code yourself.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 112}, page_content='EITHON CADAG\\n108\\na set of computational biologists. I think in modern biology you have a multidisciplinary \\nteam working on the same general problem where each person has their own task. One \\nperson designs experiments, another person does the data management. A different \\nperson follows up and sees if the results corroborate with models.\\n \\nSo in some sense it’s a squad. Each person has a specialized role and has ownership. \\nIt’s also very humbling because even for your small piece, you often realize there is \\nsomething you didn’t take into account. That’s just biology: unless you have a gigantic \\nmemory capacity, you’re never going to commit the entire breadth of the field to recall.\\n \\nAfter your stint with the government, what were your thoughts on what to do \\nnext?\\n \\nOne thing about science PhDs is typically you have to do a postdoctorate. I liked working \\nfor the government because of the emphasis on application; what I did there was being \\nused to make decisions. So I wanted to find a postdoctorate that would give me that \\nsimilar experience while still considering government as a field of work. I ended up \\ncoming over to Lawrence Livermore National Laboratory in Livermore, California, to \\nwork as a postdoctoral scientist.\\n \\nIt was perfect because it gave me options. I could stay in government because it was still \\na government institution. However, it was also a postdoctorate so it meant I could go \\ninto academia afterward. Finally, it put me within striking distance of Silicon Valley. I \\nfelt it maximized my opportunities at the time.\\n \\nAfter finishing your postdoctorate you had the chance then to look for academic \\npositions, but also you were really close to Silicon Valley so there were a lot \\nof startups and industry opportunities. So how did this influence your thought \\nprocess?\\n \\nI have to admit that I probably wasn’t as committed to doing academia at that point. \\nI think if someone is so close to everything that’s going on in Silicon Valley you’d be \\nremiss to not at least think about it. My postdoctorate was about to end, and the funding \\nwas lacking for this project. So there was uncertainty with regards to the likelihood of \\nfinding another project in my field there. Biodefense funding in government tends to \\ncome in waves of feast or famine.\\n \\nI happened to be contacted by a recruiter out of the blue, who mentioned some mobile \\ngame companies that were really interested in finding someone to do data analysis and \\nsoftware engineering. So I thought, “I’m actually interested in biology and medicine, \\nso if there’s anything there that would be a better fit.” She called me back later, tells \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 113}, page_content='EITHON CADAG\\n109\\nme about this company, Ayasdi, and sent me a summary of what they were doing. It \\nlooked quite interesting, and ended up interviewing and joining. I think I was the 15th \\nemployee of the company. \\nAnd you’ve seen Ayasdi grow from a 15-person company to now many multiples \\nlarger. You’ve worked in many different settings, including very applied projects, \\nthat eventually led you to the exciting world of startups, although it was never \\nyour direct intention. Do you think yourself very fortunate?\\n \\nLet me just step back a little bit. When \\nyou pick a major in undergraduate, part \\nof that decision is thinking about what \\nkind of job you want after you graduate. \\nAn important part of that question is: \\nwhat are the skills that you want to pick \\nup along the way? I don’t think graduate \\nschool is any different. I think one thing \\npeople in grad school have to be aware of is if they’re not fully committed to academia, \\nyou have to make sure that you’re building enough of a general skill set that you still \\nhave plenty of non-academic options open.\\n \\nTake my grad work in data integration. I wouldn’t call myself a world expert in it, but \\nI also know it’s a challenging problem that’s important for people to pick up and am \\nfortunate to have gained valuable experience in it. In many cases, it’s a neglected area of \\nexpertise. So you want to be able to pick up things that you know are going to be useful.\\n \\nBeing able to pick that up and learn from smart people and get their advice was extremely \\nvaluable. Domain and skill don’t necessarily have to be completely intertwined. You can \\nhave a domain focus (in my case it’s biology and medicine), but you can still continuously \\npick up skills that are applicable to that domain but also have broad generalizability to \\nothers. I’m thinking about not just undergraduate but also graduate school going forward. \\nMaybe you have a domain, but it’s important to understand that there are things that \\naren’t necessarily specific for that but are worth learning.\\n \\nFor me it’s been tremendously worthwhile. While developing the next iteration of \\nAyasdi’s software, we were at a little bit of a loss for how to figure out what to do with \\nregards to the usability. I actually got to leverage undergraduate experience to help our \\nteam fix some of the early difficulties with usability.\\n \\nAnother example is just general analytical capabilities. The challenge in science is \\nthat statistics isn’t something with which many researchers are very adept. In many \\nEach person has a specialized role and \\nhas ownership. It’s also very humbling \\nbecause even for your small piece, you \\noften realize there is something you \\ndidn’t take into account.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 114}, page_content='EITHON CADAG\\n110\\ncases designing an experiment, even a computational experiment comparing methods, \\nrequires just basic statistics — enough that you can write a paper that confirms you’ve \\nvalidated the results and you know that one method is likely better than others. \\n \\nAlso, I think breadth in our field is just as important in many ways as depth. Because \\nif you’re touching all this data of various size and form, it’s important to have a good \\ncharacterization of what you know and what you don’t know. The more broadly you have \\nthat, the better, but it’s also good if you have an area where you can go really deep. For \\nme that’s biology and medicine.\\nSo with all this in mind, when you joined Ayasdi, did you ever think, “Wow, this is \\nreally different from my previous roles”? And were there places where you thought, \\n“Wow I’m really glad I had x, y, z experiences because this feels exactly the same”?\\n \\nThis is a very interesting position in the sense that a lot of it is actually working directly \\nwith people. If I look back at my background it’s mostly been head down working-on-\\nnumbers research. So having this component of it is quite unique for me. We are doing \\nthat heads down and work part, but there’s also a very significant part that involves \\nworking with new customers and understanding what their current challenge is, and \\nhow best to convey a solution. One of the biggest challenges I had to overcome was to \\nsuppress my introversion enough that I could speak without stumbling over my words. \\nIt was a big hurdle initially, but I’ve had plenty of practice now and eventually got \\ncomfortable with it.\\n \\nSkill-wise, one of the key conditions when you’re looking at pharmaceutical data is that \\nyou have to be particularly rigorous about the statistics. This is a realm where we don’t \\nnecessarily want faster machine learning. We just want traditional, well-understood \\nmethods so that we know with some level of confidence that the results make sense. \\nFortunately, I’d had plenty of exposure during my graduate and undergraduate studies \\ndoing statistics and designing computational experiments.\\n \\nA lot of emphasis is placed on the use of more advanced methods when in many cases \\nhaving just a sound foundational understanding of basic statistics is more critical. It gives \\nyou grounding to look at an experimental design and understand at a very simple level \\nwhy it was design in that way. Why are these the main effects? Why are they characterizing \\nsomething this way? Why did they select these number of replicates? Using more exotic \\nmachine learning is great too and is often appropriate for contemporary data problems, \\nbut at the end of the day there are some really basic things that everyone has to know.\\n \\nWhen we say data science, most people think about just data but less about science. \\nA lot of people who do data science in industry start with the methods themselves \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 115}, page_content='EITHON CADAG\\n111\\nand never really ask the questions such as: “What is causing the phenomena in the \\nfirst place? How do I test that rigorously?”\\n \\nI think one of the good things in biology is you’re forced to ask those questions. Typically, \\neven simple methods can do quite well in biology under certain circumstances. I think \\nin some sense what we have at this company is a fairly simple method, and I think that \\nsupervised methods typically are a great way to start and a great way to start to get into \\nmore detail. But, at the same time you just have to guard against this desire to go after \\nthe most interesting method when sometimes the simplest thing will give you the best \\nand most explainable answer. As a scientist, I always want to be able to go back and \\nunderstand the underlying principles. But if you’re looking at prediction, maybe that’s \\nless important.\\n \\nYou’ve worked at Ayasdi for a few years now, but you’ve seen the injection of \\ndata science into the general vernacular of the technology companies. How do you \\nmake sense of what people are doing with the term “data science” today? How do \\nyou think Ayasdi fits into this ecosystem?\\n \\nI didn’t even know this term existed until I got this position. I didn’t know data was a \\ndiscipline of science. I thought it was a prerequisite for science, not a study unto itself. \\nI’ve heard the definition, “It’s someone who’s better at coding than a statistician, and \\nsomeone who’s better at statistics than a programmer.” In some ways you can turn it on \\nits head: it’s someone who’s worse at coding than a software engineer but is worse at \\nstatistics than a statistician! I’m joking of course, but that’s how I feel about it sometimes \\nsince I’m well aware of my own shortcomings.\\n \\nA lot of people that do this role have very interesting backgrounds. You don’t have a \\nhuge majority of people coming from a specific discipline; it’s mixed. When you look \\nat something like computational biology, we’re used to dealing with messy, noisy, ill-\\nformatted data. There are quite a few people who come from a biology background that \\ndo data analytics and data science. Maybe they picked up data wrangling skills along the \\nway to do extract-transform-load.\\n \\nThe other component that is also pretty critical is some kind of statistical training. At the \\nend of the day, the term data science means you’re a scientist, and you have an obligation \\nto deliver results correctly. If you’re not happy with it you go back to the drawing board. \\nThere’s an important ability to understand and be able to evaluate whether or not what \\nyou’ve done makes sense from a statistical standpoint.\\n \\nThen there is the domain expertise aspect. In many cases, we’re tackling problems that \\nare fairly difficult and that require a lot of knowledge of a particular area. Moreover, \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 116}, page_content='EITHON CADAG\\n112\\nbeing able to go to subject matter experts and speak the same language goes a long way \\nto gaining credibility and trust from the person with whom you’re working.\\n \\nI think many of the applied science areas \\nof study, and certainly things that involve \\nexperimentation, are where many people \\nget a lot of broad experience. Graduate \\nschool is great for giving you that deep \\ndomain knowledge and then hopefully \\nalong the way you’ve picked up sufficient \\namounts of statistics or mathematics to \\nspeak coherently about what you’ve generated, as well as the technical chops to execute.\\n \\nSometimes it’s just practice. For example, maybe you won’t know having certain data in \\na specific way is a problem, unless you’ve seen it before and have done the repetitions \\nto deal with it in a very fast way. If you do this enough, even a massive data set can be \\nturned over very quickly because you’ve seen it before and you know exactly what to do. \\nIn some sense a lot of it is as much pure practice as it is science.\\n \\nYou answered the first part of my question. The second part is: “How do you see \\ndata science in general?” Do you feel like Ayasdi is doing something different from \\nthe mobile apps companies? And if so, what is that special something?\\n \\nWhen you look at what a lot of places are doing, it’s variations on the same theme. \\nWhich isn’t to say that’s bad or wrong; sometimes that’s what you have to do and there’s \\na big market in making that better and faster. In many cases there are tools and methods \\nright off the shelf that one can adapt. Often, these were things that were developed just \\nfor those problems.\\n \\nThere’s been a big focus on supervised methods. However, as data grows, there are \\npotentially many outcomes of interest — for some problems, we may have little idea of \\nwhat to train for or what the expected outcomes even should be. It’s not that our current \\nmethods are deficient, but that with so much data, the number of potential questions \\nwith valuable answers grows very rapidly and cannot be enumerated by humans alone. \\nCan we take advantage of very basic ideas in mathematics, such as distance metrics, and \\nunderstand better where direct our attention?\\n \\nWhat we do at Ayasdi is a very interesting way of looking at the large data problem. \\nOur method applies well to high dimensional challenges or in many cases where people \\nare completely inundated with data but have no idea where to search for potentially \\nhigh impact discoveries. I can’t tell you how many times I’ve been in a meeting where \\nBeing able to go to subject matter \\nexperts and speak the same language \\ngoes a long way to gaining credibility \\nand trust from the person with whom \\nyou’re working.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 117}, page_content='EITHON CADAG\\n113\\nsomeone says, “We have a lot of data, we know there’s something awesome in it that we \\ncan use to optimize our process/business/medicine/drug. But we don’t know where to \\nstart.”\\n \\nBeing able to elegantly and mathematically tackle this is going to be extremely useful \\nas this becomes a very common problem. We’re already seeing this in many different \\nbusiness areas. Speaking just from my experience in biology and medicine, I see a lot of \\nopportunity as more genomic and health information is collected and stored. There is \\na huge amount of value in just asking the right questions; the problem is that human \\nability to formulate reasonable hypotheses is finite and limited. So being able to identify \\nand prioritize those questions in a data-driven way is going to be extremely important \\ngoing forward.\\n \\nWhat do you see coming out of the pipeline in the next three to five years in \\nmedicine and computational biology that you’re excited by, and that wouldn’t be \\npossible without the new data tools and techniques being developed?\\n \\nMedicine is a very interesting field. It’s a field where you need a lot of domain expertise \\nto be really proficient. Take a physician for example who has to go through many years \\nof school, sometimes more than a PhD, to be really good at what they do. How do they \\ndo that? They don’t do that by reading formulas or theorems. The biggest and most \\nimportant component of their training is going to the hospital and seeing patients. \\n \\nThat’s how medicine is. But I think as we move forward it’s going to be critical to inject a lot \\nof data there. To capture data, understand what’s going on, understanding how different \\npractices affect results and outcomes. That’s not even touching the genomic aspect and \\npersonalized medicine. There’s so much information, there’s so much variability in how \\npatients get treated across the board. How do we help make this more uniform?\\n \\nOptimizing patient outcomes is a very interesting problem because it’s something \\nthat’s always been there and surprisingly, we do all these things with data but that’s still \\nsomething that everyone wants to solve. I think that’s one area in medicine where where \\ndata science can help to make a positive and lasting impact.\\n \\nI think that one of the things you mentioned very early on that doesn’t get talked \\nabout much is just how much work it takes to be really good at something. When \\nyou first started working, you worked very late into the night, most nights doing \\nanalysis. What drove you, and drives you as a data scientist today?\\n \\nI think probably the biggest thing was curiosity. That’s actually a huge component. When \\nI’m up late and trying to figure out a problem, my personal goal is to better understand \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 118}, page_content='EITHON CADAG\\n114\\nwhat is driving whatever phenomena I am observing. I just want to find out. I’ve had \\nthis plenty of times here when working at Ayasdi, where I find myself facing a problem \\nthat is just driving me bonkers because I want to understand it better. Maybe I found \\nthis pattern and that pattern, and they all point to the same thing, but the outcome is \\nthe inverse of what I thought! So I want to dig deeper and know why. I think like any \\nscientist the thing that drives me the most and really compels me to work late into the \\nnight until the sun comes up is curiosity.\\nIf you could catch yourself in graduate school walking out of a lab at 3 a.m. and had \\na chance to speak to yourself, what would you have told yourself? How would you \\nhave lived life differently? Or would you have chosen anything different?\\n \\nIn terms of general direction, I probably \\nwouldn’t change very much. I love \\nbiology and medicine, and the work is \\ntremendously fulfilling. For the benefit \\nof people who are interested in the field \\nand doing data science as a career though, \\nI would definitely say take as many \\nstatistics courses as possible. If anything, I would have told myself, “Hey! I know you \\ndon’t want to take that statistics genetics course because you have a completely full \\nload, but take it anyways because you’ll end up using that information in your career at \\nsome point.” I end up having to look back at scattered notes or books because I didn’t \\ntake that statistical genetics course. Take more statistics courses, and take more math \\ncourses; though focus on statistics more than anything.\\nI think like any scientist the thing that \\ndrives me the most and really compels \\nme to work late into the night until the \\nsun comes up is curiosity.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 119}, page_content='GEORGE ROUMELIOTIS \\nSenior Data Scientist & Data Innovation Leader at Intuit\\nCould you start off by telling us a little bit about yourself?\\n \\nI’m originally from Australia, where I completed an undergraduate degree in applied \\nmathematics at the University of Sydney, and began a Ph.D. in physics which I completed \\nin the U.S. My focus was on theoretical and computational plasma astrophysics. More \\nspecifically, I investigated the physics of solar flares. I was a Senior Research Scientist at \\nStanford for several years before I realized that getting a tenured academic position was \\ngoing to be difficult -- there were so few spots in my sub-discipline. Around the same \\ntime, I started getting very interested in business applications of applied mathematics, \\nand eventually I decided to make the leap out of academia and into business.\\nIn the course of my research, I had developed Bayesian image processing techniques for \\nastronomical images, which led me into machine learning, which in turn led me into \\nonline learning. Now, those were the days when everybody was starting a company, so I \\ndecided to join the party. I co-founded Dynaptics with a few business partners, raising \\nabout $5M. This start-up pioneered the development of adaptive learning systems \\nto optimize online advertising. A non-technical marketing manager could “release” \\nmultiple advertisements into the system, and the system would learn in real-time \\nGeorge arrived on the fabled Stanford campus in the early \\n90s as a postdoc from Australia. After a couple of years \\ndoing research in theoretical and computational plasma \\nastrophysics, the beating drum of the tech boom of 90s drew \\nGeorge into the unconstrained world of dotcom startups.\\nUndeterred by the Dot Com Crash, George went on to found \\nJRG Software, which provided scheduling software for the \\nfood and beverage industry. His time as an entrepreneur \\nproved to be an invaluable experience in making him a \\nholistic Data Scientist.\\nToday, he is a Senior Data Scientist & Data Innovation Leader at Intuit, a leading provider of \\npersonal finance and tax software. His interview touches on the minutiae of the hard technical \\nskills, but also the macro and people skills which combine to make a holistic Data Scientist. \\nGeorge has since taken a role as a Distinguished Data Scientist at Walmart.\\nHow to Develop Data Science Skills\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 120}, page_content='GEORGE ROUMELIOTIS\\n116\\nwhich site visitor should be exposed to which advertisement in order to continuously \\noptimize the revenue stream. As the site visitor behavior changed over time, the system \\nwould automatically adapt. Those were very exciting days, and our customers included \\nMSN, eBay, and Cisco. Not so exciting was the Dot Com Crash in 2001, when the doors \\nfor additional funding slammed shut overnight. It was like nuclear winter for venture \\ncapital. We could not scale down our operations fast enough, so we had to shutter the \\ncompany and sell off the technology and intellectual property.\\nUndeterred, I went on to found another start-up, JRG Software, with another set of \\nbusiness partners, this time raising about $10M. That start-up was in a completely \\ndifferent domain, namely factory scheduling for the food and beverage industry. The \\nproblem we solved was to enable factories to rapidly adapt to changing demand without \\nholding a lot of inventory. One of our early customers was General Mills, which still uses \\nour system to schedule all West Coast production of Cheerios! The business challenge \\nwas how to penetrate the headquarters of large companies like General Mills where SAP \\nwas firmly entrenched. We were eventually acquired by a public company that added our \\nscheduling system to their product line.\\nAt that point, my wife said something along the lines of, “ Perhaps you should look at \\ndoing something other than a start-up next,” and I eventually arrived at Intuit as one of its \\nfirst Data Scientists.\\n \\nYou were at Intuit before people started calling themselves data scientists, right?\\n \\nThat’s right. And it’s been a fascinating journey.\\nAlong with the rest of the world, over the past five years Intuit has dramatically evolved \\nits thinking regarding the applications of big data and advanced analytics. Five years \\nago, the focus was entirely on marketing optimization. Then, starting about three years \\nago, the scope increased to include improving the user experience by analyzing how \\nusers are interacting with our products. Now, the focus is squarely on leveraging big data \\nand advanced analytics to create new products that solve important problems for our \\ncustomers. Our unique aim is to deliver “ Big Data for the Little Guy , which empowers \\nindividuals and small businesses by allowing them to benefit from the power of their \\nown data as well as the collective wisdom of millions of fellow Intuit customers. This \\nmeans that small businesses now have access to insights that were once only available \\nto big, multi-million dollar companies, and enables consumers to put their own data \\nback to work for them.\\nYou worked at Intuit before there was a lot of hype and discussion about this term \\n“data science”. As someone who’s been in this field for awhile, what are the myths \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 121}, page_content='GEORGE ROUMELIOTIS\\n117\\nand what are the truths when people talk about big data and data science?\\n \\nYou might have heard the joke, “What is a Data Scientist?” The punchline is, “ A Data \\nScientist is a data analyst, who just happens to live in California.” I think the hype \\nwill go away, but Data Science will be a permanent feature of the business landscape. \\nData Science is its own unique discipline, combining elements of applied mathematics, \\ncomputer science, business consulting, and, increasingly, new product development. I \\nconsider a good Data Scientist to be \\nlike a Swiss army knife, competent \\nacross all these areas, with deep \\nexpertise in one or two of them.\\nMore specifically, the technical \\ntable stakes for a Data Scientist \\nare advanced statistics, machine \\nlearning, SQL and Hadoop, and a mainstream programming language like Java. So there’s \\na combination of applied mathematics and computer science. But of equal importance \\nare business consulting skills. These are often overlooked, or added as an afterthought, \\nbut they are critical. Business consulting skills can be the difference between a Data \\nScientist and a Data “Gopher”.\\nA Data Gopher is someone who responds to incoming requests for analyzing this or that, \\nbut who never has a seat at the table when the business decisions are being made. On \\nthe other hand, a Data Scientist with business consulting skills is like a senior McKinsey \\nconsultant, who can translate fluently between business and technical domains, and \\nwho is a trusted advisor to business leaders. Those are highly non-trivial skills.\\n \\nWhen you talked about skills required in data science, you talked about three things: \\nclassical statistics or machine learning, computer science and business consulting \\nskills. What suggestions would you make to someone looking to build those skills?\\n \\nIn terms of database skills, it is essential to feel completely comfortable with SQL and \\nHadoop. If you are still on campus, for goodness sakes take advantage of that by signing \\nup for relevant basic courses that include a major project component. \\nIn terms of programming skills, learning R is very important. It is kind of ugly, but it is \\nthe lingua franca. Personally, I would stay away from proprietary, commercial statistical \\nprogramming languages. You know the ones I’m talking about. And certainly you need \\nto learn a mainstream programming language like Java or C++. Learning a mainstream \\nscripting language like Python or Perl also comes in handy.\\nI consider a good Data Scientist to be like a \\nSwiss army knife, competent across all these \\nareas, with deep expertise in one or two of \\nthem.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 122}, page_content='GEORGE ROUMELIOTIS\\n118\\nIf I had to assign a weight to help someone prioritize all this learning, it would look \\nsomething like this:\\nSQL      40%\\nHadoop     30%\\nR      1 5 %\\nMainstream programming language 10%\\nMainstream scripting language   5%\\nIn terms of acquiring business skills, you have \\nto get creative. At Stanford there was a fabulous \\nentrepreneurship course tailored to engineers and \\nscientists. Simply listening to lots of entrepreneurs \\ntell their story is very helpful. Subscribe to The \\nHarvard Business Review.  Talk your way into a \\nchallenging internship that presents you with an open-ended problem. Above all, just \\nstart an online business. It doesn’t need to be the next Google. Give yourself the challenge \\nof starting with $100 and seeing how much you can make it grow in a month. That can \\nbe quite eye-opening. Don’t become a Data Scientist who has never operated as much as \\na lemonade stand.\\n \\nYou have a very unconventional experience in that you left your postdoctorate \\nposition to found companies. Not only did transition from a postdoctorate to a \\nbusiness environment, but you jumped into the deep end and decided to start your \\nown company. What types of thinking did you feel like you benefited from during \\nyour experience in academia and what are the things that you felt were hindrances \\nto you when you entered the business world?\\n \\nHaving the foundation of applied mathematics was extremely useful, because then I \\ncould pick up other math-based bodies of knowledge very easily. On the Ph.D. side, I \\nmainly learned persistence.\\n \\nWhat certainly didn’t help me, and what I had to unlearn, was how academics present \\ntheir results to others. As academics, we’re trained to take an axiomatic approach. “Here \\nat the start of the presentation are my axioms, and here in the middle are the detailed steps \\nthat I took, and then here at the very end are my results. ” But if you do that in a business \\nmeeting, and you hand out copies of your slides beforehand, you’ll observe that the first \\nthing the business leaders do is flip to the back of the deck to see your conclusions. They \\njust don’t care about the detailed reasoning, because that is your job, not theirs. I have \\nfound it much more effective to start with “the bottom line up front” and then show the \\nthought process if there are questions. This is a very different mindset from academia. \\n \\nDon’t become a Data Scientist \\nwho has never operated as \\nmuch as a lemonade stand.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 123}, page_content='GEORGE ROUMELIOTIS\\n119\\nAlso, in academia you get kudos and endorphins from doing something novel. But in \\nbusiness it’s all about the efficiency with which the company can transform money into \\nmore money. So a Data Scientist needs to resist the impulse to solve problems ab initio, \\nor to spend time going from the 80% percent solution to the 90% solution. That effort \\nsometimes doesn’t make much business sense. You’ve got to think about allocating your \\ntime as though you were the owner of the business.\\n \\nIntuit is a very data-centric and financial-centric company.You didn’t start out in \\na business context, so what framework do you use to evaluate the success of \\npotential ideas at Intuit?\\n \\nThe way I look at business has definitely evolved, \\nespecially from being at Intuit. I’ve learned to \\ntake a hypothesis-driven, experimental approach \\nto developing solutions to business problems. We \\nshould all feel passionate about the problems we \\nare solving, but we must not fall in love with our \\nsolutions. We design experiments to let the customers choose between Solution A and \\nSolution B, rather than that choice being made by “the loudest voice in the room.” That’s \\na mistake I made in start-ups, and one that I saw a lot of other people make as well. We \\nwere all convinced that of course we knew what the market wanted, and we proceeded \\nto spend a lot of time building it. The way I work now, and the way I would have advised \\nmy younger self to work, is to create minimalist prototypes and test them out on real \\ncustomers. Don’t fall in love with your own ideas. Market feedback is the only thing that \\nmatters. You’ve got to do experiments, and you’ve got to be ruthless about changing \\nyour ideas based on the results of those experiments.\\n \\nWe’ve interviewed people who have recently made the transition to data science, \\nbut as someone who’s seen the growth and development of younger data scientists, \\nwhat are some of the mistakes often made by younger hires?\\n \\nFirst, you have to proactively build relationships with your non-technical colleagues. \\nData Scientists are often by temperament introverts, but if you want to be effective and \\nsuccessful, you need to step outside that comfort zone. Email a non-technical colleague \\nyou’ve never met, and ask them to lunch. Make it your responsibility to form such \\nrelationships before you need them.\\nNext, practice viewing the world in terms of business processes. What’s a business \\nprocess? It’s a foreign concept to many new Data Scientists coming directly from \\nacademia. A business process encompasses the people, systems and steps involved in a \\nbusiness activity. Generally speaking, a Data Science project has the goal of improving \\nDon’t fall in love with your own \\nideas. Market feedback is the \\nonly thing that matters.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 124}, page_content='GEORGE ROUMELIOTIS\\n120\\nsome existing business process. The truth is, it’s really difficult to change a business \\nprocess. \\nFor example, it took me a long time to grasp that improving the efficiency of a business \\nprocess might actually be perceived as threatening to someone’s job, and the natural \\nreaction of that person might be to consciously or unconsciously undermine any progress. \\nSo you have to develop deep empathy for the people involved in business processes, and \\ncreate solutions that help those people transition to higher-value work. That sounds like \\na lot of responsibility for a Data Scientist, but if you don’t think about things like that, \\nyour ideas might never be implemented in the real world.\\n \\nBeyond these three attributes, what does it take to be a successful data scientist, \\nin your opinion?\\n \\nA successful Data Scientist changes \\nthe world around them. It comes \\ndown to mindset. One mindset is that \\nyour responsibilities are to analyze a \\nsituation, construct a solution, and then \\npass along that solution to others for \\nimplementation. But that is a recipe for \\nfrustration for anyone who is interested \\nin moving the needle in the real world. A \\nbetter mindset is to think of yourself as \\nthe business owner who is responsible for changing how the business works. That’s a \\nwhole different mindset, one of taking ownership for how your ideas are going to be \\nimplemented and measured. The additional skill you need is influence without power. \\nHow do you influence others to move forward with your recommendations when they \\ndon’t report to you?\\n \\nHow do you influence others without power?\\n \\nIt is not easy, that’s for sure.\\nAs I said earlier, it starts with being proactive in forming relationships with your non-\\ntechnical colleagues, because people want to work with those they know and like.\\nIt is also important to go for small wins before trying to hit the ball out of the park. Small \\nwins prove that you are a reliable partner.\\nAnd you have to make the connection between your recommendations and the bottom \\nIt took me a long time to grasp that \\nimproving the efficiency of a business \\nprocess might actually be perceived as \\nthreatening to someone’s job, and the \\nnatural reaction of that person might \\nbe to consciously or unconsciously \\nundermine any progress.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 125}, page_content='GEORGE ROUMELIOTIS\\n121\\nline. Yes, that’s often very hard. There are usually many links in the chain between your \\nwork as a Data Scientist and the outcome for the business. But nobody else will do that \\nanalysis if you don’t. It goes back to having the mindset of the business owner.\\nWhen you’re looking for data scientists, do you feel there is a necessity for having \\nany form of senior academic credentials? A lot of the data scientists we’re seeing \\nnow have a Ph.D. background, but do you think this trend will continue into the \\nfuture?\\n \\nBack in the day, when relational \\ndatabases were brand new to the \\nworld, the folks who were most \\ncomfortable with that technology \\nwere at IBM Research. It is not \\nsurprising that the first relational \\ndatabase experts in industry had \\nPh.Ds, but over time the barrier to \\nentry has obviously been reduced. Data Science might be like that. Maybe. On the other \\nhand, Data Science might be more like brain surgery than SQL. I think it is too early to \\ntell. The well-rounded Data Scientist is competent in applied mathematics, computer \\nscience and business. Such people don’t exactly grow on trees. \\n \\nWhat distinguishes a data scientist from someone who works as a data analyst \\nin a traditional business intelligence role, or a statistician with programming \\nknowledge? How deep do these distinctions go?\\n \\nStatisticians might be steeped in mathematical tools for inference and prediction, but \\nthat alone is not going to make them an effective Data Scientist. They also need to be \\ncompletely self-sufficient in extracting and manipulating large data sets that are usually \\nfound in legacy systems, and which are often a noisy mess. They need SQL, NoSQL, and \\nprogramming skills to do that. And even if they have all the programming skills, but \\nthey don’t have superb consultative skills, they will have very limited influence. I think \\na Data Scientist is a very different animal from a statistician. But that’s just my opinion. \\nI’m not interested in getting into a religious argument about what constitutes a “real” \\nData Scientist.\\n \\nYou were the CTO of the first startup you founded and that seems to suggest \\nthat in addition to being an excellent physicist, you’re also quite skilled at building \\nsystems that provided software solutions built off your interests in image processing \\nor scheduling. Were those programming skills something you picked up during the \\ncourse of your graduate degree or was that more born out of need?\\n \\nIt is not surprising that the first relational \\ndatabase experts in industry had Ph.Ds, but \\nover time the barrier to entry has obviously \\nbeen reduced. Data Science might be like \\nthat.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 126}, page_content='GEORGE ROUMELIOTIS\\n122\\nI found that software engineering courses at Stanford taught you how to write a program, \\nbut they did not necessarily teach you how to work in teams, or with diverse systems that \\nyou have to integrate. And they did not teach you how to build, deploy and maintain \\ncomplex software. All that relates to project management and people skills which are \\nusually not addressed in computer science programs. So I learned those skills via trial \\nand error. Lots of error!\\nI acquired software engineering skills by actually building the Version 1 solutions at the \\ntwo startups I co-founded. I think it’s very hard for Data Scientists to work effectively \\nwith software engineers if they haven’t done any software engineering themselves. I \\ndon’t think a Data Scientist necessarily needs to be a production software engineer, which \\nis a different mindset yet again. But basic fluency — knowing how to write, document \\nand test code, and how to create components that are used in larger systems, that’s \\nimportant.\\n \\nWhere do you think data science is headed?\\n \\nI think we are going to see an explosion \\nof both consumer and enterprise \\nproducts that are made possible by \\nData Science — that is, by the creative \\nmelding of big data and advanced \\nanalytics. To achieve that, some \\nData Scientists will need to become \\nproduct designers, adding the skill of “design thinking” to their toolbox. Deep customer \\nempathy, rapid iterative prototyping, and in-market experimentation will be essential to \\nthis emerging sub-type of Data Scientist. Or maybe we’ll need a new name. Data Product \\nDesigner, anyone?\\nI don’t think a Data Scientist needs to be \\na production software engineer, which is \\na different mindset yet again. But basic \\nfluency ... that’s important.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 127}, page_content='DIANE WU Data Scientist at Palantir\\nTo start off with, how did you get started in data science?\\n \\nI did my undergrad in computer science and became interested in biological problems, so \\nI transitioned to bioinformatics and did a PhD in (Computational) Genetics at Stanford. \\nWhile I was there, I started taking classes in the CS department, in part out of interest \\ndue to my CS background, in part because I loved interdisciplinary approaches, but also \\nbecause these were rumored to be the most challenging classes.\\n \\nI took Machine Learning with Andrew Ng, Probabilistic Graphical Models with Daphne \\nKoller, Data Visualization with Jeff Heer, and Mining Massive Data Sets with Jure \\nLeskovec. I took these out of interest and because I thought they would be applicable to \\nwhat I was doing; sequencing and essentially going through terabytes of DNA sequences \\nto make sense of them. I was doing a lot of time series clustering, predictive modeling, \\nand building Bayesian models. I took these courses because I thought they would be \\nrelevant to my research, but what I didn’t realize through the entire process was that I \\nwas basically doing data science in biology.\\n \\nWhen I finished my PhD and decided I didn’t want to be in academia, I stumbled across \\nthe Insight Data Science program, specifically designed for helping PhDs transition into \\nWhile studying computer science at Simon Fraser \\nUniversity, in Canada, Diane became interested in biology. \\nAfter graduating, she began a PhD in genetics at Stanford \\nUniversity, where she also dabbled in courses in computer \\nscience and machine learning. Diane’s background in \\ngenetics naturally prepared her to working with large \\nvolumes of data, leading her to realize that the work she \\nengaged in at Stanford naturally belonged in the realm of \\ndata science.\\nAfter graduating, Diane became part of the Insight Data \\nScience Fellowship program where, as a Fellowship project, \\nshe built recipe searching site that used clustering to organize recipes by ingredients.\\nWhen we interviewed Diane, she was a data scientist at Palantir. She has since started a \\nnew role as a Senior Data Scientist at MetaMind.\\nThe Interplay Between Science, Engineering and Data \\nScience\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 128}, page_content='DIANE WU\\n124DIANE WU 124\\nindustry. Through this program, I realized that most of the training through my PhD was \\nessentially just data science. So the transition for me was very natural. I’m doing a lot of \\nthe same things, just not thinking about cells or biology! However, the same tools and \\nchallenges apply.\\n \\nSo after bridging this gap, where are you as a data scientist right now?\\nI work as a data scientist at Palantir — a \\ncompany that builds a platform that helps \\nintegrate data for our customers from the \\nmultiple disparate databases that they have, \\nand makes associations and inferences from \\nthese data. We work with customers from the financial sector, the medical space, \\ngovernment and local law enforcement. One of my jobs as a data scientist at Palantir is \\nto help create value out of their data and identify a human-computer symbiotic approach \\nto machine learning.\\n \\nGiven that you’re working with these large institutions, what is the scale of the \\nproblems you’re tackling?\\nThere’s a wide range. Some of our customers have hundreds of terabytes of data and \\nsome have a few megabytes. Some customers require a streaming solution while others \\nwant a static model based off all the information in their databases. The number of \\ndatabases we work with can also vary between one to many dozens.\\n \\nHaving worked as a data scientist for a while, what would you say are the main \\nresponsibilities and goals of data scientists at Palantir?\\nData science itself is a very strange term. It’s an umbrella term. In some companies and \\nin some roles, being a data scientist means to be a software engineer, building machine \\nlearning models in the back end. In this role, your success is very measurable--it is usually \\nthe accuracy or precision/recall of your model performance. At other companies or in \\nother roles, being a data scientist means that you’re an analyst working with engineers \\nto help them determine what features to build and how users are interacting with them. \\nIn this role, your success is less measurable, and it is up to you to find the right questions \\nto answer and then to try to make impact with that answer.\\nAt Palantir, we work with customers from a diverse number of sectors, with a wide \\nspectrum of problems that we solve by deploying our platforms against their data. One of \\nour core company missions is to pick incredibly difficult problems at institutions where \\nwe would provide the most value, and put our full force into solving these problems. \\nData science itself is a very strange \\nterm. It’s an umbrella term.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 129}, page_content='DIANE WU\\n125\\nSometimes, this means developing new capabilities in the platform. Sometimes these \\ncapabilities require data science techniques (machine learning, statistics, mathematical \\nmodeling), and that’s where we come in. I’m on the machine learning team at Palantir, \\nand we’re dedicated to enabling customer data science needs via our products. To this \\nend, we work closely with customers to help them scope their problems and turn an \\noften poorly defined, qualitative problem into a quantitative one. The process involves \\nidentifying an actionable goal or desired insight, evaluating the form, scale, reliability \\nand availability of the data, and building custom machine learning algorithms to solve \\nthe problem. And then we iterate. Always iterate.\\n \\nSome requests we get involve translating from qualitative problems to quantitative \\nones (identifying good proxy metrics to reach the right conclusion), statistics (doing \\nthe calculation on the data), and communication (presenting the data in a digestible \\nmanner). In most cases, however, our customers are requesting a predictive analytics \\napproach to a specific type of problem. They present a very difficult problem where a \\npredictive modeling component may be needed. Fraud detection is one of those problems, \\nfor example. It is clear that a computational algorithm could aid fraud detection by \\nidentifying patterns and outliers, but the problem is complex enough that it will likely \\nalways involve a strong human component. In such cases, it is not clear how we should \\nbreak up the tasks between the human and the computer. One of Palantir’s core values \\nis human-computer-symbiosis: let the computer do what it does best (crunch models, \\ncalculate metrics, etc.) and let the humans do what they do best (interpret patterns and \\nmeaning, make accountable decisions, especially with respect to the rights and well-\\nbeing of other humans). One of the overarching goals of our team is to figure out what \\nan ideal predictive analytical solution should look like and where on the spectrum it \\nshould lie.\\n \\nFinally, we also do data science internally, and often want to use product metrics to \\ninform business decisions. Engineers like to build cool things. It’s not intuitive to them \\nto think about things in a scientific way. I think that’s one of the reasons books on lean \\nproduct development are so popular. It’s because these are not intuitive concepts for \\nengineers. The role of a data scientist is to do the stuff that is a pain for engineers (but \\nfun for us), and help engineers make more data driven product development decisions.\\n \\nIt sounds like data scientists are evangelizing the scientific method to engineers!\\nIn a way, I guess that’s true. It’s intuitive to me to think in the scientific mindset because \\nI’ve been trained as a scientist for the past 4 years. It’s very natural for a scientist to ask \\nwhy, to dive into a problem, scope the hypothesis landscape and then perform tests. \\nHowever, scientific thinking is a double-edged sword, and is in some ways the opposite \\nof the engineer mentality. Scientists ask why something is the way it is before reaching \\na conclusion, while engineers execute on assumptions and watch to see if things break. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 130}, page_content='DIANE WU\\n126\\nOne of the hardest things in recruiting for data scientists is to find candidates who have \\nthe right balance of both scientific and engineering mentality. Almost always, with real \\nworld problems, there is no time to ask why and figure everything out before executing, \\nand you often have to act with incomplete knowledge. However, engineering without \\ndata science is like building a bridge without ever fail testing it. There is a delicate \\nbalance to be struck.\\n \\nWhat are some challenges and some of the things you’ve found easy in making the \\ntransition from PhD to Data Science?\\nThe reason why programs like Insight have been successful is because PhDs have been \\ntrained with a quantitative method of thinking. They’re also prone to ask “why” and \\n“how” rather than “what”. I think that most PhDs understand the presence of errors, and \\nhow to reduce a complex problem to a smaller problem with a quantifiable solution.\\n \\nOn the other hand, PhDs \\nare often stereotyped to \\nask “why” too often and \\nare sometimes caricatured \\nto have their heads in the \\nclouds. So if I find a PhD who \\nis also a hacker, then it is the \\nbest of both worlds. Indeed, \\nsome of the most effective \\ndata scientists I’ve seen have \\nbeen PhDs who worked on a number of side coding projects during their academic career.\\n \\nThe challenge for a lot of people is the ability to apply these insights into value. Not all \\ninteresting problems can produce insights, and not all interesting insights can inspire \\naction that causes change.\\n \\nDid you have any challenge in communicating your value as a data scientist?\\n \\nWhat I have learned in working with many different customers is that when people \\nrequest data science, they really just want magic. They want you to use all the data to \\npredict everything. When they approach data science, they often don’t actually know \\nwhat they want.\\n \\nThat’s the thing about being a data scientist in this time. It’s so new and sort of overhyped, \\nthat most people just know they want in on the excitement but don’t know how. They \\nwant things, but they have no true idea about what they want.\\n \\nOne of Palantir’s core values is human-computer-\\nsymbiosis: let the computer do what it does best \\n(crunch models, calculate metrics, etc.) and let the \\nhumans do what they do best (interpret patterns and \\nmeaning, make accountable decisions, especially \\nwith respect to the rights and well-being of other \\nhumans). \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 131}, page_content='DIANE WU\\n127\\nPart of the job is really use-case discovery. It’s not always about crunching the right \\nalgorithm. It’s about asking the right questions and framing the questions for yourself. \\nAnd once you do that, the problems tend not to be statistically or algorithmically hard.\\n \\nOn the other hand, there are people who think it’s overhyped and want you to prove that \\ndata science is worth their investment.\\n \\nSo in your experience, what distinguishes the best data scientists from the rest?\\n \\nThat’s a very good question. \\nThere are statisticians and there are computer scientists and designers. And then, there \\nare people who are very good at all of these things. The reason why this role — data \\nscientist — was created, and the reason why it’s a little bit undefined, is that it requires \\nthat you’re good at many different things. You have to think about problems, both as an \\nengineer and also as a statistician. You have to know what tests are right, how to approach \\nthe problem, how to engineer the solution and how to sift through large datasets.\\n \\nAnd then afterwards, you have to present your findings in a clear way. This might require \\nyou to create visualizations. Having an understanding of graphic theory and the language \\nof visualization is useful. This ties into communication because as a data scientist you’re \\ncommunicating with someone who doesn’t have a ton of time to analyze data. They look \\nat the figure and want to be able to extract meaning from it in a few minutes.\\n  \\nFinding someone who’s a good engineer and a good communicator is incredibly difficult. \\nYou don’t need to be the best at everything, but some people who are great communicators \\nneed to learn how to be great engineers and vice versa.\\n \\nIn academia, there’s a focus on open-ended problems. How have you made the \\ntransition to industry where there’s an environment to deliver on prompt deadlines?\\n \\nI think in an ideal world there should be a fusion of the two. In academia, it behooves one \\nto work with deadlines; most PhD students would probably tell you that if it weren’t for \\npublication deadlines and the fear of being scooped, we might never publish. Open-ended \\nproblems need to be scoped also, and often a 20% solution will get you 80% towards your \\ngoal. In industry, sometimes people can get too “hacky” and deliver v1 solutions all the \\ntime, and that can be bad too. Sometimes it’s good to step back and try our hand at some \\ncrazy ideas. I think that’s the inspiration behind company internal hackathons and why \\nthey’re so popular in the tech industry.\\n \\nWhat skills beyond what you’ve already mentioned (hypothesis testing, \\ncommunication) would you recommend to someone interested in data science?\\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 132}, page_content='DIANE WU\\n128\\nIt’s about asking the right questions and \\nframing the questions for yourself. And \\nonce you do that, the problems tend not to \\nbe statistically or algorithmically hard.\\nAs a preface, I think the skills you need to learn largely depend on what you want to do.\\n \\nI would put this into three categories:\\n1. Predictive Modeling: here, algorithms and some complex mathematical modeling \\nare required. Visualizations are probably not as heavily emphasized.\\n2. Business Intelligence: here you engage frequently with SQL and some scripting, but \\nyou don’t need great skills in computations and algorithms.\\n3. This is a spot in the middle: this is more science-y and R&D. Here you want to ask \\nmuch deeper questions about user behavior. You want to model user interactions and \\napply computational algorithms to gain business insights. This is a mesh between \\ntwo extremes. You need some computational background, and some aspects of \\ncommunication, etc.\\nBut ultimately, to answer this question requires you to think about what type of job you \\nwant, and realizing that you can’t be qualified for everything. You have to pick your best \\nshot and hone your skills there.\\n \\nBuilding off of that, what have you found to be useful in building those skills and \\nunderstanding which position you want to pursue?\\n \\nTalking to people is important. I don’t mean that in the way of networking, but in the \\nway of understanding what people are looking for. Insight Data Science brought me a lot \\nin this direction.\\n \\nLooking at folks who have moved \\ninto data science, I’ve noticed that \\nthe Coursera course by Andrew Ng \\nhas been very popular. This ties into \\nthe general skill of being driven \\nenough to simply pick up books and \\nstart learning. A lot of aspiring data \\nscientists also play around with some Kaggle competitions to get their hands on real \\ndata and practice their engineering and analytical skills.\\n \\nIn fact, most data scientists I know are self-motivated, they’ve taught themselves the \\nrelevant tools and skills to help them manipulate and understand data. In my opinion, \\nit doesn’t take that long to learn these skills. So if you pick up these things after work, I \\nthink you can take advantage of the large demand right now in data science.\\n \\nKevin Novak, another data scientist we spoke with at Uber, believes that we’re at \\nthe tip of the tip of the iceberg when it comes to data science. Do you agree with \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 133}, page_content='DIANE WU\\n129\\nthat? And if so, what are the exciting and promising things on the horizon of data \\nscience?\\nI agree with that. I think that data science is largely undefined. Being a data scientist in \\nthis time is exciting because you have a lot of potential to define what data science is \\nfor the next 10 years. What’s exciting is being able to explore this frontier. You’re also \\nlearning a great deal about very different fields intersecting with each other. I really like \\nthis position because I’m learning so much and I’m not just honing one skill.\\nI’ll predict that in 10 years we’ll use more defined terms than data science because people \\nwill realize what it is that they’re looking for (analysts vs. predictive modelers).\\n \\nAre there any final thoughts or parting feedback you’d give to someone just getting \\ninto the field right now?\\n \\nDon’t be afraid!\\n \\nMarch forward and learn what you have to learn. Many people who come into data science \\nare overwhelmed. They look at the list of ”requirements” and think that because they’re \\nnot a wizard at engineering, or a statistician and a visualizer, that they’re not qualified.\\n \\nI think they shouldn’t underestimate themselves. I think you should approach things in \\nthe T-Shaped model, where you accumulate a great deal of breadth and a concentration \\nin one skill that gives you depth.\\n \\nSo be confident and pick up skills; you’ll be surprised at how much value you can add \\nimmediately.\\n \\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 134}, page_content='JACE KOHLMEIER \\nDean of Data Science at Khan Academy\\nYou’re currently the Dean of Data Science at Khan Academy. What is your background \\nand experience up to this point?\\n \\nI was a math and computer science dual major in undergraduate school, and I also did a \\ncouple of internships in the software industry. I then entered a PhD program in computer \\nscience at Princeton, where I intended to focus on theoretical computer science.\\n \\nBut that was about 1999 and it was at the height of the Dot-Com hysteria. At Princeton, I \\nmet some people involved in the startup space and decided to take academic leave after \\nonly one semester. I went to an incubator in New York to start a software company. The \\nventure ultimately didn’t turn out to be commercially successful, but after experiencing \\nthe entrepreneurial process, I learned something tremendously valuable — I learned \\nthat entrepreneurship was more appealing to me than working on theorems for five to \\nsix years.\\n \\nAs an undergraduate student in Kansas, Jace wasn’t \\nexposed to the ins-and-outs of high-powered finance. Little \\ndid he know that within a few years of graduating, he’d be \\nworking at one of the largest hedge funds in the world.\\nAfter receiving degrees in math and computer science, Jace \\nwent off to Princeton for a PhD in theoretical computer \\nscience. There, he was lured into the startup space at \\nthe height of the 1999 bubble, where he learned that he \\npreferred the entrepreneurial process to proving theorems. \\nAfter leaving Princeton, Jace joined Citadel, where he \\nworked for 7 years before starting his own trading firm.\\nHis time in finance incubated an idea of “high frequency education.” After leaving the world \\nof trading, Jace looked towards a different field: education. After hearing Salman Khan’s \\nTED talk, Jace felt compelled by Sal’s vision and joined the Khan Academy as the Dean of \\nData Science.\\nFrom High Frequency Trading to Powering \\nPersonalized Education\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 135}, page_content='JACE KOHLMEIER\\n131\\nWhat were some of the key differences between your computer science graduate \\nstudies and the accelerator? What did you find that changed your mind about \\nindustry versus academia?\\n \\nThe question should be: “Why the heck did I ever think grad school was right for me?” \\nBecause in retrospect, grad school, or specifically PhD studies in grad school, were wrong \\nfor me in just about every way. I had always been pretty commercial. I got my first job as \\na programmer when I was fifteen. I’ve always loved markets. When I was a boy, I scoured \\nmy monthly baseball card price guides with great enthusiasm. And while I do love math, \\nmy experience in grad school was fairly solitary. I found it to be mostly time spent with \\nmy head in a book, sitting in a library or literally in a windowless basement trying to \\nprove math theorems. \\nIt was lonely and slow and felt kind of devoid of any exciting risk. My experience in \\nNew York was just the opposite. It appealed to my commercial senses and I loved the \\nintensity and time frame of trying to get software shipped or a product developed before \\nthe money ran out. I enjoyed the camaraderie and the teamwork, and basically just felt \\nfar more excited and alive.\\n \\nSo what did you do with these realizations after the incubator in New York?\\n \\nWhat I chose to do was to go back \\nand finish my Master’s degree \\nat Princeton and then look for \\nsomething more commercial. \\nLiving in New York had given me \\nopportunity to meet some people \\nin quantitative finance, which up \\nuntil then I didn’t understand or even know existed. As a kid from Kansas, I had no idea \\nthat people were combining math and computer science in awesome ways and applying \\nit to finance.\\n \\nThis is something that really opened my eyes. Rather than trying to work at the very \\ndepths of one particular subject, like computational complexity, quantitative finance \\nseemed like the combination of all three of my main interests--the market, computer \\nscience, and math. The chance to take three of my loves and package them perfectly into \\na professionally rewarding space was a no-brainer for me.\\n \\nI went back to Princeton and through on-campus recruiting, landed a job at Citadel — \\none of the world’s largest hedge funds.\\n \\nFor years when I was working in finance, I’d \\nbeen fostering an idea about “high frequency \\neducation,” of using rapid feedback loops to \\ntest educational content and pedagogy. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 136}, page_content='JACE KOHLMEIER\\n132\\nWas that your first full-time job? What was that like at Citadel?\\n \\nI joined Citadel as my first full time job out of college. I had a good experience there and \\nafter about 2-3 years, a few other people and I started a new business within Citadel that \\ncentered on high frequency trading. We traded a range of securities via sophisticated \\nstatistical models and algorithms. That internal group turned out to be very successful, \\nand after 7 years at Citadel, I was able to start another trading firm with a partner.\\n \\nGiven that Citadel was your first full-time role after college, how did you approach \\nlearning new things in quantitative finance?\\n \\nMy job at Citadel was probably the \\nfirst time that I really needed and \\nwanted to learn about how to build \\nempirical models. That was not \\nsomething that I had ever really \\nstudied in school. Maybe in passing \\nI came across a regression model in \\na statistics class, but basically, I was \\nstarting from scratch at Citadel. My \\napproach — which may not have been optimal — was to start reading books. Sadly, there \\nwere not the great online resources that exist today, which is what I would now advise. \\nI read books and I tried to pick the brains people around me that were doing the quality \\nof work that I wanted to do. I hung off of every word that they would tell me or give me \\nin terms of mentorship, which I sought. There’s no doubt that my most essential lessons, \\nfor both hard and soft skills, were learned from my mentors.\\n \\nSo how did you eventually end up turning to education?\\n \\nAfter co-founding a trading firm, I decided to seek another challenge and at that point, \\nI was looking for something different. Education was something that I had always been \\ninterested in and it also runs in my blood. My father was a high school teacher; my sister \\nwas a high school teacher and is now a professor of education. For years when I was \\nworking in finance, I’d been fostering an idea about “high frequency education,” of using \\nrapid feedback loops to test educational content and pedagogy. \\nSo that was a pet vision of mine; how we could port key ideas I had used within high \\nfrequency trading to education? As I was looking for what I wanted to do next, I explored \\nvarious options. I even volunteered in a Chicago South Side school and took the exam to \\nbecome certified as a teacher in Illinois. But when I came across Sal Khan’s TED talk in \\n2011 where he was describing a system of exercises and videos to optimize education, I \\nwas interested right away.\\n \\nThe coding side of it pervades all of this work. \\nThe faster you can code, the faster you can \\nimplement ideas. If you have a good sense of \\nbuilding systems, you can scale what started \\nout as a research project into something \\noperational.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 137}, page_content='JACE KOHLMEIER\\n133\\nLet’s talk about the questions that you attack at Khan Academy. What are the \\nalgorithms and problems like? How do you measure improvements to learning \\nfrom Khan Academy’s platform?\\n \\nOftentimes, we know the thing that we want to measure and so we can apply statistical \\ntechniques to try to measure it very efficiently. Occasionally, we ask the user a question \\nfrom a distribution that we control, but there are costs to that because the question we \\nwant to ask may not be what the individual wants to learn. So combining knowledge \\nfrom information theory or graphical modelling, we can treat the answers as evidence \\nand try to elicit the most information for a minimum cost to the user. This approach \\nrequires that you are fairly conversant with quantitative techniques.\\n \\nThe coding side of it pervades all of this work. The faster you can code, the faster you \\ncan implement ideas. If you have a good sense of building systems, you can scale what \\nstarted out as a research project into something operational. We can work much faster if \\nwe are data scientists and engineers. We can build algorithms and models right into the \\nproduct, but that obviously requires that we be competent in the product’s engineering.\\n \\nOf the people whom have applied for a data science role at Khan, what really \\nstands out to you as being fundamentally core skills and what are the skills which \\ncan be learned on the job?\\n \\nThe hardest thing to teach on the job is a \\nstrong quantitative aptitude. Most people \\nwho apply would probably rank highly in that \\nregard. They’ve been studying mathematics \\nsince they were 5 or 6 years old, and continuing \\nthrough college, so it’s taken a long time for \\nthem to build up their knowledge base. These \\nquantitative skills are definitely the hardest to \\npick up on-the-fly given the amount of time that needs to be invested, but I also don’t \\nthink that picking it up on the job is impossible. \\nWe have developers or other quantitative scientists who may not think of themselves \\nas being experts in machine learning, but who are clearly very technically minded and \\nsharp. So, I don’t mean to say it’s impossible to learn quantitative aspects on the job, but \\nsimply it is the hardest thing to pick up on the fly.\\n \\nSomewhat similar is coding experience, which is a productivity gauge. If you’re 30% \\nslower at coding, you have less time to focus on other aspects and your productivity will \\ngo down. We look for fluency in coding.\\nAs we built our team, I became \\nincreasingly skeptical of finding \\nthe perfect data science “unicorn” \\n— someone that is world class in \\nall of these categories.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 138}, page_content='JACE KOHLMEIER\\n134\\nThe hardest thing to pick up when interviewing candidates is a person’s aptitude for \\nexperiment design (model design) and how these experimental outcomes will impact \\nyour organization. We’ve experimented with bringing people in for on-site interviews \\ninvolving projects. Another initiative we have tried is to put candidates through \\ncollaborative exercises as well.\\n \\nAs we built our team, I became increasingly skeptical of finding the perfect data science \\n“unicorn”— someone that is world class in all of these categories. By definition there are \\nvery few people who are world class in even one of those dimensions, and they are in \\nextraordinarily high demand. So you really want to put together a team similar to the way \\na GM puts together a professional basketball or baseball team. There are fundamental \\nskills that all players share, but the GM puts together a team of complementary members \\nthat specialize in position or area. More and more, that’s the way I think about building \\na data science team.\\n \\nGiven that the background of the ideal data scientist you’re describing implies a deep \\nexpertise within some fields, do you find that the people who are predominantly \\ntrained in these areas come from advanced degrees?\\n \\nI think of team as an ensemble of \\nspecializations. I have seen a PhD \\nexperience be both a benefit or a \\ndrawback in a couple of ways. I’ve seen \\na PhD be a benefit when a candidate \\nor employee has really learned to \\nindependently find their path through \\na nebulously defined problem, or to \\nbe able to craft experiments to get to \\na result that’s going to meaningfully \\nanswer pertinent questions. \\nFor some people, it’s very clear that their PhD led them to develop that skill. On the \\nother hand, some people’s PhD experiences left their pragmatism atrophied. At Khan \\nAcademy, there are no medals or ceremonies if we publish a beautiful research paper. \\nWhat we really want to do is deliver demonstrable value to people trying to learn. A \\ncritical skill for a data scientist is knowing how one’s work fits within a team, and where \\nyour team sits within the concentric circles of an organization. In some cases that can be \\na skill that may have atrophied for someone who comes from a doctoral setting.\\n \\nYou’ve mentioned the importance of programming several times now — for aspiring \\ndata scientists who come from a strong quantitative research field, some might not \\nAt Khan Academy, there are no medals \\nor ceremonies if we publish a beautiful \\nresearch paper. What we really want to do is \\ndeliver demonstrable value to people trying \\nto learn. A critical skill for a data scientist \\nis knowing how one’s work fits within a \\nteam, and where your team sits within the \\nconcentric circles of an organization.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 139}, page_content='JACE KOHLMEIER\\n135\\nhave spent so much time with software engineering. What are some ways for them \\nto increase their programming skills?\\n \\nIn my opinion, to be a great data scientist, you must be a great (or at least a very \\nproductive) programmer. That doesn’t mean that you have to be a savant in computer \\nscience, it just means that you have to be fluent with code and experienced in building \\nreal systems. \\nWhat I would suggest for someone \\nwho’s looking to build skills in \\nthose areas is, number one, you \\njust have to write code and you \\nhave to write a lot of it. There will \\nalways be differences between a \\nfirst year programmer, a fifth year \\nprogrammer, and a tenth year \\nprogrammer, at least for people \\nwho spent those years practicing the right way. The hack to get better faster is to get lots \\nof good feedback. And the best way to get feedback is to find great developers to work \\nwith who will give you code reviews.\\n \\nThe great thing today — which wasn’t available in my day — is you can get involved \\nwith open source projects and get very specific feedback from great developers. This is a \\ntremendous resource and opportunity for people who want to improve their programming \\nskills. So write a lot of code, and make sure you’re getting code reviews from quality \\nprogrammers.\\n \\nOn the process of implementing the machine learning algorithms — how do you \\nlearn more data science on the job?\\n \\nThere is not a steady rate at which you learn new techniques and employ them; it \\ndefinitely comes in waves. When I made the transition into this new domain of education \\nand internet-generated data, I went through a period of needing to learn new modeling \\ntechniques. I wasn’t familiar with probabilistic graphical models; that wasn’t something \\nthat I had used in high frequency trading.\\n \\nOnce I got past that initial learning curve, learning came very much in waves. There \\nwill be a very concrete and motivating need or goal. For example, we’re very focused \\non delivering value to the users and so any new foray into a new modeling technique is \\nusually driven by that goal. Often we will have the necessary knowledge at hand. If not, \\nwe’ll take the time to learn what we need to know. \\n \\nThe great thing today — which wasn’t available \\nin my day — is you can get involved with open \\nsource projects and get very specific feedback \\nfrom great developers. This is a tremendous \\nresource and opportunity for people who want \\nto improve their programming skills.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 140}, page_content='JACE KOHLMEIER\\n136\\nAnother idea that we often hear in our interviews is the importance of communication \\nand how to cultivate more interpersonal skills. Either through their research or just \\nnatural personality, some people might be introverts. What advice do you have on \\nhow to manage communication when work relies on collaboration and teamwork?\\n \\nThat’s a great question and one \\nthat I can relate to profoundly. \\nI would describe myself as \\na pretty hard-core introvert \\nand it’s something that I have \\ncontinuously had to work on in \\nmy career and continue to work \\non to this day. One of the greatest \\nthings that anyone ever did for \\nme professionally was during \\nmy time at Citadel. My boss’s \\nboss, came to me and said, “Hey, we think you have potential but there’s something \\nthat you really need to work on, and it’s your communication skills.” They put me in \\n“communications training”, which was both useful and hilarious. \\nI was videotaped role-playing various business scenarios, which felt totally bizarre. I \\nthought, “I’m a quant, this is ridiculous!” Then I watched the tape and I was appalled \\nby looking at my body language and hearing my verbal mannerisms. I’m still working \\non this today. Despite how silly it seems, I totally recommend that my fellow introverts \\ntry the videotape technique.  Andrew Ng recently shared a great post on how he used a \\nsimilar technique to become a better teacher and presenter. \\n \\nAnother important development for me was partnering with someone who was very \\nmuch an extrovert. That helped me in two ways. It gave me an exemplar for dealing with \\nother people effectively. And, it taught me that it’s OK to lean on a trusted partner at \\ntimes to handle the extrovert work, while I remained focused on my strengths. \\n \\nSo those are a couple of strategies that people can use. Number one, get yourself feedback \\n— possibly through videotaping — and conscientiously work on your communication. \\nSecond, seek partners with extroverted tendencies that can complement your more \\nintroverted tendencies, and build extra close relationships with those people.\\n \\nThat’s fantastic advice. Switching gears to diving into your work, what’s a day like \\nin the life of a data scientist at Khan?\\n \\nIt’s fast paced. The Khan Academy engineering team, in general, is very focused on \\nOne of the greatest things that anyone ever \\ndid for me professionally was during my time at \\nCitadel. My boss’s boss, came to me and said, \\n“Hey, we think you have potential but there’s \\nsomething that you really need to work on, and \\nit’s your communication skills.” They put me \\nin “communications training”, which was both \\nuseful and hilarious. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 141}, page_content='JACE KOHLMEIER\\n137\\nshipping and iterating quickly. We try to ship code everyday. So fitting into that, what I \\nfocus on and what my immediate team focuses on is what we call “learning gain,” and \\nwe try to take a very pragmatic approach to the work. We’re not looking to just produce \\nresearch, we don’t pat ourselves on the back at the end of the day for writing a nice \\nreport or making a pretty graph. What we really want to do, which sounds grandiose, is \\nto change the lives of our users through more effective or increased learning through \\nKhan Academy. That is what we measure ourselves by and the questions that we ask \\nmust relate in some way to that goal, and hopefully, as directly as possible, to the main \\nquestion, “What are we doing to improve learning through Khan Academy?”\\n \\nThe data that we deal with is almost entirely generated from user activities on the website. \\nOccasionally, there are some complimentary external data sets, like geography, but it’s \\nalmost entirely user activity, which forms both their practice and their assessment, so to \\nspeak.\\n \\nA good day is a lot of code writing \\nbecause it’s the most direct way that we \\nbuild value. Then, as a team lead I also \\nneed to make sure our team is in sync \\nwith the organization. I learned some \\nhard lessons during my first couple of \\nyears at Khan on that front: A) make sure \\nthe product design is amenable to the \\nresearch requirements, and B) promote \\nideas for doing experimental research that may not occur to others. For example, we might \\nread something in the science of learning, like there’s strong evidence or justification for \\nthis particular style of learning, and we think it could be studied in this particular way. \\nIf we communicate this to the engineering team, they might be able to add this into the \\nproduct, and we would be able to measure and build off of that.\\n \\nSo a good day is mostly writing code, checking in on the real time results from our A/B \\ntesting dashboard and then doing the interesting work of talking to other teams to \\nunderstand how they are making their decisions, and what can we do to help them. We \\nstay focused on the product because at the end of the day, that’s what the users touch. \\nThat’s our ultimate goal. So if we’re not changing the product and changing it in a way \\nthat delivers better outcomes to users, then we’re not doing our job.\\n \\nLets talk about the future. How do you see the foray of computational statistics into \\ncomputer science? Do you see that data science will also become commoditized? \\nHow do you think data science will evolve?\\n \\nWhen you’re doing analysis, you’re not \\nreally writing code anyway. You are using \\nexisting machine learning libraries and \\nyou’re basically an intelligent matchmaker \\nbetween the data and the appropriate \\nmodel.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 142}, page_content='JACE KOHLMEIER\\n138\\nI agree there’s been a heavier commoditization of big data services, which has reduced \\nthe need for people with data infrastructure backgrounds, though I would argue that \\nthose skills are still very valuable and some of the infrastructure tools are still relatively \\nimmature. I think there’s a lot of improvement to be made there, but you can see it \\ncoming. So that leads to more emphasis on the next layer of actually analyzing the data.\\n \\nIf I have data, and there’s a standard suite of off-the-shelf models, how do I combine \\nthose techniques and know which technique I should use? I think the emphasis will \\nstay in that area for a long time. When you’re doing analysis, you’re not really writing \\ncode anyway. You are using existing machine learning libraries and you’re basically an \\nintelligent matchmaker between the data and the appropriate model. I don’t see that \\nmachines are good matchmakers, because this involves knowing which tools to apply in \\nwhich contexts. It’s a fairly high level process, which for now requires human intuition. \\nSo I think we will need people with those skill sets for a while.\\n \\nYou have done a lot of interesting work in high frequency trading, and now you’re \\nworking in the education space. What excites you about your job and what are \\nsome future prospects that excite you?\\n \\nAt Khan Academy, we give our new hires \\na couple of sci-fi books. One of them is \\nThe Diamond Age  by Neal Stephenson. \\nIn the book, Nell is a young girl who \\ncomes upon a sophisticated guided \\nlearning tool designed in the form of \\na book, and it teaches her skills and \\nknowledge in an interactive way. The \\nauthor even accounts for the presence of human-backed interaction with people called \\n“ractors,” that can bring some essential humanity to Nell’s experience. It’s an amazing \\nvision that seems tantalizingly within reach. None of the material seems far-fetched in \\nthe age of iPads and other educational technologies. \\n \\nStill, one thing that surprises me is how much harder the problems I work on at Khan \\nAcademy are compared to the problems I worked on in high frequency trading. Everyone \\nassumes that developing a model that consistently generates money in the financial \\nworld has to be the hardest thing to do, but I think it’s a different breed of difficulty. \\nThere’s a reason that what we now call data science originated in finance, because \\nfinding signals and knowing what to optimize is so ingrained in the profit and loss \\n(P&L) of financial trading. The signals and optimization objectives are so much less \\nwell defined and quantifiable in the education space, which makes it hard from a value \\ncreation perspective. So the objective function is not as well defined. In education, we \\nStill, one thing that surprises me is how \\nmuch harder the problems I work on \\nat Khan Academy are compared to the \\nproblems I worked on in high frequency \\ntrading.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 143}, page_content='JACE KOHLMEIER\\n139\\nrun into a host of considerations for defining the objective function. Should we optimize \\nfor educational breadth or depth? Is the answer to that question the same for everyone? \\nWhat about their emotional state? How do I incentivize people to stay engaged in \\nlearning? There are more human aspects which blur a well-defined objective, but which \\nalso make the work very challenging.\\n \\nI’ve immensely enjoyed my work at Khan Academy, and I think my dream of achieving \\ntechnology that facilitates completely personalized education is both realistic and \\nepically ambitious. That’s exciting.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 144}, page_content='JOE BLITZSTEIN \\nProfessor of the Practice of Statistics at Harvard\\nHow did you get interested in statistics?\\n \\nI was a math major as an undergrad at Caltech. Caltech doesn’t have a statistics or \\ndata science department, and there are also very few statistics courses there. I went to \\nStanford for graduate school in math. It hadn’t really occurred to me at the time, but \\nStanford has a ton of statistics and data science-type opportunities.\\n \\nI was working on probability for my PhD thesis because I really love it, but I decided \\nthat it’s better if you can have your cake and eat it too. With statistics, you can actually \\ndo cool math and also feel that you’re analyzing interesting data and doing something \\nuseful for the real world. It still has nice mathematical structure and lots of elegant \\nthinking. You can also feel more useful, whereas math, itself, tends to get more and more \\nabstract and disconnected from reality as you progress. Statistics, though, is rooted in \\nthe real world and real data, and data science is a version of statistics.\\n \\nCan you describe for our readers what Harvard’s Data Science course is like and \\nwhat is the philosophy behind it?\\n \\nIt’s a course that I created with Hanspeter Pfister, who is a visualization professor in the \\nComputer Science department. Our goal was to give an accessible introduction to the \\nentire data science process.\\nWe defined that process as a journey, starting from formulating a research question \\nJoe Blitzstein is a Professor of the Practice of Statistics at \\nHarvard, moving to Harvard after obtaining his PhD in \\nMathematics from Stanford. He co-taught the initial offering \\nof Harvard’s inaugural Data Science class, designed around \\nthe Data Science Process. He also teaches Harvard’s popular \\nintroduction to probability class  as well as other statistics \\ncourses. Joe regularly emphasizes intuition and storytelling \\nin his instruction. He tweets at @stat110.\\nJoe Blitzstein is a co-author of the textbook Introduction to \\nProbability.\\nTeaching Data Science and Storytelling\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 145}, page_content='JOE BLITZSTEIN\\n141\\nand gathering data. Then, you clean the data, so there’s some data wrangling. There is \\nexploratory data analysis, which involves looking for problems, biases, weird outliers, or \\nstrange anomalies in the data, as well as trying to get a sense of some possible conjectures \\nyou could formulate.\\n \\nThen, it goes a little bit into modeling. We took a Bayesian approach to that. There are \\nfull courses on Bayesian data analysis, and this was just a short introduction. Then, \\nthere’s communicating and visualizing the results.\\n \\nThe sequence of steps is not linear — you iterate between those steps in a non-linear \\nway. We defined it as the data science process, and we wanted to introduce that process \\nthrough examples. To go into detail, that process would have taken six courses, but we \\nwanted to put them together into one introductory course on how to think like a data \\nscientist. The course needed to include applications that are of current interest like \\npredicting elections, movie and restaurant ratings, and network analysis, rather than \\nusing a lot of canned, stale data sets that no one has cared about in the last 50 years.\\n \\nSo, we wanted interesting data, but that’s not enough. We wanted interesting data but \\nwe also wanted to ask relevant questions about the data.\\n \\nWhy is important for data scientists to understand the data science process instead \\nof just going through the work?\\n \\nI think it’s important in whatever you \\ndo to have a sense of direction, instead \\nof just aimlessly trying things. You want \\nsome sense of where things are going. I’m \\nnot saying it’s not useful to just grab data \\nand hack around with it. You can learn \\nfrom doing that, but in terms of doing \\nsomething that will have long-term scientific value, I think that depend on relevant \\nresearch questions.\\n \\nMuch of statistics is about distinguishing signal from noise, distinguishing valid from \\ninvalid signals, so-called “discoveries”. You need to look for patterns, but you can’t just \\nassume that whatever pattern you find is real. You have to perform some validation, and \\nif you cannot communicate the results in the end, it’s not worth much either.\\n \\nAll of these ingredients are crucial. Different people can specialize in different parts of \\nthe process. No one can be a complete expert at every step, but data scientists in industry \\nare working in teams. To be effective in teamwork, you have to understand some basics \\nWith statistics, you can actually do cool \\nmath and also feel that you’re analyzing \\ninteresting data and doing something \\nuseful for the real world.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 146}, page_content='JOE BLITZSTEIN\\n142\\nof what your teammates are doing. You need to be able to give them feedback, and you \\nneed to be able to understand their feedback about what you’re doing. You have to see \\nhow the various pieces fit together into the overall process.\\n \\nHow did you get interested in data science and teaching this data science class?\\n \\nIt’s probably a combination of a lot of factors. I noticed more and more possible data science \\nideas and applications ever since the Netflix prize and Nate Silver. The combination of \\nso many datasets that were never available before made me really interested, for my own \\nsake, as well as for teaching it to students. I felt some concern that students might not \\nhave the right kind of CS training to be able to participate in all these opportunities. So, \\nI wanted to play a role in fixing that.\\n \\nYour data science class was very popular this year. Did you expect this level of \\npopularity? How many students ended up enrolling in the class?\\n \\nI had guessed there would be 100 or 150 students (which would already be a very large \\ncourse), but we ended up with more than twice that many; we ended up having 350 or \\nso enrollments. We tried to keep the prerequisites reasonable, but it did require at least \\nsome very basic background in Stat and CS. We didn’t want to limit enrollment or do \\na lottery, so we tried to send the message that this was going to be a hard class. You’re \\ngoing to do a lot of work, but you’ll learn a lot. That was the idea, but I didn’t expect it \\nto have that much demand.\\n \\nWhy do you think there was such a large demand for the class?\\n \\nIt’s hard to know. I think there are some students who took Stat 110 and wanted to have a \\nfollow-up, even though the material is different. In Stat 110, we do probability and it’s a \\nfairly mathematical course, but we’re not analyzing data. In a data science course, we’re \\nnot doing math, but we are analyzing data. I see Stat 110 and the Data Science course as \\ncomplementary, in that we are emphasizing stories and a certain way of thinking about \\nthe world in both of them.\\n \\nSo, it’s the applied analog, and I have a huge number of Stat 110 students who were \\ninterested in going further. Then, Hanspeter had a lot of students interested in his \\nvisualization course. The visualization itself is great, but it’s very limited if you don’t \\nactually know how to analyze the data. So, the whole theme of big data attracts a lot of \\ninterest.\\n \\nYou mentioned emphasizing stories when you were comparing Stat 110 and the \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 147}, page_content='JOE BLITZSTEIN\\n143\\nData Science course. I want to extend that question: What is the role of storytelling, \\ncommunication, and visualization in data science?\\n \\nI think they’re incredibly important parts of it. Anyone with a basic level of CS can scrape a \\nbig data set and start computing things. And anyone with the right statistics background, \\nif presented with a clear data set, can start running some regression in a mechanical way. \\nI think there’s a real art to getting interpretable results and then communicating those \\nresults, especially in the age of big data where you have thousands of variables. In the \\nold days of regression, you might have two predictors, and it’s a lot easier to see what’s \\ngoing on. Now, we have thousands of variables and some very complicated models, and \\nit becomes very difficult to see what’s going on.\\n \\nI think communication includes communicating with yourself too! You are trying to make \\nsense of the data in a way that human beings can understand. If you attend conferences, \\nit’s generally hard to remember anything from the majority of a presentation. Presenters \\ntend to rush through their slides and try to show a lot of results, but are they really \\nexplaining what the story is?\\n \\nSo, if statisticians (or anyone) \\nare falling to communicate why \\ntheir results are important and are \\nfailing to explain those results in an \\ninterpretable way, that’s just a lot less \\nexciting. Visualization definitely plays \\nan important role in that case. A picture is worth a thousand words. Sometimes instead \\nof staring at a huge table of numbers, a few graphs can give you much more intuitive \\ninformation.\\n \\nDo you have any advice for data scientists or people in the industry who may \\nwant to become better communicators? What kind of philosophy would you like \\nto impart to make them care more about the storytelling and communication part \\nof data science? Why is the teaching part of data science so important?\\n \\nI think it’s an important part of clarity of thinking. As a data scientist, you’re going to \\nneed to collaborate with many different types of people with many different backgrounds. \\nYou have to be able to put yourself in their shoes and explain things in terms of what \\nthey’re interested in and what their background is. In many cases, when you can’t \\nexplain something clearly, it’s a sign that you haven’t thought it through fully yourself. \\nSo, teaching and learning go together. Learning to explain something to someone in an \\ninterpretable way makes it a lot clearer in your own understanding.\\n \\nMuch of statistics is about distinguishing \\nsignal from noise, distinguishing valid from \\ninvalid signals, so-called “discoveries”.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 148}, page_content='JOE BLITZSTEIN\\n144\\nIn terms of concrete advice on developing these communication skills, I think of it in \\nterms of something like the golden rule, which I call the conditional golden rule: try \\nto present the idea in a way that you would have appreciated seeing it presented. It’s \\nconditional because you have to adjust for the fact that as a data scientist who’s been \\nimmersed in a project for months or years, \\nyou have to step back and realize that the \\nperson you’re talking to may have never even \\nheard of what you’re doing. They don’t know \\nany details about the data. They don’t know \\nyour notation, and they may not even know \\nstatistics.\\n \\nAlso, read some of the classic design books by Edward Tufte (he’s a famous example), The \\nVisual Display of Quantitative Information. Try to find and follow good examples.\\n \\nWhat’s your opinion on his book and his philosophy on visualizing information?\\n \\nI really like his books. In a sense, he’s a victim of his own fame, in that these books are so \\npopular that it’s almost a visualization bible. So naturally, there’s going to be a backlash \\nof people asking, “what gives him the right to say what you can or can’t do?” I wouldn’t \\ntake everything he says religiously, but these are important things to think about. Clear \\ncommunication is incredibly important.\\n \\nWhat are your favorite philosophies about visualization? What is your favorite \\npiece of knowledge from this book, and what is your best advice for visualizing \\nquantitative information?\\n \\nI think the best advice is just to think hard about what you want your audience to take away \\nfrom the visualization. It’s sad to think of how many talks I’ve been to, presentations on \\nall kinds of subjects, where the speaker will make ridiculous mistakes, like not labeling \\ntheir axes or having things so small that the audience can’t see what is going on.\\n \\nSometimes, presenters want to show some kind of comparison, but the things they’re \\ntrying to compare are on separate slides. Graphs are effective in showing something \\nchanging over time or a comparison between things, and it is more about relative \\ninformation than absolute information most of the time. You want to make it as easy as \\npossible to see those comparisons. Avoid something that looks really fancy but distracts \\nattention from the fundamental comparison you’re trying to display.\\n \\nCan you tell our readers more about your story behind the conditional golden rule?\\n \\nThere were two course reviews about Stat 110 that went well together. One of them said \\nIn many cases, when you can’t \\nexplain something clearly, it’s a sign \\nthat you haven’t thought it through \\nfully yourself.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 149}, page_content='JOE BLITZSTEIN\\n145\\nI designed the course to the credo that it should be taught in the way I myself would \\nlike to take it as a student, which is the golden rule. Then, the other one, which is a \\ncounterpoint to that, said that the homework only induced pain, not learning. The joke \\nis, that if you combine those two things, it implies that I’m a masochist.\\n \\nObviously, I’m trying to induce learning, not pain, but it does require a lot of hard work \\nto learn all these things. I try to make as many resources available as possible, in terms \\nof having great Teaching Fellows, having lots of office hour times, and having large \\namounts of practice problems. It’s just like if you were practicing a sport or a musical \\ninstrument. It’s something that you need to practice, practice, practice. Just doing a few \\nhomework problems a week is not going to be enough.\\n \\nIt’s like learning a whole new language. Language courses tend to meet every day, and \\nyou have to go to labs. There are tons of things going on, but statistics and data science \\nare new languages, too. They should be approached in the same way. You have to do the \\nmath and CS as well as learning grammar and syntax. You just have to immerse yourself \\nin the learning process.\\n \\nFor my fellow students and me, we’re very fortunate to be in this environment \\nwhere our only duty is to learn. But there are many data scientists out there who \\nfeel like they’re missing some knowledge and are trying hard to fill the gap. My \\nquestion is in reaction to those data scientists. What’s the best way to keep on \\nlearning after university?\\n \\nI noticed that’s a trap that people fall into, \\nthinking, “I’m perpetually feeling unprepared.” \\nIt’s a dangerous way of thinking — that until \\nyou know X, Y, Z and W, you’re not going to \\nbe able to do data science. Once you start \\nlearning this thing, you realize there are four \\nother things you need to learn. Then, you try \\nto learn those things, and you realize you don’t have this, this, and this.\\n \\nYou do need some basic foundation in statistics and CS skills, but both statistics and \\ncomputer science are enormous fields that are also rapidly evolving. So, you need durable \\nconcepts. Right now, for people that want to do data science, I highly recommend learning \\nR and Python. But in 10 or 20 years, who knows what the main languages will be?\\n \\nIt’s a mistake to think, “why am I learning R now? R won’t be used in 20 years.” Well, \\nfirst of all, R might still be used in 20 years, but even if it isn’t, there’s going to be a need \\nfor the thinking that produced R. The people who create the successors to R will have \\nIt’s a dangerous way of thinking — \\nthat until you know X, Y , Z and W, \\nyou’re not going to be able to do \\ndata science.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 150}, page_content='JOE BLITZSTEIN\\n146\\nprobably grown up using R. So, they’re still going to have that frame of reference.\\n \\nYou want the skills that are language-independent. You need fundamental ways of \\nthinking about uncertainty and communicating those thoughts in a way that is not that \\ndependent on any particular programming language. It’s definitely important to have \\nthat kind of foundation, but keep in mind that it’s hopeless for anyone to actually know \\nall the relevant parts of statistics and CS, even for some small portion of data science. It’s \\nnot feasible for anyone, but it doesn’t mean that you can’t make useful contributions.\\n \\nIn fact, I think it’s a good idea to continue \\nlearning something new every day. The \\nway you can learn something, and really \\nremember it, is by using it in your work. \\nInstead of saying, “I need to study these \\nfive books so that I will know enough \\nto become a data scientist,” it should be about getting a basic level and foundation. \\nThen, start immersing yourself in a real, applied problem. You will realize what types of \\nmethods you need. Then, go and study the books and papers that are relevant for that. \\nYou will understand them so much better because they’re in the context of a problem \\nthat you care about.\\n \\nYou have to be energetic and work really hard, but not get discouraged just because you \\ndon’t know everything. And just because you don’t know everything, it doesn’t mean \\nyou can’t contribute useful things while gradually expanding your understanding and \\nknowledge.\\n \\nTo strengthen one’s understanding in a concept, would you also recommend teaching \\nthat concept to other people (stemming back to your philosophy on storytelling \\nand communication)?\\n \\nYes. I think that’s a great way of checking your own understanding. It’s a lot of fun. \\nYou’re helping someone. You have to think about the important things to emphasize, \\nthe common misconceptions, etc. Think back to when you first learned the concept, the \\nobstacles and conceptual roadblocks that you had to get past, and the most important \\nthings to emphasize. That is very useful for everyone.\\n \\nWhat are the parallels between being a data scientist and being an educator?\\n \\nCommunication and feedback. If you’re just lecturing to a class and not paying attention \\nto see if the students are actually understanding, that’s a pretty stupid way to teach. \\nThere’s a story of a professor who got a really poor teaching evaluations, and the \\nYou have to be energetic and work \\nreally hard, but not get discouraged just \\nbecause you don’t know everything.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 151}, page_content='JOE BLITZSTEIN\\n147\\nevaluations said his lectures were very unclear. He said, “My lectures aren’t unclear. The \\nstudents just don’t understand.”\\n \\nCommunication is a two-way street and you have to pay attention in various ways, \\nthrough feedback, watching people’s expressions, trying to get people to speak up and \\nfeel comfortable asking questions. Do whatever you can when you’re teaching to assess \\nwhat people understand and what they don’t. A lot of that information stays the same \\nfrom year to year.\\n \\nThat’s the reason why every week in Stat 110, I ask the teaching fellows for the most \\ncommon mistakes from the homework. I can clarify those things or they can be clarified \\nin the sections for that year. Those things tend to stay fairly constant from year to year, \\ntoo. I don’t have a formal data set, but I am trying to gather as much information as I can \\nabout what the students understand and what they do not.\\n \\nData science is like that, too. You don’t compute something without getting feedback \\non whether it’s working or not. You’re communicating messages to people, but you need \\nfeedback on whether or not that message is getting across.\\n \\nThis is a very important idea in software development, too, with continuous \\ndeployment and instant feedback and quick iterations. It’s nice connecting data \\nscience and software engineering principles. As a data scientist, you’re always \\ngetting feedback and trying to improve.\\n \\nI think that’s extremely important. That’s another mistake I’ve noticed, the tendency \\nin applied problems where new students just want to fit one model and be done with it. \\nBut, the world is too complicated. There are too many challenges with data. We know the \\nsaying, “ All models are wrong, but some models are useful.”\\n \\nIt’s not realistic to expect that the first model you come up with will actually work well, \\nbut if it takes too long to figure out how to fit that model and run the computations on \\nsome massive data set, you may feel that you need to move on.\\n \\nThat’s very unsatisfying. What you need to do, first of all, is get comfortable on Python \\nso that you can fit the models very quickly. If you have a large data set, fit it on a subset \\nfirst so you can quickly get models and better intuition. You have to iterate and build \\nsomething better.\\n \\nYou have to manage your time so that you can actually go through a whole series of \\nmodels and get feedback on which one is actually working through measures of fit or \\npredictive capabilities. Even just explaining or communicating with someone else to try \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 152}, page_content='JOE BLITZSTEIN\\n148\\nto get a sense of whether the model is actually doing something useful and what aspects \\nneed to be improved, is very good.\\n \\nBuilding off of that, what other mistakes do you see made, or what other things do \\nyou think data scientists should improve on?\\n \\nStatistics is just a hard subject and there are all kinds of mistakes made. I think the \\nbiggest one tends to be not thinking enough about sampling. Where did the data come \\nfrom? What do you want to assume about possible selection bias or other forms of bias \\nin the data? If there’s a systematic bias, no matter how large the data set, it still has to be \\naccounted for. It doesn’t wash away in the limit of large data. You can’t necessarily think \\nof the data as being an objective, unbiased portrait of reality.\\n \\nAnother thing is trying to be very clear, at all times, about what the goal is. What are you \\ntrying to estimate? What are you trying to predict?\\n \\nHow can university education better prepare students for opportunities in data \\nscience? What skills are students missing in general?\\n \\nThere are very few data science courses in universities currently. There’s a large number \\nof statistics and CS courses that are closely related, but there are not many courses \\nthat integrate statistics and CS. There are also not many courses on communication, \\nvisualization, and storytelling.\\n \\nI think the problem is that there are not a lot of clear paths to follow. There aren’t data \\nscience majors generally, and even the statistics major is small or nonexistent in most \\nschools. It’s a recent trend that statistics even exists as a major.\\n \\nOne purpose of a major is not just what degree shows up on your diploma. It’s also about \\nproviding tracks, having some coherent path through the material. For data science, you \\ndefinitely want a strong combination of both statistics and CS, and different schools \\ncertainly vary in how much relevant material they have in each of those. I think very \\nfew have developed a road map, a coherent ordering, and a scheduling of how to get the \\nrequisite knowledge.\\n \\nThere are going to be a lot of readers whose schools don’t really offer these kinds \\nof opportunities. How do you feel undergraduate or graduate students can get the \\nrequired data science knowledge when universities don’t offer these specialized \\ntracks and courses?\\n \\nIt may or may not be a formal online course, but there’s a massive amount of excellent \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 153}, page_content='JOE BLITZSTEIN\\n149\\nonline material. I really can’t curate it right now. That’s something I’d like to do at some \\npoint, to try and recommend the most useful online materials, and try to recommend a \\ncurriculum. I know others have tried to do that.\\n \\nThere are a lot of great books, but like I \\nsaid, you don’t just want to read a stack of \\nbooks. Maybe you can read or study a couple \\nof books or do a couple of online courses, \\nbut just try to start doing something like \\nKaggle competitions at Kaggle.com. They \\nhave very interesting data sets and problems, often about predicting some quantity. Try \\nout one of these competitions or find some data you’re interested in and just get a feel \\nfor it. You can look through different resources about regression models and machine \\nlearning. Look at different materials and then try it out on the data set you’re working \\nwith. You’ll get a lot more intuition about which methods work well for which problems.\\n \\nA lot of those things are very hard to teach in a course anyway. Even if universities offered \\nmore data courses, many of these things are best learned through hands-on experience \\nin internships, in competitions, or with just playing around on your own with some data.\\n \\nDo you have any funny or interesting anecdotes to share with our readers?\\n \\nI read an article in Wired recently, about the importance of A/B testing at Google and \\nvarious tech companies, and I thought it was nice that they’re calling attention to \\nthat. The thing that was funny and sad about it was that the article made it sound like \\nthey had never heard of the history of experimental design and randomized controlled \\nexperiments in statistics, which goes back to R.A. Fisher in the early 20th century.\\n \\nThat is 100 years of history on how to efficiently design experiments. For example, if there \\nare many variables you’re interested in, it’s really inefficient to design an experiment \\nin which you only change one thing at a time. You want to have a full factorial design \\nwhere you’re changing different variables at the same time. It’s much more efficient, and \\nthere’s a lot of good theory and application for randomized experiments. Some people \\nconsider randomized experimentation as one of the biggest breakthroughs in medicine \\nin the 20th century.\\n \\nThe article was talking about A/B testing, which is just a trendy word for randomization, \\nwhere you have one treatment group and one control group. The article went on to \\nspeculate, is it even conceivable that we might be able to A/B test the offline world, too?\\n \\nSo, I thought it was funny that, apparently, they never heard of a randomized \\nBut now, in this era of big data, it’s \\neven more important to understand \\nexperimental design.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 154}, page_content='JOE BLITZSTEIN\\n150\\nexperimentation, but also, it was a reminder that data scientists need to be familiar \\nwith traditional statistical concepts, such as experimental design and sampling theory, \\nin order to be able to be much more efficient in how they deal with data.\\n \\nExperimental design was one of the main topics in statistics in early 20th century, and at \\nsome point, it started having a reputation of being a bit old-fashioned. It was only old-\\nfashioned because it was one of the founding topics on which statistics was created. But \\nnow, in this era of big data, it’s even more important to understand experimental design.\\n \\nSo, it’s coming back but with new challenges related to the new types of data sets that \\nwe have. It’s very interesting to see old and new ideas come together.\\n \\nLastly, what advice would you give for undergraduate and graduate students who \\nare interested in going into data science?\\n \\nI just recommend getting a mixture of math, \\nstatistics, and CS background, to build a \\nstrong foundation. Then, concurrently, \\nimmerse yourself in as many real world \\napplications as you can, remembering that \\ndepth is often better than breadth. Immerse yourself into challenging problems that you \\ncan hopefully integrate with your coursework, so that you see some ideas and how they \\nare or are not relevant for particular types of data science questions.\\n \\nWhen you’re learning, constantly question and constantly be critical. Whenever possible, \\nask fundamental questions like, “Who cares?” Constantly think about the motivation. \\nWhy is that relevant? Why is this data set interesting? What questions could we hope \\nto answer? When you’re trying out different statistical methods, don’t just use it like an \\noff-the-shelf, black box type of thing where you just spit out results. Question! Do those \\nresults make sense? How do you assess whether the method you’re using is working \\nwell, or how do you know if it’s actually working better than random guessing or using \\na complicated method? How do you know that it’s better? In what way is it better? Is it \\nbetter than some simple, naïve thing you can try? Constantly try things and compare \\nthem. Question whether or not the results make sense.\\nWhenever possible, ask fundamental \\nquestions like, “Who cares?”\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 155}, page_content='JOHN FOREMAN Chief Scientist at MailChimp\\nCan you start off by talking about your book, “Data Smart”? How did the motivation \\nfor writing it come about, and what type of audience is it for?\\nI felt like there were a lot of business analysts and middle managers in the enterprise \\nworld who were not familiar with “data science” as a practice and set of techniques.  \\nThese folks still lived in a world of “business intelligence” or “business analytics” from \\na decade ago, and I wanted to bring them up to speed on current methods (for example, \\nensemble AI models built on transactional data, data mining in graphs, forecasting with \\nerror bounds). I wanted to get these enterprise readers up to speed, so I needed to find a \\nlanguage and teaching approach that they’d understand.\\nA lot of data science books that were being introduced at the time required learning \\nboth R and techniques at the same time. With a lot of those books, rather than actually \\nlearning the techniques, you just loaded the AI package or the data mining package.\\nInstead, I wanted to write a book that introduced these concepts step-by-step with a tool \\nthe reader knew, and then, once they got it, slowly push them into a programming mode. \\nSo in Data Smart, I explained the gamut of data science techniques by using spreadsheets. \\nSpreadsheets are kind of like a functional programming language and GUI in one, and \\nthey’re actually pretty good for step-by-step model building.\\nAs an undergraduate math major, John thought that he \\nwas going to be a pure mathematician. A few experiences \\nworking as a programmer, combined with a talk with his \\nadvisor, pushed him instead into the world of applied math.\\nAfter a sojourn in academia through MIT’s Operations \\nResearch PhD program, John realized that a long-term \\ncareer in industry would be more interested and fulfilling.\\nJohn held a series of jobs in business intelligence at various \\nconsulting companies, before taking on the Chief Scientist \\nrole at MailChimp, a fast-growing, completely bootstrapped, \\nemail startup based in Atlanta Georgia that boasts over 7 million users.\\nHe is also the author of the book “Data Smart,” which presents an overview of machine \\nlearning techniques, as explained through spreadsheets.\\nData Science is not a Kaggle Competition\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 156}, page_content='JOHN FOREMAN\\n152\\nThe last chapter is an introduction to R, and it harkens back to previous chapters now \\nthat the kernels of understanding had been planted. For example, if you’re doing an \\nexponential smoothing forecast  (which I cover in my book), you should not be doing all \\nthese steps every time. You should be doing it on the shoulders of the giants who’ve \\nwritten the Ph.D. theses you’re using and just open their package.\\nUltimately, people who want to know each little detail of how a boosted tree model \\nworks or how modularity maximization works seem to love the book. Programmers who \\nare used to relying on black-box libraries, functions, etc. aren’t the biggest fans.\\nGiven your interest in opening up black boxes to examine the nitty-gritty of \\ndifferent techniques, did you ever want to write your thesis on a new statistical or \\nmachine learning technique?\\nI started at MIT wanting a Ph.D., but in my first year of graduate work I had the opportunity \\nto do some applied work on Dell’s supply chain, and it showed me that my passion lie \\noutside of academia.\\nYou see, my advisor was really interested in publishing results. Although we came to \\nDell trying to understand how to help the business generate revenue — which I enjoyed \\n— that wasn’t our ultimate goal. The problem with consulting when you have ulterior \\nacademic purposes is that the goal of academic publishing is counter to the goal of \\nhelping a business, because in order to publish, you need something academically new \\nto say. But if it’s a new technique, it is often not maintainable by the business once the \\nacademics leave.\\nThat was a good experience for me, because I realized that I’m not an academic despite \\nthe fact that I like technical things. Rather, I’m an analytics professional who enjoys \\ntailoring technical approaches to business settings where the solutions are sometimes \\ncomplex but often simple, depending not on my needs as a data scientist but on the \\nbusiness’s needs or the customer’s needs.\\nThat ability to think simply and “edit” models is something I just published an article \\non. One thing I reference in the article is a paper from 1993 by Robert Holte titled “Very \\nSimple Classification Rules Perform Well on Most Commonly Used Datasets. ” His basic \\npremise is that simple decision rules – a single rule that splits the data on one feature — \\nare pretty effective compared to more complex models, like a CART model. That makes \\nsense since oftentimes in naturally occurring data sets within the business, you have a \\ncouple of features that are good, and everything else is just icing on the cake.  \\nOne of the things Holte says in the paper is your model complexity has to be justified, \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 157}, page_content='JOHN FOREMAN\\n153\\nand that really grabbed me.\\nIt made me think, especially in a business context, what it means to justify your \\ncomplexity. Part of that is the additional expense of keeping the model running versus \\nrevenue. Part of that is the poor sap you’re saddling \\nwith keeping this thing running. And something \\nthat people don’t often consider is the likelihood \\nof abandonment.  \\nOnce you move on, whoever gets saddled with it \\nmight find some organizational reason or anecdotal \\nevidence to ignore it. They may not even tell you or get back to you. Are you going to \\nstick around and babysit all your models? How do you hand them to someone if they’re \\ncomplex?\\nSo to come back around to getting a Ph.D., for me, it was this desire to go out and use \\ndata to serve a business, and to do that using both complex and simple approaches that \\npushed me to leave graduate school early and join the workaday world. I don’t regret it.\\nIt seems like the academics are trying to do the most complex models, and the \\nbusiness decision makers are thinking it may not be all that helpful, that 80% of the \\nway there is good for us already.  \\nCan you talk more about your background? What were you doing before your \\nPhD?\\nMy dad is an English professor so I thought I was going to do English. Slowly, I realized \\nI was pretty good at math. In my undergrad, I studied pure math. I really liked abstract \\nalgebra, and I thought I was going to be a pure math guy. My advisor sat me down and \\nsaid, “You’re alright. You’ll probably go to grad school in a top 10 program, but you’re \\nreally not going to amount to much in the math community.” I felt at the time that it was \\npretty harsh, but it was true. I couldn’t compare myself to other people doing pure math.\\nThe way math works is a lot of people toy with little results for a long time, and suddenly \\nthere are huge jumps from certain people. I would never be that individual who would \\npush the mathematical fossil record forward into a new era. I would be a guy that toys \\nwith smaller results. So it came down to a question of passion: how passionate was I \\nabout pure math?\\nAt the time, I was also doing research for another math professor on knot tying. I got \\nYour model complexity has \\nto be justified, and that really \\ngrabbed me.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 158}, page_content='JOHN FOREMAN\\n154\\npaid as part of this research group to write code that would take two 3D models of knots \\nand join them into a compound knot without crossing over other sections of the knots \\nand forming a new knot type. It was crazy specific, but I learned a lot about Unix and \\nprogramming. I wrote code to do simulated annealing in C. I was getting all sorts of \\nmemory leaks, and I had to do a lot of stuff in the command line with data sets.\\nI didn’t know what that was at the time. I thought it was just math research that involved \\ncode, but I liked it. It turned out to be my most valuable experience as an undergraduate. \\nAfter all, what would a data scientist do without piping in Unix?\\nWhat did you end up doing once you graduated?\\nI did a couple of internships at the NSA over the summers, and I loved the applied, \\nproblem-focused environment. When I did my first summer internship, it was all math \\nstudents hopped up on stories of Bletchley Park, etc. Lots of energy. It was great, but then \\nI did another internship there and they put me in a regular office with regular employees \\nthat had been there for a long time. And that’s what ultimately scared me away.\\nI remember talking to one guy who had a picture of a golf course above his computer. He \\nsaid, “That’s what I’m doing next year when I retire, playing golf.” Everyone was tired, \\nand everyone was burned out. I figured that a government job wouldn’t be exciting for \\nlong, so I began to look at other applied analytics opportunities.\\nSo in graduate school I chose to study operations research where math was applied to \\noptimization modeling. I went to MIT in their Operations Research Center which is an \\ninterdepartmental program between engineering, stats, math and business. It was cool \\nbecause you could take business classes alongside highly technical classes. I got a kick \\ndoing MBA case studies because it was so foreign to a math class. No proofs!\\nI thought the OR program was awesome, so I knew that career-wise I was headed in \\nthe right direction. When I did my graduate research for Dell and was able to use the \\nOR concepts in a consulting framework, though, that’s when it all clicked. I applied to \\nanalytics consulting firms and the rest followed.\\nIs this when you went to Booz Allen? What did you do there?\\nYes. I went to Booz Allen and did a lot of analytics consulting work. I was on a team called \\nModeling, Simulation, Wargaming, and Analysis which exposed me to a huge variety of \\nanalytics approaches, techniques and problems. One month I’d be doing system dynamics \\nmodeling, the next month I’d be building an optimization modeling tool whose GUI was \\na bunch of Gantt charts. You never knew where the next project would lead.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 159}, page_content='JOHN FOREMAN\\n155\\nFrom there, I went on to do consulting at a boutique consulting firm called Revenue \\nAnalytics that does pricing models that adjust prices on hotel rooms, cruises, etc. These \\nmodels are complex IT projects, so most of the clients who had the data to power them \\nand could afford them were Fortune 500s.  \\nDuring this stint, I worked with Coca Cola in Shanghai to build an optimization model \\nthat pulls frozen barrels of orange juice pulp from oranges sourced all around the world \\nand blends them together so that every time you drink one of Coca Cola’s Pulpy drinks \\nin China, the feel of pulp in your mouth is consistent. The project felt like discovering \\nsome bizarro corner of the analytics universe halfway around the world.\\nAll these Fortune 500 projects were really fast-paced. But from there I jumped to \\nMailChimp, which is more of a startup, and nothing in the Fortune 500 world could have \\nprepared me for MailChimp’s pace. We’re on a release cycle where every four weeks, \\nwe’re putting out a new version of the application. That’s light speed for me and, in fact, \\nit’s too fast for a lot of data science projects, especially if you have a lot of infrastructure \\nrequirements. I’m the slowpoke of the organization. That’s an exciting place to be \\nbecause it means people are pushing me.\\nOne fascinating aspect of MailChimp as a startup is that it’s based in Georgia. Not \\nin Silicon Valley or even New York or Boston. What is the startup scene in Atlanta \\nlike? \\nThe startup scene is alright because Georgia Tech produces a lot of talent in the Atlanta \\narea. Some of those folks want to stick around our fair city. But that isn’t to say there \\nisn’t a massive magnet out at the West Coast, because people want to go out to the \\nValley, join a startup, get equity, and see if they can cash in that lottery ticket later.  \\nThat’s a very different culture than what you find in Atlanta.\\nThat’s something that we have to think about when we recruit, so we play to our strengths. \\nWe have some of the most amazing data sets in the world. Two of our domains are in the \\nAlexa 500. We send ten billion emails a month and process another three billion events \\non top of that. We added 200,000 active sending customers this quarter. We’re growing \\nso fast, and the nice thing about that message is it attracts those applicants who want \\ninteresting work rather than those who merely want an opportunity to cash out later.\\nHow does the company think about staying in Atlanta?\\nThere are a couple of advantages in being where we are. What I found is that if you’re in \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 160}, page_content='JOHN FOREMAN\\n156\\nthe Silicon Valley, you can be part of a conversation that’s occurring between all these \\ncompanies, and there are advantages to that because you know where things are headed. \\nThere’s also a disadvantage, because you lose a lot of mental freedom.  \\nIn fact, it can instill a lot of fear.\\nYou hear a lot of what other people \\nare doing, and it’s like being \\non Facebook where everyone’s \\nprojecting the best version of \\nthemselves. This puffery makes \\nyou depressed, and you flail about \\nto technologically keep up with the \\nJones. MailChimp doesn’t have that \\nperspective, because we are slightly \\nisolated. This isolation allows us a \\nlittle breathing room to seriously evaluate technologies, opportunities, markets, trends, \\netc., rather than just jumping head first into something because everyone else is doing it.\\nThat said, the folks at MailChimp get around a lot. I travel nonstop. I speak a lot. I meet \\nwith companies. I have conversations constantly with folks around the world, but it’s \\ntargeted and intentional rather than getting an earful all over the place because you live \\nin Silicon Valley. What that means is that there’s less fear, so we’re not thinking, “We \\nhave to take VC money” or “We have to acquire this start-up.”\\nTalking more about unconventional thinking, you’ve written in the past that “Your \\nmodel is not the goal; your job is not a Kaggle competition.” Can you talk about \\nwhy you don’t think Kaggle is where data scientists should be spending their time?\\nThere’s nothing wrong with Kaggle. I think it’s a great idea. If a company’s at that point \\nwhere they want a model that’s that good and they’re getting a lot of revenue and want \\nto push like Netflix, go for it.  \\nMy one criticism is that the way journalists write about it gives a skewed view of what data \\nscience is. There was an article on GigaOM where the author said, and I’m paraphrasing, \\n“The main thing data scientists do is build predictive models. That’s how they spend \\nmost of their time.” This is a myth that something like Kaggle will perpetuate.\\nBefore you build a model, you need to know what data sources are available to you within \\nthe company, what techniques are available to you, what technologies are available, you \\nhave to define the problem appropriately and engineer the features. Usually, when you \\nWhat I found is that if you’re in the Silicon \\nValley, you can be part of a conversation that’s \\noccurring between all these companies, and \\nthere are advantages to that because you \\nknow where things are headed. There’s also \\na disadvantage, because you lose a lot of \\nmental freedom.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 161}, page_content='JOHN FOREMAN\\n157\\ngrab data from Kaggle, all of these steps are done for you. You don’t have to go around \\nlooking for data. You can’t say something like, “Maybe they left some data behind. Can I \\ncome into your company and look around?”\\nI feel that there’s so many steps before you get to modeling that are crucial. Can I ever ask \\na Kaggle competition, “Is this the competition this company should actually be having?”  \\nThink about the Netflix prize. They were trying to predict what star rating readers would \\ngive a movie given past data, but I think they backed off that a little bit because they \\nnoticed it’s not all about five-star movies. For example, I watch garbage. I will give it two \\nstars, and I will watch it anyway. It’s more about moods. A lot of things drive viewership, \\nsuch as what my friends are watching on \\nFacebook. That’s something Netflix is \\ndoing now — and it’s made their original \\nmodeling endeavor somewhat irrelevant.\\nSo there’s this notion in data science \\nabout whether or not a project should be \\ntackled in the first place that is a priori  \\nignored by Kaggle. And I think a big \\ncomponent of data science is questioning \\nwhy you’re doing what you’re doing — \\nchoosing problems to solve while rejecting other problems that are irrelevant to the \\nbusiness. With Kaggle, for better or for worse, that job is done for you. Kaggle is just an \\nexercise in using a data scientist as model-building machine.\\nI still think that Kaggle competitions are awesome, and I will never match the intellectual \\nability of some of the competitors on that platform. I just like to emphasize the other \\nfundamentals of operating in a data science role at a company. I wish there was more \\nfocus on them, but those aren’t really sexy to talk about in the media.\\nWhat are some of these other fundamentals of operating in a data science role at \\na company?\\nWell, one of the fundamentals that everyone talks about is cleaning and prepping data \\nyourself. Finding, pulling, prepping, cleaning, the list goes on. Data manipulation prior \\nto model building is huge. But let’s go beyond that.\\nFor me, a core skill that any data scientist should possess is the ability to communicate \\nwith the business. It’s dangerous to rely on others at a business to actively identify and \\nthrow problems at the data scientist while he or she passively waits to receive work. \\nThere was an article on GigaOM where \\nthe author said, and I’m paraphrasing, \\n“The main thing data scientists do is \\nbuild predictive models. That’s how \\nthey spend most of their time.” This is \\na myth that something like Kaggle will \\nperpetuate.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 162}, page_content='JOHN FOREMAN\\n158\\nWhen that’s the setup, the business often hands over the wrong problems, because other \\nteams have no idea what data science can help and what it can’t.\\nBut if you’ve got a data scientist who’s good at communicating, then that data scientist \\ncan actively engage in conversations with the business and with executives to prioritize \\nhow to best use analytics.\\nI believe a good data scientist is one who’s engaged enough in conversation with the \\nbusiness to say, for example, “Hey, I know you guys think social data is cool, and I do too. \\nBut only 10% of our customers are on Twitter, and it’s anything but a random sample. \\nHave we considered using this other transactional data source to approximate what you \\nwant instead?”\\nSo now we’ve got two skills that are important other than building models: data \\nmanipulation and communication. What else?\\nThere’s one skill that I like to harp \\non: the skill of editing. People \\nhave a strong desire to distinguish \\nthemselves from the herd by flexing \\ntheir expertise. We see this in all \\nindustries and jobs. If you have a \\nparticular knowledge set, you’re \\ngoing to show that off. In analytics, \\nthe way that tendency manifests is by making models overly complex. And by that, I \\ndon’t mean “using a complex model when a simple one gives the same performance.”\\nNo, I mean “using a complex model that is brittle and overly burdensome for the \\norganization to maintain, i.e. whose likelihood of abandonment is high, when a simpler \\nmodel has a better chance of long-term survival.” Sometimes that means using a simpler \\nmodel even when some performance is lost. That takes an editing eye. And in data science, \\nas in many disciplines whether that be journalism, oil painting, or speechwriting, editing \\ndistinguishes the experienced practitioner from the newbie.\\nOne of the big ideas you mentioned is the fact that complex model-building is not \\nwhat a data scientist spends most of his time on.\\nDo you think, in the future when there are more tools built for data scientists to \\ntake care of all the steps before modeling, data scientists will in fact be spending \\nmost of their time on complex modeling?\\nI think a big component of data science is \\nquestioning why you’re doing what you’re \\ndoing — choosing problems to solve while \\nrejecting other problems that are irrelevant to \\nthe business.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 163}, page_content='JOHN FOREMAN\\n159\\nI think we’re already seeing the commoditization of a lot of these skills. It’s not that \\nhard to read a book on R and learn how to build models. It’s pretty easy, and that’s where \\nonline education can come in and fill in a lot of technical gaps. If that’s all you need \\nas a business, I have faith that not only can cheap labor fill in that gap, but tools are \\neventually going to get there, too.\\nThe part that will be irreplaceable is knowing what’s possible from an analyst’s \\nperspective. So, there are a lot of unsupervised techniques, but knowing these techniques \\nand identifying data and opportunities within the company where those opportunities \\ncan be married with the data is not purely a technical problem. It’s a creative problem. \\nIt’s knowing all these things and being able to connect the dots. I feel like that’s going to \\nbe a very human problem for a very long time.\\nThis is related to what you’ve said before — that a data scientist is a Renaissance \\nfigure because it’s connected to sociology, ecology, business, computer science \\nand math where you put it all together to solve problems.\\nRight. One of the things I’ve noticed \\nwhenever we try to hire data scientists is \\nthat the most effective data scientists are \\nthe ones who can communicate effectively. \\nThey can talk to people. They can \\ncommunicate in writing. They can craft an \\ne-mail. They can craft a document that’s \\ntechnical while also lucidly explaining what they’re doing. They can tell a story. Those \\nare skills that are refined by studying, wrestling with and arguing ideas across disciplines. \\nAnd when I encounter data scientists who often enter the discipline tangentially through \\na variety of other disciplines, I see this breadth and the way it facilitates communication.\\nNow, why do I think that’s important?\\nJust as crucial as data cleaning is to the beginning of a modeling engagement, \\ncommunication in the form of change management is crucial during and at the end of a \\nmodeling engagement.\\nChange management is the idea that after you build a model, how do you get other \\npeople to use it? You don’t just walk into a business and say, “I built you a model. Trust \\nit.” There are issues around working with people, communicating, and understanding \\ntheir context that don’t come from just learning to do data modeling. That’s a completely \\ndifferent skill set and it’s one that the Renaissance person (i.e. an employee with a wide \\nbreadth of study and experience) is more likely to possess. If I’m going to be telling \\nIt’s dangerous to rely on others at a \\nbusiness to actively identify and throw \\nproblems at the data scientist while he \\nor she passively waits to receive work.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 164}, page_content='JOHN FOREMAN\\n160\\nstories and communicating to a wide group of people, I need more training than just \\nbeing siloed in the math department.  \\nSo I try to hire people who look like that. They can do all these things. They can talk \\nto people. They can write spaghetti code. They can push around data. They can build \\nprototypes.  \\nWe’re seeing this Renaissance-person idea, i.e. this multidisciplinary, quasi-quantitative, \\nquasi-liberal arts approach affect a whole host of disciplines. Just look at the new “digital \\nhumanities” movement where things like \\nthe Trans-Atlantic Slave Trade Database \\nare being built that historians, linguists, \\netc. are setting their SQL on.\\nI love that we’re seeing data and the \\nhumanities collide, and that’s happening \\nin business, too. That’s why we have this \\nweird hybrid concept of a data scientist \\nwho’s not really a scientist. When you look at the preeminent data scientists out there, \\nthey are not people who are just in a lab acting out your canonical, stereotypical view \\nof a scientist. A lot of them are writers and speakers and executives and a whole host of \\nother things than your typical white-coated scientist.\\nAt the same time, there exist a lot of the people who are doing that are in a Ph.D. \\nor are considering a Ph.D., and one of the reasons they’re attracted to data science \\nis because they’ve heard that it applies to their researching skills in the industry. \\nGiven all the things you mentioned that couldn’t be acquired by staying in the \\nmath library, do you think this idea of the data scientist as an applied researcher is \\na misconception?\\nThere are certain companies where there’s a resemblance between the two. For example, \\nif I’m going to be doing ad targeting on Facebook, I’m going to be part of Yann LeCun’s \\nnew deep learning lab. I imagine for that type of data science, academics are going to \\nfind that a fine transition.  \\nHowever, there is a vast array of companies now that think they need data science talents, \\nand the data science talent they need is not someone who has been specializing in one \\nparticular academic area for six years of graduate school.\\nThat’s not what companies need. They need someone with a broader skill set.\\nJust as crucial as data cleaning is to the \\nbeginning of a modeling engagement, \\ncommunication in the form of change \\nmanagement is crucial during and at \\nthe end of a modeling engagement.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 165}, page_content='JOHN FOREMAN\\n161\\nI’ve seen too many Ph.D.s go into companies with a not-my-job mindset where they’re \\ngoing to wait for you to bring them a problem that fits perfectly with their expertise. If \\nyou don’t bring them that problem, it’s not their job. I get it — they fought hard for that \\ndoctorate.\\nBut this is a dangerous way of thinking that could sour a lot of people in the industry.  \\nI like people who are more aggressive and want to find problems to solve. Maybe they \\ndon’t get to use the techniques they’ve used in the past, but they know there are a lot of \\nanalogous concepts in these techniques. For example, one of the things I put out in my \\nbook is that machine learning algorithms, whether they’re unsupervised data mining \\ntechniques, AI modeling, or forecasting, all have an optimization component.  \\nThe point I’m trying to make is that even though you are focused on one thing, all these \\nthings are related. All these concepts are related. Cluster detection and outlier detection \\nare two sides of the same coin in a graph, and I try to tie them together to show people \\nthat if you can do one of these things, you can do all of them. You should be excited to \\nlearn all these things and figure out which ones you can use forever.\\nYou’re like a kid in a candy store where you’ve got all these opportunities to do these \\nthings. Those are people I would love to see move into this industry. Some of those folks \\nare Ph.D.s, but sometimes the specialization that comes with too much time in graduate \\nschool can be a burden.\\nAs more people move into and understand data science, do you think that the \\nfuture will bring data, and statistics, literacy for the masses?\\nKnowing how slow academia moves, it’s going to take some time to get there. I went \\nto the University of Georgia, and everyone there had to take a math class where the \\ntextbook had a cover with Waffle House on it, which shows you the level of math they \\nwere learning. I think we’re moving into a world where people need to know more math, \\nand it’s no longer acceptable to say, “I’m not good at math. Math isn’t for me.”\\nEveryone’s going to have to be literate. When I worked in management consulting, I met \\na lot of strategy consultants who came from non-quantitative backgrounds, but every \\nsingle one of them knew how to do a pivot table. They knew how to write a VBA macro \\nand filter data. They knew the basics of how to move data around in a spreadsheet. They \\nwould never call it math or programming, but it’s pseudo-math-programming. Oddly \\nenough though, those simple skills were an essential part of what the client was paying \\nfor.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 166}, page_content='JOHN FOREMAN\\n162\\nI think there’s going to be more of that need in the future. People are going to need to \\nknow how to do things like significance tests, sample size calculations and so on. We \\nneed to find a way to fit this data literacy into a liberal arts curriculum. That requires \\nmotivating the concepts.  \\nIn “Data Smart” I try to motivate people to \\nlearn these techniques as much as possible \\nby showing how to explicitly use them in \\nbusiness. The cool thing with teaching \\npeople later on in life, once they have a job, \\nis that the motivation totally clicks. When \\nit comes to teaching students, especially \\nthose majoring in something else, they’re \\nunmotivated. School’s never really cracked that nut, but I think it’s headed that way. \\nPeople need to be data-literate. There’s no way we’re going to get by without it.\\nAt the same time, there’s a debate in some parts of the Valley. There are people \\nsaying that numbers are pushing out the usage of human intuition, and that there’s \\nan over-usage of analytics, where you’re AB testing every shade of green on your \\nbutton and you go with whichever one performs the best. As the future becomes \\nmore driven, what’s your take on this type of criticism?\\nI do agree, and I think that approach is dangerous. At MailChimp, we often make fun of \\nKey Performance Indicators, aka KPIs, which are the lifeblood of the corporate analytics \\nworld. When we listen in to the quarterly calls our competitors have, we can see they’re \\ndriven by metrics like ARPU (average revenue per user) so much so that they’ve lost \\nsight of things that are not unimportant but are just harder to measure.\\nYou’re optimizing average revenue per user not because it’s the most important things \\nbut because you can measure it and Wall Street can measure it and look at it. That’s a \\nway to grade your company, but what does average revenue per user mean when there \\nare users on your Facebook site saying, “I fucking hate you guys”? That could be a red \\nlight that something is wrong, but you’re not paying attention to it because it’s not a \\nmetric you care about.\\nI think we should leave room for people to be creative and to think about soft things like \\ncustomer happiness. At MailChimp, we purposely don’t measure a lot of metrics against \\nour marketing team. Our marketing team has a budget, but we don’t look at things like \\nconversion. We took out billboards in cities across the US, and the billboards just have \\na picture of Freddie, our chimp mascot, with a blue background and no words at all. \\nThe only people who really understand what it is are already MailChimp customers and \\nmaybe our competitors.  \\nPeople are going to need to know how \\nto do things like significance tests, \\nsample size calculations and so on. \\nWe need to find a way to fit this data \\nliteracy into a liberal arts curriculum.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 167}, page_content='JOHN FOREMAN\\n163\\nWe can’t look at conversion of that, or how it affects revenue. That’s not something we’re \\ninterested in. It’s about giving our users a good experience. They see a billboard on their \\nway to work, and they’re thinking, “ Aww... That’s MailChimp.” And there’s value there. \\nIt’s like an inside joke in a subtle way. I might go to a conference and have a MailChimp \\nuser come up to me who’s excited to meet \\nsomeone from MailChimp. They might say, \\n“I love using your site. It’s so much fun. It’s \\none of the best sites I use for my job.” That’s \\ngreat. That’s a kind of person who’s going \\nto go tell other people about our product, \\nbut we don’t have to measure it.\\nIts better that we just keep delighting customers so they tell other people about the \\nproduct rather than AB-test button colors. I’m perfectly happy to leave things in the \\nhands of talented designers, people who are not quantitative but know what they’re \\ndoing.\\nHave you ever heard of Tony Hsieh, Zappos CEO, Downtown Project in Vegas? He \\nmoved the headquarters of the online retailer from the Silicon Valley to Vegas. His \\nperspective is that it’s important to engender serendipity but not with contrived \\nmethods. Although he runs a tech company, he’s much more open to the intangible \\nthings such as human creativity and experimentation.  \\nIt’s interesting having two well-known companies in very different parts of the \\nworld that are technology-driven but not in Silicon Valley, and as a result they \\nthink of things differently than other firms. Do you think there’s any relationship \\nbetween being not in the Valley and being able to think the manner you described?\\nHonestly, part of that for us is that we are privately owned. We are not seeking to go \\npublic, and we’re not taking funding from any other companies. We have the freedom to \\nbe creative, because there’s no one breathing down our neck.\\nMailChimp’s bootstrapped, and, because of that, we have immense freedom. We’re not \\ntrying to sell the company to someone else. When your goal is to sell your company, \\nthings can get perverse. You get distracted, and that is dangerous from a competitive \\nstandpoint. If we get distracted, we might check out or lose sight of what other competitors \\nare doing. Part of our different perspective is driven by being outside of the Valley. But \\nanother large part of it has been knowing that we’re not taking funding.\\nA lot of people these days are interested in starting companies — being founders, etc. \\nWe at MailChimp are interested in being a company in the long-term. That looks very \\nAt MailChimp, we often make fun \\nof Key Performance Indicators, aka \\nKPIs, which are the lifeblood of the \\ncorporate analytics world.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 168}, page_content='JOHN FOREMAN\\n164\\ndifferent, and I’d argue it’s a better place to be as a data scientist. When you’re a data \\nscientist at a young company looking to go public or be acquired, then your work ends up \\ngetting commandeered for marketing purposes. It becomes difficult to invest in analytics \\nthat might have long-standing customer value versus some short-term wow! factor.\\nWow. That’s a pretty amazing distinction between MailChimp and other tech \\nstartups. I’ve heard of one project at MailChimp called the Email Genome Project. \\nCan you talk more about that?\\nThe Email Genome Project was essentially an infrastructure initiative at MailChimp to \\ncreate a dossier for every e-mail address we’ve ever seen and store data about it. In fact, \\nright now it resides in RAM. It’s one of the largest in-RAM databases in the world. We use \\nRedis to do it, so it’s essentially a big Redis key-value store summarizing interactions \\nwe’ve had with about three billion unique e-mail addresses.  \\nWe built APIs around this data store \\nand use those internal APIs to power \\ndata products. We have an anti-\\nabuse AI model called Omnivore, \\nand that runs off EGP . One of my \\nfavorite internal products is called \\nNotABot. When users sign up for MailChimp, we check NotABot, and if you look legit, \\nwe hide CAPTCHA because of everything we know about you. We say, “We’ve already \\nlooked at your behavior. We know you’re a human, so you’re good to go and we’re just \\ngoing to hide the CAPTCHA.”\\nThe funny thing is that the data science project is not something built in D3. It’s not \\nsomething cool with bubbles. Literally, this data science product is the absence of \\nsomething. All I’ve done is taken CAPTCHA away, and I feel very proud of that. Removing \\nthings improves the user experience; this is one way to make users’ lives suck just a little \\nbit less.\\nWe had CAPTCHA in front of our help form to contact support, but when you want to \\ncontact customer support, you already have a problem. It’s a perfect opportunity to \\nreduce friction for these confused people rather than adding some shitty CAPTCHA icing \\nto their confusion cake. That’s a small project we’ve done, and we’ve done a lot of things \\nlike that using EGP’s internal APIs. We tell people, “Here’s what this API call does. Here’s \\nthe data that backs it.” Then we expose the API call to the devs and see what happens.  \\nWe did another project called Send Time Optimization where we noticed a couple of \\nthings. One was people asking what time they should send. People were going online \\nMailChimp’s bootstrapped, and, because of \\nthat, we have immense freedom. We’re not \\ntrying to sell the company to someone else.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 169}, page_content='JOHN FOREMAN\\n165\\nand just reading anecdotes. It’s not like all your customers go to work from 9 to 5 and \\ntake lunch at noon. But those are the kind of assumptions you’ll see in anecdotes from \\nsupposed marketing gurus.\\nOne of the things data science promises is that we can provide people’s personal \\nexperiences. Using EGP , MailChimp can tell you about your particular subscribers. What \\ndo you know about their behavior? If you’re writing to line cooks who work the night \\nshift, they’re probably not awake at 2 PM. So what Send Time Optimization (STO) does \\nis it pulls all the records for these email addresses (even if we have new e-mail addresses, \\nwe’ve seen them before due to other MailChimp email they’ve gotten), and using those \\nrecords, STO hands you a send-time recommendation. Anecdotes are for chumps.\\nHow does MailChimp then use data science to power these personalized product \\nfeatures?\\nSo far I’ve laid out a few of MailChimp’s data science products: Omnivore for anti-abuse, \\nSend Time Optimization, and NotABot. But we’ve got a lot more. For instance, we use \\nAI models trained on past interactions with customer support to make knowledge-based \\narticle recommendations. We use data mining algorithms to find segments on people’s \\nlists and suggest those segments to them. We use optimization modeling to schedule \\nour customer support employees to meet forecasted ticket demand. We use a lot of Holt-\\nWinters with prediction intervals when making infrastructure forecasts.\\nSome of these products are supervised machine learning products, others are classic ops \\nresearch products, graph mining products, forecasts, etc. We use whatever techniques \\nand whatever data gets the job done.\\nSome products are user-facing, some are internal. Some are big and require tons of \\ninfrastructure. Others, like our likelihood-to-pay model, are nothing more than a logistic \\nregression whose coefficients fit in a single short vector.\\nSo how do we use data science to power these products? Any way we can.\\nThe one common theme these products have is not an approach or a data source or \\na technology. The one common theme is that each product solves a problem for the \\nbusiness or the customer. I run my data science team like an internal consultancy. We’re \\nall about being useful.\\nThere’s this joke going around making fun of data scientists that says that a data \\nscientist is just a statistician who lives in California who calls himself that to get a job. \\nGiven that you’re someone who is both professionally a data scientist, yet at the \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 170}, page_content='JOHN FOREMAN\\n166\\nsame time seems to share a sense of skepticism about things that are overhyped, \\nwhat is your take on the burgeoning field of data science?\\nI think the term “data science” is somewhat ludicrous. The phrase “Data science” is two \\nvague words glommed together that don’t actually describe most of how I spend my time. \\nData science as a term may die, nothing but a fad title, but the skill set is so important \\nthat it will spread into many roles within the business. It wouldn’t surprise me if, a few \\nyears from now, most MBAs require a couple of data science-style classes.\\nThe field is just going to get into the water.  \\nThe more you investigate data \\nscience as a category, the more you \\nsee it’s an umbrella term disguising \\ninsane amounts of variety in skill sets \\nand backgrounds. A data scientist \\nis unlike a stonemason in that way. \\nThere isn’t one background for data \\nscientists and there isn’t one thing that we do. We’ve seen data scientists who are more \\ndata engineers. We’ve seen data scientists who are AI professionals. We’ve seen data \\nscientists who are good at visualization and doing front end development.  There are \\ndata scientists like me who are nothing more than embedded strategy consultants who \\nlike math.  \\nThe term could die or fracture into multiple titles, but need for those skill sets won’t. \\nStudents tend to worry about that and say, “People won’t need data scientists by the \\ntime I graduate.” They’ll need something like a data scientist for sure, so just call yourself \\nthat. My past job titles used to include words like “analytics” and “business intelligence.” \\nThat’s fine. The terms come in and out of style, but if you are good at understanding \\nproblems and communicating with people, and answering their questions with data, the \\nneed for you in particular will never go away. You will never be automated. You will have \\nplenty of job security.  \\nDuring a conversation we had with D.J. Patil, he told a story of how, at some point, \\nhe consulted for the US government when they were in Afghanistan. He mentioned \\nhow there was a lot of chaos and everything was going crazy, but there was a lot \\nof opportunity that came out of that chaos and you could influence people because \\nno one knew what was going on.\\nData science seems to be evolving in the same way: where there’s chaos, there’s \\nuncertainty and as a result, plenty of opportunity. Do you think there are going to be \\nThe more you investigate data science as a \\ncategory, the more you see it’s an umbrella \\nterm disguising insane amounts of variety in \\nskill sets and backgrounds.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 171}, page_content='JOHN FOREMAN\\n167\\nlarge opportunities in the future as data and technology become more prevalent?\\nYes. I touched on this in an article I wrote about Disney . The “meat space” world, i.e. \\nthe one not confined to a screen, is full of chaos and uncertainty, and so there’s huge \\nopportunity to take the analytics we’ve been doing for web companies and move it out \\nof that orderly sandbox and into the physical world.\\nObviously, wearables are an immediate example of how that’s happening. But humans \\nare being “cookied” in meat space by more than just wearables. Think about Nest (and \\nhow much Google paid for it). We’re doing all sorts of physical tracking, such as MAC \\naddress tracking in stores and appending demographic data to surveillance video feeds, \\nso we understand a bit about your demographics and what racks you go to in department \\nstores.\\nDisney saw this opportunity when \\nthey introduced a long-range tracking \\ncomponent to their wristbands. They \\ntrack you in physical space so that they \\ncan provide personal experiences in the \\nphysical world and not online. My kids \\nrode “Pirates of the Caribbean” eight \\ntimes at Disney World. Then we visited \\nthis animatronic Mickey and all he would talk about were pirates, because he knew that’s \\nwhat my kids were into based on their transactions in the physical world.\\nThe physical world is messy and chaotic, nonetheless we can understand people’s actions \\nas they move throughout that space. That’s where I see the most opportunity for data \\nscience.\\nIt sounds like the overarching theme is that the personalization of the internet, of \\nvisual space, is going to move towards the personalization of the physical world?\\nIt’s going to merge. In fact, the internet is simpler than the real world because I \\ncan “cookie” you on the internet. We’re going to learn how to cookie people all over \\nthe physical world too, and I think people are freaked out about this from a privacy \\nperspective. I agree and sympathize. There’s a creepy side to the word “personalization.”\\nIt’s a frightening affront to our personal freedom. While I’ve gotta live my work-a-day life, \\nthere will be companies tracking me that will be dedicated to getting me to do one thing, \\nlike opening a credit card or drinking a Coke. It’ll be data-driven asymmetric warfare. \\nThey have my data. They know my issues — financial, personal, etc. Their models will \\nThe physical world is messy and chaotic, \\nnonetheless we can understand people’s \\nactions as they move throughout that \\nspace. That’s where I see the most \\nopportunity for data science.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 172}, page_content='JOHN FOREMAN\\n168\\nknow how to target me. They can pull my strings.\\nI think that is concerning, but, at the same time, we’re doing this to ourselves and share \\nthe blame. I install whatever mobile app I want to and just blaze through the permissions. \\nPeople always say “but it’s my data.” If you give it up in exchange for a free game, it may \\nnot be anymore. The undervaluation of personal data by consumers is endemic today.\\nSo yes, personalization on the internet will morph into personalization everywhere. But \\nwe’ve got to figure out all this creepy stuff as we head in that direction. Part of that will \\nbe cultural, and part of that I’d imagine will be legal and legislative.\\nA term I’ve heard before is “data superhero”, and it’s the idea of putting yourself, \\nas a data scientist, into a position where no one in Congress knows what data \\nscience is. They’ve never read “ Data Smart”, and the superhero is the one who \\nknows what it is and is able to inform people and stand up for the public interest.\\nData scientists have a particular set of skills and knowledge that makes them essential to \\nbusiness today. A lot of that knowledge and skill is being used to blaze new trails for how \\nwe as individuals, consumers, citizens, etc. interact with businesses, our government, \\nour peers. There is abuse and confusion as well as opportunity to fundamentally change \\nentire industries and practices for the better.\\nGiven that, data scientists can take on public-facing roles as subject matter experts. \\nPeople want to know what’s possible with data, both to understand if abuse is possible \\nas well as to understand if progress is possible. Too many people think of data science as \\nmagic, but data scientists can come in and bring the discussion back down to earth. We \\ncan say, “no that’s not possible,” and “yes that’s possible,” and “yes that other thing is \\npossible but you’ll need express legal consent from consumers,” and so on.\\nAnd that’s a role we should take up, because if data scientists don’t engage the conversation \\nthen we should expect voices with less training to fill that information vacuum.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 173}, page_content='JOSH WILLS Director of Data Science at Cloudera\\nTo start the interview, we’d love to revisit your undergraduate days, from when \\nyou were just going into college, to graduate work, and how your experiences led \\nyou to where you are now. \\n \\nI was a math major in college. The funny thing is that I never really liked math when \\nI was growing up, even though I was pretty good at it. I was more into history and \\npolitical science, until I got to high school and discovered calculus. I was enthralled. \\nI loved calculus and felt that it was the first interesting piece of math that I had ever \\nencountered.\\n \\nI was a pretty big nerd in high school, which won’t be shocking to anyone. I did things \\nlike study for AP exams for classes I wasn’t actually taking. During my junior year, I took \\nexams for AP Political Science and Comparative Government without actually taking \\nthe classes. I did well on those exams, so I ended up doing the same for Art History, \\nEconomics, and Physics during my senior year. I also read all of Calculus AB and BC in a \\nsemester, and then I got into multivariate calculus and proceeded to linear algebra, all \\non my own. I was just completely enthralled with the beauty of mathematics, the same \\nway a person would appreciate a beautiful painting or work of art.\\n \\nFascinated with the beauty of calculus at an early age, Josh \\nWills majored in pure math at Duke. His first introduction \\nto statistics was in the final year of university, where despite \\nsome misgivings of it being not nearly as interesting as \\nhyperbolic partial differential equations, he actually fell in \\nlove with the discipline. \\nAfter a brief stint at IBM, he returned to do a PhD in \\nOperations Research at UT Austin, trying to solve NP-hard \\nproblems. Afterwards, he joined the startup world, working \\nas a statistician first at Zilliant, then Indeed and finally \\nGoogle.\\nIn this interview, Josh offers beautiful thoughts on the intersection of literature and data \\nscience, learning through humility and masochism, profound moments in open source \\nprojects, and the deep impact that Google’s engineering had on him. Josh Wills is currently \\nthe Senior Director of Data Science at Cloudera, where, according to him, he “makes data \\ninto awesome.”\\nMathematics, Ego Death and Becoming a Better \\nProgrammer\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 174}, page_content='JOSH WILLS\\n170JOSH WILLS 170\\nI ended up going to Duke University. The best part about Duke was that I got to take \\nwhatever math courses I wanted right away. My first course was graduate level topology. \\nThat was interesting because I was taking it with the other math freshman who \\nwere really good mathematicians. It became apparent to me relatively quickly that I \\nwhile was good, the other freshmen were on another level altogether, which was very \\nhumbling. I think everyone \\nruns into this at some point in \\nlife, and I felt relatively lucky \\nthat I encountered it during my \\nfreshman year because it gave \\nme time to recover.\\n \\nAnyway, I stuck with math, and I thought I was going to become a math professor. \\nBut I was also interested in many little side things- I did philosophy, economics for a \\nwhile, and then  became interested in cognitive neuroscience. I was lucky enough to \\ndo a Research Experience for Undergraduates (REU) fellowship at Carnegie Mellon the \\nsummer after my sophomore year, modeling road and spatial navigation. That was my \\nfirst introduction to real programming in MATLAB, building large models to simulate \\nbrain function. That experience is what got me interested in programming in general.\\nDid this push you to start taking programming classes at Duke as well?\\nYes. I took Duke’s introductory courses in computer science and I learned how to program \\nin C++. I never really studied algorithms or operating systems or other things computer \\nscience majors study. In my professional career, I’ve discovered all of these huge and \\nembarrassing gaps in my computer science knowledge, usually during job interviews.\\n \\nAt the start of my senior year, I decided to put the academic career on hold and go get a \\nreal job. I was interviewing with some startups and accepted an offer, but it was rescinded \\nas part of the whole dotcom implosion thing that was happening in late 2000/early 2001. \\nI wasn’t alone here, and Duke’s recruiting office was really great in helping folks find \\njobs elsewhere. I ended up getting a job in IBM’s Austin office. My first day was June \\n17th, 2001, and the week after I started, IBM announced a hiring freeze, so I suppose I \\nslid in just under the wire.\\n \\nIBM Austin had a hardware group that does chip design and system bring-up, which \\nis where you hack early stage hardware to get around all of the bugs so that you can \\nload and run an operating system. I was managing a MySQL database of test data \\nfor microprocessors. All in all, it was 15 gigabytes of data, which at the time seemed \\nenormous, but now seems laughable — my phone has more storage than that whole \\nvolume of test data! I was building dashboards and running statistical analyses of machine \\nI was just completely enthralled with the beauty \\nof mathematics, the same way a person would \\nappreciate a beautiful painting or work of art.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 175}, page_content='JOSH WILLS\\n171\\nperformance and chip performance; trying to predict how fast a chip would clock based \\non a number of measurements that were made during wafer fabrication. It was classic \\nstatistics, classic data analysis, and just learning how to program. To be honest, it was \\npretty dull, and I got bored with it fairly quickly. I also have this masochistic approach \\nto achievement, and so sometimes I like to do things just to prove that I can do them, \\nregardless of whether or not it’s actually a good idea or not. So in that vein, I applied for \\nand got into the Operations Research (OR) graduate program at the University of Texas \\nat Austin (UT). UT didn’t have a statistics department, which is what I actually wanted to \\nstudy, and OR was as close as I could get without having to leave Austin, which was just \\na really great place to be at the time.\\n \\nAs an undergraduate, I didn’t take any statistics courses at all until my very last \\nsemester, which was really my blow-off semester. It was when I took music appreciation, \\nintroduction to logic (oddly enough, a philosophy course), and introduction to statistics. \\nIntro stats was actually a requirement to graduate, but I felt like it was beneath me after \\nall of the abstract algebra and hyperbolic partial differential equations. And the funny \\nthing is that I completely fell in love with it. A lot of the philosophy and neuroscience \\nstuff I was into were things involving epistemology and symbolic reasoning, about \\nunderstanding how we can say that we know something to be true. \\n \\nAnd statistics is about quantifying uncertainty and what we can’t know.\\n \\nPrecisely! It is the quantification of what is knowable and what is not. Here is your data, \\nwhat can you say that you know? It was deeply appealing to me. Personally, that kind \\nof stuff really winds my clock. I loved statistics. Fast-forward a couple of years, and now \\nI’m at UT and taking a full graduate course load in OR. I did three courses a semester for \\ntwo years to get my Master’s degree, while simultaneously working at IBM. That was a \\nterrible idea. It was absolutely horrible. I had no life.\\nIt sounds like you learned how to do the relatively simple statistical analysis at IBM \\nand thought, “I want to expand my intellectual horizon.”\\n \\nVery much so. My IBM introductory software engineering job was pretty easy, and I wrote \\na bunch of crazy Perl scripts that more-or-less automated my job. But I had this kind of \\nresidual itch from my statistics class and from seeing that statistics was actually pretty \\nuseful to people in the real world. My mental model at the time was that if you wanted to \\nlearn more about something, school was a pretty good place to do it, and so I went back \\nto school.\\n \\nA semester into my graduate program, I made another switch: I changed teams at IBM to \\nbe able to do some “real” programming, not just dashboards and Perl scripts. I switched \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 176}, page_content='JOSH WILLS\\n172\\nto a team did very low level firmware programming in C++. This was basically writing \\nfirmware for hardware systems that didn’t fully work yet because they haven’t debugged \\nall the circuits. I was working as part of a team and learning to use things like source \\ncontrol, write tests, all of those good practices that I never learned in school. More than \\nanything though, the most useful skill I learned was how to debug black box systems. \\nI was trying to run firmware on a piece of hardware that didn’t really work yet, and my \\njob was to figure out a way to make that software run by hacking around whatever bugs \\nI came across in the hardware itself. I didn’t know anything about hardware. I still don’t \\nknow anything about hardware. I can’t even program a VCR. I think that I became a \\nsoftware engineer because I can’t understand any system that I didn’t design myself. \\n \\nAnyway, the black box system is a piece of hardware that doesn’t work. I would give it \\nan input, and it would not give me an output. I had to figure out a hack, some sequence \\nof commands, that would cause this piece of hardware to begin communicating with \\nthe rest of the system. And this skill, the art of debugging something that you don’t \\nunderstand at all, is maybe the most useful thing I learned there.\\n \\nWhat did you end up learning through this experience of debugging black box \\nsystems?\\n \\nI don’t think there’s any secret to it: I’m \\nobsessive. I was one of those kids that played \\nwith Legos for five or six hours straight. \\nI’m still pretty much like that. I was born \\nin 1979, so I’m borderline millennial. It is \\nunacceptable to me for a computer system \\nto not do what I want it to do. I was willing \\nto beat on the black box hardware for whatever amount of time was required to make it \\ndo what I wanted.\\nI’ve had a few instances in my life where I have worked on a very satisfying problem. A \\nsatisfying problem is one where your technical skills are good, but the problem is just a \\nlittle bit too hard for you. You’re trying to do something slightly more difficult than what \\nyou already know how to do, and that is great, great feeling. I can lose myself in those \\nkinds of problems. That’s typically when my personal relationships tend to fall apart, \\nbecause I’m not really paying attention to anything else.\\nThere was this trend for awhile in data science job interviews to have candidates analyze \\nreal datasets during the interview. I’m a huge fan of this practice. I had one job interview \\nwhere they gave me a problem and a dataset and two whole hours of quiet time to just \\nsit and do data analysis. It was maybe the happiest two hours of my entire year. I should \\ndo more job interviews just so I can do that. \\nIt is the quantification of what is \\nknowable and what is not. Here is your \\ndata, what can you say that you know? \\nIt was deeply appealing to me.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 177}, page_content='JOSH WILLS\\n173\\nYou had mentioned how, at one point of your college career, you were burned \\nout from academia. One of the hallmarks of academia seems to be that once \\nyou’ve reached a certain point, you have the opportunity to spend all of your time \\nobsessing over an open problem. Given that your personality type seems to fit \\nthat role, why wasn’t academia appealing to you anymore?\\n \\nAs a pseudo-millennial, I’m not just entitled, I’m impatient. I don’t think the requirements \\nof academia were appealing anymore; there were large sets of things I would have to \\ncomplete before I reached that point of being able to obsess over an open problem.\\n \\nOnce you’re a graduate student, you work for a professor on that professor’s grant, doing \\nlargely what the grant says you’re supposed to do. Then, you do a post-doctorate for a \\ncouple of years and become an assistant professor. You go through that horror, and, after \\n10 years, you get tenure. It’s a really long time to wait before you can have that promise \\nof obsessive problem solving fulfilled. Even then, I don’t feel the promise is fulfilled \\nbecause you have to spend a lot of time working on grant proposals and managing your \\ngraduate students and postdocs.\\n \\nNow I’m 35 years old. Time-wise, I may be roughly at that point in my career now. I have \\na really great job where I get to do what I want and do, whatever is interesting to me. But \\nit’s also a be-careful-what-you-wish-for situation. The freedom to work on whatever you \\nthink is interesting is stressful because there’s no one else you can blame if you’re not \\nworking on the right thing or if you miss a technology shift that has a profound impact.\\n \\nAmr Awadallah (Cloudera’s CTO) wrote a blog post about what a chief technology officer \\ndoes. He was comparing the CTO’s performance to CFO’s performance. The CFO is not \\nresponsible for making the sales numbers every quarter, but if there is a big surprise \\nmiss, the CFO gets fired. Similarly, the CTO is not responsible for shipping products on \\ntime, that’s what the VP of Engineering is for. But if the CTO misses a major technology \\nshift, he or she gets fired. \\nI have a CTO-kind of job right now. I am free in my job to think about analytics, the future \\nof data science, what exactly is coming down the pike. If I miss something, I should be \\nfired because that miss could have profoundly negative consequences for Cloudera.\\n \\nThere’s tremendous pressure that comes with that freedom. Now that I get that, it’s \\nslightly horrifying. I have a fair amount of anxiety about it.\\nCan you talk a little bit more about what happened in between IBM and Cloudera? \\nHow did you get to this point?\\nWe skipped the part of graduate school when I was taking a class in price optimization. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 178}, page_content='JOSH WILLS\\n174\\nOne of my professors worked with a local startup in Austin called Zilliant. I wanted a job \\nfocused on operations research, so my professor hired me to work as a data analyst there. \\nThere, I went back to SAS and R and started doing data analysis and building models for \\nthings like market segmentation and price elasticity.\\n \\nWhen you come from academia, you tend to \\nthink the world is more interesting than it \\nactually is, or that a problem is more complex \\nthan it is. The reason that price optimization \\nhasn’t really taken off as a software discipline \\nis because the primary pricing problem for \\nFortune 500 companies is to sell things for \\nmore money than it costs to make them. If \\nthey don’t know how much it costs to make things, they can’t know how much they \\nshould sell those things for to ensure that they make a profit. It’s not rocket science. You \\ndon’t need a data scientist to do that. You just need good reporting.\\n \\nWhy is it that companies don’t know this bit of crucial information?\\n \\nIt seems like a fundamental component, and yet many of them do not actually know. The \\nproblem is incentives. The person who is selling the deal, the salesman, is going to get a \\ncommission, and his or her income depends on the commission. They’re putting together \\na package of things that are going to be sold as a part of the deal. There’s going to be \\nsome materials and professional services, that’s just text and contracts. These contracts \\nget read and improved, but no one necessarily understands how much it’s going to cost \\nto fulfill these contracts. There’s way too much variance. And people have a tendency \\nto be very optimistic. They don’t think they’re going to have conflicts. They don’t think \\nthey’re going to have errors. They don’t think there are going to be hurricanes.\\n \\nThese aren’t trivial problems, but they’re also not the kind of problems that are amenable \\nto the complicated data analysis techniques that you typically learn in graduate school. \\nThey’re very different kinds of problems.\\n \\nThey are simple problems. They’re simple but not easy. Losing weight is simple but not \\neasy. Most industrial problems are simple but not easy.\\n \\nSo after Zilliant, did you make it your goal to attack the industry problems?\\n \\nI like to be useful more than anything. I like to solve people’s problems. I like to be \\nhelpful. I’m a helpful person by nature. I enjoy abstractions. I enjoy art and weird stuff \\naesthetically, but I would rather have my day-to-day work be more focused on people’s \\nproblems and making their lives better. The beauty and the theory are never so appealing \\nWhen you come from academia, \\nyou tend to think the world is more \\ninteresting than it actually is, or that \\na problem is more complex than it is.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 179}, page_content='JOSH WILLS\\n175\\nthat they manage to draw me away from the real problems.\\nYou worked at a bunch of different startups before Google. Were you solving \\ndifferent initial problems at these startups? What prompted the shift to Google?\\n \\nIt really took me forever to leave Austin. I could make a list of all of the bad financial \\ndecisions that I made because I was too afraid to leave Austin. I had a job offer from \\nGoogle to be an engineering analyst, which I turned down in 2005. I turned down a data \\nscience job at Facebook in 2007. I try not to think about that one too much.\\nThe thing that finally got me to San Francisco was auction theory. I was working on \\nmy PhD at UT and had taken some classes in game theory and mechanism design, and \\nwe covered auction theory. I absolutely loved it; it was beautiful math that could also \\nbe used to create socially optimal outcomes. I was really curious about how auctions \\nworked in the real world, but there weren’t really any places in Austin where I could go \\ndesign auctions for a living. I was fortunate that I had kept in touch with Diane Tang, who \\nhad tried to hire me at Google back in 2005 and was running Google’s ads quality team \\nwhich was responsible for the ad auction. \\nShe’s now Google’s first and only female \\nGoogle Fellow, but at the time, she was just \\nmy friend who hired me to go to Google and \\nwork on auctions full time. She has been \\nan amazing mentor to me, one of the most \\nimportant people in my career.\\nWhat was it like on Google’s ad quality team? Was that a confluence of smart \\npeople who had studied auction theory as well and then implemented it in the real \\nworld?\\n \\nI think the thing to know about Google is that it is smart software engineers with no \\nspecific expertise designed most of the core systems. Eric Veach, who had a PhD in \\ncomputer graphics but no machine learning experience, designed Google’s original \\nmachine learning system. Eric was tasked with the problem, read a book, and came up \\nwith a wholly new solution.\\n \\nI remember when I first got to Google and read about how that system worked. It was the \\nmost brilliant and unique solution to the world’s first truly large-scale machine learning \\nproblem. His original algorithm was really clever and I’ve never seen anything like it \\npublished anywhere, and I don’t think we ever will because, of course, Google has now \\ngone on to even more advanced machine learning systems.\\n \\nEric was also the person who designed Google’s original auction algorithm. Again, Eric \\nThey are simple problems. They’re \\nsimple but not easy. Losing weight is \\nsimple but not easy. Most industrial \\nproblems are simple but not easy.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 180}, page_content='JOSH WILLS\\n176\\nis a graphics guy, he’s not an auction theorist. So he read a book about second-price \\nauctions, and he came up with this very simple generalization that is called the GSP , the \\ngeneralized second price auction.\\n \\nI worked on a number of auction-related features and launches at Google. I really enjoyed \\nit, but at the end of the day, the auction can only be as complicated as the understanding \\nof the auction participants. Advertisers are wonderful, but they’re still just people, while \\nthe really interesting bidding strategies and auction models are so complicated and \\ncomputationally intensive that they require serious software engineering chops just \\nto participate in them. It wasn’t in Google’s interest to have an auction that was so \\ncomplicated that no one besides auction theorists could appreciate it.\\nThis seems to be emblematic of one of the differences between academia and \\nindustry. In academia you’re focused on getting the optimal solution. In the real \\nworld, you find that your implementation priority queue is dominated not only by \\noptimality but also by feasibility and expedience. Was this shift hard for you to see \\nand interact with?\\n \\nI don’t think so. I was fairly lucky. Most of my graduate work in operations research \\nwas working on impossible problems. Operations research consists primarily of very \\nhard problems where you cannot find the optimal answer. The job is to do the best you \\ncan, and I actually love those kinds of problems because the expectations are low. If the \\nproblem is impossible and you are able to do anything even remotely close to a good \\nsolution, it’s kind of amazing.\\nThere is a joke: “If you have a NP-hard problem and you make it slightly better, \\nyour solution is exponentially better”?\\n \\nI could not agree more. It was a good headspace to be in. Operations Research is a very \\npractically oriented science and academic discipline, so transitioning to that industry \\nmindset was not one of my problems.\\nYour story illustrates that to be a great data scientist, you have to be slightly \\nmasochistic. You have to be willing to go out of your way to be in areas where \\nyou’re the least skilled person in that domain and programming. What was your \\ndevelopment like as a programmer?\\n \\nI may not be able to give myself too much credit. I was a pretty good programmer in school \\nwith algorithms and optimization routines, but I wasn’t really a great team programmer. \\nEven at IBM, although I was on a team of four developers, we really didn’t have to work \\nall that closely together. The structure of the software was already well-defined and the \\ninterfaces were clear.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 181}, page_content='JOSH WILLS\\n177\\nWhen I was at Zilliant, the company decided to redo their pricing engine. The data \\nanalysts got together and wrote a spec about what they wanted the pricing engine to \\ndo. It required some domain expertise, and of course I had programmed for many years \\nat IBM. So I was tasked with doing the implementation, but it quickly became clear to \\nbasically everyone that I did not know how to build a real software product from scratch.\\n \\nI give the managers at Zilliant a lot of credit for what they did next: they apprenticed me \\nto a much more senior developer, John Adair, who is another great mentor and friend. \\nFor three months, he implemented the spec, and I unit tested it. I wrote unit tests and \\nintegration tests for his code every single day for three months.\\nIt was the most useful learning experience of my professional life, because John writes \\nbeautiful code. When I describe this experience to people, they always make a face, \\nbecause it sounds tedious and awful and lots of developers hate writing tests. But when \\nit’s your job, and you’re measuring yourself the whole day, it can actually be fun. And I \\nwas just learning so much about how you actually build systems from scratch.\\n \\nI was somewhat involved in writing the spec for what the software was going to do, so \\nI knew both the spec and the software very well. What was interesting was was getting \\nto see how to write code that is designed to be testable. John and I went through a few \\nrefactorings over the course of \\nthe project, but the QA team only \\nfound like two bugs when the \\nsystem was tested. It was the best \\nsoftware I’ve ever been a part of. \\nIt was beautiful code.\\n  \\nAfter I left Zilliant, I did a brief \\nstop at Indeed, the job search \\nengine. There, I was a statistician. \\nI wrote some code, but I was primarily there in my capacity as a statistician. And when I \\nleft Indeed to go to Google, I was also hired as a statistician. For whatever reason though, \\nwhen I actually got in the door at Google, all I did was write code. There was just so much \\ngreat code everywhere that you could read and use and learn from. After nine months \\nat Google, the company changed my job title from statistician to software engineer, and \\neven gave me a promotion. I’ve always felt a little shady about that, because there’s \\nbasically no way I could have ever passed a Google software engineering interview.\\n \\nFor someone like me, I am really just a good mimic, and I can pick things up pretty quickly. \\nBeing inside Google with so much good code, was an absolutely amazing experience. I \\nam 20 times better as a software engineer just because of my time at Google and seeing \\nWhen I describe this experience to people, \\nthey always make a face, because it sounds \\ntedious and awful and lots of developers hate \\nwriting tests. But when it’s your job, and you’re \\nmeasuring yourself the whole day, it can actually \\nbe fun.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 182}, page_content='JOSH WILLS\\n178\\nwhat the people who are really good do. It was an unparalleled experience, absolutely \\namazing.\\nCan you give us specific examples of how you did that? Do you go to the people that \\nwrote code, understand the problem from them, see how you would implement it \\nand read it? What was your procedure for learning all that you did?\\n \\nI don’t know how other places do it, but Google imposes it on you. They force you to code \\nthe way Google codes. Readability standards are a big deal. You have to get readability \\nin any language that you want to be able to commit to Google’s source code repository, \\nor have your code approved by someone who does have readability. To get readability, \\nyou have to write a large chunk in a way that adheres to Google’s coding style, and the \\nprocess of readability reviews is basically hazing for software engineers. I will never \\nforget my readability review for Sawzall.\\n \\nI was writing some code to analyze the ad logs, studying correlations between advertiser \\nbids and various machine learning probabilities that we were calculating. I wrote some \\nbasic correlation routines and then submitted them to the core Sawzall libraries, and \\nit turned out that my code reviewer was Rob Pike. If you don’t know Rob, he’s an old \\nschool AT&T Labs guy. He wrote Plan 9, and he’s the creator of the Go programming \\nlanguage. He also created Sawzall. He’s also the most pedantic code reviewer I had at \\nGoogle, and I’m sure that he will consider that a compliment. I think I went through 26 \\ncode revisions during that review with him, and it was absolutely awful. It was so bad \\nthat I really thought hard about quitting. So, so, so many nitpicky comments. I think that \\nwas a great thing about Google, they tortured me into becoming a better programmer by \\nforcing me to think hard about all of these little decisions. No pain, no gain.\\nThat seems to be one of the nice things about being a data scientist. It’s at the \\nintersection of many fields, so when you’re in a particular field, you can humble \\nyourself by not thinking of yourself as a practitioner of that field and say, “What \\ncan I learn from this person as they are a practitioner of this field?”\\n \\nI think that is a big part of your job description as a data scientist. The reality is that these \\nthings are never one-way streets. For every software engineer who gave me a scathing \\ncode review, another one would come to me later with a data analysis problem, because \\nthey knew me as a statistician who spoke their language and could explain things to \\nthem.\\n \\nIt’s hard to humble yourself, but keep in mind that it almost always comes back around in \\na positive way. It’s good for your career to come in and be seen as an expert in something \\nwho knows how to communicate their expertise.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 183}, page_content='JOSH WILLS\\n179\\nHow did you deal with the transition between a large company like Google, where \\nthere’s so much institutional knowledge to draw upon, and a startup like Cloudera?\\n \\nThere are lots of things I miss at Google. I miss the people. I miss the food. I miss the \\ntoys. They had a lot of great stuff at Google. To the extent that we have a product strategy \\non the data science team at Cloudera, it’s to take stuff that we loved at Google and create \\nopen source versions of it. That’s all there is to it. It’s the easiest product management \\nstrategy in the world. Know what you like and try to improve upon it.\\n  \\nWhen I got to Cloudera, it was roughly \\n85 people. It wasn’t a startup, but it was \\npretty small. I was like, “Hey everybody, \\nI’m the new director of data science. \\nWhat should I be working on?” No one \\nhad any idea, and I didn’t have any idea \\neither. It wasn’t entirely clear to me \\nwhat I was hired to do. I had a couple of \\ndays of tremendous anxiety about that. I was completely useless. At Google, I had 150 \\nemails a day from people who needed stuff from me. Here, I could hear crickets chirping. \\nIt’s that anxiety-inducing freedom we talked about earlier.\\n \\nSo my job at Cloudera was to figure out what I could do that would be useful. I spent a lot \\nof time talking to customers, and I still do a lot of that. I give them advice about building \\ndata science teams or about particular approaches they can take to solving different \\ntypes of problems.\\n  \\nI also started working on problems that customers talked about and various customer \\nengagements that seemed interesting and useful. I was also new to the Hadoop stack, \\nand so a lot of it was just learning what was out there and how things worked. I remember \\none project where I was building a model for detecting adverse drug events using an \\nalgorithm that was created pre-MapReduce but that was really a perfectly MapReduce-\\nable problem. That was the first useful thing I did, and I know that because Mike Olson, \\none of our co-founders, presented the results of my analysis as a five-minute quick hit \\npresentation at a conference and we got a lot of nice press and Twitter coverage for it.\\n \\nA little later, I was working on a problem that required processing lots of seismic imaging \\ndata, which is time series data oil and gas companies analyze to try to figure out where \\noil and natural gas deposits are located under the earth. That was the first time I really \\nmissed FlumeJava. It was the perfect tool to solve the problem I was working on, and so \\nI rewrote enough of FlumeJava to be able to solve my problem.\\n \\nJust because I’m not the best programmer \\nin the world doesn’t mean I can’t contribute \\nuseful things, and the community that has \\nsprung up around Crunch is something I \\nam incredibly proud to be a part of.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 184}, page_content='JOSH WILLS\\n180\\nThat process brought me back to my black-box debugging days at IBM. When I was at \\nGoogle, I had used FlumeJava to write data pipelines, so I knew what the APIs looked \\nlike, but I didn’t really understand how it worked under the covers, only how it worked \\nconceptually. The FlumeJava team had published a paper about the system, and that \\nwas tremendously helpful, but there was still this process of sitting down and saying to \\nmyself, “okay, I know the API worked like this. I don’t know why it worked like that, so \\nlet’s see if we can sit down and figure out what had to be going on so that this thing will \\nwork.”\\n \\nIt really took three times to create the FlumeJava clone that eventually became Crunch. \\nThe first time I wrote it, I really coded myself into a corner; I made some design mistakes \\nthat I just couldn’t unravel. So I started over, but I ended up creating this ridiculously \\nover-engineered monstrosity, and I wasn’t really getting closer to being able to solve \\nmy original seismic data analysis problem. So by the time I started over again, I really \\nneeded to get the thing to work quickly, and fortunately I had learned enough from the \\nfirst two attempts to get something that basically worked together in a week.\\nI probably should have been too ashamed of what I had created to open-source it, but \\nthanks to my time at Google, any sort of ego I had about the quality of my code was \\nbasically gone, and I was more than happy to put it out there for everyone so that other \\npeople would be able to work on it and improve it over time. Just because I’m not the \\nbest programmer in the world doesn’t mean I can’t contribute useful things, and the \\ncommunity that has sprung up around Crunch is something I am incredibly proud to be \\na part of.\\nYou wrote a blog post about building Crunch, and then having someone contribute \\nto the open source project, as this amazing moment. Can you talk a bit more about \\nwhat that was like? \\nIt was about understanding the complicated software written, finding a non-trivial bug, \\nand improving it. I like literature a lot. I like David Foster Wallace, and I’m wearing \\nmy favorite David Foster Wallace t-shirt. It the motto of the Enfield Tennis Academy \\nin Latin. It translates to, “They can kill you, but the legalities of eating your corpse are \\nquite a bit dicier.” \\nWallace writes a lot about loneliness. There’s a character in Infinite Jest called Madame \\nPsychosis which is a reference to metempsychosis. It is a notion of the transmigration of \\nsouls from Greek literature, that’s like a John Malkovich situation of being picked up and \\nstuck in someone else’s head. Gabriel doing that fix was like metempsychosis because \\nI put some aspect of myself into this code and he improved it. That was sublime. I was \\nvery lucky.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 185}, page_content='BRADLEY VOYTEK \\nProfessor of Computational Neuroscience at UCSD, \\nFormer Data Evangelist at Uber\\nHow did you get to where you are today?\\n \\nI started as a physics major at USC in Los Angeles, and I briefly worked in an ultra-low-\\ntemperature physics lab. As a young kid, I thought that physics would be the direction \\nI would go in. But I realized quickly after working in the lab that it wasn’t really what I \\nwanted to do.\\n \\nI didn’t know what to do or what my interests were going forward, but I had taken a \\npsychology class to fulfill a general education requirement, and I became interested in \\nthe topic. Around the same time in college, I started learning to socialize better and \\nalso became more interested in other people. My grandfather, who I had grown up with, \\nhad also gotten sick with Parkinson’s disease. Although he was a really smart engineer, \\nhe started to decline cognitively really quickly. The confluence of all these things that \\nhappened at the same time in my life made me realize that I needed a shift in my long-\\nterm career path, and neuroscience became something that I was interested in.\\n \\nAs an undergrad, I started working in a neuroscience research lab, and the very first \\nproject I was assigned was to take flat text files and copy and paste different parts into \\nExcel to aggregate the data. They gave me two weeks to do this, and I was like, “This is \\nridiculous.” I wrote a simple C++ script to do it for me, and I came back the next day with \\nall of it finished. To the other people in the lab, it was like I had worked some kind of \\nmagic. Programming was this amazing thing that they did not understand.\\n \\nBrad has had an eclectic career. From working in \\nneuroscience and academia, to becoming a world authority \\non zombie brains to contributing to the data science team \\nat Uber as employee number seven, his story is one of \\nembracing learning, overcoming challenges, and cross-\\npollinating ideas from disparate fields.\\nHe is currently a professor of computational neuroscience \\nat the University of California, San Diego (UCSD).\\nData Science, Zombies and Academia\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 186}, page_content='BRADLEY VOYTEK\\n182\\nFrom that point forward, I became the “tech guy”. I started automating a lot of the things \\nthat were going on in the lab. I found my niche there.\\n \\nAfter graduating, I started working at UCLA in the Brain Mapping Center, and I was the \\nPET (positron-emission tomography) scanner operator. PET is a type of non-invasive \\nbrain imaging and I was running the PET scanner and collecting data from people. I \\nstarted doing a little of my own research and used that time to figure out if I wanted to \\ngo to grad school and do my PhD. Through this experience, I realized that computational \\nneuroscience was what I wanted to do.\\nI applied to places in California like \\nUCSD, Berkeley, UCLA, and UC San \\nFrancisco. I almost didn’t get an \\ninterview anywhere because my grades \\nin undergrad were terrible, but I got \\nlucky and got into Berkeley. It was an \\namazing environment with a ton of \\nincredibly smart people. Berkeley has \\njust now started its own data science \\ninstitute, but it was clear when I was there from 2004 to 2008 that this idea of “data \\nscience: was percolating through the Bay area.\\n \\nAt the end of my PhD, I was approached by my friend Curtis Chambers, who was the first \\nhead of engineering at Uber. He was employee number four in the architectural dispatch \\nsystem and was a close friend of mine in high school (I was the best man at his wedding). \\nHe said, “We have a ton of data, and we don’t have anyone to do anything with it. I know \\nyou do this kind of stuff. Would you be interested in working with Uber?” \\nAt that time, I had just finished my PhD, and my initial reaction was, “I don’t think \\nit’s that interesting.” However, as we talked more, I started to get a better idea of the \\ncompany and I decided to go meet with the CEO. I had lunch with Travis Kalanick, the \\nUber CEO, and he wanted me to do a coding challenge to see what I knew. I said to him, \\n“Look, you can have me doing coding challenge games, but how about you give me your \\ndata to play with? If I haven’t done something cool by the end of the day, that will settle \\nit.”\\nTravis liked that, and so they gave me some data to analyze. I sat around and hacked at \\nit for a while and, by the end of the day, I had some analyses and visualizations for them. \\nThat’s how my work at Uber started.\\n \\nYou mentioned that you applied to different graduate programs and only got \\nThey gave me two weeks to do this, and \\nI was like, “This is ridiculous.” I wrote a \\nsimple C++ script to do it for me, and \\nI came back the next day with all of it \\nfinished. To the other people in the lab, it \\nwas like I had worked some kind of magic. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 187}, page_content='BRADLEY VOYTEK\\n183\\naccepted into UC Berkeley, despite your low GPA. What did you do to convince \\nthem that somebody with your unorthodox background could do a PhD there?\\n \\nI don’t know. I wish I had a solid answer. I actually asked somebody very high up in the \\ndepartment how I got into Berkeley when I couldn’t get in anywhere else. The professor \\nsaid very bluntly, “Well, we looked over your application and thought you were a fuck \\nup, but we thought you were a fuck up with potential so we decided to give you a shot.” \\nI don’t know what the potential was. I do a lot of writing and public speaking so I think I \\nam able to communicate ideas clearly, so that might have helped me in my application.\\n \\nI think Berkeley also embraced the Silicon Valley ethos where failure is something that \\nhelps you move forward. In a lot of other places, failure is generally looked down upon, \\nbut I think there’s something to the idea that failure is how you grow. I’ve been embracing \\nthis philosophy for a long time, and I didn’t try to hide anything in my application. I said, \\n“Here’s what happened. It’s not an excuse. This is just what happened. Here’s the story, \\nand here’s what I learned from it.” I think most people didn’t really care, but every now \\nand then, it just takes one person to actually read what you write and appreciate it.\\nNow that I am a professor, I just \\nparticipated in my first rounds of \\nadmissions for the PhD program \\nat UCSD. UCSD’s Neuroscience \\ndepartment is one of the best in \\nthe world. It’s a very competitive \\nprogram, and during the \\nadmissions, there was one person \\nwho I wanted to admit. This person had a low GPA but had strong GREs and an incredibly \\nstrong background. They had thought very clearly to get to the point where they were. \\nThey were slightly older than the other applicants because they had done real world \\nwork instead of going to graduate school directly, so I highly recommended that this \\nperson get accepted.\\n \\nIf you look at other professors’ CVs, listed there will be numerous publications, incredible \\ncompanies they’ve helped fund, students they’ve mentored who are now amazing \\nprofessors, and incredible research grants that they’ve received. I remember looking at \\nthose as a fresh PhD student and thinking “I’m not cut out for this.” I couldn’t even \\nimagine what it took to write a single research paper and get it published. I couldn’t \\nimagine doing that once, and I saw people with over 200 publications.\\n \\nIn my CV, I actually have a section that’s listed as my failures so for every paper that \\nI’ve gotten published, I say how many times it was rejected from different journals. I list \\nI said to [Travis], “Look, you can have me doing \\ncoding challenge games, but how about you \\ngive me your data to play with? If I haven’t \\ndone something cool by the end of the day, \\nthat will settle it.”\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 188}, page_content='BRADLEY VOYTEK\\n184\\nevery grant that I didn’t get which I applied for, every fellowship, and every faculty job \\nI applied for but didn’t receive. Everything that I’ve done that didn’t come true is listed \\nin the failure section of my CV, and I’ve gotten positive feedback from students looking \\nat that because it’s a litany of crap. There were papers that were rejected by 10 journals \\nbefore they got accepted. I think people don’t recognize that behind these incredible \\nCVs of these 60-year old professors, they’ve got 60 years of failures that they had to go \\nthrough in order to do it. I try to be a little honest about that.\\n \\nDJ Patil had this great quote that, to paraphrase, goes something like, “In the very \\nbeginning, in order to do something new, you need to leap across this chasm and \\nyou need someone on the other side to catch you in order to cross it.” \\nIt seems like from your experience in graduate school, you’ve really internalized \\nthat and believe in that. Now you’re on the other side of the chasm, trying to catch \\npeople, hoping that they can make it across despite their unconventional training.\\n \\nDJ is a smart guy and I like that analogy a lot. \\nI come from a pretty low socioeconomic status background. My family’s not well off at \\nall, and to get to where I am today, I can easily name at least a dozen people who gave \\nme lucky breaks. Everybody likes to talk about the value of hard work and work ethic, but \\ngetting to where I am today required tons of luck. It required someone to reach across \\nthat chasm for me, and I don’t know why. I’m certainly on the other side now, trying to \\ndo the same for as many people as I can.\\n \\nWhat was your exposure to computer science and the idea of interacting with \\ndata? How did that evolve as you went through your undergrad research and PhD \\nresearch? \\n \\nIn hindsight, what I did throughout that undergrad project was very simple data munging. \\nUSC didn’t have a neuroscience major at the time. They had a psychology major and a \\nneurobiology major, but I wasn’t interested in neurobiology or cell molecular biology, so \\nI tried to throw together a major on my own.\\n \\nI ended up taking courses like Introduction to AI and C++ programming. I took these \\nclasses because I had several friends who were computer engineering majors and after \\nspending a lot of time talking to these guys, I thought that programming would be a \\nuseful skill to have.\\nWhen I worked in the lab, I realized that my programming skill was applicable to the \\nproblems. For example, the lab I worked in was doing brain imaging, and the analyses that \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 189}, page_content='BRADLEY VOYTEK\\n185\\nthey were doing seemed complicated, requiring the use of obscure programs. I realized \\nat some point  that it was just matrices of data. Once you had the realization that these \\nare just numbers, it allowed me to do a lot more. You can start writing your own analyses \\nand doing things that people may not know or understand. It’s mind boggling because \\nwith two lines of Python, you can do much of data analysis much more efficiently.\\n \\nI told this story once, and someone told me, “In the land of the blind, you are the one-\\neyed man.” That’s essentially all it is. You find that you have a skill set that is valuable \\nto the field that you’re working in that not everyone has. Suddenly, it’s just something \\nmagical that you can do.\\n \\nIn 1999, I imagine that the science lab was not very technical. You coming in and \\napplying programming must have been mind boggling to them. It was something \\nthat you’ve seen in class, but for people who haven’t been exposed to programmatic \\ndata analysis, that must have seemed like magic. Similar to what you do now, \\nat that time you were leading the way and evangelizing the different ways that \\npeople can think about and manipulate data.\\n \\nI remember taking a statistics \\nclass in psychology. They were \\ntrying to use SPSS which is a \\nstatistical package for social \\nsciences. It allows you to do \\nthings like regression analyses, \\nand ANOVA. I remember \\nbeing confounded by the idea \\nof assuming that the data \\nfollowed certain probability distributions. I didn’t quite understand why you’re making \\nassumptions, and I didn’t get the difference between ANOVA and the t-test. Then as a \\ngrad student, I remembered that they were all the same thing. You have a general linear \\nmodel; the t-test, ANOVA, and regressions are just extensions of that.\\n \\nIn my lab right now, I have a lab manager who is a fresh out of undergrad. We were \\ntalking about that, and I described to him how a t-test by drawing it on the board really \\nquickly. He said, “I took a year of stats, and I never got it as clearly as I do now from what \\nyou just drew.” \\n \\nIt’s shocking to me how bad people are at explaining data, data science, and statistics. \\nIt’s not a magical thing. There’s a reason some people are so good at it. It takes some \\ntime internalizing and getting it, but once someone shows you that, it just becomes so \\nclear. \\nIn my CV, I actually have a section that’s listed as \\nmy failures so for every paper that I’ve gotten \\npublished, I say how many times it was rejected \\nfrom different journals. I list every grant that I \\ndidn’t get which I applied for, every fellowship, \\nevery faculty job I applied for.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 190}, page_content='BRADLEY VOYTEK\\n186\\nIt requires you to think outside of preparing for a test, and see how the ideas can \\nbecome an actual tool you can use.\\n \\nRight. I think my failure to become a physicist was that I was too young to get that. When \\nI was taking physics classes, it was memorizing all these different equations and trying \\nto figure out which equation to plug into. That didn’t seem interesting to me. Now, of \\ncourse, I realize it’s not what physicists do. I think if I had figured that out earlier, I could \\nsee my career path diverging.\\n \\nRight now, you’re quite active on Quora. You teach different people about many \\ndifferent concepts, and I see that as being a very important package of being \\nan effective professor or data scientist. Can you talk more about this missing \\naspect of data science that isn’t as heralded, which is the aspect of being able to \\ncommunicate effectively?\\n \\nYes. I always think back to the movie Office Space, which was making fun of the first \\ndotcom industry. In the movie, there’s a great line where they’re trying to figure out who \\nto keep and who to fire in this tech company. They’re talking to this guy who is a product \\nmanager. But since he’s a product manager, he’s not a manager per se, so these guys \\nthat came in to interview him are asking, “What do you do?” He’s replied, “I talk to the \\nengineers, and I learn what they’re doing. Then, I relay the information clearly up to the \\nmanagement.” They said, “Why can’t we just have engineers talk to management?” And \\nhe says, “They need a people person.”\\n \\nI think about that a lot. There’s something very critical about being able to communicate \\nyour ideas effectively. When I came into Uber, one of the things I thought about was that, \\nbefore they got bought by Match.com, OkCupid had a really good data blog. They were \\nusing all of these dating interactions on their website and metadata about people to try \\nto do analyses about what gets people dates and what people find attractive. I read those \\nwell before I was a grad student and well before I got into data science. Everybody loved \\nit.\\nWhen I started working with Uber, I was thinking about how the data can be used to \\ntell an interesting story. Just like writing code, telling a story effectively takes a lot of \\npractice. That’s a part of the reason why I do a lot of writing on Quora. I teach, and I do \\na lot of public speaking at elementary schools, junior high schools, high schools, or at \\na bar to a bunch of drunken aficionados. It’s practice. Just like I have to sit down and \\npractice writing code, I also have to sit down and learn how to communicate the idea.\\nMy wife is actually a very good sounding board. Whenever I write something, I always pass \\nit by her because she’ll read something and say, “You’re making this more complicated \\nthan it needs to be. You can explain this in fewer words. You didn’t connect from A to C. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 191}, page_content='BRADLEY VOYTEK\\n187\\nYou skipped over B.”\\n \\nI remember the first time I took a programming class. It was an algorithms course. The \\nhomework was to write an algorithm for making a sandwich in which you had to explain \\nevery step you took to make a sandwich. You realize so many parts you skip over that you \\nthink are obvious, but if you had to program a robot to do it, simple things like pulling \\nthe knife out of the drawer must be explained. You have to explain exactly how you pull \\nthe knife out of the drawer to spread the mayonnaise.\\nWe skip over a lot of stuff that seems obvious, but it’s not always obvious if you’re not the \\nperson staring at that data all day long. It’s a good point of practice to try to remember \\nhow to be very explicit about every step that you take and connect the dots for people. \\nYou’ve worked with data while at Uber and have an academic background with a \\nlab in UC San Diego. Do you think that your academic background better prepare \\nyou for Uber?\\n \\nAbsolutely. The one thing that you get from an academic PhD in data science is learning \\nto tackle a big problem by breaking it down into bite-sized chunks. When you start a \\nPhD, what you’re doing is saying, “I am entering this 3000-year-old human endeavor of \\ntrying to figure out where we are in the world and what we’re doing, and I think I can add \\nsomething new.” That’s a ridiculous \\nassumption, but people do it head \\non. \\nYou start reading papers, and you \\nknow what you’re interested in. You \\nsee that there’s a hole somewhere, \\nthat there’s something missing. \\nYou think to yourself, “I can add \\nsomething. How do I go about tackling \\nthat, addressing that problem? How \\ndo I define the scope of the problem, and what do I need to do to tackle it?” That’s what \\nyou’re trained to do as a PhD student and is the important skill that you don’t get if you \\nskip academia and go directly to data.\\n \\nIf you are fresh out of your undergrad and go work in a company like Facebook as a data \\nscientist, you’ve got access to two billion people’s worth of data. Unless you had an \\namazing undergrad experience, you don’t know how to begin to tackle that. How do you \\nwrap your head around what kinds of problems to ask, and once you have the problem in \\nmind, how do you tackle it? What do you do?\\nIt’s shocking to me how bad people are at \\nexplaining data, data science, and statistics. \\nIt’s not a magical thing. There’s a reason \\nsome people are so good at it. It takes some \\ntime internalizing and getting it, but once \\nsomeone shows you that, it just becomes so \\nclear.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 192}, page_content='BRADLEY VOYTEK\\n188\\nOne of the things that struck me was that people in research tend to de-emphasize \\nthe infrastructure required to do large-scale analysis. That’s not as sexy as being \\nable to ask the research questions, but it gives you more breadth. You can ask \\nbigger questions if you know how to leverage the industrial tools.\\n \\nYes. It’s helped on every level. When I started in Uber, there were seven of us and we were \\nworking in a co-working space with a bunch of other startups. The hustle of a startup is \\nsomething that a lot of large research institutions don’t have. \\nIn my lab, I do a lot of methods development for analyzing human brain data, but \\npreviously I did that in MATLAB and posted the MATLAB file on my website and linked \\nto it in published papers. It’s complicated and doesn’t really make sense. Now, I’m \\nconverting everything so the code in the notebooks are also tutorials. These are things \\nI’m developing in my lab and growing in the lab culture.\\n \\nA common problem that’s endemic to academic researchers is if some PhD students or \\npost-doctorates do a really good project but have the data backed up on their computer. \\nThen, if they leave or graduate, the data is gone. This happens at least 75% of the time. \\nThese are things that regress in the development of my research lab.\\n \\nOn the actual research side of things, I have learned different ways of looking at data. \\nThere’s a company called Lumosity. They do online brain games, which is interesting, \\nbut the thing that really interests me is that they have more data on human cognition \\nthan have ever been collected in the history of science.\\nWe looked at Lumosity data that measures your distractibility. I looked at the distractibility \\naverage across geolocation areas like California, New Mexico, or Washington. You just have \\nthese aggregate values, and I pulled up these data that estimate country or state-level IQ \\nand GDP . I found that state-by-state and country-by-country estimates of distractibility \\ncorrelate with fatal car accidents. Countries or states where people are more distracted \\nare more likely to have fatal car accidents, which makes sense. It’s statistically robust. \\nIt doesn’t appear to be an outlier. Ultimately I’d like to publish all the scripts I used to \\ngo from raw data to final published figures my research so that anyone who reads the \\npapers can do the same analysis, or build on it.\\n \\nYou’re one of the few people that we’ve spoken with who have gone back from \\nindustry to academia, and it still sounds like you’re playing with private data sets \\nof different companies like Lumosity and Uber. Why did you not choose to stay in \\nindustry? What advice would you have for these PhD students who will read our \\nbook who are trying to leave the more standard track of become a professor for \\nindustry?\\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 193}, page_content='BRADLEY VOYTEK\\n189BRADLEY VOYTEK\\nGetting a faculty job is highly unlikely. Ten or 20% of PhD students will go on to get a \\ntenure-track job, so in my lab, I’m trying to train people to be able to do other things \\nbeyond research. We’re doing the research, but we’re also trying to train them in version \\ncontrol, Python, and data analysis to make sure they have a skill set that is transferable \\nif they decide not to go into academia.\\nAs for me, not staying in Uber and \\ngoing into academia was a really \\nhard call. They offered me a full-\\ntime position and a lot of stock. \\nThat was before the stock is \\nwhere it is right now. I was doing \\ngrowth projections early on, and \\nI knew where the company was going. What made it hard was that while Uber was doing \\nsome cool work, at the end of the day neuroscience is where my heart is. I try to refrain \\nfrom using the word “passion” because people have a misunderstanding of passion, but \\nneuroscience what I really want to be doing. It’s more fun and exciting for me at the end \\nof the day.\\nAnother big part is that I’ve gotten a lot of big breaks over the years, much of which has \\ncome through really good professors. I wanted to give some of that back, and academia \\nis one way to do that. \\nFor example, I’m teaching an introductory class on data science at UCSD for the cognitive \\nneuroscience group. \\nStudents don’t understand why they have to do computations, and I’m trying to explain \\nto them that right now part of the criteria of understanding cognition and intelligence is \\ndata. Part of it is my desire to give back through teaching. Part of it is that the research \\nI’m doing has a lot of big long-term potential plans in terms of public health. And I have \\nto say that it feels good.\\n \\nThat’s a really powerful and amazing message to share with people who are going \\nto be interested in your background, that you chose to stay in academia. The final \\nthing I want to talk about is what is up with you and your interest in zombies? \\nWhat’s up with that?\\n \\nHaha, are you asking what’s wrong with their brains? Actually this has been surprising \\nand how much it’s taken off. This goes back to the science, communication, and outreach. \\nIf I go to a high school and talk about how neuronal shot noise and channel leakage leads \\nto an increase in neural noise, or how to estimate areas of communication between brain \\nWhen I started working with Uber, I was thinking \\nabout how the data can be used to tell an \\ninteresting story. Just like writing code, telling a \\nstory effectively takes a lot of practice.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 194}, page_content='BRADLEY VOYTEK\\n190\\nIf I go back to high school and start talking \\nabout zombie brains, show videos of zombies \\neating people, and explain why zombies are \\ndoing that, suddenly people are going to \\nunderstand. It’s Trojan-horse teaching.\\nregions, people’s eyes would glaze over and they’d say, “What are you talking about?” \\nHigh school students don’t care, and quite frankly, most people don’t care either.\\nHowever, if I go back to high school \\nand start talking about zombie \\nbrains, show videos of zombies \\neating people, and explain why \\nzombies are doing that, suddenly \\npeople are going to understand. \\nIt’s Trojan-horse teaching. It’s a \\ngimmick that we used to do science \\ncommunication and outreach, and it took off. People are really into it. I was on some \\nNational Geographic TV show; Princeton University Press recently published our book, \\nDo Zombies Dream of Undead Sheep?, about the zombie brain soon. We got to meet George \\nRomero, the director of the original zombie movie, Night of the Living Dead . There are \\ntons of speaking engagements. I was a guest of honor for a science fiction and fantasy \\nconference in 2014.\\n \\nIt’s a weird shadow career I have, but it’s been a ton of fun. It’s really silly and it works. \\nPeople seem to dig it. It’s nice. It’s powerful and effective communication.\\nOut of all the things you’ve done in your life, the theme here is your willingness to \\nwrite, talk, and teach people. That’s also one of the reasons we’re grateful that you \\ntook time to share with us your stories. \\nThank you for being so honest and willing to share both the stories of success, and \\nfailure and struggle. I think a lot of these stories are going to resonate deeply with \\nthe readers, especially those who branch out from the traditional path.\\n \\nThanks, guys.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 195}, page_content='LUIS SANCHEZ Founder / Data Scientist at ttwick\\nWhere do you work?\\nI am the CEO and Data Scientist of ttwick Inc, a data analytics startup with roots on Wall \\nStreet.\\nWhat was your personal career path like?\\nI started my analytical career as a Civil Engineer specializing in structural engineering, \\nhydraulics and numerical analysis with a degree from a military university in Venezuela in \\n1987. I also obtained a specialization in systems analysis and programming from another \\nVenezuelan institution, but it was the combination of engineering and programming \\nthat put me in the right frame of mind and gave me the skills to eventually evolve into \\na data scientist.\\n \\nIn 1990, I decided to move to Washington, D.C. and begin studying for my MBA on a \\nLASPAU scholarship (a Fulbright scholarship for Foreign Students). My goal at that time \\nwas to get accepted into the World Bank’s Young Professionals Program and work in \\nglobal  infrastructure development. I dreamed about all the data I would have access to \\nat the World Bank, to play with and analyze.\\n \\nBack in 1990, it was not easy to get enough data to analyze, and I used to spend a lot \\nof hours in the computer lab with my newly issued email address and Internet access. I \\nLuis trained as a civil engineer in Venezuela before arriving \\nin the US for his MBA on a Fulbright in the early 90s. Though \\nhe aspired to join the World Bank, Luis found an alternative \\napplication of his data skills in the world of finance.\\nAfter an illustrious career as a quant at AIG and Deutsche \\nBank, Luis found himself structuring exotic asset backed \\nand catastrophe linked securities at Lehman Brothers \\n(you can see his video here), where he worked till the firm’s \\nbankruptcy on September 15, 2008. With plenty of free time \\non his hands, he dabbled in cross pollinating the ideas from \\nhis structuring days to areas of social media.\\nHe is the founder of and data scientist at ttwick, a search engine for social media content.\\nAcademia, Quantitative Finance and Entrepreneurship as a \\nData Scientist\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 196}, page_content='LUIS SANCHEZ\\n192\\nstarted to gather as much data as I could via Gopher, Archie (the first search engine for \\nFTP archives), or whatever I could get my hands on. I then discovered the University of \\nChicago’s CRSP database, which had some securities data available in a monthly format. \\nIn the summer of 1991, I got a 2400 bps modem, which allowed me to access the CRSP \\ndatabases from my IBM PS/2 at home, and finally, I did not have to spend so much time \\nin the computer lab, which always annoyed Gabrielle, my girlfriend at the time. In 1991, \\nit was difficult to obtain large volumes of high-quality data, so I started to explore other \\nmethods such as creating synthetic data via Monte Carlo simulation, which kept some \\nof the features of the original data set. Because of that, I started to do a lot of research \\nin computer science.\\n \\nI never got the job I wanted with the World Bank, but after graduating in 1993 I started \\nworking for a New York-based hedge fund that wanted a quant for its newly established \\nQuantitative Analysis department, to complement the work of analysts doing pure \\nfundamental analysis on securities.\\n \\nBy the way, I ended up proposing to Gabrielle, believe it or not, after writing a program \\nbased on professor Thomas Saaty’s Analytical Network Process. I thought his multiple-\\ncriteria decision algorithms would help me make sure I did not have any inconsistencies \\nin my logic. (Years later, Gabrielle got kind of upset when she learned I based my proposal \\ndecision on an algorithm.)\\n \\nWhat are your responsibilities at ttwick?\\n \\nI found out a lot of the market-based algorithms for allocation of resources I developed \\nand used in finance could also be used to search and organize unstructured data on the \\nweb; to determine if an online ad should be launched today or in a few days; to create real-\\ntime portfolios of content at low cost; to dynamically calculate probabilities of reaching \\ncertain audiences, etc. These algorithms coupled with natural language processing, data \\naugmentation, and other techniques  could be used for many applications, including the \\ndiscovery of arbitrage opportunities in certain financial markets, forecasting of political \\nevents, etc.\\n \\nAs CEO and Data Scientist, I am developing a series of B2B and B2C products and consulting \\nservices  based on the above-mentioned applications, some of which are currently being \\nused and/or tested by hedge funds, advertising agencies and other institutions.\\nWhat is data science to you?\\n \\nTo me, data science is the art and science of extracting actionable intelligence from sets \\nof data, big or small.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 197}, page_content='LUIS SANCHEZ\\n193\\n \\nI call it “art” because there is not really a one-size-fits-all technique that can help \\nyou answer the questions you want to ask your data. You need to be creative and have \\nimagination to see what others don’t see in the data. If you are anything like me, the \\nbest solution to your most challenging \\nproblems has come to you when you \\nleast expected it, in the form of an \\ninspiration. When that happens, I get in \\nthe zone and the solution just comes to \\nme, and I can’t focus on anything else.\\n \\nI call it “science” because you need to know the theory behind what you do and put in \\nyour 10,000 hours of problem-solving so you develop “muscle memory” so to speak, and \\nyou acquire the right foundation to become a good data scientist.\\n \\nOne thing I believe but don’t know if other people would agree with: Good data science \\ncan’t be 100% theoretical or 100% practical. There has to be a mix.\\n \\nSo, in your opinion, what is the goal and purpose of a data scientist?\\n \\nThe purpose of a DS is to extract actionable intelligence from sets of data with the most \\nefficient use of resources and under time constraints. The DS should be able to connect \\ndata together in meaningful ways, to create new knowledge from the combination of \\ndata, to be able to analogize and solve problems in creative ways, and to do all that \\nquickly. Like General Patton used to say: “ A good solution applied with vigor now is better \\nthan a perfect solution applied ten minutes later.”\\n \\nWhat are some past projects you have worked on?\\n \\nAs a financial quant, I worked on many interesting projects, many of them being the first \\never of their kind. Many of the projects on which I worked set the foundations for niche \\nmarkets within structured finance and trading.\\n \\nSome of the most interesting deals were:\\n \\n• First sovereign catastrophic (CAT) bond: Using a parametric structure, I designed \\nan ABS structure that covered the Government of Mexico against the effects of an \\nearthquake. The bond was rated and successfully launched to market.\\n• Weather options:  one of the most fascinating projects during my time at AIG, \\nwhere I was in charge of developing a model to price the risk of extreme rainfall or \\ntemperature in several cities across the world. This topic is extensive, but developing \\nData science is the art and science of \\nextracting actionable intelligence from \\nsets of data, big or small.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 198}, page_content='LUIS SANCHEZ\\n194\\nthe mechanism for a new market and seeing it grow and find participants that included \\nenergy companies, theme parks, airlines, etc., was a fascinating experience.\\n• Music and film royalties:  Have you heard of Bowie Bonds (as in David Bowie)? \\nBasically, the same idea was involved in deals I was pitching while at Deutsche Bank \\nfor some high profile artists. After I left in 2005, I retrofitted my own model to value \\nfilm productions yet to be made, and all of a sudden, I found myself giving speeches \\nat Hollywood events about the use of Monte Carlo Simulations and Bayesian analysis \\nto price film productions.\\n \\nMore recently, as a DS, I demonstrated to a hedge fund that there is a way to gain an edge \\nin the market via non-conventional financial analysis, using non-conventional sources \\nof data and machine learning tools such as those I am developing at ttwick. This sort \\nof analysis, coupled with the right financial derivatives, could generate superior alpha \\nreturns in various market environments.  \\nWhat was your experience like transitioning from academia to industry data \\nscience?\\nThe experience was effortless, with a dash \\nof good timing. As I mentioned before, I was \\napplying the math and coding skills I had \\nacquired as an engineer to solve problems \\npresented as part of the curriculum of my \\nMBA. I found it interesting that only a few \\nof my classmates had any coding skills, so I \\nbecame the “class quant.” Classmates came to me for help with assignments for classes \\nsuch as Strategic Marketing, where data science could be applied to solve marketing \\nproblems. By helping them, I also gained exposure to their areas of concentration.\\n \\nI started to write code for small projects with demos of things for marketing, financial \\ntrading, etc., and towards the end of my MBA, I started to attend specialized seminars in \\nNew York that concentrated on real-life problems about trading non-liquid securities, \\ncorrelation trades, technical analysis, etc.\\n \\nOver several of these seminars, I started to see a core group of people attending the most \\ninteresting ones, whom I later learned were investment managers looking to expand \\ntheir knowledge of the markets, while at the same time scouting talent for their own \\nhedge funds. I met Marc Chaikin, a famous technical analyst who created one of the first \\nplatforms for real-time technical and fundamental analysis of securities, with a huge \\ndatabase of tick-by-tick data.\\n \\nEventually, I ended up working for Marc’s best friend, a smart hedge fund manager, Chris \\nGood data science can’t be 100% \\ntheoretical or 100% practical. There \\nhas to be a mix.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 199}, page_content='LUIS SANCHEZ\\n195\\nCastroviejo, who had left Bear Stearns and teamed up with a group of traders and analysts \\nwho were starting their own group of onshore and offshore hedge funds.\\n \\nMy last job in my over 15-year career as a Wall Street financial engineer was Senior Vice \\nPresident for Lehman Brothers, where I was a Senior Quant.\\n \\nWhat drew you from Financial Quantitative Analysis to Data Science?\\n \\nIt was very simple: after the bankruptcy of Lehman Brothers where I was a Senior Vice \\nPresident, I (as well as many other quants), was in “job limbo,” meaning there were \\npractically no jobs available anywhere, much less for structurers of exotic assets. I \\ntransitioned to Barclays Capital, but by the end of the first quarter of  2009 I was laid \\noff along with most of the senior structurers and bankers who made the transition from \\nLehman.\\n \\nThe general public barely understood what a credit default swap or a credit transition \\nmatrix was, much less credit-linked notes, synthetic CDOs, CAT bonds, Markov-chain \\nMonte Carlo and some of the instruments and techniques I had specialized in over the \\nyears. There was no appetite for any sort of exotic instrument, and no capital available \\nfor anything.\\n \\nIt was very frustrating because precisely then, as a consequence of the credit crunch, \\nsome of the best investment opportunities I had ever seen in my life materialized in the \\nform of “Obama projects,” but I did not have any funds to invest, and they were clearly \\nadvantageous only to the wealthy with knowledge and some political connections.\\n \\nAlong with a couple of my friends from Deutsche Bank and Lehman Brothers, I put \\ntogether a basic  infrastructure to raise capital and invest in such opportunities created \\nby the Obama administration, but we were not able to get any commitments  by the \\ndeadlines set by the programs, and I found myself with a lot of free time, compared to \\nthe 70-90 hours per week I was used to putting in at investment banks.\\n \\nAt the same time this was happening, I found myself improving my programming skills, \\nand learning all I could about data scraping, web crawlers, and artificial intelligence. I \\nwas fascinated by the possibilities. I started experimenting with  spiders to crawl some \\nsites, and all of a sudden I was using the data in creative ways to find solutions to real-\\nlife problems.\\n \\nOne of those problems had to do with valuation of film productions. Years earlier, I had \\ncreated a rather sophisticated valuation model, focused on securitization of film assets \\nfor Hollywood clients. I wondered if, by using comments in social sites, I could improve \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 200}, page_content='LUIS SANCHEZ\\n196\\nthe accuracy of the model. I succeeded, but first had to develop additional algorithms to \\nfilter out the noise.\\n \\nI kept coding and discovering more interesting things about the film industry, but was \\nparticularly attracted to the Internet Information Provider subsector of the tech market, \\nsince I could see analogies in the way Hollywood earns profits from films: you need to \\nbe in content creation, distribution, and advertisement in order to minimize your risks.\\n \\nSo I started reading the 10Ks and 10Qs of Google, Yahoo and other companies in the \\nsector, and doing Monte Carlo simulations to learn about their strengths and weaknesses. \\nI learned a great deal from that exercise.  At that point, I started considering myself a \\nhybrid data scientist/financial quant, which I believe is a rare combination.\\n \\nWhat would you have done differently if you were able to speak to yourself right \\nat the end/middle of your graduate school career?\\n \\nIf I had that opportunity, I think I would just tell my earlier self to code more in languages \\nother than Visual Basic. I would set up a plan for my earlier self to learn Octave and \\nPython, and Java when it came out in 1995.\\n \\nIf I had the opportunity to speak to myself right \\naround the middle of my professional career, let’s \\nsay circa 2001, I would have told myself to stay in \\nNew York as a general quant, instead of moving to \\nLondon to be a front office quant pitching deals \\nto European governments and corporations. Not \\nthat I didn’t do a good job as a structurer and \\nrelationships guy, but an unintended series of events happened around that time which \\nI think could have had a better outcome for me and others, but who knows?\\n \\nMy advice is, focus more on what your own strengths are and less on what is perceived \\nas a cool career path at the time.\\nHow do you describe the value that you and other DS bring to the company?\\n \\nThe value I bring to ttwick is my diversified analytical background and real-life experience \\nin several industries that helps differentiate ttwick from other startups operating in DS.\\n \\nI have been conducting informal job interviews with PhDs  I might eventually hire from \\ndiverse fields such as physics, economics, linguistics, engineering, microbiology, etc. \\nwith amazing potential to become Data Scientists.That is the sort of analytical diversity \\nI want to have at ttwick.\\nFocus more on what your own \\nstrengths are and less on what is \\nperceived as a cool career path \\nat the time.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 201}, page_content='LUIS SANCHEZ\\n197\\nWhat are some surprising things about working in industry vs. academia?\\n \\nI can best answer that question by giving two examples of situations taken from my own \\ncareer.\\n \\nThe first example is the design of a financial structure to cover the government of El \\nSalvador against the effects of excessive rainfall, which has a definitive impact on the \\nGDP of that country. I was given that task in 1998 or 1999, I can’t remember. El Salvador’s \\neconomy is mainly driven by agricultural production, and extreme weather events \\ncould have catastrophic effects on the economy. Conventional countrywide insurance \\nprotection was either too expensive or unavailable, so I started to design a parametric \\nbond-type structure. As usual, data was of the essence.\\n \\nI got the data, but it was terrible, with wild swings in it that could not easily be fixed. The \\ntime-series had a numeric code representing the station, the name of the town/village, \\nand the daily precipitation. The gaps represented a big problem in valuing the risk. But \\nthen I did some interesting data exploration: I asked some of my younger colleagues \\n(Associates and Analysts) to help me gather the geolocations of the stations.\\n \\nThe time gaps corresponded to \\nmore or less well-defined, circular \\nareas, always near a river or \\nstream. I shared the findings with a \\ngovernment official in El Salvador \\nwho confirmed that the time \\nperiods of wild swings or gaps in \\nthe data corresponded more or less \\nto the heights of internal political conflicts in El Salvador. The geographic areas I showed \\nthem represented the geolocations of what later were found to be the main camps of the \\nFMLN (a guerilla coalition at war with the government in the 1980s and ‘90s). By looking \\nat the wild standard deviations and their locations in time and space, you could more or \\nless predict the next hideout of the guerilla leaders, since they seemed to follow a defined \\npattern. It turned out the fluctuations were simply due to the destruction or misuse \\nof pluviometers by the guerrillas, coupled with the fact that data collection was not \\nfrequent. In any case, I came up with a solution for the problem of rainfall measurement \\nat certain points by correlating rain accumulation with water levels of rivers near the \\ndata collection stations, where I had better data.\\n \\nThe second example was from my time at Lehman Brothers. I was analyzing a corporate \\ndeal in an emerging market that involved a commodity as collateral. I had the data I \\nneeded for a conventional type of analysis. But something did not feel right , so I \\ndecided to enlist the help of another colleague, Jami Miscik, also a Senior Vice President. \\nI shared the findings with a government \\nofficial in El Salvador who confirmed that the \\ntime periods of wild swings or gaps in the data \\ncorresponded more or less to the heights of \\ninternal political conflicts in El Salvador.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 202}, page_content='LUIS SANCHEZ\\n198\\nBefore Lehman, Jami ran the National Clandestine Services of the Central Intelligence \\nAgency under George Tenet. Around 2005, she joined Lehman Brothers as Global Head \\nof Sovereign Risk Analysis, and to this day I consider her a very unique type of data \\nscientist.\\n \\nI was fascinated with Jami’s analytical skills for political risk; she’s equally talented in the \\nart and science parts of data science. While at the CIA, Jami ran a complex quantitative \\nand qualitative program to forecast political instability in 40 countries based on 25 \\nindicators, and I was lucky enough to be one of the few executives invited to gather for \\nher weekly world outlook meetings. At the suggestion of the Head of High Yield Trading \\nat Lehman, I enlisted Jami and her team to dig a little deeper on the company I was \\nanalyzing.\\n \\nAfter her report, I decided not to go ahead with the deal (this could be a topic for another \\nbook), and informed Jami of my decision, but in any case, Lehman was already in bad \\nshape. I called to set up a meeting with her to personally thank her for her great work \\nand see if I could discover a little more about her proprietary models and exchange ideas \\non a couple of topics. Both her calendar and mine were free for the same day: September \\n12, 2008, which turned out to be the historic last day of operations of Lehman Brothers. \\nNevertheless, we still kept our meeting and managed to talk for a little while.\\n \\nA couple of years later, I started thinking about creating real-time political risk indicators \\nby tapping and correlating many sources of publicly available data on the Internet, and \\n“calibrating to market.” We did it and now we are successfully using our analysis to \\nadvise a few interesting groups out there..\\n \\nI think the likelihood of getting exposure to the sort of data problems described above is \\nzero or very small if you only have exposure to academia.\\nHow do you measure your own personal career success?\\n \\nA few years ago, I realized I had always been an entrepreneur inside much larger \\norganizations and managed to obtain R&D funding to develop and launch securities \\nthat many times were called crazy or impossible to launch.\\nSo I ended up as a DS because when I started to analyze what my skills were, I realized \\nthat a DS is more or less a financial quant minus the financial knowledge. Remember, \\nfinancial quants come from all fields: computer science, physics, math, economics, \\nfinance, etc.\\nAt this moment, I measure my own personal career success by the fact that ttwick exists, \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 203}, page_content='LUIS SANCHEZ\\n199\\nit is funded, and some of my investors are either former bosses or colleagues of mine, \\nand even traders, analysts, and/or executives of well-known financial institutions and \\nmedia companies.\\nHow do you work with other people on your team?\\n \\nI assign tasks to the teams with the most \\nrelevant experience to the problem at hand \\nwhenever possible. Then I have periodic \\nprogress reports to review their work, and if \\nI don’t understand something, or think there \\nmight be a better way to do it, I encourage \\ndiscussion. We have all gained interesting insights from this process, and so far I am \\nsatisfied with the results.\\n \\nI have several machine-learning specialists, data wranglers and general coders on \\nmy team who support what I do in DS. I would like to hire more DSs like me, but it is \\nvery difficult to find “diversified” DS, and even more difficult to find any with financial \\nbackgrounds.\\n \\nEverything we’re doing at ttwick involves multiple disciplines, and my experience with \\nmultidisciplinary teams across several industries allows me to have fluid communication \\nwith my team members.\\nWhat type of careers could people working in DS transition into if they decide DS \\nisn’t for them?\\n \\nBased on my own experience, I would say that financial quantitative analysis would be \\nan option, but a person would have to learn at least some basic finance and get a CFA (or \\nbetter yet, a CAIA) if they want to excel. \\nWhat separates the best data scientist from the merely good?\\n \\nSince I describe data science as the art and science of extracting actionable intelligence \\nfrom data, I would say a good data scientist has an academic and professional background \\nthat makes him or her good in the science part, but the best data scientists are talented \\nin the art part as well.\\nWhat backgrounds do these best data scientists tend to have?\\n \\nI can’t really say, but to me, more than having a particular field of concentration, the \\nbest data scientists probably have experience solving problems for diverse industries. \\nThe best data scientists probably \\nhave experience solving problems \\nfor diverse industries.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 204}, page_content='LUIS SANCHEZ\\n200\\nThat creates the right frame of mind to attack problems from different perspectives; this \\nmight not be obvious to somebody who has only worked in one industry.\\nWho are some DS people you admire? Who are people doing interesting things \\nwith data that you admire?\\n \\nTo me, Hilary Mason is a great data scientist whom I would love to meet someday (and \\nmaybe invite for a cheeseburger). I find her work very interesting, as well as the work \\nClaudia Pelrich at Dstillery has done in the area of detecting fraud in online advertising.  \\nAlso, the work that professors David Cope, Larry Polansky, Peter Elsea and Daniel Brown \\nat the University of California Santa Cruz are doing with artificial intelligence applied \\nto creativity is extremely interesting. I spent a few weeks interacting with them at the \\nUCSC, and what I learned is truly fascinating; for example, the use of non-speech audio \\nto perceptualize data as a complement to visualization techniques, or even as a stand-\\nalone technique.\\n \\nThere is also a group of Wall Street data scientists (or quants) whom not many people \\nknow of outside of trading, structured finance, risk management and/or political risk \\nanalysis. I already mentioned Jami Miscik and Marc Chaikin, but I should also mention \\nJorge Calderon and Phil Weingord (ex-heads of Global Asset Securitization for Deutsche \\nBank and Credit Suisse), Dr. Mark Shi at Citigroup, and Dr. Jose Hernandez and Blythe \\nMasters at JP Morgan. I have worked with all of them, with the exception of Blythe \\nMasters, who almost hired me for her Credit Risk Trading group, but I opted to take \\nanother offer.\\n \\nThe group above created many cutting-edge analytical and computational methods used \\ntoday in financial engineering, risk management, and other fields, but unfortunately, the \\n2008 financial crisis and problems in the risk valuation of many MBS and CDS by rating \\nagencies tainted a big chunk of the industry and overshadowed the work of a lot of good \\npeople.\\nCan you tell me about some of the ways you and other data scientists at ttwick \\nkeep ahead of the curve, education wise?\\n \\nI attend a lot of conferences and meetups, and I read as many books as possible about the \\nlatest findings in artificial intelligence,, financial engineering and many other related \\ntopics.\\n \\nI attended the Strata Conference 2014 in Santa Clara and it was fascinating to learn \\nabout some of the cutting edge initiatives at DARPA in the area of big data, the latest ML \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 205}, page_content='LUIS SANCHEZ\\n201\\nR&D projects at Stanford, and in general, getting a feeling for the general direction of \\nthe industry. I highly recommend it to aspiring data scientists. \\nI also run a meetup group in New York called “ Algorithmic Art - Quadrivium”, where \\nIexplore Machine Learning applied to creative arts, and the legal ramifications of \\nproprietary artificial intelligence code creating content.\\nWhat are your personal 1 and 3-year goals as a DS?\\n \\nMy goals are to complete all the pending projects I have for ttwick, file patents for all the \\ntechnologies we are developing, and help improve the efficiency of a couple of industries \\nin which I have not seen significant improvements in decades.\\nHow do you think DS is changing over the next few years?\\n \\nI expect the biggest advancements to come from high-performance computing and data \\nstorage.\\n \\nDefinitely, there will be more “toolkits” available to do data analysis. Data wrangling will \\nbecome easier and faster (hopefully), data collection systems and sensors will probably \\nhave built-in data cleaning capabilities, or something like that, and testing of different \\nmethods will become faster. Also, I think data scientists will be incorporating a lot more \\nhardcore time series analysis into their work, which I don’t see much outside of finance.\\nWhat are some new developments in the field that you are really excited about?\\n \\nThere are several exciting new ones:\\n• The DeepDive probability inference methodologies that Christopher Ré is building at \\nStanford;\\n• DARPA ’s Memex project;\\n• A few of the developments related to semantic search, coupled with natural language, \\nand the intersection with fintech, including the one in development at ttwick;\\n• The work of some people I know with cryptocurrencies;\\n• Artificial intelligence applied to algorithmic art (music derivatives, visual arts, etc.)\\n \\nI think any progress in any of those initiatives, along with adequate user adoption and \\nnew ethical business models for the data economy — all of these have the potential to \\ndisrupt many industries over the years to come.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 206}, page_content='MICHELANGELO D’AGOSTINO\\nSenior Data Scientist at Civis Analytics\\nCan you talk about your career from undergrad to PhD? How did you transition to \\ndata science and data analysis, and what were your various roles afterwards?\\nMy career has been strange. Sometimes, it feels like a random walk, but it’s more of a \\ngreedy algorithm. Every time I’ve had a choice of what to do, I think about what seems \\nlike the best opportunity, the most interesting thing for me to do. It’s worked out really \\nwell even though there hasn’t been this overarching plan.\\nI started as a Harvard undergrad and studied physics. I always really loved physics, but \\nI also really loved doing other things outside of physics. So, I took tons of literature \\nand history classes when I was an undergrad. I liked working in the lab and doing the \\nresearch stuff, but I always had lots of different interests.\\nI graduated, and I wasn’t sure if I wanted to go to grad school because I wanted to get a \\njob. Looking back on it now, I wish data science existed when I was an undergrad. I really \\nAs an undergrad at Harvard, Michelangelo was fascinated by \\nphysics. He finished his PhD in astrophysics from Berkeley, \\nand developed a love of working  collaboratively on hard \\nproblems with other people while analyzing neutrino data \\nfor the IceCube experiment.\\nMichelangelo started his data science journey as a senior \\nanalyst in digital analytics with the 2012 Obama re-election \\ncampaign, where he assisted in optimizing the campaign’s \\nemail fundraising efforts and analyzed social media data. \\nAfterwards, he worked as Lead Data Scientist at Braintree \\nbefore he rejoined many of his former colleagues from \\nthe Obama reelection team at Civis Analytics. At Civis Analytics, Michelangelo works on \\nstatistical models and writes software for data analysis.\\nMichelangelo has travelled to the South Pole and has written about science and technology \\nfor The Economist.\\n \\nIn his interview, Michelangelo shares his story and offers practical advice on transitioning \\nfrom a PhD into data science. He also shares his thoughts on data science for social good.\\nThe U.S. Presidential Elections as a Physical Science\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 207}, page_content='203MICHELANGELO D’AGOSTINO\\nloved quantitative research. I loved the stuff I did in the lab, but it felt a little distant \\nto me. It didn’t feel connected to the world. I think that’s what always made me a little \\nhesitant about research, but when I graduated from college, there was not really a path \\nfor technical people to do things outside of academia. You could go work in finance, and \\ntons of people I know worked on Wall Street. But outside of that, there wasn’t a clear \\nthing to do. \\nI took a fellowship to go teach physics at \\na boarding school in England for a year \\nbecause I also really loved teaching.  It \\nwas a great way to experience teaching \\nphysics, learn about high school kids \\nand what they’re like, and travel around \\nEurope.  I really enjoyed it, and I could really see myself teaching for a long time, but \\nI started to apply to grad school because I knew that teaching would always be there.  \\nI liked it and I knew I could go do that. I also knew that if I wanted to go back to grad \\nschool, I felt like I had to do that relatively quickly before I got too old and just too tired.\\nI started grad school at UC Berkeley in physics, and I enjoyed the classroom aspect of \\nit.  I started doing research in condensed matter physics.  I enjoyed that, too, but I was \\nbasically in a second sub-basement.  I was doing this condensed matter research, and I \\nhad this feeling that it was detached from the outside world.  Also, it was really solitary.\\nI made a transition and switched research fields to particle physics and astrophysics.  \\nI did my PhD on a neutrino physics experiment that is located at the South Pole.  It’s \\ncalled IceCube, and it’s operating now.  We basically buried sensors in the polar ice cap \\nto measure cosmic neutrinos.  It was a transition for me because, all of a sudden, I was \\nworking with a couple hundred people all around the world. Half of them were in Europe, \\nthe other half in the US spread out across all of these different time zones. It felt like I \\nwasn’t working on something by myself. I was working on really interesting problems \\nwith other smart people and doing really hard work. I think that was what kept me in \\ngrad school — knowing that I was working with other smart people in a collaborative \\nenvironment.  \\nI found out that it suited my personality a lot better than solitary research, and that was \\nwhen I was introduced to everything I know about data science. That’s when I learned \\nmost of the statistical techniques and most of the computer programming I know, and it \\nwas when I started using machine learning techniques.  Basically, the common thing in \\nparticle physics now is you have a big detector, and there are tons of things happening \\nin your detector, the vast majority of which you don’t care about and are not trying to \\nstudy.  But you also have something happening in your detector that you care about.  \\nMy career has been strange.  Sometimes, \\nit feels like a random walk, but it’s more \\nof a greedy algorithm.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 208}, page_content='204MICHELANGELO D’AGOSTINO\\nThe whole game is trying to figure out what is signal and what is background. These \\ndetectors are so complicated, and the signal-to-noise ratios are so low, that techniques \\nfrom computer science and machine learning have really infiltrated physics. It’s \\ninteresting because the old school professors don’t like machine learning.  You go to \\nthese seminars with old guys from the 1960s, and they ask aggressive questions and \\ngive you these looks.  They don’t like these techniques.  They just think they’re black \\nboxes. But for the younger generations, they are common tools to do the most sensitive \\nanalysis of the thing you care about.  \\nThat was how I was \\nintroduced to machine \\nlearning.  For my thesis \\nresearch, I used a lot \\nof neural networks to \\ndo pattern recognition \\nfor a particular kind of \\nneutrino signal in the detector that we cared about.  I found that I liked programming \\nand statistical work and machine learning a lot more than I liked lab research.  \\nThat was how I was introduced to this field, and I finished my PhD.  I did a post-doctorate \\nfor a year in neutrino physics, and this was when the term data science first came out and \\npeople started talking about it.  I started reading lots of blogs about the field, realizing \\nthat this is something I wanted to do and had the right skills for. \\nI started messing around with Kaggle when Kaggle first came around. I started learning \\nR and just took any chance I could get to learn. I went to meet-ups and other things that \\none does to learn these things out of the classroom, started messing with data sets and \\ngoing to hackathons. \\nOne day, as a post-doc, I was in my office randomly reading KDNuggets, which is a blog \\nfor learning data science stuff. They posted an ad for the Obama campaign looking for \\nscientists, statisticians, and computer scientists to go work for the campaign. It seemed \\nlike an intriguing opportunity for me. I had never worked in politics before, but I had \\nalways been interested in it. Because I had been reading a lot about data science and \\nmaking that transition, it seemed like a good opportunity to test out if I was any good. \\nAs it was only a year, this work also seemed like a low pressure way to test out if data \\nscience was interesting to me. I didn’t have to quit my post-doc. But in reality it was \\nactually the opposite of a low pressure environment. \\nI applied. I had an interview, and I got an offer. The funny thing was I assumed that since \\nit was a political campaign, they would pay me so little money that there was no chance \\nI started learning R and just took any chance I could get to \\nlearn — like going to meet-ups and other things that one \\ndoes to learn these things out of the classroom, messing \\nwith data sets and going to hackathons. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 209}, page_content='205MICHELANGELO D’AGOSTINO\\nI would be able to accept the job. It turned out that it was basically the same as my post-\\ndoc salary, which shows you how well-paid academics are. \\nI took the job. I started \\nin November 2011 and \\nworked through election \\nday.  It was a transformative \\nexperience for me in a \\ncouple of ways. First, I \\nrealized that a lot of the \\nthings I was doing were not \\ndissimilar to the things I \\nwas doing in physics. I spent tons and tons of time writing Python code to grab data from \\nAPIs (Application Programming Interfaces - the way one programmatically interacts \\nwith another application or data stream)  or to scrape data. It was a lot like writing data \\nacquisition code in physics. I was doing statistical stuff in R rather than the packages we \\nused in high energy physics, but I was still building statistical models, predictive models. \\nInstead of particle physics models, I was building models to predict how much money a \\nfundraising email was going to make from its early returns.  The question we had was: \\n“If we sent an email asking people to drive to a neighboring state to canvas, who found \\nthe people most likely to respond favorably to that email?” That information allowed us \\nto focus our targeting efforts. \\nI realized that the techniques of working with data, understanding statistics and being \\nable to visualize something and tell a story about it - these were precisely the skills I \\nlearned in physics and carried very well over to the data science context. \\nWe can talk more later about the campaign if you’re interested, but we did lots of \\nmodeling, randomized experiments, e-mail fundraising optimization. It was an amazing \\nexperience. It was actually the first time I felt the technical skills I had could be used to \\naffect the world, to work towards something that could affect the world positively.  That \\nwas really cool.\\nThen, I thought briefly about going back to finish my post-doc afterwards, but I decided \\nthat I really liked working in data science more than I liked working in research. It was \\nlike the feeling I had when I switched to astrophysics. I like working with people a lot \\nmore than I like working by myself.  I like to work on things that have more impact.  You \\nsee a lot more of it in industry, in data science, than you do in research.  I like the pace \\na lot more.  I think research can often be very slow, especially particle physics.  It takes \\n10 years to build an experiment now.  You have to have a monastic personality to be a \\nphysicist nowadays.  \\nThe funny thing was I assumed that since it was a \\npolitical campaign, they would pay me so little money \\nthat there was no chance I would be able to accept \\nthe job. It turned out that it was basically the same as \\nmy post-doc salary, which shows you how well-paid \\nacademics are.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 210}, page_content='206MICHELANGELO D’AGOSTINO\\nI found the pace suited me better, and the work was actually just as interesting or more \\ninteresting to me than a lot of the stuff I was doing in physics.  That’s how I ended up \\nwhere I am.  After the campaign, I went to a startup in Chicago called Braintree, which \\ndoes credit card processing for other startups like Uber, Airbnb, Github, and a lot of other \\ngrowing tech companies. I started the data team there, and it was a really interesting \\nintroduction to the world of startups.  Then, Braintree ended up getting acquired by \\nPaypal in the fall, and for reasons mostly unrelated to that, I decided to make a switch. I \\nwent to work with some old campaign colleagues at a startup called Civis Analytics, that \\nspun out of the analytics shop on the Obama campaign.\\nAt Civis we’re doing really interesting data work for a lot of political clients and campaigns \\nlike we did on the Obama campaign, but we’re also working with some interesting non-\\nprofit and corporate clients.   We’re really trying to do a lot of individual level predictive \\nstuff like we did on the campaign, focused on political and social good work.\\nThat’s my story in a nutshell. \\nYou mentioned that some of the most useful things you did during your time as a \\nPhD were working on hackathons or working on Kaggle or data sets and working \\nwith people.  Do you have more to add to that? What was the most useful part of \\nbeing a post-doc and PhD student for your later data analysis/data science career? \\nI always tell students that I think the most useful skill you learn in grad school is how \\nto teach yourself stuff and \\nhow to figure out things \\nthat you don’t know.  That’s \\none thing.  The second \\nthing is to be stubborn \\nand beat your head on a \\nproblem until you make \\nprogress.  It’s really those \\ntwo things.\\nI feel like grad school gave me confidence.  Physicists tend to be a pretty arrogant \\nbunch.  They think they can learn anything, but that was the lesson I learned in grad \\nschool. I don’t know every programming language in the world, but I’m confident that \\nif I spend a few months, I could pick up a new programming language or pick up some \\nnew infrastructure tool or modeling technique. I can teach myself those things.  I can go \\nout there and read academic papers, read software manuals, and teach myself the tools I \\nneed to get the job done. I think that’s pretty common across grad school fields.  Most of \\nI always tell students that I think the most useful skill \\nyou learn in grad school is how to teach yourself stuff \\nand how to figure out things that you don’t know.  \\nThat’s one thing.  The second thing is to be stubborn \\nand beat your head on a problem until you make \\nprogress.  It’s really those two things.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 211}, page_content='207MICHELANGELO D’AGOSTINO\\nthe things you learn you don’t learn in the classroom.  You learn by completing a project \\nand teaching yourself things.  In data science, that’s a crucial skill because it’s a quickly \\ngrowing field and it encompasses a ton of things.  You can’t finish a degree and know all \\nthe things you need to know to be a data scientist.  You have to be willing to constantly \\nteach yourself new techniques.  \\nThat was one of the things I \\nlearned in grad school.  The \\nother is the ability to work on \\na hard problem for a long time \\nand figure out how to push through and not be frustrated when something doesn’t work, \\nbecause things just don’t work most of the time.  You just have to keep trying and keep \\nhaving faith that you can get a project to work in the end.  Even if you try many, many \\nthings that don’t work, you can find all the bugs, all the mistakes in your reasoning and \\nlogic and push through to a working solution in the end.\\nHaving confidence in yourself is another thing. I think that working on a really hard \\nproblem like in grad school can help you learn that. And then there are just the technical \\nthings like learning how to program, running on large computer clusters. On top of \\nmastering those techniques, the advice I give to grad students is: if you feel like you want \\nto leave grad school and do something else, keep that in mind when picking which tools \\nand techniques you use for a dissertation. If you can write your dissertation in Python \\nrather than some obscure language like FORTRAN, it’s probably going to be better for \\nyou. Try to be as marketable as possible with the things you learn when you’re doing \\nyour PhD.\\nAnd the final thing is that it really helps to have experience working with data. The only \\nway to learn how to work with data is to actually work with data. You can read about it, \\nand people can teach you techniques, but until you’ve actually dealt with a nasty data \\nset that has a formatting issue or other problems, you don’t really appreciate what it’s \\nlike. There is no substitute for the experience of having to merge a bunch of data sets \\ntogether or make a bunch of graphs to sanity check something. Or finding all of a sudden \\nthat nothing makes sense in your distributions, and you have to figure out what’s going \\non. Having those experiences makes you a better data scientist.\\nSo far, you’ve given a lot of advice for graduate students, for example working \\nwith more common tools or working with data. Can you expand on that because \\nyou are a physicist-turned-data-scientist? What is your advice for other physics \\nPhD students or other physicists who are transitioning to data science?\\nMy advice is to recognize the skills that you have. In terms of actually mechanically \\nAnd the final thing is that it really helps to have \\nexperience working with data.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 212}, page_content='208MICHELANGELO D’AGOSTINO\\nmaking that transition, there are lots of ways people can learn more about the field and \\ndemonstrate their interest.  From a hiring perspective, when I talk to PhD students who \\nsay they want to be data scientists, I become skeptical if they haven’t taken any active \\nsteps.  “Hey, I participated in these Coursera courses or these Kaggle competitions.  I’ve \\ngone to the Open Government Meetup and have done these data visualizations.”  Things \\nlike that demonstrate that you can work on problems outside your academic specialty, \\nand they show that you really have initiative.  They also show that you can teach yourself \\nnew things.\\nThe worst thing is when people present the physics job market as terrible, and they say \\nthat’s why they want to get a data science job.  You don’t want to hire someone like \\nthat. You want to hire someone who’s going into data science because of what it’s like, \\nbecause they want to work on data in the real world. You want it to be a positive thing \\nrather than a negative reason that they’re leaving physics.\\nTo be honest, it’s not a terrible \\nreason to want to leave \\nacademia because there’s no \\njob, or because you’re lonely, \\nbecause you’re working on a \\ntiny, tiny problem. Those are good reasons to leave academia. From a practical standpoint \\nthough, when you’re presenting yourself to other people, I think you should focus on the \\npositive reasons that you’re excited to do something else rather than negative thoughts \\nabout about what you’re doing. Having said that, all those things are true, and all those \\nthings are reasons why I also personally decided to leave.\\nThe other piece of advice I always give to job seekers is when people talk about data \\nscience jobs, it can mean so many different things.  At each different place, when they’re \\ntalking about hiring a data scientist, that can mean something totally different.  In some \\nplaces, they just want someone who can run SQL queries and numbers for every report.  \\nIn other places, they want people who are actually going to build data infrastructure. In \\nother places, they want some people who are going to build predictive statistical models \\nand design experiments. In some places they want the unicorn that can do all that stuff. \\nSo it’s really important to ask a lot of questions and figure out what a company really \\nwants when they want a data person. What would someone actually want in that role? \\nAre there other people currently working as data scientists at the company? What are \\nthey doing? Is there an engineering team? Is there a product team?\\nYou mentioned earlier about working with people and making a large impact.  \\nWhat about the future of data science excites you the most?  What are some of \\nI’m excited about future applications where data \\nscience is going to be seen as a positive force.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 213}, page_content='209MICHELANGELO D’AGOSTINO\\nthe positive reasons that you would give to graduate students on why data science \\nhas greener pastures?\\nI’ll leave out all the sociological reasons that I already talked about, why it’s more \\nenjoyable to work in a collaborative, fast paced environment, and to see the impact of \\nyour work.  In academia, you don’t have clients. In physics, I always felt that we had \\nto beg people for money to do what we wanted to do, and that may still be true in data \\nscience, depending on your company. But most of the time, there are people who are \\ninterested in the output of what you’re doing and really appreciate those skills. \\nI also think the work is exciting.  \\nIt’s incredibly exciting, and it’s \\nstill in an early phase.  I’m not \\ngoing to go into the cliché of how \\nmuch data we’re collecting and \\nhow all of these organizations \\nare collecting more and more \\ndata.  Many people have talked \\nmore eloquently than I can \\nabout that.  But it’s true. Organizations have tons and tons of data, and they don’t \\nnecessarily know what to do with it.  They’re starting to think about what to do with it, \\nand they need help from people like us to actually do that work.\\nThis is the reason that I came to Civis. I’m really excited about future data science \\napplications that people are going to look at and think are benefiting society in a positive \\nway.  Like working with non-profits to use their data in smarter ways, or working with all \\nthe data that cities are releasing now.  \\nOpening up public data is great, but there are not many cities that are using their data in \\na real, predictive way right now.  New York has done some really interesting predictive \\nthings. Chicago has released a lot of data, but Chicago hasn’t done a lot of interesting \\nanalytics with its data as a city. They just release data to the community and hope the \\ncommunity will do it.\\nI’m excited about future applications where data science is going to be seen as a positive \\nforce for good, because honestly I’m a little worried.  Right now, a lot of the applications \\nwe have with data have to do with targeted advertising, cookie collection, online \\noptimization of ad click rates, etc. That’s great, but I’m worried that, at some point, \\nthere’s going to be a backlash against collecting more and more data about people. \\nI’m hoping that before that happens or when that happens, there are enough positive \\nThere are lots of people who are writing tutorials \\nexplaining different techniques and different \\nprojects they’ve worked on.  None of that existed \\nwhen I was younger, and it’s awesome that you \\ncan go out, get that stuff, and get an idea of \\nwhat’s going on.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 214}, page_content='210MICHELANGELO D’AGOSTINO\\ncounter examples of ways data is being used to benefit people and society that it can \\nprevent some of that backlash.\\nI wish I could talk about this a little more specifically with the clients we’re working with \\nat Civis, because that’s something we’re really focused on.  Before I started here, one of \\nthe big engagements we had was with the College Board, the folks who administer the SAT \\nexam. We spent a very long time working with their data and helping them build models \\nto understand which kids weren’t going to colleges and universities commensurate with \\ntheir abilities.  Could we predict that?  If so, what are the implications for designing \\ninterventions to help those high school students? I’m hoping that we’ll have more and \\nmore examples of data science work like that, work that people feel good about rather \\nthan just seeing that companies are trying to collect data from them.\\nAlso, one of the data scientists from the campaign started a Data Science for Social Good \\nFellowship in Chicago, where I was a volunteer mentor. Some of the projects we worked \\non addressed really interesting social impact problems, and I’m hoping there will be \\nmore and more of these kinds of applications in the future. That’s what excites me about \\nthe future of data science.\\nWhen we spoke to Jace from Khan Academy, it was inspiring to see him apply his \\nknowledge from quantitative finance to education. How can we encourage more \\nof this in the nascent data science community?\\nI think people really want to do more and \\nmore of this kind of work. I think about \\nthis a lot. My wife is a lawyer, and almost \\nall lawyers do some amount of pro bono \\nwork in a given year. I think it would be \\nawesome if we could get some engineers \\nand computer scientists and data people to \\ndo a certain amount of pro bono hours every year working with a non-profit. A lot of \\npeople are already doing that as a volunteer thing, but if we could institutionalize that, \\nI think that would really be awesome for the field. \\nYour background as a science teacher and as a writer is different than most of the \\nother people we’ve interviewed.  As a science teacher and writer, how is data \\nscience doing on the PR side?  What is data science missing on the teaching and \\nwriting side? \\nI forgot to mention that earlier. I was briefly a science journalist. I took a summer off \\nand worked at The Economist and wrote about science and technology. I freelanced for \\nI do worry that there’s a little bit of \\nhype, but it’s undeniable that there’s \\na very solid grain of truth to the whole \\ndata science thing.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 215}, page_content='211MICHELANGELO D’AGOSTINO\\nthem for a while after I was in London for that summer. I actually think teaching and \\nwriting have helped me become a better data scientist because a lot of what I do is \\ninteract with my colleagues on a daily basis. I teach them new things all the time. They \\nteach me things. We sit in meetings and look at graphs and talk through algorithms and \\ntechniques, and we ask each other questions. We explain things to each other, and you \\ntell a story about the data.  That’s very similar to the things you do in a classroom when \\nyou’re teaching people something.  It’s very similar.  When you’re writing about science, \\nyou try to simplify things and explain them to people.  Those skills have been useful for \\nme as a data scientist. \\nAs a field, I think data science is doing a pretty good job. There are so many people who \\nare blogging about their work and telling stories about their work.  There are lots of \\npeople who are writing tutorials explaining different techniques and different projects \\nthey’ve worked on.  None of that existed when I was younger, and it’s awesome that \\nyou can go out, get that stuff, and get an idea of what’s going on.  I think that is really \\nawesome.\\nSometimes, when we talk with people who come from an academic background, \\nthey are suspicious of data science.  They think of it as a fad.  I’m thinking about \\nthe hype that might be behind that or how some people react to it.  What would \\nyou say to somebody who thinks it’s a fad?\\nFirst of all, I think it’s a valid concern. \\nI do worry that data science is being \\nsuper hyped up right now. Not by the \\npeople that are doing it or who know \\nwhat it’s really about, but there are \\nlots of companies who want to sell \\npeople things. A few journalists write \\nan article on something, and everyone \\nelse feels like they need to write an article too.  Then, it becomes this big giant thing.\\nI do worry that there’s a little bit of hype, but it’s undeniable that there’s a very solid \\ngrain of truth to the whole data science thing. We do have lots and lots of data, and we’re \\ncollecting more every day.  I can’t imagine that companies and organizations are going \\nto want to be less efficient in the future about how they reach out to people, about how \\nthey optimize their own operations. I think that trend is going to continue, and they’re \\ngoing to want people to help them analyze that data. The skills you need to do that just \\ndon’t come from a single discipline like statistics or computer science. They have all the \\ninterdisciplinary aspects of what people call data science.\\nThis is why I’m excited about more positive \\nexamples of data applications. I think the \\nmore positive examples of data science that \\nwe have, the more it will help counteract a \\nlot of the hype.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 216}, page_content='212MICHELANGELO D’AGOSTINO\\nThis is why I’m excited about more positive examples of data applications. I think the \\nmore positive examples of data science that we have, the more it will help counteract a \\nlot of the hype. I think all the hype has not just been around data science but about tools. \\nEveryone’s been talking about Hadoop. Hadoop is great, but it’s a tool. It’s not the most \\nimportant thing in the world, and not every organization needs to have a giant Hadoop \\ncluster, but, with the hype, the message is, “If you’re not running a Hadoop cluster, you’re \\nnot doing anything interesting with your data.” \\nThe term big data makes me want to throw up because it’s become an overused, overhyped \\nthing. To me, it’s not the amount of data you have. It’s what you do with the data you \\nhave and how you apply it to problems and what interesting things you’re doing with it. \\nThat’s so much more important.\\n \\nI actually don’t think that anything we did on the campaign, when you talk to someone \\nfrom Silicon Valley, counts as big data. We didn’t have a petabyte of data, but it was what \\nwe did with it, how we were changing the organization and the practices of the campaign \\nthat was really important.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 217}, page_content='MICHAEL HOCHSTER \\nDirector of Data Science at LinkedIn\\nYour background spans both pure mathematics at the undergraduate level, law \\nstudies and then a Ph.D. in statistics. How did that happen? Can you talk a little bit \\nabout that process?\\n \\nI have never been great at long-term planning for anything, so I’ve always followed my \\nnose. Even the decision to go into math in the first place — I’d decided at the end of high \\nschool that I was finished with math and that I didn’t really enjoy it that much. But I kept \\non taking just one more class in college. Then at a certain point, that was the only thing \\nI had taken enough classes in to have a major. So I ended up majoring in math. I did end \\nup liking it a lot, but that wasn’t a directed decision.\\n \\nI was mostly interested in the pure math. My dad is a mathematician so that might have \\nsomething to do with it. More than anything, I really liked the fields of abstract algebra, \\ntopology, logic, and set theory. I didn’t take any statistics courses as an undergraduate, \\nalthough I studied probability if that counts.\\nThen at the end of college, my thought was, “This is too abstract. This is fun, but I need to \\ndo something connected to the real world. ” At that time, I didn’t see math as something \\nMichael Hochster’s path into the field of data science \\ntook a series of winding turns. After graduating from high \\nschool, Michael believed himself to be done with math. Yet, \\nhe eventually received his bachelors in pure mathematics \\nfrom UC Berkeley.\\nAfter graduating and seeking something more practical, \\nMichael entering law school, but quickly learned that it \\nwasn’t for him. After leaving law school, he eventually \\nended up enrolling in the Statistics PhD program at \\nStanford, despite having minimal exposure to statistics.\\nAfter some time spent in industry, including stints at a pharmaceutical company, a web \\nstartup, Google and Microsoft, Michael became the Director of Data Science at LinkedIn.\\nWhile we interviewed Michael when he was in his role at LinkedIn, he has since become the \\nDirector of Research at the music company, Pandora.\\nThe Importance of Developing Data Sense\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 218}, page_content='MICHAEL HOCHSTER\\n214\\nthat was going to lead me to a connection with the real world. So I speculatively decided \\nto go off to law school with the reasoning: “ I’ll probably be able to find something useful \\nand interesting to do with this.”\\n \\nLaw seems to have a logical aspect, which is similar to math in some ways.\\n \\nI’m guessing that the logic part translated from math to law very well.\\n \\nWell, that’s what I thought. There’s a superficial similarity: it’s reasoning. It’s making \\nyour career out of reasoning. I always liked the reasoning part of math; it was one of \\nthe more appealing aspects. This was the story that I told myself when I went off to law \\nschool.\\n \\nSo I went to law school for a \\nyear and it was a bit of a mixed \\nbag. I did like law school; I \\nenjoyed the classes and liked \\nmy fellow students. But at a \\ncertain point, I started realizing \\nthat the “ I will probably find \\nsomething interesting to do with \\nthis” thinking wasn’t going to pan out if I didn’t have a real plan. It seemed like everybody \\nwas defaulting to corporate law. If you were taking the next step up the ladder, you went \\nto a good law school, you went to work at a good firm, and then you became a partner.\\n \\nSo there was a certain point during the summer when you were supposed to find a law \\nfirm for an internship. As I was sitting in these interviews explaining to the interviewers \\nwhy I wanted to work for their firm over the summer, I realized that I didn’t really want \\nto do that. I didn’t really know what I did want to do and it seemed misguided. I was just \\ngoing down a path that didn’t make sense.\\n \\nI didn’t know what I was going to do next, aside from not-law-school. I did have a friend \\nwho was doing a Ph.D. in statistics at Berkeley and I got in touch with her. She told me \\nabout some of the things she was working on (she’s now a professor of Biostatistics at \\nthe University of Florida). It just sounded interesting, at least more interesting than the \\nthings I was doing. Again, this was completely speculative. I didn’t know anything, but I \\njust thought, “I know some math so I’ll probably be able to pick this up.”\\n \\nSo I started applying to graduate schools in statistics and took some time off. I was a \\ntemp for a while. Eventually, I got into graduate school. It was funny because all I had \\nwas a general idea that I wanted to do something connected to the real world. I wanted \\nAt the end of college, my thought was, “This is too \\nabstract. This is fun, but I need to do something \\nconnected to the real world.” At that time, I didn’t \\nsee math as something that was going to lead me \\nto a connection with the real world.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 219}, page_content='MICHAEL HOCHSTER\\n215\\nto use my math background, but I didn’t know anything. I didn’t know what confidence \\ninterval was, I didn’t know what a t-test was. I didn’t know anything.\\n \\nDid you find the statistics graduate school experience to be more closely aligned \\nwith what you were expecting?\\n \\nGraduate school was rough for me, because of my lack of background going in. I didn’t \\nunderstand the point of a lot of things we were studying. In grad school, you immediately \\nlaunch into theoretical statistics; you don’t really have any idea about its applications. \\nUnbiased minimum variance estimator? Who cares?\\n \\nIt seems like you still had the question of, “what is this applied for?”\\n \\nYes, in the end, the “I want to do something connected to the real world” fell by the wayside, \\nin the sense that I was most comfortable doing math. Even though my math was a little \\nrusty at this point, my graduate school experience resulted in my being most comfortable \\nin the theoretical side of statistics where I could prove theorems and know I was getting \\nthe right answer. That’s the gratification you get from math.\\n \\nI ended up, first of all, being very far behind in understanding the point of statistics. \\nUltimately I fiddled around with it and tried to work out what to study. I ended up in \\nsomething that is very theoretical. Which I enjoyed in a way, but it didn’t have the \\nconnected-to-the-real-world feeling. It was very tenuous.\\n \\nIt wasn’t until I entered the workforce that I started understanding what statistics were \\nuseful for. It was a pleasant surprise that I actually like the job, and am well suited to \\nit. I’m more interested in working out how to do useful things with data than I am in \\nproving theorems. It was only after school was over that I started to figure out it was a \\nvery good fit for me. It was accidental.\\n \\nEven after having finished the Ph.D., I felt I was going up the next rung of the ladder. You \\nget your Ph.D. from a good school and then you want to get a postdoc at a good school \\nor a tenure track position, that’s the next step up. On top of that, both my parents are \\nacademics, so that path seemed natural to me. And I wasn’t too well-informed about \\nother options. But in the end, it was clear to me that I wasn’t passionate enough about \\nproving theorems in theoretical statistics to make that my livelihood.\\n \\nIt sounds like from your story that after you finished your Ph.D., you then evaluated \\nyour options and said, “I don’t really want to go down the full professor route.” Is \\nthat correct?\\n \\nIt was a mixture of things, that’s a somewhat nice revision of it. I applied for a few things, \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 220}, page_content='MICHAEL HOCHSTER\\n216\\ndidn’t get anything. Then it became a question of, “ should I really press hard and apply \\nand go to a place where I may not really want to live? Or should I think about what else I can \\ndo?”\\nIt wasn’t that clear. This was a time when a lot of people were going into finance. You \\ncould go into the pharmaceutical industry. That seemed about it. It wasn’t like you \\ntype “data science” into a search engine and you get fifty million jobs. I was looking for \\nstatistician or quant, something or other. I applied for some finance jobs and I ended up \\nmeandering into this position as a biostatistician for a pharmaceutical company.\\n \\nWas that was the first time you were confronted with real data?\\n \\nIt was an interesting experience. Again, I was going in as with every step, very ignorant. I \\nstill think especially here in the Valley, people don’t appreciate the huge role traditional \\nstatistics plays in the pharmaceutical industry. These companies employ armies of \\nstatisticians who are really good people. All this A/B testing that’s so in vogue now \\nhas been thoroughly worked out in the pharmaceutical industry. All the philosophical \\nhand wringing: “can you peek at the data,”  “Bayesian versus frequentist” and looking at \\nsubgroups. Those people have really thought about this. So that was fun for me.\\n \\nI started out at Schering-Plough, \\na pharmaceutical company in \\nNew Jersey, where statisticians \\nwere divided into preclinical and \\na clinical side. I started in the \\npreclinical group at Schering-\\nPlough, which was statistical \\nconsulting for the scientists \\nresearching new treatments. That was the role. So it was very open-ended and some of \\nit was interesting. This was when gene microarray technology was first getting started. \\nThey had acquired a microarray company and there was some interesting data there.\\n \\nThe stuff didn’t work very well. The errors were huge and they needed some statisticians \\nto work it out. They may not have been aware of this, but they needed statisticians to \\nestimate the signal-to-noise ratio. There was a lot of explaining of t-tests to scientists \\nas well. It was a mixture of things.\\n \\nThe clinical side had way more statisticians, since it was all about the design of clinical \\ntrials that would ultimately end up as submissions to the FDA. That was the more serious \\nside of the business. The research scientists could get along without us to a large degree. \\nHowever, doing analysis that ends up as an FDA submission was a pretty big deal.\\nPharmaceuticals is such a heavily regulated \\nindustry. It’s not just about creatively doing \\nthe best analysis you can give. It’s doing the \\nbest analysis you can do within the constraints \\nof the regulations.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 221}, page_content='MICHAEL HOCHSTER\\n217\\nPharmaceuticals is such a heavily regulated industry. It’s not just about creatively \\ndoing the best analysis you can give. It’s doing the best analysis you can do within the \\nconstraints of the regulations. Some really clever Bayesian thing isn’t going to fly.\\n \\nThe thing that was a little bit unappealing about it was it can have a bit of a lawyerish \\nflavor. Yes, you are trying to do the best analysis. But it’s not like your employers don’t \\ncare which way it comes out. It’s almost impossible not to look at it as finding the best \\nstatistical case.\\n \\nThe methodology requires that it be rigorous in some sense. But there’s always a funny \\nspace of choosing what analysis to do and convincing yourself what’s the best.\\n \\nSo with that experience in hand, were you motivated to transition to the tech \\nindustry in the late 1990s when technology was becoming big?\\n \\nThat’s exactly what happened. I switched from Schering-Plough in 2000, which is when \\nthe web had arrived and it was the first dot-com boom. I was living in New York City \\nand had an opportunity to work at this dot-com start up in the city. I got on board with \\nthat and I started working for a company that was basically doing customer satisfaction \\nsurveys on the web. So I ended up having an analytical role. It was a startup that had \\nbeen acquired by a larger company so it wasn’t exactly a startup. That’s how I got started \\nin technology.\\n \\nWhat data questions were you asking at these web companies? What was the \\nnature of the analysis?\\n \\nThe idea was to do quick, popup customer satisfaction surveys that would be lightweight \\nenough so that people were willing to fill them out, so you could get a decent response \\nrate. That was the idea, rather than having an extensive survey where you would have to \\ngive people a lot of incentive to do it, and then have to deal with all the biases that you \\nincur by doing that. The goal was, you have a website that wants to know how it’s doing \\nand so it wants to ask its users some questions. This still exists today.\\n \\nWhat was interesting was doing some analysis such as which features of a website are \\ndriving overall satisfaction on the website. That’s an example of a question. The design \\nthat they had was each customer had a large set of questions and then to make the survey \\nshort, they’d take a short sample of the questions. So you’d have a list of 50 questions, \\nbut you’d only ask each user 5 of them.\\n \\nThen you have some data that’s massively missing, a survey that’s only one-tenth \\ncomplete for each user. Then you want to do some analysis with that data, where every \\nrow is mostly missing.\\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 222}, page_content='MICHAEL HOCHSTER\\n218\\nSo it’s a cool problem. There are also a few interesting methodological questions about \\nthe right way to do this sampling. One is how to make the popup random, whatever that \\nmeans. There was a lot of writing SQL and trying to keep the lights on as well. It wasn’t \\na huge fraction of methodologically sexy work but it was fun.\\n \\nIt’s very hard to answer these questions, but the goal was to get answers to questions \\nlike, “Which aspects of the site did customers get the most satisfaction from? ” So you’ve \\ngot a few problems here, one of which is that it’s all correlation. For instance, customer \\nsatisfaction appears to be highly correlated with appearance, but that’s because good-\\nlooking sites are also the most satisfying in other ways. So it’s not that if every crap site \\nmade itself look better then it would be more satisfying.\\n \\nDid any of your experience in grad school carry over to this area? Or were you \\nlearning on the fly?\\n \\nMost of the time the advanced stuff I learned at school did not directly apply in any of \\nmy jobs because most of the math I learned at school was very specialized. But in the first \\ncouple of years you get some understanding of how things like regression work. Then \\nwhen you come to a problem where you have missing data in every row you think, “ If I \\nwant to do linear regression that only depends on the first two moments of everything, I can \\nestimate those fairly well. Because it’s balanced in a particular way. If I just fit the regression \\nusing the first two moments of everything that might actually work, and not be too biased… \\nAnd well if the covariance matrix isn’t positive-definite then maybe I can fix that up.”\\n \\nSo there’s a little bit of basic math \\nthat you learn that gives you the \\nfoundations to feel comfortable \\nwhen you hit something strange. In \\nall these situations you’re always \\nhitting problems that are slightly \\nweird. In any real life work experience, you never hit anything that’s just a textbook \\nproblem. It always has some weird aspect. The more advanced your education and the \\nmore work experience you have, the more comfortable you are about hitting something \\nweird and figuring out how to adapt what you know.\\n \\nYou did metric design at several different companies including Google. Based on \\nthe different things you’ve seen, how do you approach the problem of metric \\nmeasuring and also experimental design and knowing what to collect?\\n \\nThat’s a pretty big question. Let’s take that one piece at a time. I’ll just make one point \\nabout experimental design which I think is a subtle point. Doing A/B testing is actually \\nreally hard to do well. One thing I learned at Google is you get huge value when you’re \\nIn any real life work experience, you never \\nhit anything that’s just a textbook problem. It \\nalways has some weird aspect.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 223}, page_content='MICHAEL HOCHSTER\\n219\\ntesting something if you can isolate the effect of your test as much as possible. So for \\nexample, if you’re making a change to Google’s ranking algorithm and you want to \\nevaluate it, and that change only affects a small number of queries, you need to look at \\nthe queries that are going to be affected. You may not know which those are in advance, \\nbut you have to focus on those, otherwise you’re not going to be able to see anything \\nsmall if you pull a random sample of queries.\\n \\nThat sounds obvious, but it’s not. Without being too specific, I’ll say that it has not \\nalways been done, that approach has not always been taken. But the whole notion of \\nisolating the treatment effect — that has a lot of ramifications that get complicated.\\n \\nFor example, you think it’s straightforward. You just want to compare A with B. Treatment \\nversus control, it’s very straightforward. Treatment on one side, control on the other and \\nonce you figure out your success metric and you measure both sides, you’re finished.\\n \\nYou can do that. But you might end up with a very noisy comparison if you do that — if \\nthe treatment is only targeted to a low number of samples. What you really want to do is \\ncompare those subjects that were exposed to the treatment, that were affected, to those \\nin the control group who would have been affected by the treatment.\\n \\nSo this counterfactual comparison is what you are really interested in. Because it means \\nthat if you’re doing things the right way, you need to be logging on the control side \\nwhether each subject would have been exposed to the treatment. This means that you \\ncan’t just use your standard production, unless your standard production involves \\nlogging counterfactually what treatments would have accomplished.\\n \\nIt’s often not so obvious how to identify, in the control, whether they would have received \\nthe treatment. So I’ve seen that people usually ignore this. That’s what I would have \\ndone starting out, it’s only because I’ve worked through these problems at Google that I \\nrealized we’re not seeing anything because we’re comparing the whole treatment to the \\nwhole control. It’s just swamped in noise.\\n \\nThis has been a running theme for me, trying to hammer home this point. There are a lot \\nof cases, even at Google (where experimentation is an extremely well-oiled machine), \\nwhere this kind of thinking is not carried as far as it could be.\\n \\nHow did you balance the theoretical rigor you were coming in with, given your \\nacademic training, with the practical demands of actually applying statistics in an \\nindustry setting? Were there tradeoffs you had to make?\\n \\nThat’s definitely a constant challenge. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 224}, page_content='MICHAEL HOCHSTER\\n220\\nThere’s a more basic thing, especially where there’s a division between engineering and \\nanalysis — then who decides what gets logged? From what I say it’s clear it matters a lot \\nwhat’s logged. You may need to log a lot of things to do it correctly and it might not be \\nobvious that the company needs to log it.\\n \\nThus, even if you want to do the basics, you ask engineering to do some work that’s not \\nvery interesting and a pain. There’s a reaction of, “ Really? I have to log that? Explain to \\nme why I need to do this.”\\n \\nThe more nuanced the reason, the harder it is to do. It’s hard to demonstrate the value of \\nit until it’s already in place and then you can say, “Look at this analysis that we were able \\nto do.” It’s 100x more informative than it would have been if you hadn’t done this extra \\nlogging. So yes, it’s a challenge.\\n \\nThe closer and better-aligned engineering and analysis is, the less friction you get.\\n \\nIt seems that analysis spans many different domains of the company. Not only do \\nyou have to work with engineering, but also once you update your analysis then \\nyou need to show it to someone who will act on it.\\n \\nI do think the communication needs of the data scientist role is one of the most important \\nthings. When I’m hiring, there are always some trade-offs between different skills, but \\nthe ability to communicate well is a given. Because it’s important in so many ways, \\nboth in negotiations with other teams and making your analysis have an impact on the \\norganization. You have to be able to talk to people and explain why it matters.\\n \\nThere are people who are good at \\nanalysis and people who are good at \\nwriting code. For some of these people, \\nthere’s such a strong temptation to \\npresent things as, “ I did this, and then I \\ndid this, and then I did this. And then I did \\nthis really smart thing and here are the \\nresults after I did all these really smart things.”\\n \\nNo one gives a shit about that. No one really cares how smart you are. This is why it’s \\ndifferent from graduate school. The subtext of “ I’m smart ” doesn’t matter anywhere \\noutside of graduate school. You have to start with: Here’s what I found and why you should \\ncare about it.\\n \\nSeeing as you’ve worked intensely with understanding metrics at numerous \\nThe subtext of “I’m smart” doesn’t matter \\nanywhere outside of graduate school. \\nYou have to start with: Here’s what I \\nfound and why you should care about it.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 225}, page_content='MICHAEL HOCHSTER\\n221\\ncompanies over the past few years, what have been some of your important \\ntakeaways?\\n \\nI have two main things to say about metrics.\\n \\nFirst, there are two very different angles of looking at metrics. There’s the overall \\nevaluation criterion idea, where you think of a metric that everybody agrees represents \\nprogress. Then you focus all your efforts on improving that metric with the understanding \\nthat this is our understanding of when progress is made.\\n \\nSo when I worked at Microsoft, this philosophy was very strongly advocated. “This is our \\noverall evaluation criterion, you have to move this. I’m sorry but if you can’t move this \\nthen it isn’t worth shipping. Too bad.”\\n \\nMy philosophy of metrics is almost the opposite of this. I think overall the evaluation \\ncriterion is good — you want something you can track. You want to have a number you \\ncan believe in that represents the overall health of your product. But generally, anything \\nthat’s accepted as the driving metric in this philosophy is going to be too broad and you’re \\nnot going to be able to move it. So you really have to make a conceptual distinction in \\nmy opinion between approximate metrics — that you use to decide whether a feature \\nis good, and which are going to be very fine-grained and specific to your feature — and \\nthese overall global metrics that you hope go up.\\nIt depends a little bit if you’re in a business that depends on small improvements or \\nwhether you’re at a stage where you’re making many big improvements. For example, in \\nGoogle search many of the improvements were small. If you’re improving the ranking, \\nit’s small. If you restrict yourself to these broad metrics you can never ship anything \\nbecause they don’t register on the global metrics.\\nOne example of a broad metric is searches per unique user. Using that you can do \\nsomething to ranking and your search engine gets better so people might use it more. \\nBut that’s really hard; you’re not going to be able to see that in most experiments.\\n \\nSo I am very big on thinking very hard about what a particular feature is trying to \\naccomplish, and how we can measure that as narrowly as possible. It’s good to have a \\nsmall number of metrics, but for shipping you want something that measures as closely \\nas possible the positive impact you expect that feature to have, and not think of it as an \\noverall evaluation criterion. So my philosophy is the opposite of what I saw at Microsoft.\\n \\nThe second thing about metrics is that you don’t have metrics on the metrics. You never \\nreally know what a good metric is. So you spend a lot of intellectual cycles trying to \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 226}, page_content='MICHAEL HOCHSTER\\n222\\ndevelop things that are useful. And these things are being used as a yardstick for other \\nthings. So you never have clear guidance about whether your metrics themselves are any \\ngood.\\n \\nIt comes back to getting a new metric established. How do you do that? You have to \\nlawyer it again. That’s tough. How do you do that? How do you go about convincing \\nyourself that a metric is good? And how do you go about selling it or convincing other \\npeople that it’s good?\\n \\nIt’s really hard. A lot of the time, at least in the domains I’ve worked in, you’re interested \\nin “is a particular feature good?” Or, “Is a particular change to a website good?” You \\ndon’t have access to seeing the electrodes in users’ brains to know if it’s good or not, so \\nyou end up inferring what’s a positive impact from behavioral data. While there are all \\nsorts of things you can do to try and quantify user behavior, the issue is that you never \\nreally have absolute truth about what’s good.\\n \\nSo one possibility is to try a lot of things that seem plausible. You don’t have absolute \\ntruth but you have correlation: lots of plausible approaches that seem to point in the \\nsame direction.\\n \\nIt’s not logically guaranteed, but if you start with some plausible things, a lot of them \\nmove together. Some seem much cleaner than the others. That’s how you proceed. \\nIt could be something else that’s making all these things move together, but it’s also \\nplausible that there’s underlying goodness that’s driving them all. So I start to believe \\nthat.\\n \\nThe other way, that’s somewhat of an empirical approach. You observe different possible \\nthings and the fact that they’ve all moved together gives you some interactive evidence \\nthat they’re all doing something reasonable.\\n \\nThis is a really good point. Could tell a brief story about one of these instances? I \\nunderstand the lesson in the general case, but, what was one thing that you tried \\nto measure that was hard to get at, and what were some things that you designed \\nto tackle this problem?\\n \\nI’m going to go back to the example of search. \\nLet’s say you want to use clicks on a search as a measure of accuracy of search results. \\nWell, a lot of that is based on a “more-clicks-is-better” principle — you start thinking \\nabout when more clicks are better. If I have a query, “What is the capital of Albania” \\nand I have a lot of clicks on that query, is that a good thing? Probably not. But if I have a \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 227}, page_content='MICHAEL HOCHSTER\\n223\\nquery such as “Best digital camera” and I have a lot of clicks for that kind of query, that \\nprobably is a good thing.\\n \\nFirst you take a proposal for a metric. Even without looking at any data, you start \\nthinking about under what circumstances the metric could point the opposite way that \\nit’s supposed to. Then you get some ideas; you see there are some major cases where \\nthe metric points the wrong way. Maybe we need some segmentation. Maybe there is no \\nsimple metric that is going to cover everything; maybe we have to consider navigational \\nqueries and more browsing queries separately to have any behavioral metric that makes \\nsense.\\n \\nYou can convince yourself by introspection. The story also becomes more convincing \\nwhen you observe how this new segmented metric compares in practice to just counting \\nclicks. Neither of those things is entirely satisfying. Because your empirical stuff isn’t \\nconclusive, your empirical evidence is never conclusive. Your thought experiments are \\njust thought experiments. So it’s not math. It’s not science.\\n \\nThis sounds like a deep distinction between academia and industry. How has \\nindustry changed your view of math?\\n \\nI still like doing math puzzles for fun. I still think math is beautiful. But in terms of when \\nI think about math as something on the job for me, I don’t consider myself any kind of \\nmathematician. It’s just there, it’s a tool.\\n \\nI’ll say something a little broader than that: math is just there as something that will help \\nme figure out my problem. I feel the same way about all the machinery of data science.\\n \\nFor me it’s the actual substantive questions. For me, there’s data, there are interesting \\nquestions. I want to answer the questions. There are interesting products you can make \\nthat require the data to be big and that’s cool. But the big data per se isn’t interesting. \\nMaybe I’ve been spoiled a little bit at Google where you have this massive infrastructure \\nand you don’t need to think about it that much. You just write a script and send it off and \\nGoogle’s massive infrastructure processes it, and you get your answer back.\\n \\nLet’s talk about your view on data science. How do you see the term, and the \\ndivision within the roles in the field?\\n \\nIt’s a good question. I think I will probably say something similar to what Pete Skomoroch \\nsays, although I’m pretty much all the way type A. For me, a type A data scientist is about \\nAnalysis. B is for Building. Of course there’s no dividing line between those things. A lot \\nof people do some of both.\\n \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 228}, page_content='MICHAEL HOCHSTER\\n224\\nAt LinkedIn, it’s divided up that way. There’s a team called Decision Sciences. They \\nare focused more, but not exclusively, on analysis, working with product teams, \\nexperimentation, some model building. But for the most part it’s far from putting stuff \\ninto production.\\n \\nAnd then there’s the data products team which uses data science techniques to build \\nthings. So I think that’s a reasonable distinction to make.\\n \\nSo why even have this term “data science”? What’s new here? Why don’t we just call type \\nthe A data science a “Statistician” and type B something else? Well, I do think there’s a \\nlittle bit more to say than just that. \\nThere’s a lot of practical work with data that is not covered, and it’s totally different \\nfrom the statistics curriculum. I’m talking about all the practicalities of data, all the \\nvisualization, the critical aspect of it and the communication piece that we talked about \\nearlier.\\n \\nStatistics as a field has focused itself very narrowly as a field on producing certain artifacts: \\nconfidence intervals, hypothesis tests, p-values etc. These are the work products of the \\nstatistician. In the pharmaceutical industry, that’s what it is. You have a report but at the \\nend of the day you’re saying, “Here’s my p-value and it’s less than .05.”\\n \\nHowever, for data science, there is so much more to it than that. Although I have to admit \\nthe term “data scientist” took me a while to get used to. I was a late adopter. I laughed when \\nmy friend sent me this meme that said: “Data scientist, is that like a hammer carpenter?” I \\nthought that was funny. But \\nI accept it now as a term that \\nencompasses much more \\nthan statistics.\\n \\nI think that the type B data \\nscientist — the data engineer \\n— I think that’s a reasonable \\ndistinction to make. It really amounts to: these people all have some mix of statistics \\nand analysis skills and coding. And then you can make a continuum or you can say you’re \\nmostly stats or you’re mostly engineering. Josh Wills defines a data scientist as someone \\nwho’s a better coder than every statistician and a better statistician than every coder.\\n \\nTo me there’s probably no-one in that category. At Google, the really strong coders who \\nknow a lot of statistics are software engineers. They don’t have a special title. They’re just \\nsoftware engineers who know a lot about machine learning. They might call themselves \\nI laughed when my friend sent me this meme that said: \\n“Data scientist, is that like a hammer carpenter?” I \\nthought that was funny. But I accept it now as a term \\nthat encompasses much more than statistics.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 229}, page_content='MICHAEL HOCHSTER\\n225\\na data scientist to get a job. I can see that point of view.\\n \\nSometimes you get people who are quite good coders, but they’re not all the way to being \\na software engineer. But they know a lot of machine learning. So they can implement \\nprototypes, but not all the way to production. That I think becomes a tricky place for \\ndata scientists because you’re in between things. But I still consider it to be a useful \\ndesignation.\\n \\nWith that designation in mind, when you are trying to hire people who are coming \\nout of school right now, what are the features you’re looking for? And then more \\ngenerally, how do you think when you’re building a data science team? What goes \\ninto that composition?\\n \\nI’m not sure I can answer the second question that well, since it depends on what you’re \\ntrying to do. At LinkedIn, I’m not exactly the person who built the team. I came into a \\nteam that was already there. When I think about hiring, I want people who can code \\nsomewhat, although I myself am not a particularly good coder. But we’re more focused \\non analysis. So when I’m looking for people, the most important qualities that a data \\nscientist should have include having a feeling of how to take a data set and answer a \\nquestion with it. Figuring out what should I compare? What’s the control? What’s the \\nway of transforming the things that I have available to me to make it reasonable? What \\nam I missing here that I need to go and collect?\\n \\nThis isn’t stuff you learn in school. Some people have it; it comes from experience too. It \\ndefinitely comes from working with data. So I look for people who have real experience \\nwith data – whether it’s in a hard science, a social science, computer science, or statistics. \\nJust understanding theory isn’t enough. You need data sense.\\n \\nI’m also really looking for the ability to \\ncommunicate well about things you’ve done, and \\ngood judgment. Understanding that when you’re \\nworking through a problem you have a series \\nof choices to make and being very aware of the \\nchoices you’re making and why you’re making them at every stage. That’s part of data \\nsense too. So these are somewhat intangible factors.\\n \\nI also look for some facility with coding — you need to be able to get your data and \\nmanipulate it. Therefore coding is required. I myself don’t look for super-heavy coding \\nskills because I feel like a lot things in my world have to be picked up. Also, I can’t \\nevaluate it myself when I talk to people.\\n \\nJust understanding theory isn’t \\nenough. You need data sense.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 230}, page_content='MICHAEL HOCHSTER\\n226\\nThen, the more formal statistical inference is the last thing that I look for. Not that it’s \\nunimportant, but it is probably last.\\n \\nFrom what you’ve said, it seems that what’s most important is to have real life \\nexperience working with data.\\n \\nNot everyone who has worked with data gets the data sense that I’m trying to pick out. \\nBut working with real data seems to help with that. It’s one of the factors.\\n \\nI spent so many years at Google inventing and asking people math brainteaser questions, \\nwhich is basically a “How smart are you?” type of gauge. I’ve totally given up on that stuff, \\nbecause although it measures something — people who can do all those things, they \\ntend to be smart people — there’s a job opening that I have and I don’t think an ability \\nto answer these questions is that strongly correlated with being able to do the job well.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 231}, page_content='KUNAL PUNERA Co-Founder/CTO at Bento Labs\\nLet’s start with where you are and where you came from. Starting from undergrad, \\nwhat was your journey? Why did you go into data?\\n \\nI did my undergraduate work in computer science in India. During that period I was \\nmore of a hacker, building things without being too worried about the theoretical side. \\nAt some point, towards the end of my undergraduate studies, I received all these offers \\nto work for some software companies and to just hack on things. I didn’t quite know \\nmuch about the Master’s or Ph.D. programs in other parts of the world. Then, one of \\nmy close friends was accepted into a Ph.D. program in the U.S., and I started hearing \\nthe vocabulary surrounding graduate schools in the U.S., GRE scores, the application \\nprocess, etc. That’s when I started considering the possibility of studying further.\\n \\nI was not really sure at first if I wanted to pursue further studies. So after finishing my \\nundergraduate studies, I took a year off from the software companies to work with a \\nprofessor and helping with his research; if I was going to commit many years of my life \\nto research, I wanted to first see if I would enjoy the work. And what I discovered was \\nthat I loved it. I loved research just as much as I loved ad hoc hacking. The professor, Dr. \\nSoumen Chakrabarti, and I wrote a couple of papers on data mining that ended up being \\npublished at the 2002 World Wide Web conference.  \\n \\nKunal Punera started hacking on computers at an early age \\nin India. Inspired by the way Google transformed internet \\nsearch through indexing and information retrieval, he \\ncame to the United States to do his PhD in data mining \\nand machine learning at UT Austin. \\nAfter for years at Yahoo Research working on diverse data \\nproblems, he joined Customer Relationship Management \\n(CRM) startup RelateIQ, as their fourth engineer and first \\ndata scientist. At RelateIQ, Kunal built the data mining \\nsystem from scratch — as well as many of the data products \\ndeployed.\\nRecently, Kunal recently left RelateIQ to start his own company, Bento Labs. RelateIQ was \\nacquired by Salesforce for $380M. In this interview, Kunal shares his experiences bridging \\nfrom research to data science, thoughtful lessons about data science engineering, and the \\nimportance of tool making. \\nData Mining, Data Products, and Entrepreneurship\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 232}, page_content='KUNAL PUNERA\\n228\\nThe way I got started on data mining was coincidental. From my hacking experience, \\nI was interested in databases and operating systems, but Soumen told me that OS and \\nDB research was already pretty mature, and that there was a new field of research that \\ninvolved combining artificial intelligence and data that he needed help with, so that is \\nhow I started working on data mining problems. Some of the first projects I worked on \\nwere on web mining and machine learning for the Web. I enjoyed thinking about those \\nproblems and really got into them. There was a sense that I could have a tangible effect \\non the lives of users through my research, which was pretty exciting.\\n \\nTo provide some context, this was back in 2001 and I had just discovered Google. It \\nprovided a real life example of “what data mining can accomplish.” The other search \\nengine at the time, AltaVista, was not nearly as strong as Google. You could clearly see \\nthe difference in search quality. This was one of the first times that I saw how data \\nmining could make a huge difference in the way people live their day-to-day lives, how \\nthey accessed information, and how they behaved online.\\n \\nAfter working with Soumen \\nfor a year, I applied and was \\naccepted into graduate school \\nat the University of Texas \\n(UT-Austin). My Ph.D. advisor \\nthere, Dr. Joydeep Ghosh, gave \\nme a lot of space to explore \\nvarious problems in data \\nmining and machine learning. \\nIt took me a little while to get \\ninto the academic mindset – I spent my first 2-3 years exploring the new country, with \\nroad trips across the U.S., and weeks spent in national parks. I also spent a lot of time at \\ninternships at industrial labs – IBM Almaden and Yahoo! Research. I finally got serious \\nabout research in my third year as a graduate student, and did some good work in my \\nfourth and fifth years to wrap up my Ph.D.\\n \\nWhat was your Ph.D. in?\\n \\nTopics in machine learning and data mining. The topic specifically was classification in \\nthe presence of structure in data. If you have structure in the data, could you use that \\nto make learning algorithms better by enforcing constraints? I was very motivated by \\nreal world problems. My last two years of Ph.D. were funded by Yahoo! so the problems \\nI tackled tended to be rooted in challenges Yahoo! was facing at the time: searching and \\nindexing, classifying web pages, and trying to model user preferences and behavior. I \\nsolved a bunch of real world problems, and the thing I found in common between the \\nThis was back in 2001 and I had just discovered \\nGoogle. It provided a real life example of “what \\ndata mining can accomplish....This was one of the \\nfirst times that I saw how data mining could make \\na huge difference in the way people live their day-\\nto-day lives, how they accessed information, and \\nhow they behaved online.”\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 233}, page_content='KUNAL PUNERA\\n229\\ndifferent solutions was that they always exploited the structure in the data – websites \\nare hierarchical structures, web pages as well, and people’s browsing could be modeled \\nas Directed Acyclic Graphs (DAGs).\\n \\nIn reflection, my Ph.D. thesis topic came about more from figuring out a common thread \\nin the different problems I worked on, as opposed to having a particular research agenda \\nand pursuing it. That’s been my approach to research since my Ph.D. as well. I don’t have \\na specific agenda or an area that I’d like to advance. I don’t really feel like pushing any \\none particular technology.  All I want to do is solve hard and interesting problems. After \\nmy Ph.D., I took a full-time position at Yahoo! Research which, in those days, was almost \\nan academic organization. It was basically a university department without the teaching \\nload. It was perfect because I basically went from being a graduate student to a similar \\nplace, but was paid significantly more. Plus, they had the benefit of having an immense \\namount of data as well as great infrastructure to work with.\\n \\nWhat kind of problems were you solving there? Were they motivated by Yahoo! \\nuser-facing business?   \\n \\nAt Yahoo! Research, we had a pretty open \\ncharter to help direct our work. 50% of our \\ntime was to be spent making an impact for \\nYahoo! and the remaining half could be \\nspent working on research problems that \\nmay not have much to do with the immediate \\nneeds of the company. That was an amazing \\nexperience because I got to touch pretty much \\nany problem I wanted to. Since I could code as \\nwell as do research, I got to work on a lot of different data mining problems – including \\ndesigning better CAPTCHAs, email spam detection, phishing detection, search engine \\nranking, targeting for the advertising systems, and new approaches to user modeling. \\nI spent four years at Yahoo! Research and worked on a wide variety of projects ranging \\nfrom short-term ones (3-6 months) to some engagements that lasted years.\\n \\nDid you focus mostly on the research aspect of coding, or did you also deploy your \\nresearch, such as spam filters, in production?\\n \\nResearch scientists at Yahoo! were judged based not only on the amount of internal \\nimpact that we had, but also on the number of research papers we wrote, the number \\nof external talks we gave, etc. Typically, Yahoo! Research did not own the projects I was \\nworking on, and so I had to work closely with the products teams responsible for them. \\nGiven the nature of the engagement, naturally, the product teams were hesitant to have \\nI don’t have a specific agenda or an \\narea that I’d like to advance. I don’t \\nreally feel like pushing any one \\nparticular technology.  All I want \\nto do is solve hard and interesting \\nproblems.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 234}, page_content='KUNAL PUNERA\\n230\\nresearchers make direct changes to the code base; the products teams had a focused \\nagenda while I had a broader agenda and different responsibilities. But I had a strong \\ndevelopment background and wanted to build/optimize the systems end-to-end, and \\ntherefore, I felt a little frustrated.\\n \\nAlso, after years in research, I realized that academic careers require one to be an expert \\nin a specific, narrow area. There’s a lot of pressure to become an expert at one thing, \\nso everyone would know Kunal Punera is an expert at so-and-so. My research agenda \\nhas always been “show me an interesting problem and I will work towards solving it.” \\nOver my four years at Yahoo! I moved across a lot of different types of problems and \\ndomains, ranking problems in search and ads to adversarial data mining in mail spam \\nand CAPTCHAs. That doesn’t mesh very well with how academia expects publications \\nand careers to progress. Eventually, I realized that a purely academic career wouldn’t \\nsustain my interest enough. Moreover, outside Yahoo! I was watching the emergence of \\nthese interesting companies that are using data to solve important problems for people, \\nand I really wanted to get involved with that.\\n \\nAt some point, I started \\nconsidering leaving Yahoo!, and \\nmaybe starting my own company. \\nDuring this process I realized that \\nI had been away from software \\ndevelopment for too long. During \\nthe five years of my Ph.D. work \\nand four years at Yahoo! Research, \\nI had written a lot of code, but code written for research doesn’t have to be production-\\nquality; it doesn’t have to be maintainable, it isn’t typically changed by anyone else. \\nAlso, the whole world of web development had undergone considerable change since \\nthe time I had been writing systems in cgi-perl. You probably don’t even know what that \\nis — it was the precursor to the modem web application frameworks. I realized that I had \\nto update my knowledge about software development, especially when it came to using \\nthe open source stack.\\n \\nSo I realized that I had much to learn before I could start my own company, and that I \\nwouldn’t be able to do it while at Yahoo! I had to go work at a place that would appreciate \\nthe fact that I had a very strong research background, but would give me the opportunity \\nto learn stuff beyond data mining, and RelateIQ fell right in the sweet spot. The match \\nwas amazing. The founders were interested in building a company that solved key pain \\npoints around relationship management using cutting-edge data mining. Furthermore, \\nsince I was to be the fourth engineer, I would have to build everything from scratch on \\nmy own, and consequently, would learn a lot from the experience.\\n \\nMoreover, outside Yahoo! I was watching the \\nemergence of these interesting companies that \\nare using data to solve important problems \\nfor people, and I really wanted to get involved \\nwith that.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 235}, page_content='KUNAL PUNERA\\n231\\nI spent two years at RelateIQ. I worked on building the data mining system from scratch \\n— and by the time I left I had built most of the data products deployed in RelateIQ. And \\nin the process I learnt a hell of a lot.  \\n \\nWow! How did you learn all of this on the job, and on the fly?\\n \\nMy data mining background was very \\ndeep and broad, so I didn’t really have \\nto learn any of the learning algorithms \\nor approaches on the fly. I picked up \\nNatural Language Processing (NLP) \\nas needed, but once you have a decent \\nstatistical modeling background, \\nthe rest of machine learning is just \\nvariations of the same thing. Those \\nwere not an issue. But, software development skills were something I had to learn a \\nlot about. For example, while I was a good coder, it is a different experience to work \\nwith engineers who had worked in production environments their entire careers. So, \\nwhile Maven (for dependency management) was obvious to them, it was new to me. \\nUsing Guice for dependency injection was normal to them, while it was something I was \\npicking up for the first time.\\n \\nDuring my time at RelateIQ, in terms of software engineering, I learnt a lot. Sometimes \\nI feel I didn’t learn nearly enough. [Laughs.] I think there’s a lot more I could have \\nworked on, but whatever I learnt, I learnt well. Whatever I know about machine learning \\nalgorithms, I learnt at Yahoo! Research. Whatever I know about software engineering, I \\nlearnt at RelateIQ.\\n \\nI had come to RelateIQ as a stepping stone to starting something on my own. But as two \\nyears passed, RelateIQ blew up, in the sense that it was doing extremely well. So, there \\nwas a strong temptation to stay because the stock options were going to be worth a lot at \\nsome point. But then I also had some confidence that I could make something valuable \\nof my own in the next few years. I loved the people at RelateIQ, but with a heavy heart, \\nI made a decision to leave. If I hadn’t left now I might never have had a chance to do my \\nown startup.\\n \\nI left RelateIQ to do my own startup. In the last two months, I’ve just been rebuilding \\nmany of the things that had always existed at RelateIQ. I’ve been building a backend \\nand figuring out how to get continuous deployment working, learning how to get the \\ndatabase to perform well — all these things which I didn’t have to do before. It’s been \\ninteresting.\\n \\nI spent two years at RelateIQ. I worked \\non building the data mining system from \\nscratch — and by the time I left I had \\nbuilt most of the data products deployed \\nin RelateIQ. And in the process I learnt a \\nhell of a lot.  \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 236}, page_content='KUNAL PUNERA\\n232\\nThat’s amazing. It seems like you’ve systematically identified areas of knowledge \\nyou wanted and found either employment or career opportunities where you could \\ngo and be paid to learn those things. Once you mastered those things, you can go \\nto other things. How did you do that?\\n \\nSilicon Valley is the place where, first of all, there’s a huge demand for the kinds of skills \\nwe have built up. I’m lucky that I’ve chosen to work on something that has a huge demand, \\nand companies are willing to let you learn on the job as long as you can contribute back. \\nRelateIQ, for the entire time I was there, did not have another data scientist, so I had to \\ncarry that whole load, but in return, I learnt a lot. Working in startups is always a give \\nand take, and I think good companies in Silicon Valley understand that the employees \\nthey are trying to hire are, in general, smart, and have their own long-term goals that \\nthey want to pursue. As long as they contribute a lot back to the company — and I like to \\nthink that I did — then the companies help further the goals of the employees.\\n \\nWhen I wanted to leave RelateIQ, \\neveryone, from Adam to Steve \\nto DJ, was very supportive. \\nSteve wanted to introduce me to \\ninvestors. DJ wanted me to come \\nby and get his advice on the \\nnew idea. The environment was \\nextremely supportive. We are \\nvery lucky to live in a business \\nenvironment where companies \\ndon’t even think about locking \\nemployees in. There’s no notion of an employee lock-in. There’s no notion of company \\nlock-in. There’s always flexibility.  Everyone wants to make the best possible use of their \\ntime. We all understand that we’re on Earth for a short time, and we all want to go \\nto a company or work on things which uniquely need us. Silicon Valley is unique, and \\namazing in that way. We’re lucky to be in this situation.\\n \\nBeing able to learn new things really quickly is one of the things we need today \\nmore than ever, but there’s an art to doing that. You need to have some sort of \\nfoundation, core programming skills, core modeling skills. If you were to decompose \\nthose down to the principle skills, what do you feel is most important?\\n \\nIn terms of programming skills, I’m not sure what the curriculum nowadays looks like, \\nbut in my undergraduate days, I started by learning C. Actually, I learnt Pascal first. Then, \\nI learnt C. These are pretty low-level languages with few rules and close interaction \\nwith the machine. So, I learnt from the very beginning how programming languages \\nmanage memory, what pointers are, what an execution stack looks like, etc. I think that \\nOnce you have a decent statistical modeling \\nbackground, the rest of machine learning is just \\nvariations of the same thing. ... But, software \\ndevelopment skills were something I had to \\nlearn a lot about. For example, while I was a \\ngood coder, it is a different experience to work \\nwith engineers who had worked in production \\nenvironments their entire careers.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 237}, page_content='KUNAL PUNERA\\n233\\nexperience was useful because now, if I have to learn new concepts, it’s easy for me to go \\nback and reconstruct them from the first principles in my head.  \\n \\nIn terms of programming, I would \\nthink learning about core programming \\nconcepts is important. You should start \\nlearning from there. I have a feeling that \\nif you started learning programming with \\nJavascript, it might be a little bit more \\ndifficult to know exactly what’s happening \\nin the background. I would encourage one \\nto learn what is happening at a low level, but also to not spend too much time on it. I \\nspent way too many years working with C and C++. Nowadays, I wouldn’t build systems \\nin those languages. Java, Scala, Ruby, Python have amazing framework support, open \\nsource libraries, and lots of solutions documented in sources like Stack Overflow.\\n \\nIn terms of data modeling, I think I was lucky that I took some good statistics courses. \\nIt’s useful to understand the underlying concepts of algorithms. I think a graduate-level \\noptimization course is important, as well.\\n \\nOne of the obstacles I sometimes see engineers running into is confusing the core problem \\nthat needs to be solved and the one particular solution to that problem. Sometimes \\npeople have one way of solving the problem already in their head, and they might not \\nsee that the core problem is not the same thing as their solution. As much as possible, \\nI would encourage people to constantly ask the question “What am I optimizing?” For \\nexample, if you want to obtain a clustering of data, it’s useful to first try to determine what \\nproperties you would want in a good solution, and then attempt to encode these criteria \\ninto a loss function. If one is not careful it is easy to think of clustering data in terms of \\nsteps the algorithm should take, or a series of methods that must be implemented. This \\ncan sometimes lead the engineer astray in that the preconceived solution might never \\nend up obtaining clusters with the desired properties. Of course, the time constraints in \\na startup don’t leave data scientists the luxury of carefully thinking of every problem. In \\nthese situations, experience helps.\\n \\nDo you have any specific examples for that? I know what you’re saying in the \\nabstract but it would be helpful to hear a concrete example.\\n \\nFor example, suppose you want to do classification. Say I have two classes, and I wanted \\nto learn a model that separates them. I can use one of the many algorithms out there: \\ndecision trees, support vector machines (SVM), random forests, etc. But one might come \\nto erroneously think that the classification problem is equal to learning decision trees — \\nwithout completely understanding what underlying problem is being solved.\\n \\nWhatever I know about machine \\nlearning algorithms, I learnt at Yahoo! \\nResearch. Whatever I know about \\nsoftware engineering, I learnt at \\nRelateIQ.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 238}, page_content='KUNAL PUNERA\\n234\\nBefore jumping into implementing a solution, one might want to consider some questions \\nabout  the nature of the problem. The core problem here is that there is a boundary, a \\nseparation between the two classes, that we need to find. Well, what does it mean to find a \\nboundary? What kind of boundaries do decision trees find? And what kind of boundaries \\ndo linear SVMs find? Will using a kernel method help? Is this a situation where I need \\nto worry about irrelevant features? Does that mean I need to regularize via a L 1 norm \\nor stick with L 2? These are fundamental questions that once answered can guide us to \\nthe appropriate approach and thus avoid a lot of  trial and error. Moreover, they help \\nin the following situation: once we have applied the first algorithm and it obtains 65% \\nclassification accuracy, what should we do next to improve the results? Carefully defining \\nthe parameters of the problems \\nand the characteristics of a good \\nsolution help us figure out what \\nthe next step to take is.\\n \\nSometimes when reading Hacker \\nNews, I get a sense that people feel \\nmachine learning is simply about \\ntaking open-source libraries and \\napplying them to data. In many \\ncases, this works okay as the first \\nstep, but, often, the next step to \\nfurther improve the model is difficult to figure out. But if one has a strong understanding \\nof what these libraries are trying to optimize for, what each core algorithm is good for, \\nhow the curse of dimensionality effects learnability, what the difference is between L1 \\nnorm and L2 norm, and other such kinds of things, then it becomes much easier to figure \\nout how best to apply these open source resources.\\n \\nSo is this the set of skills you are looking for when you are interviewing for the data \\nscientist position?\\n \\nWhen I am looking for data scientists, the most important thing I am looking for is \\nwhether their approach to machine learning is systematic. Sometimes I meet people who \\nknow what first step to take, and can do it pretty fast because they’re amazing coders, \\nbut the second step becomes a little harder. When I interview people, I don’t really want \\nthem to solve anything on the whiteboard, I don’t want them to code. The key thing I \\nwant to know is whether they get the underlying principles of what they are building. I’ll \\ntypically ask them about something they’ve previously built and then just delve deeper \\nand deeper into that same problem. I find this is a good way to evaluate candidates \\nbecause if they contributed significantly to the work and know their fundamentals, they \\nwould be able to defend their decisions from first principles and not just say, “Everyone \\nGood companies in Silicon Valley understand \\nthat the employees they are trying to hire \\nare, in general, smart, and have their own \\nlong-term goals that they want to pursue. \\nAs long as they contribute a lot back to the \\ncompany — and I like to think that I did — \\nthen the companies help further the goals of \\nthe employees.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 239}, page_content='KUNAL PUNERA\\n235\\nlikes SVMs so I used it.” They should say, “Well, the problem had the following properties, \\nthat’s why we needed a SVM”. Or “I also tried this other thing. It didn’t work well because \\nI believe... ” as opposed to “I just didn’t try it.”\\n \\nI think that’s a key thing to look for — \\nstrong fundamentals. If someone has \\nstrong fundamentals, but doesn’t know \\nwhat a random forest is, I don’t really \\ncare, because individual machine learning \\napproaches can be easily learnt.  Having \\na strong background and then picking up \\nrandom forests is way easier than having \\njust shallow knowledge of random forests \\nand then trying to debug them. People \\nwho are looking to work with data mining \\nalgorithms should take a systematic \\napproach to learning them. I think it’s difficult to do that nowadays because there’s so \\nmuch demand for the skill set. But I would urge them to get more fundamental skills \\nvia, maybe, a machine learning course which focuses less on the specific algorithms and \\nmore on the fundamentals, and then some core statistics, optimization, and algorithms \\ncourses. These will give them a good foundation for their work.\\n \\nWhen you were trying to build the data science team at RelateIQ, how big was the \\nteam?\\n \\nAt RelateIQ we were not building a data science team. One of the things I’m not fond \\nof is the kind of process I used to follow at Yahoo! Research, where the science team \\nbuilds the models and then passes them off to the engineers to implement or deploy. I \\nfeel like a lot gets lost in the translation. Sometimes the models that one builds assume \\nan environment that doesn’t really exist in production, and one doesn’t know that until \\nthe models are deployed. And in fact, when models get deployed and accuracy lags, it’s \\nvery difficult for engineers who didn’t build the models to convey back what’s exactly \\nhappening.\\n \\nI prefer that the scientists be closely involved in the implementation of the feature \\npipelines and the models in production. They should know how the model is deployed, \\neverything that happens to the data — filters, sampling — before it shows up as input \\ninto the model. If there’s a particular filter which takes out one particular type of data, \\nthe scientists should know about it. Moreover, in the first few months after a model is \\ndeployed, the scientists should be the ones maintaining it.\\n \\nSo, I learnt from the very beginning \\nhow programming languages manage \\nmemory, what pointers are, what \\nan execution stack looks like, etc. \\nI think that experience was useful \\nbecause now, if I have to learn new \\nconcepts, it’s easy for me to go back \\nand reconstruct them from the first \\nprinciples in my head.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 240}, page_content='KUNAL PUNERA\\n236\\nAt RelateIQ, we were following this principle and building a  data products engineering \\nteam. We didn’t call it data science at all. In the data products engineering team, we \\nlooked for people who had a very strong sense of data, who liked playing with data, but \\nalso had reasonable engineering skills so that they could actually touch production code \\ndirectly. We didn’t expect them to roll out their own hadoop infrastructure, though many \\nof our data product engineering people did. But we wanted them to be able to deploy \\ntheir own models, run them, write the feature extractor pipelines, etc. Apart from the \\nprinciple I mentioned earlier, a second reason for building the team this way was more \\npragmatic; we were a small team and we couldn’t spare engineers dedicated to taking \\nthe work done by data scientists to production.\\n \\nIt seems like you not only focused on people who can do data analysis but also on \\nthose who have a strong engineering background, people who started out hacking \\nor coding and then went to data science.\\n \\nI find that you can go both ways: start from \\nthe data side or software development side \\nof things. But in a startup, having people \\nwith both skill sets is critical. One thing that \\nyou never want in a startup is to have a data \\nscientist working alone with no established \\nprocess to get work into production. I’ve \\nseen many startups where data scientists \\nare six months ahead of production \\nsystems; they have done six months of \\nwork that hasn’t been deployed because \\nthe engineers that touch production are \\nbusy with their own work or fires. These \\ndata scientists have done the work in R or matlab and are not able to integrate it with \\nthe production backend system. You don’t want to have that situation.\\n \\nIn a slightly bigger startup, one may want to have small teams of two or three people \\n— one data scientist, one person with engineering system type skills, and one with \\nproduct management type skills — to build and maintain data products. They work as a \\nteam to build features as opposed to a data science person building a model alone, and \\nhoping that one day some engineer is going to step forward and bring those features to \\nproduction.  \\n \\nWhen RelateIQ was small we avoided this situation by having one person perform all \\nthree roles — data scientist, engineer, and product management. Now that we are larger \\nwe are building multi-skilled teams.\\n \\nAt RelateIQ, we were following this \\nprinciple and building a data products \\nengineering team. We didn’t call it \\ndata science at all. In the data products \\nengineering team, we looked for \\npeople who had a very strong sense \\nof data, who liked playing with data, \\nbut also had reasonable engineering \\nskills so that they could actually touch \\nproduction code directly. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 241}, page_content='KUNAL PUNERA\\n237\\nThis is a fantastic example of data science and product done right. You avoided \\nsome of the pitfalls of great, locked up models that you can’t deploy. Were there \\nother things you saw at RelateIQ that you felt were really good lessons in building \\ndata products?\\n \\nOther than the constitution of the team, \\nanother important aspect to keep in mind \\nis the cadence of development of data \\nproducts. Engineering the systems that \\ninvolve data mining is a little different in \\nthe sense that most times it is not clear how \\nmany engineering resources will be needed \\nbefore the models reach production quality, or even whether the desired quality can even \\nbe reached. This may not be a big problem at large companies, but it makes scheduling \\nand resourcing data products tasks problematic when resources are constrained, as in \\na startup. In a startup, one should want to break down data products work such that \\nvisible, measurable progress can be made in two-three weeks so that the engineers have \\nintermediate wins. This also prevents engineers from going too far down the wrong path. \\nOf course, the development cycles need to be long enough so that hard problems can be \\nattempted and solved; very short inflexible cycles typically lead to data products that \\nhave been patched together and are not robust.\\n \\nAnother important aspect relates to scheduling; if you want a data product deployed at \\nany point in time, you probably should give the data engineers a head start so that they \\ndefinitely have their models or features built before the front-end or back-end resources \\nbecome available. This is simply a consequence of the uncertainty around the pace of \\nprogress on data products.\\n \\nFor a long time after I joined RelateIQ, I was the only one working on data products. In \\nthese early days, scheduling was not that much of an issue since I was the only data, \\nbackend, and frontend resource. Moreover, I have a lot of experience with data mining \\nand was able to avoid going down bad paths, and was able to get most models deployed \\nin the first couple of iterations. As the team grew and I had more frontend and backend \\nresources that could help me, we had to work harder on scheduling and we applied the \\nprinciples I outlined earlier.\\n \\nAny other data product hacks from RelateIQ?\\n \\nThe other thing that we did a lot is we took shortcuts. We took shortcuts all over the \\nplace. At the beginning we were in a hurry and we didn’t even know whether the products \\nwould be received well by the users, and so we tried to get away with putting in as many \\nOne thing that you never want in \\na startup is to have a data scientist \\nworking alone with no established \\nprocess to get work into production.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 242}, page_content='KUNAL PUNERA\\n238\\nhacks as possible. We made our decisions on the hacks in this particular way:\\n \\nAnything that was fundamental, core-level, functionality, such the parsing of emails, we \\nmade sure it was extremely strong. There are many reasons why functionality gets put \\ninto this category: in the case of email parsing, first every email has to be parsed and the \\ncost to reparse is very high (I’ll have to go back and fetch every email and reparse it), and \\nsecond, a whole bunch of other features of the data system depend on accurate parsing \\nof email. Therefore, my system for parsing is very strong. It involves nice, sound models \\nbased on CRFs and SVMs that we learnt over large quantities of training data and that \\nare continuously trained as data changes; these models are sound.\\n \\nOther functionalities are higher \\nlevel, such as automatically \\nmaking a suggestion to follow-\\nup with a contact. There are \\nmany questions that need to be \\nanswered here that are difficult \\nto optimize using data since the \\ndegrees of freedom are too high or \\ntraining data is too noisy. When a \\nsuggestion has to be created, the \\nsystem has to determine if a follow-up to an email is warranted, whether the user has \\nalready done the follow-up, how long the system should wait before reminding the user \\nto follow-up, and if multiple users are referenced in the email that the suggestion to \\nfollow-up will be directed to. The dimensionality of this space of choices is so high that \\nthe first attempt to model this should involve using manual rules and hard thresholds.\\n \\nAnother example is trying to learn the effectiveness of our rules for follow-up \\nsuggestions via usage data, and using the feedback if a user rejects the suggestion. Even \\nthis is complicated since rejection is a very aggregate action and it’s not clear what the \\nuser is rejecting; maybe we made a mistake in parsing the email and no suggestion was \\nwarranted or maybe the user liked the suggestion but we made it too early, or the user \\ndoesn’t like the sender of the email, or even the user hates all suggestions in general. So \\neven here I shied away from modeling the entire problem and put in a lot of rules, a lot \\nof very simple models. The first cut solution involved counting the number of rejections \\nand rules for actions to be taken when certain thresholds are met. As the data product \\nimproved we used more advanced approaches to model user feedback.\\n \\nYet another important aspect is tools, and this is something that was driven home to me at \\nRelateIQ. Before working at RelateIQ, I had a very high threshold for tooling. Sometimes \\nI ended up doing the same thing 10 times without automating it because every time I did \\nThe other thing that we did a lot is we took \\nshortcuts. We took shortcuts all over the place. \\nAt the beginning we were in a hurry and we \\ndidn’t even know whether the products would \\nbe received well by the users, and so we tried \\nto get away with putting in as many hacks as \\npossible.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 243}, page_content='KUNAL PUNERA\\n239\\nit, I was not sure I would be doing it again. After RelateIQ I can safely say that if someone \\ndoes something 3 or 4 times, they will be doing it again in the future, so they should \\ntry to automate it; automate data cleaning scripts, automate model deployments, write \\ntools for re-training of models, don’t do it by hand. Write tools that will automatically \\ncreate a fresh data set, retrain the model, check its accuracy, and send you an email if the \\naccuracy is below a threshold, and, if the accuracy is good then deploy the model. This \\ntooling might seem excessive but is going to easily pay for itself in terms of saved time \\nin the long run.\\n \\nWas that a change of pace compared to when you were working in research?\\n \\nWell, I did a lot of work at Yahoo! \\nResearch. I worked on new projects \\nevery 3 to 6 months. I was writing \\nthree to four papers every year \\nand that’s a lot of work. I’m used \\nto working a lot of late hours. At \\nRelateIQ what changed was the emphasis. At Yahoo! Research, the emphasis was always \\non doing something innovative. It was all about asking, “ Last year Microsoft Research \\npublished this. The year before, Google did. What’s the new angle I can find and solve the \\nproblem?” Sometimes the problem being considered was not an immediate concern for \\nYahoo. Other times the problem could be solved using simpler means. At these points, \\nwe would consider more complex versions of the problem with additional hurdles, and \\nthen figure out how to solve them. The goal was to constantly push the envelope of what \\nwas possible with data mining, and not just to solve immediate practical problems. The \\ntask was as much to find new problems as to solve them.\\n \\nAt RelateIQ, I worked extremely hard as well. There, the problem to be solved was pretty \\nclear, and main question facing me was “ What is the minimum effort that I can put forth \\nand get something into the hands of the users so that I can test whether the solution is \\nuseful?” And from that feedback I can figure out how much more effort I want to put into \\nit in the future to improve the feature. Moreover, the solutions I tried out were chosen \\nnot just for their innovativeness, but using a tradeoff between effectiveness and the cost \\nof implementation and future maintenance.\\n \\nSo the main difference from the earlier days of research was not one of pace of work. It \\nwas a change in priorities.\\n \\nHow do you measure cost? Development effort or time?\\n \\nCost in this case involves implementation and future maintenance. In a startup you have \\nYet another important aspect is tools, and this \\nis something that was driven home to me at \\nRelateIQ.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 244}, page_content='KUNAL PUNERA\\n240\\nto constantly trade that off for accuracy of models. If one option is a complex model such \\nas a Conditional Random Field (CRF), but we can come up within 5% of the accuracy using \\na Naïve Bayes model, then we would choose to go with the Naïve Bayes. It is not just that \\nCRF models would be significantly harder to train within a typical project timeline in a \\nstartup, but as the data environment changes in the future, the CRF will break in non-\\nintuitive ways and it won’t be easy to debug. Whereas in the Naïve Bayes model, you can \\nlook at the parameters and try to see what might be happening.\\n \\nA big issue that impacts machine \\nlearning at startups is that \\nmanually labeled training data \\nmight be hard to come by. This \\nis why at RelateIQ a lot of the \\nmodels I had to build involved a \\nlot of manual intervention. I had \\nto be very careful about picking \\nthe right features that, based on my experience, would not cause me to overtrain; \\nbecause I knew my training data was so biased and so limited that I could not rely on \\ncross validation. I had to basically look at each feature and ask, “While using this feature \\ngives me a reduction in test error, what is the chance that this is simply because of the \\nway the data in the training set was selected?”\\n \\nAnother side effect of limited training data is that sometimes it is useful to closely \\nexamine and perhaps manually twiddle the model’s parameters, setting them to values \\n(or signs) that intuitively make sense. This intuition has to be balanced against the \\nparameters coming from the learning algorithms. As in most cases, extensive experience \\nwith learning algorithms in limited data situations helps.\\n \\nYet another impact of limited training data is the high likelihood that the training data \\nis from a different distribution as your deployment data. For example, at the beginning \\nthe startup might have 48 customers, and they are probably all friends of the CEO. The \\nmodels trained on data obtained from these customers are likely to be biased towards \\nthem. However, one year down the line, the startup might have 4,800 customers. If one \\nis not careful, the models created in those early days will fail miserably on the new \\ncustomers a year later.\\n \\nYou said that you’re building out your own tools that you took for granted at \\nRelateIQ. That is really interesting because when you work in data science at a \\ncompany, you have a lot of things that are taken care of for you. Deployment \\nusually is handled by other people as a day job. So how are you approaching that? \\nWhat are you rebuilding, and how do you know how to rebuild it?\\n \\nThere, the problem to be solved was pretty \\nclear, and main question facing me was “What is \\nthe minimum effort that I can put forth and get \\nsomething into the hands of the users so that I \\ncan test whether the solution is useful?”\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 245}, page_content='KUNAL PUNERA\\n241\\nI am playing around with some ideas on mobile, app re-engagement, and advertising.  \\nI am currently implementing the backend part. But since I learnt from RelateIQ that I \\nneed to invest in tools early, I am being careful in designing the backend “properly” from \\nthe very beginning. It plays nicely with my IntelliJ IDE; I am ensuring that I am able to \\nrun it entirely offline. When I push code to GitHub, the remote systems pick the code up, \\nautomatically compile/test it on the server, run the DB migration scripts, automatically \\ndeploy the APIs, etc. If we were to not invest in this now, then I would have to do this \\nentire process manually, every time I deploy some small bug-fix. Moreover, I would \\nprobably make mistakes in the deployment steps (forgetting to migrate the DB) and find \\nbugs that end up being simple deployment errors.\\n \\nHow do I learn all this? Some of this I worked on, but a lot of these technologies were \\njust words that I heard while at RelateIQ. I was working with these extremely talented \\nengineers, and I heard them talk about Docker or Maven or Guice all the time. So when I \\nleft and started working on my own company, I Googled all this stuff. Google, along with \\nsites like Stack Overflow, is a great resource for these things.\\n \\nAnd if all else fails, there’s GChat \\nso I can ping my ex-colleagues \\nwho are friends of mine. These \\nguys have so many years of \\nexperience that even without \\nmy completely describing the \\nsituation, they are able to point \\nme in the right direction. I did the \\nsame thing when I moved to RelateIQ and I was the only data scientist. Since I couldn’t \\ntalk to anyone at RelateIQ about some of the problems I was tackling, I would ping \\nmy friends from Yahoo! Research to ensure that I was thinking about the problem and \\nsolution the right way. In turn I would help them think through data mining problems \\nthey were thinking of. I have been pretty shameless about asking people for help, because \\nfor any topic I am working on, except maybe one or two topics, there is someone out \\nthere who knows it better than me.\\n \\nIf you want to start your own company, you have to build the first version of the product. \\nEventually, you’ll get funding and be able to hire amazing engineers, who are going to \\nscoff at my code and change everything, and I’m okay with that. But in the meantime, I \\nneed to build this. And there’s never been a better time to build things yourself – there \\nare a lot of good tools out there. You can use the Google App Engine for example, and \\nmany aspects of the backend are abstracted away. They have their own version of Task \\nQueue, their own databases. You don’t even know how your data is hosted. I didn’t want \\nto use Google App Engine because it abstracts way too much, and I felt like the lock-in \\nI have been pretty shameless about asking \\npeople for help, because for any topic I am \\nworking on, except maybe one or two topics, \\nthere is someone out there who knows it better \\nthan me.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 246}, page_content='KUNAL PUNERA\\n242\\nmight be rather severe. That’s why I am building the backend from scratch on Digital \\nOcean.\\n \\nThe other reason to build all this myself is that it helps me interview people. [Laughs.]\\n \\nOne day, I will have to interview someone who will help me with DevOps. It is significantly \\nharder to interview someone if I don’t know much about DevOps myself. My advice to \\nanyone who’s thinking of leaving a company and starting their own is that six months \\nbefore you plan to leave, talk to your CTO or your manager. Tell them what your career \\ngoals are, and that you want to do this. Have them put you in situations where you \\ncan learn some of this stuff because there’s nothing better than learning on the job. \\nSomeone’s paying you, and you’re learning while doing work for them. Like I said earlier, \\nSilicon Valley is good at giving you opportunities to learn and extend yourself.\\n \\nWhat are the opportunities you see in data science right now?\\n \\nThere are many different aspects of data \\nscience. One is data analysis, to support \\nbusiness decisions. There is of course a \\nhuge need for data analysts in all sorts \\nof businesses; at RelateIQ we need data \\nscientists to analyze our product usage and \\nSaaS business and suggest ways to improve the product or sales processes. But there is \\nalso a huge opportunity to actually build a layer between these data scientists and the \\ndata. These guys would prefer to use higher-level statistical languages such as R, but \\nthey want their analysis code to run on large-scale data on a distributed set of machines. \\nThere are a bunch of companies looking to provide this interface between the scientists \\nand data, so that they write their analysis in R and don’t have to worry about where it \\nruns, and how it runs. The interface might even contain features that might help data \\nscientists collaborate and make them much more productive. Mode Analytics and Sense \\nare two of the newer companies I have seen in this market.\\n \\nIn terms of products enabled by data mining and machine learning, there are huge \\nopportunities out there. Some are in the usual areas: Digital advertising, Search, and \\nRecommendation systems. There are some mature players in these areas, providing both \\none-off services and platforms, but there is plenty of novel work coming out of startups \\nas well.\\n \\nOne generic area that is seeing a lot of work is in trying to make sense of unstructured data. \\nIn the most straightforward cases, some startups are trying to automatically understand \\nweb pages and construct APIs over their data. However, at an abstract level this is what \\nIf you want to start your own company, \\nyou have to build the first version of \\nthe product. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 247}, page_content='KUNAL PUNERA\\n243\\nRelateIQ is doing as well. RelateIQ is trying to mine people’s communications data and \\ngive them insights about their own data. RelateIQ takes a mix of structured (phone call \\nmetadata) and unstructured information (email texts) and tries to extract structured \\nobjects that are of interest to the user (follow-up suggestions, new phone numbers for \\ncontacts, best connections to use to reach people etc).\\n \\nWhile RelateIQ is mining relationship data sitting within enterprises, there is a huge \\nopportunity to mine all sorts of unstructured data within enterprises and make it useful \\nto them. For example, data within emails, calendars, etc. could be used to help large \\nenterprises grow and maintain their talent; many startups are pursuing this.\\n \\nAnother area where data mining can help is by helping people deal with information \\noverload. Right now there is all this news just flying by me. I always feel like I’m missing \\nout on so much and so I need help consuming this. There are some companies trying to \\nhelp with this, trying to use machine learning to do that. Have you seen Prismatic?\\n \\nI’ve heard of them.\\n \\nI downloaded the app a little while ago, \\nand with some help from me it was able \\nto deliver some relevant stories to me. \\nHowever, it wasn’t quite as relevant as I \\nwould have liked and it wasn’t helping with \\nthe problem of me feeling that I’m missing \\nout on a lot of good content, and, recently, \\nI stopped using the app. Another potential \\nexample is Google that knows so much \\nabout me. If I was an Android user, they would know everything about my mobile use. I \\nuse Chrome, so they know about my browser use. I use Google Docs and Gmail so they \\nhave all my work data as well. I use a search tool heavily, so they have the set of things I \\nam interested in as well. Given all this information, Google is in a position to completely \\npersonalize the web for me. Have you seen the movie “ Her”? Other than the falling-in-\\nlove-with-a-robot part, why is the rest of that movie not a reality?\\n \\nI think the technology to build much of that is already here. The data is siloed so maybe \\nthat’s an issue. Maybe the user appetite to engage with the app in such a personal way is \\nnot there yet. I feel people may not be ready to give up that much control, but I think it \\nis headed there. I think the next big thing is going to be in that vein. The way RelateIQ \\nworks for salespeople, there will be digital services that help regular people live. There’s \\na soccer mom somewhere being driven insane by having to run her household, arrange \\nfor her kids to attend school and various activities, managing events for the entire family \\nGiven all this information, Google is in \\na position to completely personalize \\nthe web for me. Have you seen the \\nmovie “Her”? Other than the falling-\\nin-love-with-a-robot part, why is the \\nrest of that movie not a reality?\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 248}, page_content='KUNAL PUNERA\\n244\\nand interacting with her friends, all at the same time. Why is her phone not figuring all \\nthis out for her — making her life easier for her?\\n \\nA dominant trend in the world is the move towards mobile. A lot of the mobile world \\nright now is replicating what the desktop world did. On the desktop we have websites. \\nAnd so we have a notion of apps on mobile. We used to navigate between websites, often \\nthrough searches. So now we are devising a way to navigate across apps via deeplinks. \\nHowever, it seems to me that my usage of my mobile device is very different from my \\nusage of my laptop. I do most of my information access on my mobile device right \\nnow. I use my laptop for coding and for long-running information searches like buying \\nsomething. It seems like technologies that make my life on the laptop easier may not \\nnecessarily work on mobile devices. I don’t know the answers here yet, but I feel like data \\nmining has a large role to play. This interests me a lot and I am likely going to select a \\nproblem in this space for my startup: a mobile frontend with an intelligent backend.\\n \\nSo there are plenty of huge opportunities; though, I think they are very difficult to predict \\nand quantify.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 249}, page_content='SEAN GOURLEY Co-Founder and CTO at Quid\\nTo start off, can you tell us a little bit more about your background from your early \\ndays to now?\\nFor starters, I’m from New Zealand. Unlike many data scientists, I did not grow up doing \\nhuge amounts of mathematics, but I think this was probably a little bit of a conscious \\ndecision from my parents. When I was five or six years old, I used to stay awake all night \\nunder the bed covers with a flashlight, solving math problems . My parents thought, \\n“He’s probably doing more than enough math, so we don’t need to push him on this \\nskill.” As a result, at school, I never really focused on math. Instead I spent a lot more \\ntime learning psychology, English, politics and philosophy.\\nI enrolled in university as a law student, which I really loved. After a few semesters, I \\nalso realized that law was a lot of hard work, and it was simply easier for me to get the \\nbest grades in math and physics. So after one year of university, I switched out of law and \\nmade the decision that I should focus on what I excelled at. I changed my major, but I \\nmade a deal with myself that if I didn’t like it after a year of studying, I would go back and \\nbecome a lawyer. As it turns out, I loved it so much that I went on to get a PhD in Physics.\\nSo while I had a lot of mathematical abilities at a young age, I wasn’t pushed in that \\ndirection. Instead, I spent a lot of my time learning about law, philosophy, politics \\nand psychology. I truly believe that it gave me a better perspective on the world, \\nthan mathematics alone would have given. Although I didn’t know it at the time, the \\ncombination of physics and politics would allow me to make breakthroughs in a field of \\nmathematics that didn’t yet exist.\\nSean is a physicist, decathlete, political advisor, and TED \\nfellow. He is originally from New Zealand where he ran for \\nnational elected office and helped start New Zealand’s first \\nnanotech company. Sean studied at Oxford as a Rhodes \\nScholar, where he received a PhD for his research on the \\nmathematical patterns that underlie modern war. This \\nresearch has taken him all over the world, from the Pentagon, \\nto the United Nations and Iraq. Previously, Sean worked at \\nNASA on self-repairing nano-circuits and is a two-time New \\nZealand track and field champion. Sean is now based in San \\nFrancisco where he is the co-founder and CTO of Quid, an \\naugmented intelligence company.\\nFrom Modeling War to Augmenting Human Intelligence\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 250}, page_content='SEAN GOURLEY\\n246\\nI immersed myself in the world of physics and loved it. Mostly because it allowed me to ask \\nquestions about the world and come up with testable theories to explain it. With physics, \\nyou can explain why the sky is blue. It’s fascinating to just be able to do something as \\nsimple as that. Once I got in further and started doing nanotechnology and quantum \\nmechanics, I ended up pushing the boundaries of the world we experience. In nanotech, \\nfor example, you become obsessed with explaining the very small. The theories you \\ndevelop start to speak to a world of atoms and electrons. The interactions don’t make \\nsense on a human scale; they’re non-intuitive because you’re not really modeling our \\nhuman world anymore. \\nLikewise, in cosmology, the equations \\nyou build represent systems on a \\ngalactic scale. Again, at the edges \\nof modern physics, you’re modeling \\nworlds that are divorced from the \\neveryday human experience. It’s not \\nreally addressing the big questions \\nthat we face as humans. Questions like: “Why does the financial market move in a way \\nthat allows it to crash massively, while at other times remain stable?” “Why do wars \\nseem to start?” “How do epidemics spread?” “Where do ideas come from and how to they \\nevolve?”\\nThese were the questions about our world that I wanted to answer — and I believed \\nthat the tools and techniques from physics and mathematics might have something to \\ncontribute.\\nIt wasn’t until I got to Oxford, being very lucky to go on a Rhodes scholarship, that I \\nhad the freedom to explore these ideas. I was originally taking my PhD in biomolecular \\nmotors, which, like most physics projects, involved a lot of time spent in the lab. After \\nspending a couple of days in the lab, I thought, “I don’t really want to spend the next five \\nyears in these rooms.” I went looking around to see if there was a branch of physics that \\nwouldn’t involve time in a lab. As it happens, there was a really interesting professor \\nthere who was modeling the dynamics of human interactions, particularly financial \\nmarkets. I asked him if he would take me on as one of his students, and after a bit of \\nconvincing, he said yes.\\nMy supervisor’s name was Neil Johnson. He was a relatively young physicist who was \\nmaking a name for himself by publishing on a range of different topics, from quantum \\ncomputers to statistical physics. I worked with him, getting my initial start in the field, \\nby creating models for financial markets. For me, this felt like home. \\nAlthough I didn’t know it at the time, the \\ncombination of physics and politics would \\nallow me to make breakthroughs in a field \\nof mathematics that didn’t yet exist.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 251}, page_content='SEAN GOURLEY\\n247\\nThe first thing I started researching was the dynamics of ensembles of agents. Or, simply \\nput, what happens when a range of intelligent objects start to interact. We used this agent-\\nbased modeling approach to start to understand the dynamics of financial markets. Not \\nnecessarily to predict where the market was going, but rather, to understand the forces \\nthat are shaping and driving it. The work was pretty novel at the time, but it suffered \\nfrom the limitation that the computer simulations being used to model human behavior \\ncould not capture all the intricacies of our human psychology.\\nThis study raised some interesting thoughts. On one hand, there is the issue that we still \\ndon’t fully understand the complexities of human decision-making. On the other hand, \\nwe’re definitely more predictable than we think we are. What unfolded in the financial \\nworld was that humans got out of the market, and algorithms started trading. The \\nalgorithms looked exactly like our models. We had created pretty accurate simulations \\nof a market of competing non-human algorithms, along with some warnings about \\nvolatility when algorithms dominate a market. This modeling of financial markets led \\nme to my next line of research, and towards modeling the dynamics of insurgency. \\nWar was topical in 2003, as the US had just sent a massive deployment of troops to both \\nIraq and Afghanistan. In 2003, we also saw the information landscape change as we \\nstarted to get data sources, like blogs coming online, where reports of violence would be \\ntransmitted by many different sources, all of which could be read by machines. So not only \\ncould we create virtual models of insurgency, we could tune these models to precisely \\nreplicate the statistical signatures of the data that we were collecting in near real time. \\nAll of this required building machines that would read news and design algorithms that \\nwould extract events from these stories. This was a challenging proposition given the \\nstate of Natural Language Processing technology circa 2003. We used a lot of heuristic \\ntechniques combined with supervised machine learning models. They performed well \\nenough that we were able to assemble a very complete data set of violent events. We \\nanalysed this data set for any statistical patterns and built the agent-based models to \\ndescribe them.\\nYou’ve got everything from data coming in, looking for signals within the noise, building \\nmodels to replicate those dynamics, and being quite at the fringe of physics. In the \\nend, my PhD was in physics, modeling the dynamics of insurgency mixed with some \\nalgorithms, natural language processing, and political dynamics. \\nThat must have been a fascinating topic of study. In 2003, it sounds like it was quite \\nhard to get the data to actually conduct analysis.\\nYou could say that. The data that the U.S. military had was classified and as a foreigner, \\nyou weren’t going to get it or even know if they had it to give. It was this restriction that \\nactually drove us to use alternate data sources in the first place. We didn’t think that our \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 252}, page_content='SEAN GOURLEY\\n248\\nopen-source data was very good at the time. We thought that the classified data must be \\nmuch better. It was funny, the first time at the Pentagon, I said, “Look, I’ve got this data, \\nand this what we’re seeing. If you’ve guys have better data, can I have it now?” After a \\nfew minutes of talking amongst themselves, they came back to me and simply said, “No. \\nYour data is broadly in line with what we have. You don’t need ours.”  \\nAs it turns out, it wasn’t just broadly in line — it was better! That was just crazy!\\nThe idea that through open source \\nintelligence, you can beat the entire US \\nmilitary’s data collection about significant \\nevents in Iraq. When WikiLeaks released \\nthe Iraq significant events database, the \\ninformation was of a lower resolution than the data we had. Data that was already out \\nthere and available to the public if you just had the right algorithms to make sense of it. \\nThis trend of open-source intelligence dominating closed data collection is one we are \\nobserving again and again. We saw it with the financial markets. It used to be, ‘do you \\nknow the price and volume of stocks?’ This was the valuable information. Then, price \\ninformation becomes a commodity. So people switch to making sense of the data with \\nadvanced algorithms. You see this transition from data being valuable to algorithms \\nbeing valuable.\\nI went through all that. It was a challenging few years. I spent time in Iraq, the Pentagon \\nand the United Nations. I had enough war to last me a lifetime.\\nYou mentioned spending time in Iraq. Was this during your PhD?\\nI wasn’t in Iraq during my PhD. I went in 2008, after my PhD, but the events in the UN \\nand the Pentagon were during my PhD. A lot of it was knocking on doors. I was literally \\nin D.C. stating, “I’ve got this equation — all this useful data.”  I just showed it to a couple \\nof people I knew, who helped get me in touch with some of their connections. Over the \\ncourse of a week, I had impressed enough contacts that that I ended up in the Pentagon \\npresenting to four-star generals, the intelligence team from US central command, and \\nthe Iraqi ambassador to the U.S.\\nWhat was the reaction like? How did the folks from the US government respond to \\nyour presentation of your research?\\nI expected two or three people to show up, but instead, I was surrounded by 40 people, \\ncircling one of those classic war room tables that they have in the Pentagon. Reflecting \\nback, I would have prepared a more polished presentation if I had known exactly the \\nYou see this transition from data being \\nvaluable to algorithms being valuable.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 253}, page_content='SEAN GOURLEY\\n249\\nscale of my briefing. There were people who did not fully understand what the data was \\ntelling them, and were opposed to the findings. One of the main points of difference was \\nthat Pentagon analysts were insistent that there were six groups of insurgents in Iraq. \\nSince I could not make any of the mathematical models work with six groups, they simply \\nstated, “This is not how things are done. You don’t know anything about this space.” My \\nrebuttal was that if they didn’t like this theory, what was their theory to explain this \\ndata? They replied, “Our theory wasn’t designed to explain any data,” to which I replied, \\n“How is that even a theory?”\\nIt was as if I was talking to people who spent their whole lives avoiding numbers. They \\nstudied political science, and every decision they made along the way was so they didn’t \\nhave to deal with mathematics or statistics. But there was the small percentage of those in \\nthe room who had spent time on the ground in Iraq, and seen the reality of the situation. \\nWhen they saw the analysis, they understood what the numbers were saying and they \\nagreed, “this explains a lot of what is going on in Iraq.” The Iraqi ambassador to the US, \\nwho luckily had a degree in engineering, was able to see the power of the data driven \\napproach. He said, “It’s like the Wild West out there. There are hundreds of different \\ngroups fighting each other. We can’t just sit down and negotiate a truce when the group \\nmight not even exist tomorrow. The models you have show this.”\\nDid you find any allies amongst those you presented to?\\nYes. People on the ground: the soldiers and the Iraqi government. Those were two big \\nallies because they had the very real challenge of having to navigate this violence on a \\nday-to-day basis. Many of the officers from West Point asked, “What do I do? What does \\nthis mean for me? How do I operationalise this? I’ve got guys on the ground and I don’t \\nwant them harmed. What does this mean for getting them home safely?” You go through \\nthe dynamics with them; tell them what the basic statistical signatures are showing \\nyou, and what the models point to from a strategic perspective. Here is the probability \\nof attack. Here’s how the different insurgent groups coalesce. Here are the signals that \\nsuggest a group is starting to break apart, and operationally, they get it.\\nOn the flip side however, many of the Pentagon analysts weren’t moved. They would \\nstate, “We’ve got game theory.” I replied, “What does game theory mean when you have \\nhundreds of different groups constantly evolving and the estimated half-life of a group \\nis under 6 months? What does that mean for your game theory?” The insurgents don’t \\neven know what’s going on. How are they supposed to take the rational decisions needed \\nfor Game Theoretic models? Game theory is great if you’re in the Cold War and have a \\ngood understanding of your one or two enemies, but these guys are 40 years behind. This \\nis a different war.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 254}, page_content='SEAN GOURLEY\\n250\\nJust as game theory emerged out of the research from the RAND corporation \\ntrying to model the standoff in the Cold War, are you saying that complexity is the \\nnew model for human actors and chaotic warfare?\\nThat’s exactly right. But they were limited by the restrictive nature of the classified \\nworlds their analyst teams work in. If you were to ask them to look it up on Google, they \\nwould tell you, “I can’t open Google. We’ve got an encrypted system. We’ve got to go \\ninto that room outside of the building to use Google!” They couldn’t use any data that \\nhadn’t been approved. This limits their view of the world so much so that their analysis \\nbecomes dissociated from the activities on the ground.\\nThat said, things are slowly changing. You see General Petraeus moving the thinking of \\nthe military towards a more data centric approach. David Kilcullen, an Australian ally, \\nwas chief adviser to Petraeus, and they started to become more data oriented. What they \\nwere doing with the data was still pretty naïve — but it was a start.\\nI think it’s changed quite a bit over the last six or seven years, and it’s more accepted that \\nthis is the way it’s done. But the first time we submitted our research on the mathematical \\nstructure of insurgency to the top scientific journals, they said, “We don’t do politics.” To \\nwhich we replied, “It’s not politics, it’s mathematics.” Still, they were pretty closed to the \\nidea of publishing this type of research. It took a long time. The academic establishment \\ndidn’t want to know about it. The politicians didn’t want to know about it. No one \\nwanted to publish it. Not because it wasn’t any good — but mostly because it didn’t \\nbelong anywhere. So you had this new type of academic work that had no home. \\nIn many ways, TED played a pretty instrumental role in getting this research into the \\npublic eye. They put me on stage in 2009. At the time, I was only 28. I was the youngest \\nTED speaker from an academic background. Every other academic, who had been on the \\nstage, had a very well established name in their field. Yet here I am presenting this work, \\nI haven’t published, and I’ve just finished my PhD, so everyone is like, “Who is this guy?” \\nI was a nobody with some interesting ideas — nothing more. But that exposure (over 1 \\nmillion downloads of the lecture) did force people to stand up and take notice. When \\nwe submitted the research the second time, the editors at Nature realized that they had \\nto take a closer look at the work. The paper finally went out for peer review and was \\naccepted. Later that year, the research was on the cover of Nature. It was a huge win for \\nour work and for us. But it took three years to get to that place, after many of the world’s \\njournals said they wouldn’t have anything to do with it. \\nNow, we’ve evolved the theory and so on, but the world also became ready to look at conflict \\nin a way that was quantitative. The lesson is that you can have all the mathematics, you \\ncan have all the science, but you also need to bend the world. The world has to be ready, \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 255}, page_content='SEAN GOURLEY\\n251\\nbut through telling great stories you can help it get there. The million plus viewers that \\ndownloaded the TED Talk, and the attention that it garnered, changed the conversation. \\nIt made people everywhere begin to think differently about war and mathematics.\\nFor those six months from the TED talk until \\nthe Nature paper was published, I encountered \\na lot of criticism. Wired magazine put a out \\na very critical article about my work, saying, \\n“This guy is naive. He’s saying he’s going to \\nmake war simple. But he doesn’t know what \\nhe is doing,” but they fundamentally didn’t \\nunderstand the research. At the time, I was surprised by the reaction to the research. I \\nthought that the research would be relatively straightforward, that the reaction would be \\nmore positive and open, but there was so much politics surrounding this kind of research, \\nit was always controversial. You can’t expect to analyze an ongoing conflict and not deal \\nwith politics. At the time, I guess I saw science and politics as being two different things. \\nOf course, fast forward a few years to today and the research is now widely accepted to \\nthe point of being ”obvious.” It’s obvious and accepted that when people kill each other, \\nit is done in a mathematically predictable way that doesn’t seem to be dependent on \\npolitics or religion.\\nI still think that experience taught me a few things. One is, if you really want to change \\nthe way the world looks at things, you have to be ready to be the first one through the \\nwall. You have to be ready to get the bloody nose that comes with breaking through \\nentrenched ideas, and know that you’re going to get beat up a little bit. The world won’t \\naccept a new idea without having you fight for it. The second is, that you get to write the \\nstory but you also have to be willing to tell the story. The third is, eventually, when the \\nidea does come to be accepted, it will seem so obvious that everyone will forget there \\nwas any struggle to start with.\\nI remember coming out of that time and needing a break from academia. I started \\napplying for jobs, not really knowing what I was looking to do, but wanting to explore \\nsome different options. I started looking for jobs in hedge funds, technology companies \\nand the big strategy, consulting firms. \\nYou did a stint at BCG — a consulting firm, right?\\nThat’s right. I spent a whole week there at the Chicago office. It was 2009 and during the \\nrecession. I felt like I needed a stable job, and I knew I wanted to get out of academia. \\nBut after a week I knew that it wasn’t for me and I quit the job to move to San Francisco.\\nThe lesson is that you can have all \\nthe mathematics, you can have all \\nthe science, but you also need to \\nbend the world.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 256}, page_content='SEAN GOURLEY\\n252\\nBefore we move on to the story, I want to point out that you didn’t have the usual \\ngraduate school experience, where you’re tucked away in basement number 2, \\nin building number 3, and you don’t see anyone. You were out there trying to \\nchampion and defend this new idea.\\nYes, and trying to get people to listen. That’s exactly right.\\nCould you  expand on the different ways in which your graduate experience was \\ndifferent? It’s amazing that you had the audacity to go to D.C. and began knocking \\non doors, when most researchers would rather sit behind their papers.\\nIn hindsight, I know that I was very lucky in that I managed to choose my supervisor \\nvery well. Neil Johnson gave me the freedom to succeed, and I think that was really \\nimportant. I didn’t have a predefined goal of what I was going to do when I started my \\nPhD. I knew I was going to follow what was interesting to me, and I had the ability to \\ndo that. I think that’s really important. You should pivot your research as you progress \\nin your PhD, because in your third year you are simply going to know a whole lot more \\nabout what is interesting than you are in your first 6 months. Be open to finding that \\nsidetrack that changes the direction of your path.\\nYou’re in a place, as a PhD student, to be able to think deeply about a problem and \\ncomment on things from a pretty unbiased angle. This is a very valuable thing, and \\nsomething that should be encouraged more..\\nI think the other piece was the total time I spent in the physics lab department, which \\nwould probably turn out to be less than a few days. I didn’t spend a lot of time in the \\nphysics department, but instead, I spent a lot of time talking to people in political \\nscience. I spent hours with the soldiers that were coming back from Iraq and starting \\ntheir Master’s in international relations. I spent a lot of time with people with a range of \\ndifferent ideas about how the world worked, and a lot of time reading interesting papers \\nthat were outside my discipline; collecting information and ideas from disparate places. \\nI then assimilated this information together to create a new set of theories about war.\\nThere are two very different strategies that I could have used to get my PhD. There was \\na strategy whereby I could work really hard in the physics lab, plugging away at a niche \\nproblem for 5 years and making an incremental gain. Or, I could expose myself to a range \\nof different ideas that no one else from the world of physics was seeing. I could connect \\nthe dots better than anyone, and then put a structure on it to make it relevant to the \\nworld. That was very much my philosophy. I spent five years of my life asking questions \\nand answering them, and if I’m going to spend that amount of time, the questions should \\nbe interesting to me.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 257}, page_content='SEAN GOURLEY\\n253\\nOnce you’ve taken care of your PhD requirements, you have a lot of freedom as a graduate \\nstudent — probably more freedom than anywhere. Get out and enjoy that. Be a part of \\nthe conversation and seek to answer the things on your mind while always seeking out \\nnew things. Take risks!\\nGiven everything you’ve just said, it actually seems like you had a great PhD \\nexperience, in contrast to other data scientists we’ve spoken with.\\nI loved it! \\nI ran track a lot; spending three hours a day training for a Decathlon, pole vaulting and \\nhurdling. I think it was really necessary to do that physical exercise because it cleared \\nmy head every day. I never went to the track and came back with the work on my mind. \\nIf you clear your head every day, it allows you to have fresher thoughts and filters out \\nideas. Sleep and exercise are two things that we now know removes weaker synaptic \\nconnections. As you can imagine, I did a lot of sleeping and running and filtering out all \\nthe weak connections that I would make during the day.\\nTo be honest, I think I only did maybe 2 hours of \\nwork a day during my PhD. But it was five years \\nof working for 2 hours a day. Everything else, \\nlike the conversations, the things outside of your \\nfield that you read, the random ideas you stumble \\nacross — these filled the rest of the day. You build \\na life around a space that will expose you to the maximum number of ideas, and you \\nbuild a pruning system in your life that allows the concrete ones to stay. In that regard, \\nyou build a lifestyle, as a PhD, that is less traditional. The other life you can build is \\nto show up at the lab, do your studies, and repeat. That’s a lifestyle that’s pretty well \\nproven, but there’s another, which is the one that’s going to create the new connections \\nbetween the dots. \\nI think that’s what really excites us about putting this book together. We feel like \\nthis whole data science thing is comprised of people, like yourself, who are in the \\nfield defining and fleshing out what it means to bring analytics to industries that \\nnever had analytics before, and being willing to fight that uphill battle. Despite \\nyour unique experience, you decided you didn’t want to stay in academia for the \\nrest of your life. What made you decide to switch to this other world that you were \\ncreating?\\nI made that decision before the Nature paper came out. I was frustrated that you couldn’t \\nget the resources from outside to solve the kinds of problems I wanted to solve. I knew \\nBe open to finding that sidetrack \\nthat changes the direction of \\nyour path.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 258}, page_content='SEAN GOURLEY\\n254\\nEveryone asks, “Does your theory work?” \\nand for me, I can tell you that it does, or I \\ncan show you it does. Showing is a much \\nbetter way of doing it.\\nwe needed to combine teams together from different backgrounds. I knew I needed \\npeople with expertise in Natural Language Processing; infrastructure people to store and \\nprocess large amounts of data. I would have loved to have had more marketing people to \\nhelp spread the ideas. \\nThere were all these things I knew \\nI needed, and in academia, all I had \\naccess to was grad students from the \\nPhysics Department. It was too limited. \\nI couldn’t get cross-departmental \\nteams, and I couldn’t run them on the \\nscale I needed. Maybe after tenure I \\ncould have run a small team of 5-6 PhDs, but it felt too long to get there, and the team \\nsize seemed too small to solve the problems I wanted to solve. Physicists can do a lot \\nof things, but they are not developers who are going to build a real time, self-updating \\ndatabase of Chinese television transcripts with high precision named-entity recognition \\nengines. It was never going to happen. You need a database guru from EMC to build that \\ntype of infrastructure for you.\\nSo academia was too constraining?\\nIt was. \\nI remember a particular instance in one of my days at the Pentagon. There were a couple \\nof guys from Lockheed Martin who were selling some sort of new radar tracking system. \\nWhile we were both waiting for our respective meetings, I remember thinking, ‘I’m on \\nthe wrong side of this equation. I’m here to give the Pentagon ideas. These guys are here \\nto sell them product. They’re going to get the money to build this — I’m going to have \\nto hope that someone listens to me.’ Somehow, the academics become the people that \\nare the advisors, but the money is spent with the people who are the builders. Everyone \\nasks, “Does your theory work?” and for me, I can tell you that it does, or I can show you \\nit does. Showing is a much better way of doing it. For me, I have to make this thing real. \\nI have to make this theory concrete. I had a real desire to build something that made use \\nof this research.\\nThe building side of it was key, and so I came out here to the Valley. That was a pretty big \\nmove. Honestly, I didn’t know anything about business. I didn’t even know what a Series \\nA was. I didn’t know anything about hiring, or legal, or product management and quality \\ncode. But despite all of that, I felt as though I was ready to start a tech company.\\nI think that’s a good first step. You’re starting at the bottom, but it’s all uphill from \\nthere.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 259}, page_content='SEAN GOURLEY\\n255\\nIt was a good first step, but I still had to convince myself that I could start a company \\nand take on this kind of risk. I remember coming out to San Francisco and sitting down \\nwith Max Levchin, talking about what it was like to start a company. He told me, “It’s \\nnever going to be easier to start a company. You might think it’s hard now and that’s fine \\n— but it will never be easier to start a company than when you’ve come out of graduate \\nschool, because you’re living on no money. You’ve got no one to support. If it all goes \\nsouth in a year, you’re still incredibly employable and you can roll the dice.”  That stuck \\nwith me — “It’s never going to be easier,” because in my mind, I thought, “If I can go to \\nMcKinsey and learn all about business, when I go back, it’s going to be easier.”  But that’s \\nnot the case. It’s never going to be easier to start a company than when you’ve just left \\ngrad school.\\nI think the second step was finding my co-founder, and without him I wouldn’t have been \\nable to make the jump into starting a company. He had been out in the Valley for about \\nfour years. He was the first employee of Yelp, and I thought he knew everything about \\nstartups and business. Of course, looking back, he didn’t know everything, he just knew \\nmore than me, which wasn’t hard, but the things he did understand were vital to our \\nearly progress and survival. He was instrumental in helping me build the infrastructure \\nfor the ideas and the product that I had. I could not have started the company by myself, \\nnor would I have wanted to. Starting a company is difficult and trying to do that alone is \\ntoo much responsibility, especially when it is the first company you have started. A co-\\nfounder makes it bearable. \\nWhat have been the biggest changes since grad school? I think you skipped the \\npart where you tried to be employable, and you just went straight to employing \\npeople.\\nWell, I did try to be employable. I went around to the consultancies, and I remember they \\nwere quite interested in me. I ended up working at BCG, but I found there was no way \\nfor me to apply the kinds of research and theories I had developed to the problems that \\nthey were solving. Working at BCG, I felt as though I had lost the talents that made me \\nunique.\\nIt’s like the Pentagon all over again, except you were going to be a part of the \\nPentagon!\\nThat’s right. I was looking at working there; trying to have it make sense for me, but \\nit really didn’t. The ironic thing is that now things have come full circle. We’re selling \\nsoftware to all the major consulting firms like McKinsey, BCG and Bain. BCG and \\nMcKinsey now use our software, which is a great result, but at the time, I felt like I was \\na losing a part of myself by working there. I had worked on all these cutting edge ideas \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 260}, page_content='SEAN GOURLEY\\n256\\nabout data, and I was asked to give them up so I could conform to the way things were \\nbeing done at consulting firms. I did it for a week, and I finally said, “I can’t do this.” It \\njust wasn’t a fit for me.\\nI remember being at the BCG training program in little country resort just outside of \\nBarcelona. It was a 3-week long immersion course for scientists and lawyers to give \\nthem business skills, or the “mini-MBA,” as it was called. It was half way during the first \\nweek and I had had a call with one of the senior government officials in Iraq about the \\nescalation of violence over there. The call ended at around 5am in the morning, as such I \\ndidn’t get much sleep and I was showing up a half an hour late to the 8am training session \\nin modern accounting practices for strategy, and the Partner running the training was \\nobviously not happy with me. “This is very important that you show up here on time.” \\nOf course, they wanted (and were paying me) to come here and learn important skills for \\nstrategy consulting, but that just didn’t seem to be so important as taking the late night \\nphone call from the Iraqi government to discuss IED modelling techniques. At this point \\nI was thinking that I might be in the wrong place. Right then I knew it wasn’t for me and \\ndecided to get out at the first opportunity.\\nI was disappointed. I didn’t want to be at BCG, but I didn’t know where I did belong. I \\nwanted to keep doing this research and push forward the data analysis techniques I had \\ndeveloped, but there wasn’t a place to do it. There was nowhere that would employ me \\nto do what I wanted to do. So, without any other options on the table, I decided that if I \\nwanted to make these ideas real then I would have to create a company myself. I didn’t \\nknow exactly how to do this, or what the company would look like, but ultimately I made \\nthe jump. I remember the day. It was a Sunday morning, and I was driving back from Los \\nAngeles up the pacific coast highway. Somewhere right around Big Sur it became very \\nclear to me , “I can’t get on the plane tomorrow and fly back to BCG in Chicago.”\\n \\nI rang them up then and left a voice message, “I can’t go back to work. I’m done.” It was \\nscary to do that, but it was also a rush to cut all the ties. I kept thinking, “I finally get to \\ndo this.” That was the transition.\\nWow. That’s amazing. So after that point, you ended up creating Quid. Can you tell \\nus about Quid?\\nSure! I ended up out here in San Francisco in the middle of the recession without a job, \\nwithout anywhere to stay, with only the last pay check from BCG in my bank account. \\nThat was when it all became real. I started to do some contracting work to pay the bills, \\njust talking to companies that I thought had interesting data and they paid me to start \\nplaying with it to see if there was any value. At one of these companies, I met my co-\\nfounder Bob. He was the CEO of a company with some very interesting data, and I said, \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 261}, page_content='SEAN GOURLEY\\n257\\n“I can help you with that.”  We worked together for a few months, and it was a blast. So \\nI told him, “You have to help me start Quid. We’ve got to start Quid. You have to get out \\nof this company. Quit. You have to come to Quid!”.\\nSo we pitched the idea for Quid to Peter Thiel at a breakfast meeting at his house. He \\nliked it and came in to lead the first round.\\nWhat was the pitch at the time? Were you pitching a commercial version of your \\nresearch?\\nAt the time, I didn’t think my research was commercializable. I thought the military \\nmight buy it, but it wasn’t clear that companies would buy the idea of an intelligence \\nplatform. No one was banging down our door asking for a platform to allow unstructured \\ndata, collected from outside sources, to make their biggest strategic decisions. It didn’t \\nseem like there was an obvious market. Customers wanted the machines to predict what \\nto do next; to push a button and have the computer spit out an answer. But this wasn’t \\nwhat we were offering. We were saying that we could build an intelligence platform that \\nwould combine the best of the human brain with the best of the artificial, computer \\nbrain. We didn’t have a name for it then, but today it would be known as augmented \\nintelligence.\\nWe needed a first group of customers who would adopt this new way of making decisions. \\nWe needed a group in which the decisions were too difficult for a computer to make by \\nitself and a group in which the biological limitations of the human brain were running \\nup against the increasing complexity of the world. Silicon Valley, in 2010, provided us \\nwith just this environment. There were groups of people, working to figure out the right \\nM&A deals to make for big companies, like Microsoft and Google. Their task was almost \\nimpossible to do well, simply because of the time it takes to adequately understand an \\nemerging technology space, before the space has changed to the point where your analysis \\nis no longer accurate. This reminded us of the same challenges we had come across in \\nIraq. Trying to keep track of many small groups (startups), any of which could do damage \\nto a larger dominant force (Google, Microsoft, etc.). It seemed like you could apply these \\nsame research techniques, developed to understand insurgents, to the global technology \\nlandscape. If you did that, you could make better bets than were currently being made. \\nIt could move the market cap of companies by billions and create new winners in the \\nspace.\\nThat seemed like the right place to get started. In my mind, I thought, “I want to build \\nthis. I want to build a company that remotely monitors the globe and allows analysts to \\nplug in and see structures, like I did in my PhD.” By rolling out this technology to the \\ncorporate M&A market, it allowed us to begin the project with a clear business case on \\nwhich to focus our development.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 262}, page_content='SEAN GOURLEY\\n258\\nThat’s how we got our start, but in the back of my mind I was always thinking, “I have to \\nhack this venture capital financing structure to do some really cool science fiction stuff. \\nWhat I really want to do will take a long time, but as I go through this process, I’ll be able \\nto do it. First, I have to make money. Once you make money, you can do anything you \\nwant.” This was the hack.\\nThat being said, venture capital is not \\nreally set up to do this. For the most \\npart it is easier to arbitrage market \\nopportunities than it is to create \\nscience fiction type products. Even if \\nyou do get money for this, there’s no \\nguarantee that it is even possible to \\nbuild the things you are imagining. \\nLooking back now, 2009 was too early \\nfor this intelligence platform to exist. \\nThere were just too many technology \\nsolutions missing from the equation; \\ntoo many things that we would have to build ourselves. The right time to make this \\nfor venture capital would have been at the start of 2012. I think if I wanted to start the \\ncompany, I should have started in 2012, but the problem would not have been nearly \\nas interesting to work on. This is the issue with venture capital — if you want to really \\npush the limits of what science can do, there just might not be any business applications \\nready and waiting for you, once you’ve done it.\\nWhen things come to market, they are not as interesting as they were five years earlier, \\nand when you live in academia, you’re 10 years ahead of the market. You think a certain \\nthing is possible, and of course, it’s not possible for 10 years. One of the heuristics is \\nthat whenever a group of papers are published, it will take 10 years for any academic \\nbreakthroughs to become commercial realities.\\nYou learn to appreciate that timeframe. You can’t port your research straight into \\nventure- at least not with the current financial tools that we have. If you’ve finished your \\nPhD, and you can immediately start a company, then your PhD wasn’t any good, because \\nyou should be far enough ahead of the world that there isn’t a market for what you’re \\nbuilding. On the flip side, you’re going to be at a place where you’re the first to market, \\nand you’ve already made all the mistakes, and now others can copy your breakthroughs. \\nThat’s a difficult place to be. It’s an exciting place, but a difficult place from a business \\nperspective.\\nIn many ways you have to constrain your science aspirations by business realities. We \\nhad done this war stuff, and we were going to create a platform to improve private equity \\nThat’s how we got our start, but in the back \\nof my mind I was always thinking, “I have to \\nhack this venture capital financing structure \\nto do some really cool science fiction stuff. \\nWhat I really want to do will take a long \\ntime, but as I go through this process, \\nI’ll be able to do it. First, I have to make \\nmoney. Once you make money, you can do \\nanything you want.”\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 263}, page_content='SEAN GOURLEY\\n259\\ninvestment decisions. It’s not quite revolutionary, but you also have to keep in mind that \\nit is the first step, and venture capital is all about levelling up. If you make the first step, \\nthen you move from $2.5M in funding to $10M. Make the next step and you get $50M to \\nplay with. You have to keep the grand vision, and at the same time execute on the day-\\nto-day elements of creating product market fit.\\nMy vision with Quid is to have an intelligence platform that monitors the world through \\nopen data sources, so that anyone can plug into the platform and see the patterns that \\nshape the world. From that vantage point, everyone can make better decisions in their \\nworld that will ultimately impact our world. Users can see further, see deeper, leveraging \\ndeep intuitive AI combined with immersive visualizations. To ultimately amplify \\nintelligence through software — that’s where I want to go with this. I want to have a \\nsystem that makes us smarter, that is distributed as widely as possible, and to as many \\npeople as possible.\\nWe’re talking about augmenting human cognition across the planet. I think we’re maybe \\n10 years away from having a complete working version of this. There’s certainly another \\nbillion dollars of investment here. Whether we get there or not, no one knows. But I \\nthink something to take away is that with science, you hold a piece of the puzzle, you \\ndirect the field, and you get to shape it a little bit.\\nHere, the traditional thinking is that if you don’t win financially, you haven’t won. But \\nI know that by even being here, I’ve shaped the direction of the technological vector. I \\nwill continue to shape it as long as I keep playing. Even if I don’t win the money at end \\nof the game, I’ll do very well, but the direction is going to be shaped because of me. In \\nscience, we know that we play a part in a bigger human endeavor and in the Valley its all \\nabout me — and did I win.\\nThis is why we need to be in this game, because these things that are happening are \\nshaping all of us, and if it’s just a monetary grab, we’re a little off. Science brings in the \\naspect of having a sense to do something worthwhile and good.\\nIn 2006, you were working on this paper and Nature wasn’t ready, the Pentagon \\ndefinitely wasn’t ready. Now, it’s almost 10 years later, and now we see the \\nmovement in industry towards making strategy decisions. Relative to your paper \\nin 2006, do you think that within that 10-year deadline, we’re going to get to the \\nplace where your vision is?\\nThe paper came out in 2009, so there’s probably still a few years left before we see \\ncommercializations. Based on the work from 2006, we are definitely going to see this \\nin the commercial world. In the last 6 months, since Quid released the second version \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 264}, page_content='SEAN GOURLEY\\n260\\nof our Intelligence Platform, we have seen a great uptake in all types of people using \\nit; from hedge funds, to strategy consultants and advertising creatives. Fast forward \\nanother 18 months, I think that we will have thousands of strategy consultants running \\nQuid software. I’m very confident that we’re putting the elements in place to make this \\nhappen: the relationships, the technology, and the algorithms. We’re getting our first \\ncourse at the University College of London’s management science class and the entire \\nclass is getting Quid accounts. They’re plugging in. They’re training on it. The first \\nMcKinsey teams and the first BCG teams are spinning up. We just signed a major deal \\nwith a group of publicists to roll this out to their creative strategists across the entire \\nfirm.\\nWe’ve got small, boutique consultancies that are winning massive contracts because \\nthey’re running Quid software. They’re getting great results and even moving into new \\noffices based on all the new business they’re winning. Consulting used to be a case where \\nyou arbitrage smart PhD students and then you plug them in to BCG. You throw people at \\nthe problem. Now, these same people can drive the kinds of software Quid is pioneering. \\nThe AI behind the Quid engine can do a lot of the heavy lifting, saving literally, weeks \\nof work. The analysts can spend time \\ndoing the things that matter — which \\nis figuring out the implications of the \\nstrategy in front of them. Hopefully, \\nif nothing else, I’ve given some of our \\nusers a bit of their life back instead \\nof spending it doing those tedious \\nthings.\\nThe strategy part of the problem is well on the way towards being solved, and I think \\nthe next step is to start integrating more of our Artificial Intelligence capabilities into \\nthe system. Scientists talk about the brain having a neural circuitry for intuition. Expert \\nintuition comes from two parts of the brain: the precuneus and the caudate nucleus. The \\nprecuneus is the pattern recognition engine that identifies patterns to extract signals, \\nwhere most of us non-experts would only see noise. I think we’ve built a lot of that in the \\ncurrent release of the Quid platform. We’ve built a lot of pretty good pattern recognition \\nengines, to allow users to see structure in news, science, Twitter etc.\\nThe next phase of the Quid project is to build the AI version of the caudate nucleus. \\nThis is the part of the brain associated with the learned response function. I think in \\nthe next couple of years, we will have built a good, learned response function into the \\nQuid platform. At the moment, humans are learning the patterns and figuring out what \\nthey should do next based on their experience. We can start hinting at things that have \\nhappened in the past. That’s not to say that we should replicate them, but we can build \\nA lot of the process, for me, is continuously \\nlearning to let go of the things that I have \\nbuilt and let other people in the company \\ntake ownership of them.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 265}, page_content='SEAN GOURLEY\\n261\\non that functionality so they can see what an artificial caudate nucleus would look like \\non top of these data streams. It’s a kind of simulation that would project the current \\nworld forward in time to explore different scenarios. I think that’s going to be really \\npowerful.\\nI think what the Quid platform ultimately does is allow people that are good at \\nrecognizing patterns, and knowing what to do about them, to jump between different \\nareas of expertise. You should be able to jump into the world of material science and see \\nall the papers written in that field, and then jump into the world of swarm robotics for \\nUAVs, and to then into the world of Ukrainian politics. You should be able to leverage the \\nintelligence engines of Quid to give you a deep understanding, across all these fields, in \\njust a few hours.\\nI think when we put that tool in front of people, they will begin to broaden their \\nknowledge. They will see further and they will see new things. I want to try and replicate \\nthe experience I had in grad school, where I was able to jump between things but to give \\nthat in a tool to other people, and I think that will change the way people will see the \\nworld. I think it will also allow things to be thought and to be built in ways that otherwise \\nwouldn’t have happened. I’m more confident now than ever of getting that right. \\nA lot of the process, for me, is continuously learning to let go of the things that I have \\nbuilt and let other people in the company take ownership of them. It seems obvious, but \\nit’s a continual process of letting go. You build the first versions and then you have to \\nstep back and give it to the other team members. You might not like how they choose \\nto update your solution, but the point is that it’s no longer just yours anymore. The \\nchallenge then becomes knowing when to let go and when to step back in to make sure \\nthe essential parts of the project are still being maintained.\\nFor example, one of the key features of the product is the animated transition between \\ndata spaces. When building this, I was adamant that we had to have transitions. Some \\nother members of the team rightfully challenged this because it’s an expensive part of \\nthe product to build. They would ask, “Why do you need transitions?” There’s no real \\nempirical evidence as to why we need this feature, but it somehow just feels right. So \\nI replied, “We’ve got to have transitions. The data has to move between a timeline and \\na network. People need to orientate themselves”. Other members of the team again \\nobjected stating, “No one wants to have that.”  Until I finally stated, “I hear you, but \\nwe’re doing it.”\\nFast forward a few weeks, and one of the engineers says that a cylindrical coordinate \\ntransformation would be better. I said, “You know what? I never thought of that. I’m not \\nsure it does.” Then I looked at it, and they were right; it does. A cylindrical transformation \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 266}, page_content='SEAN GOURLEY\\n262\\n— translating between two points using cylindrical coordinates; I never would have \\nthought of that. I had nothing more to add. Their understanding of this problem was \\nbeyond me. That was the right time to let go.\\nYou have things that are important and then at some point, you realize, “I have nothing \\nto add to this.” That’s the continual balance when you create things that are pushing the \\nboundaries of what is possible. It’s important to know what matters and what doesn’t.\\nThat’s the beautiful lesson in leadership. It must have been a hard lesson to learn. \\nI feel like there’s so much investment involved. Not only have you carried this, you \\nalso fought for it for so long, and then, at the very end, you give it away to others \\ntorchbearers. \\nThat’s right, and it can only be done with thousands of people building this. It’s fighting \\nthe battles that need to be fought and letting go of the ones that don’t. Now, for me, it’s \\ntrusting in the machinery that I’ve set up, and it’s also going out and helping the world \\nto learn to use this. With a team, you can keep making the products better. \\nIn life, it’s always 0 to 1, and you’re either a one person or a 1 to 1.1 person. I think a lot \\nof things we do in life are 0 to 1, and that’s also important to recognize. That means that \\nwhen you’re the first one through the wall, you have to fight for it. No one wants to listen \\nto you, and by the time the idea gets accepted, you’re bored with it. You move on to the \\nnext thing.\\nThe nice thing about startups is there’s always a next thing. Everything you do is \\nsomething you’re doing for the first time and not something you’re very good at. It’s \\nsomething you’re unqualified to be doing.\\nNow at this point in your life, I have to say that you have a lot of credibility in doing \\nthings you’re unqualified for.\\nThat’s how you learn about your strength. My strength is consistently doing things I’m \\nnot very good at and quickly becoming reasonably competent. My hope for grad students \\ncoming out of their PhD is to pick whatever job you want in a way that takes advantage of \\nthe skills you have as a graduate student. In data science, if you feel you have to conform \\ntoo much in a box and don’t get the freedom, that job is not for you. Find a place where \\nyou can shape a little bit of the world and keep doing that, which will probably involve \\ndoing a lot of things that you’re unqualified for and not very good at.\\nI think we’ve got a very narrow view of what data science is, which has largely been \\nshaped by data analysts working in the big social networks, like Facebook and Linkedin. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 267}, page_content='SEAN GOURLEY\\n263\\nSo for many of us, data science seems concerned with things like A/B testing to optimize \\npersonalized ad recommendations. But data science can be so much more than this. \\nWe must recognizing what data can do, what data can’t do, recognizing that it’s messy, \\nthat it’s biased, and understanding that it needs a human layer — that it needs stories. \\nRecognizing that it can solve a certain degree of complexity, but it can’t solve any \\nfurther. Remember that humans have \\nbiases and they absolutely need data. \\nWe don’t want to move towards \\nnaive empiricism — that’s not what \\ndata science should be. It’s not what \\nscience teaches us, but, at the same \\ntime, we don’t need to throw data out \\nthe window just because it can’t push \\na button to solve an equation.\\nI think a lot of that will come together. Data science will evolve. I think the second \\npiece is data scientists have an obligation to do good things in this world with that data. \\nIt’s not enough to just not be evil; it can fundamentally be good. If you come out of \\nscience, you are contributing to the world’s knowledge. When you come to the business \\nworld, you should also be contributing towards building the tools that help us to live and \\nfunction in society.\\nThis is an imperative that should be fought for very hard. This should be one of the \\ndecisions you make in the jobs that you do. We have a set of technologies that can and \\nwill shape our world in ways that are positive and potentially very negative. It ultimately \\ncomes down to the mentality of the people that are building the technologies. We can \\nwash our hands and say, “I can’t do anything about it. It’s not in my control.” But we \\nreally need to challenge this assumption. You can do something about it! You’re making \\nthis or your company is making this stuff. You’re the data scientists that are building this \\nstuff. Of course you can do something about it, and of course you have that responsibility.\\nIf you choose to do it in a different way, you are the one shaping the world. We are \\nthe people who are creating this technology, so you can’t just wash your hands and say \\nyou’re not part of it. We saw what happened when a bunch of quants on Wall Street, with \\nlittle regard for the consequences said, “I’m just going to use these algorithms to make \\nmoney.”  This is not good enough. You can’t arbitrage a system and make money for \\nyourself without also having the responsibility to make it better.\\nSo much of data science has been concerned with equations for the optimization of an \\nexisting world. But we need to use data science to build and engineer a better world, \\nand that’s where it starts to move beyond black box predictions and basic statistical \\nIn life, it’s always 0 to 1, and you’re either a \\none person or a 1 to 1.1 person. I think a lot \\nof things we do in life are 0 to 1, and that’s \\nalso important to recognize. That means \\nthat when you’re the first one through the \\nwall, you have to fight for it.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 268}, page_content='SEAN GOURLEY\\n264\\ntools and moves into design. One of the big things for data scientists is to understand \\nthat their role is also one of design. If you create algorithms, you shape the behavior of \\npeople who interact with these algorithms. So what kind of behavior are you designing?\\nI think data science is really going to become more of a product design process; actually \\nan algorithm design process. Algorithms take information and direct us; whether it’s the \\ninformation we read, the music we listen to, the places we drink coffee, the friends we \\nmeet, or the updates in our lives. \\nYou are designing algorithms that \\nfundamentally shape humanity, and \\nwe do it in on a population scale in \\nthe billions. So how we choose to \\nshape this world certainly has a lot \\nof challenges. We can’t just hide \\nbehind the imperative to optimize an \\nalgorithm for maximum revenue. You designed an algorithm that created a certain kind \\nof behavior — for better or worse — and now this algorithm is potentially impacting the \\nlives of billions of people you have never met. What kind of behavior do we want? I think \\nyou need to fall on the line of making humans more human, making them see further, \\nmaking them see deeper, making them understand and appreciate the nuance. Don’t try \\nto hide the complexity from them, but instead, make them more conscious. Make them \\nsmarter. Help make them smarter. I think that’s what you design for. That’s what you use \\ndata science for.\\nThat is amazing. I love that vision, the imperative you stated for people that want \\nto work in data science.\\nI think most of the data scientists I meet are pretty good people. It’s been refreshing to \\nsee this culture emerge from the community that we built up over the years. It’s one of \\nthe things we started in 2009, DDG (Data Drinking Group), which was Pete Skomoroch, \\nMike Driscoll, DJ Patil, Bradford Cross, and me. There were five or six of us that would just \\nget together and drink and talk about this stuff. These were some of the most creative \\ntimes. The ideas we discussed, the questions we would ask, and the technology we would \\nshare. I think this really influenced how the discipline is unfolding today.\\nData science is its own philosophy. We’re not the same as the production engineers of \\nthe world. We’re not product people. We’re our own kind of group with our own set of \\nvalues. Data scientists have a distinct kind of DNA that is measurably different from a lot \\nof the other groups. As this culture emerges and develops, I think good things will come \\nfrom it. I’ve always been very impressed by the data science people I’ve met. They have \\nthis nice coupling between the real word and the computer world. They know data and \\nData scientists have an obligation to do \\ngood things in this world with that data. \\nIt’s not enough to just not be evil; it can \\nfundamentally be good.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 269}, page_content='SEAN GOURLEY\\n265\\nthey know engineering. They value the beauty in their algorithms and the beauty in their \\ndesign. They span a lot of traditional disciplines and can combine their experiences to \\ncreate new things. I think we’re going to see this group of data scientists solve many of \\nthe bigger problems we are facing in the world, and that’s pretty exciting.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 270}, page_content='JONATHAN GOLDMAN \\nDirector of Data Science and Analytics at Intuit\\nCan you give us a sense of the background and the path that you’ve taken to get \\nwhere you are today?\\n \\nI completed my Bachelors in Physics at MIT. I just absolutely love math and physics. \\nI actually loved a lot of other fields as well, but knew I wanted to stay with math and \\nphysics in particular. I also absolutely loved MIT — it was the perfect place for me. When \\nit came to graduation, however, I still didn’t know what I wanted to do with my future. I \\nknew I wanted to do something more in science, but I didn’t know if I definitely wanted \\nto be a professor. I ended up applying to Ph.D. programs but still wasn’t certain if that \\nwas what I wanted to do.\\nI also applied for a few jobs, but was just not excited about any of the jobs I saw, and how \\nthey would leverage my skills. In comparison, grad school was exciting since I would get \\nto work on fundamental research there. At the time, I was really excited about what was \\nhappening in the world of quantum computing.\\n \\nI got into Stanford, and I found an advisor who was specifically working on quantum \\ncomputing. So I came out to Stanford and liked it for a while, but towards the later \\npart of my Ph.D. recognized I wanted to something else. Research was hard and not as \\nrewarding in the short-term — it took me seven years to get the results that I needed to \\ngraduate. It was in my fifth or sixth year that I thought, “I want to do something that has \\na little bit more immediate impact.”\\n \\nJonathan is currently Director of Data Science and \\nAnalytics at Intuit. He co-founded Level Up Analytics, a \\npremier data science consulting company focused on data \\nscience, big data and analytics which Intuit acquired in \\n2013. From 2006–09 he led the product analytics team \\nat LinkedIn which was responsible for creating new data-\\ndriven products. While at LinkedIn he invented the “People \\nYou May Know” product and algorithm which was directly \\nresponsible for getting millions of users connected and \\nmore engaged with LinkedIn. \\nHe received a Ph.D. in physics in 2005 from Stanford where \\nhe worked on quantum computing and a B.S. in physics from MIT.\\nHow to Build Novel Data Products and Companies \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 271}, page_content='JONATHAN GOLDMAN 267\\nThe parts of the Ph.D. program I loved most were when I was actually getting the data, \\nanalyzing it, and iterating very fast. I had these experiments I’d have to run for 30 \\nhours, and basically after that, the system would shut down, restart my experiment, and \\nit would take a day or two to get the system to reset. It was during this period that I \\nwas getting this amazing data, make a hypothesis then and test it. I loved the actual \\nthinking, the theoretical aspects of it, what that told me to do with the experiment, and \\nwhat parameters to explore.\\nTowards the end of my program, I got involved in some entrepreneurship activities at \\nStanford. I got involved in this organization called a nanotechnology forum, where Steve \\nChu, Stanford physics professor and later the Secretary of Energy came to speak. A lot \\nwas happening back in the early 2000s in that area. I was trying to go into that area, \\nlooking at solar energy technologies — I was very excited about that. But then I looked at \\na few of the solar technology companies, and the basic approach that they had was, “Hey, \\nyou get to work on this technology as a postdoc, and if it works, you’ll get a full-time job. \\nIf not, that’s a nice postdoc for a year or two.” That just didn’t seem appealing to me.\\nAt the end of graduate school, I was looking for a job, and I knew at that point I just did \\nnot want to stay and do a postdoc. I ended up going to the consulting firm Accenture, and \\nI was excited about going to work in energy. I had been working on energy-related stuff, \\nand I was getting more excited \\nand interested in that. I wanted to \\nwork in strategy for Accenture — \\nthe focus was in the utility/energy \\nsector, especially in the natural gas \\nmarket.\\nSo, I was working for a little while \\non natural gas strategy for one of \\nthe partners, and that was fun. I got \\nput on a project to work at a utility \\ncompany, and it was good to get that exposure — to find out what the corporate world \\nis like. What is it like to do consulting? What’s it like to work in this company? How do \\nthey operate? I actually learned a lot about how to communicate and how they work; it’s \\nsuch a different world from academia. \\nCan you tell us a bit more about what you did at Accenture? What were you \\ninvolved in there?\\nI was in the supply chain project for a utility company, and we did a lot of work on \\nsupply and demand, and other sorts of optimizations. When should the utility company \\nAcademia becomes a very competitive world \\nsince you have to make a name for yourself \\nto succeed. The business world is also \\ncompetitive, but in my experience, teamwork \\nis more highly valued there because it really \\ndoes take a significant effort from many people \\nto make something interesting happen.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 272}, page_content='JONATHAN GOLDMAN\\n268\\nbuy? How much inventory should they have and what do they have to plan for? They’re \\ninteresting problems because you need math and analytics to figure out the optimizations. \\nIn the case of a utility company, it’s different because you have to plan for worst-case \\nscenarios. If there’s a storm, I need to be able to repair everything quickly enough so \\npeople have enough power. There’s demand and supply planning, as well as strategic \\nsourcing — there’s a whole bunch of interesting problems.\\nCan you tell us more about your transition from Accenture to LinkedIn?\\nAt that point where I was thinking, “Let me see if I can do something a little more \\ntechnical.” I felt like I learned what I needed to learn so I was trying to find new projects. \\nI started looking around to new places, including LinkedIn. Initially it seemed like it \\nwas a recruiting platform and I wasn’t that excited about it, but after I went and met \\nwith various people there, learned about their data, and learned about what they were \\nthinking about, I thought “Wow, this is awesome.” \\n \\nWhat was it about LinkedIn that hooked you?  \\n \\nWell, what really excited me was thinking, “Well, look, you have this data about people’s \\ncareers, where they went to school, where they are now working, what they have done \\nin their careers, and descriptions of their past jobs. So how do I help people get the right \\njob?” It’s a problem that actually felt very personal. While I’m trying to find the right \\ncareer for me, I could help work on solving that problem for others at scale.  \\n \\nThe data was all there, and I could ask questions about the data very quickly. It was \\nexactly the part of the Ph.D. program that I liked. Suddenly I didn’t have to deal with \\nthe experimental apparatus which took me two years to build. It was like, boom, I have \\nthe data, and it’s actually very interesting. I was learning all these new techniques and \\nit was great.\\nWithin two weeks of starting, I had already felt that this was my dream job. It was \\nawesome, and I totally loved it. I found people even more collaborative in companies \\nthan they were in university research — we were all working to help the company do \\nwell and make a dent in the universe. In academia you also try to make a dent, but it \\nwas very often your own dent. Academia becomes a very competitive world since you \\nhave to make a name for yourself to succeed. The business world is also competitive, \\nbut in my experience, teamwork is more highly valued there because it really does take a \\nsignificant effort from many people to make something interesting happen.\\nIt sounds like you really enjoyed your time at LinkedIn. What did you do there?\\nI was trying to figure out what I could do with the data to improve things. One project I \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 273}, page_content='JONATHAN GOLDMAN\\n269\\nworked on involved sending invites on LinkedIn. I looked at questions such as whether \\nor not the click-through-rates changed depending on the level of the person who sent \\nit to you (more senior than you, more junior to you, a peer). Something else I thought \\nof and looked at was the reminder emails that we send a week or two later after you \\nhaven’t accepted an invite. I looked into the best time to send such a reminder, and \\ndiscovered neat facts such as 80% of invites go to people in the same time zone. This \\nmeans that even though I don’t know what time zone you’re in, I can guess pretty well \\nfrom the time-zone of the person who sent you the invite. We optimized the time of day \\nthat the email went out and saw boosts of 2-3% in click-through rate. This improvement \\ncompounds and the result can be massive.\\nBasically, we were trying to look for all these little knobs to turn to understand the \\nLinkedIn dynamic and to understand LinkedIn at a fundamental, physical level. I thought \\nof it as a physics problem involving people and invites. I was asking myself — who’s \\nconnected to whom, and how can I get more people to join? How can I get more people \\nconnected? When you understand the system, you try to think of it not just as these \\ndisparate things but more as an overall global pattern that you want to understand — an \\nengine that you want to get to move faster.\\nI started thinking about some of the dynamics \\ninvolved in what gets people to sign up, and \\nthen I also started looking at the data. I found \\nthat a lot of people didn’t even have that many \\nconnections. And people were not going to \\nreally get the value of LinkedIn until they had \\na good network — until they had ten, twenty \\nor thirty connections. Most people only had \\none, two, even zero. I observed these things in the data, and realized that we really need \\nto just work on getting people connected. I asked myself — how can we get more people \\nconnected? Well, we can make it easier for you to find people to connect with. Back then, \\nthere was Friendster, MySpace, and the beginnings of Facebook, and no one had been \\nworking on recommending people you might know.\\nSteve Stegman (Steve was what we would call a data scientist today) and I, within the \\nspan of one day, conceived the beginnings of the “ Viewers of this profile also viewed… ” \\nfeature. We could quickly get stuff out onto the site, test it, and see the click-through \\nrates, so that was awesome. I had this idea of trying to recommend people you know and \\nwe ultimately called it “People You May Know”. I was working on the heuristics, mostly \\nat night, just iterating and iterating, and asking, “What are the things that can work?” And \\nwe ended up using a lot of stuff like company and school, and also the graph structure \\nof how connected they are. The initial click-through rates were amazing — and then \\nWe optimized the time of day that \\nthe email went out and saw boosts \\nof 2-3% in click-through rate. This \\nimprovement compounds and the \\nresult can be massive.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 274}, page_content='JONATHAN GOLDMAN\\n270\\nmachine learning helped increase click-through rates another 2- to 3-fold. This work \\nwas spearheaded by Monica Rogati who I hired onto my team.\\nThis was not a product that was on \\nany roadmap — I think that’s an \\nimportant thing to point out. I pitched \\n“People You May Know” to a few \\nproduct managers and they were all \\nlukewarm about the idea. It was hard \\nfinding people who really bought into \\nthe idea at the beginning, but we ran tests and had data we could go back to and show \\npeople. Once we had data, no-one stopped us from expanding and doing more but it \\nstill took some time to get the proper engineering investment we needed. Because of \\nthe viral nature of “People You May Know”, we demonstrated with data that this feature \\ngot millions of users back to the site who otherwise would not have visited the site. \\nWe showed this to Jeff Weiner in 2009, and he was like, “Yes, we’ve got to go on and do \\nmore.” At that point there was lots more engineering investment put in place across \\nLinkedIn and fortunately PYMK got significant additional investment.\\n \\nThis was a great example of a data product that was never actually on the product roadmap. \\nIt’s the impact that a data scientist can have on a business, because you can observe \\nsome pattern in the data, build something, and start doing some pretty sophisticated \\nstuff with all these different signals. You end up transforming the trajectory of growth.\\n“People You May Know” started as my original work. I did basically all of it initially, \\nincluding the algorithm and the product, but ultimately, as it grew and grew, many more \\npeople became involved. Monica and Steve Stegman made contributions to some of the \\nalgorithm, and DJ helped with getting it onto mobile and getting it faster. Other product \\nmanagers, like Janet, were also involved.\\nLater on in your career, you started your own company with your wife and a \\nthird co-founder, Lucian Lita — can you tell us more about this? What was it like \\ntransitioning from a role as a data scientist at a large company to running your \\nown?\\n \\nThe three of us saw this opportunity — the demand for data science and building \\ntechnology that would help solve data science problems. We saw a huge need that was \\njust constant, and thought we could build a premier consulting firm and we would go to \\nthese companies and help them transform their businesses, while hiring people that we \\nreally liked working with. \\nBasically, we were trying to look for all \\nthese little knobs to turn to understand \\nthe LinkedIn dynamic and to understand \\nLinkedIn at a fundamental, physical level.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 275}, page_content='JONATHAN GOLDMAN\\n271\\nThe amazing thing was that we were able to get really good talent, get really good \\nclients, and work on really challenging problems. There weren’t that many people doing \\nexactly what we were doing — no-one else did the full end-to-end, including “What’s the \\nbusiness problem you’re facing? Where’s the place we can have the most impact? What \\ntechnology might need to be built or deployed? What algorithms and analysis need to be \\ndone? We could do the full stack — I think a lot of companies really liked that approach.  \\n \\nOne of our clients, Intuit, after we got to know them and they got to know us, approached \\nus about getting our entire company focused on Intuit — namely they wanted to acquire \\nus. We really liked the problem they were working on. They were fundamentally changing \\npeople’s lives by making it easier to manage their finances, do their taxes and run a small \\nbusiness. It’s actually quite an interesting problem because they see so much of the \\neconomy. They are really truly one of the few companies that I think is mapping the \\nworld’s economy. You could say that LinkedIn is mapping the talent economy, but Intuit \\nis actually mapping the real transactions that are happening. I don’t know any other \\ncompany that has such interesting data. The impact on the economy and economic \\nwealth is profound.  To me, it was a good mission to be a part of, and I really liked the \\nculture and the people. \\nGiven your own experiences in a PhD program, what advice do you have for our \\nreaders who are in a PhD, or just recently finished one, and are looking to start \\ntheir career in data science?\\n \\nFind the companies that are aligned with \\nyour values, where you get to work on things \\nthat are impactful and making a dent in the \\nuniverse. There’s never going to be a shortage \\nof interesting problems to work on that are \\nmassive and impactful. When you’re at that kind of company, it’s easier to take that data \\nand turn the data into transformational business impact.  \\nI think one of the most important things is to learn to be curious. You see something that \\nmight spark new questions for future projects. Once you’re curious about something \\nwith the data, you’ll figure out how to go solve and answer those questions, regardless \\nof the technique. You need to be able to go back and forth in an iterative manner as \\nbusinesses don’t always have well-defined problems. \\nI think one of the most important \\nthings is to learn to be curious. \\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 276}, page_content='WILLIAM CHEN Data Scientist at Quora\\nCan you tell us about your journey transitioning into data science?\\nI started my freshman year at Harvard wanting to study math, but then took Stat 110 \\nwith Joe Blitzstein. The class changed the way I thought about uncertainty and everyday \\nevents, while teaching me how to value intuition and communication. The class \\ninfluenced me to declare statistics as my major in my sophomore year.\\nIn my sophomore year, I started looking around for internships that would use some of \\nmy probability and statistics background. My knowledge was mostly theoretical then \\nwith little experience in application, so I was pleasantly surprised when Etsy invited \\nme to intern with them as a data analyst. This was my introduction to using data to \\nimprove business — every facet of my internship helped me grow and develop my skills \\nas a budding data scientist.\\nEtsy is a very metrics-driven company and I was able to see and understand the heart \\nof how Etsy makes decisions with A/B testing. The frequent statistics discussions on \\nthe mailing list were engaging and I was able to learn about common techniques and \\npotential pitfalls in metrics-driven tech companies.\\nThe presentation of data at Etsy was beautiful (with d3 dashboards and highly polished \\nslide decks). In that kind of environment and attention to visuals, I taught myself ggplot2 \\nand started making my own plots and graphics. I was able to learn a lot during that \\ninternship — it was the start of my career in data science.\\nAfter my internship at Etsy ended, I started my junior year. That year, I returned to being \\na teaching fellow (the equivalent of an undergraduate teaching assistant) for Stat 110. \\nWilliam Chen is a data scientist at Quora, where he helps \\ngrow and share the world’s knowledge. He became a data \\nscientist after finishing his joint degree in Statistics and \\nApplied Math at Harvard, and is part of the first wave of \\ncollege undergraduates who took data science courses and \\nsought data science jobs straight after graduation. Prior to \\njoining Quora full time, he interned at Quora and Etsy as \\ndata interns. He has a passion for telling stories with data, \\nand shares his knowledge extensively on Quora.\\nWilliam is one of the co-authors of this book.\\nFrom Undergraduate to Data Scientist\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 277}, page_content='WILLIAM CHEN 273\\nIn helping people with their probability problems, I realized that teaching probability \\nhelped me improve both my communication and storytelling capabilities. It was also \\nvery enjoyable and I got more in the habit of trying to share and teach whatever I could.\\nMy junior year, I also started \\nto take a lot more CS classes \\nas I realized their importance \\nin a data science role. Not \\nhaving enough programming \\nbackground to implement \\nyour statistics knowledge can \\nseverely limit the number of \\nthings you can do. I realized that having both was imperative to succeeding in a data \\nscience career, so I worked to excel at their intersection by taking classes that I felt \\nwould augment my skills.\\nI was also applying for internships my junior year, with the mindset that I wanted to \\nuse my statistical and programming skills to help companies make better decisions. I \\nreceived an internship offer from Quora and decided to take it, even though I was still \\nfairly new to the product at the time.\\nAt Quora, I touched a lot more of the codebase and learned much more about software \\nengineering. There was a sense of dynamism and importance to my project. It involved \\nnew growth initiatives, and I appreciated the level of freedom and trust that Quora gave \\nme. I enjoyed my time there working with both the people and the product a lot, so I \\ndecided to go back full-time.\\nIn my senior year, I continued developing my statistical and programming toolkit while \\nworking on my thesis.\\nWhy did you choose to major in statistics instead of computer science?\\nI put a lot of time into Stat 110 and a whole bunch of other statistics classes — I enjoyed \\nthose classes so much that it would have been unreasonable for me to major in anything \\nelse!\\nDuring my internship at Etsy, I saw first-hand how limited my abilities would be if I \\ncould only do statistics and not code. I put a lot of effort that summer into developing \\nmy abilities to analyze data in R.\\nMy junior and senior years I took an equal load of statistics and computer science courses. \\nNot having enough programming background \\nto implement your statistics knowledge can \\nseverely limit the number of things you can do. \\nI took computer science courses so I could more \\neffectively do statistics.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 278}, page_content='WILLIAM CHEN\\n274\\nI took computer science courses so I could more effectively do statistics. I took classes \\nto make me better at applying statistics (Machine Learning, Parallel Programming, Web \\nDevelopment, Data Science) or just because they were fun mathematical topics (Data \\nStructures and Algorithms, Economics and Computer Science).\\nMy primary interest is still statistics, but I heavily value computer science since it \\nempowers me to do more complicated analyses, generate visualizations, deal with \\nmassive amounts of data, and automate away a lot of my work so I can focus on what’s \\nreally interesting.\\nThat being said, I actually declared a secondary (aka minor) in Computer Science my \\nSenior Spring. I fulfilled its requirements (accidentally) and pursued the secondary \\nbecause it would require no extra effort on my part, just some paperwork.\\nCan you tell us more about what you felt that your main challenge was during your \\ndata internships?\\nOne exciting thing about working for a tech \\ncompany where data is central is that there’s \\nso many potential projects to tackle. There’s \\nso much data that can be analyzed and never \\nenough data scientists to really look deeply \\ninto every single thing. My main challenge \\nduring my internships, especially at Quora, was figuring out how to prioritize all the \\npossible things I could be doing, especially since I took on many projects in parallel.\\nAt Quora, I realized I couldn’t replicate what I did at school by working on everything \\nat the same time. I realized that I needed to prioritize things that would have the most \\nimpact for the company. I spent a bit too much time working on certain tools and not \\nenough time focusing on researching growth initiatives that would have potentially \\nhigher impact.\\nHow do you see data science in terms of it being the intersection of math, statistics \\nand computer science? What weight would you give each in terms of importance?\\nI would say that the programming and software engineering part is very important \\nbecause you may be expected to implement models, write dashboards, and pull out data \\nin creative ways. You’ll be the one in charge of hauling your own data. You’ll be the one \\nwho owns the end-to-end and the full execution, from pulling out the data to presenting \\nit to the company.\\nI realized that I needed to prioritize \\nthings that would have the most \\nimpact for the company.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 279}, page_content='WILLIAM CHEN\\n275\\nThe Pareto principle is in full effect here. Eighty percent of the time is spent pulling the \\ndata, cleaning the data, and writing the code for your analysis. I found this true during \\nmy internships (especially because I was new to everything). A good coding background \\nis particularly important here, and can save you a lot of time and frustration.\\nTo emphasize: pulling the data and figuring out what to do with it takes an enormous \\namount of time, and often doesn’t require any statistics knowledge. A lot of this is \\nsoftware engineering and writing efficient queries or efficient ways to move around and \\nanalyze your data. Programming is important here.\\nOne interesting thing to note is that the statistics used day-to-day in data science is really \\ndifferent than the kind of statistics you’d read about in a recent research paper. There’s \\na bias towards methods that are fast, interpretable, and reliable instead of theoretically \\nperfect.\\nWhile the statistics and math may not be that complicated, a strong background in \\nmath and statistics is still important to gather the intuition you need to distinguish \\nreal insights from fake insights. Also, \\na strong background and experience \\nwill give you better intuition on how to \\nsolve some of your company’s harder \\nproblems. You may have a better \\nintuition on why a certain metric might \\nbe falling or why people are suddenly \\nmore engaged in your product.\\nAnother benefit of a strong statistics and math background is the contribution to \\ncommunication. The better you understand the theoretical bases around a certain idea \\nor concept, the better you can articulate what you’re doing and communicate it with \\nthe rest of your team. As a data scientist, a large portion of your work is presenting an \\naction that you feel would have an impact. Communication is very important to make \\nthat happen.  \\nSome data science roles require a very strong statistical or machine learning background. \\nYou might be working on a feed or recommendation engine. Or dealing with problems \\nwhere you need to know time series analysis, basic machine learning techniques, linear \\nregressions, and causal inference. There are lots of kinds of data for which you’d need a \\nmore advanced statistics background to be able to analyze.\\nFiguring out the balance between computer science, statistics and math will really \\ndepend on the role you take, so these are just some of my general observations.\\nThe better you understand the theoretical \\nbases around a certain idea or concept, \\nthe better you can articulate what you’re \\ndoing and communicate it with the rest \\nof your team.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 280}, page_content='WILLIAM CHEN\\n276\\nWhy do you think so many people entering data science have Ph.D.s?\\nData science is a new field now, and employers are looking for people with the qualifications \\nto become a data scientist. Because it’s such a new field, not that many people have \\nmuch industry experience in this, so you have to find people who show some other signal \\nthat they’d be qualified for the position. Having a Ph.D. in a computational/quantitative \\nbackground is a great choice usually, since they’ve already done plenty of research and \\ndata work. Ph.D. and Master’s students with data experience often have qualities that \\nare great for data science: learning quickly, asking questions, and being resilient.\\nI think companies will start hiring \\nmore and more undergrads to fill data \\nscience roles in 5-10 years as there will \\nbe more people coming out with the \\nright data science background. There \\nare a ton more Sophomores at Harvard, \\nfor instance who want to become data \\nscientists, then there were when I was a Sophomore. I think they view it as a promising \\nand exciting career opportunity, of which I wholly agree.\\nRight now, there are plenty of MOOCs (Massive Open Online Courses) offering classes \\nand certificates, and universities all over the world are offering their first data science \\nclass. For example, Harvard’s first data science class and first predictive modeling class \\nshowed up in the 2013-2014 school year. These classes are perfect for undergrads who \\nwant to work on data.\\nIf you’re trying to hire data scientists and there are very few people with experience, \\nthose with Phds and Master’s are good candidates. That will probably change in 5 to 10 \\nyears as there will be more undergraduates who come out with the right data science \\nbackground.  \\nRight now on Coursera, there’s already a data science specialization, and at Harvard \\nthere’s a new class called Data Science taught by Joe Blitzstein and Hanspeter Pfister. Joe \\nis the same professor who taught the statistics class I loved. \\nIn Spring 2014, a predictive modeling class started at Harvard. This is a class that focuses \\non Kaggle competitions. This kind of class is perfect for undergrads who want to work \\nwith data.  \\nIf you had to go back to when you were just starting out, what would you have \\nfocused on more, and what would you have focused on less?\\nPh.D. and Master’s students with data \\nexperience often have qualities that are \\ngreat for data science: learning quickly, \\nasking questions, and being resilient.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 281}, page_content='WILLIAM CHEN\\n277\\nI think my big regret in course selection in college was not taking programming classes \\nmy freshman year. Programming is so vital in data science — there’s not that many roles \\nfor pure statisticians who don’t code unless it’s a giant company like Google or Amazon \\nthat might be specialized enough to need research statisticians. Programming is so \\nessential that you can’t get away with not doing it well.\\nWhen it comes to this term “data science”, a lot of people are worried or claim \\nthere’s a lot of hype around the field in that it’s overblown. What’s your take \\naround this hype and craze around big data and data science?\\nIt’s definitely a bit overhyped right now, just like cloud computing and the mobile / local \\n/ social craze. However, just because it’s overhyped doesn’t mean it’s not important. I \\nthink over the next few years, the hype will die down but the importance of data science \\nwill not.\\nDo you think that the need for data scientists will die down as tools get better?\\nPersonally, I appreciate the new tools a lot. I think the job of the data scientist will \\nchange a lot over the next few years as the tool kit gets better. \\nHowever, I don’t think the need for data \\nscientists will decrease because we’re \\nalways going to need people who can \\ninterpret results and distill insights into \\nactionable plans to improve business. Data \\nscience is never going to run out of hard \\nproblems — there will always be the need \\nfor people to interpret results and communicate ideas. That’s what I think data science \\nis — it’s distilling the data into actionable insights to improve product and business.\\nTools will make what some data scientists do outdated, as some startups provide \\nenterprise solutions and commoditize certain tasks. Even with the new enterprise tools, \\nthere will be a need for data scientists to be able to use the tools intelligently. You’re \\ngoing to want your data scientists to look at the results and think about how they can \\nhelp the company directly.\\nHow much domain expertise do you need in order to be a good data scientist? \\nHow much do you need to know about people’s behaviors online, and does that \\ndrive the products to be built?\\nAt Quora, I worked on a project that involved understanding user engagement. I was in \\na unique position while trying to understand that problem since I was an avid user of \\nWe’re always going to need people \\nwho can interpret results and distill \\ninsights into actionable plans to \\nimprove business.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 282}, page_content='WILLIAM CHEN\\n278\\nQuora myself. When you have domain knowledge, you have an advantage in that you \\ncan make better hypotheses on what you’re curious about before you even look at the \\ndata. You can then look at the data to gain a better intuition on why you were right or \\nwrong. Domain expertise and the intuition that comes coupled with that can help a lot, \\nespecially if your models are complicated or you need to present them to an internal \\naudience. The domain expertise facilitates \\nthe sharing of insightful stories that help \\nexplain the drivers of human behavior in \\nyour product. This is really different than \\nsome data sets on Kaggle where you aren’t \\neven given the column names (because of \\nprivacy) and don’t really understand the \\ndata you’re working with.\\nYou were choosing between quantitative finance and data science and eventually \\nchose data science. Why did that happen, and what were the considerations when \\nyou were making that decision?\\nI think quantitative finance and data science are both really good options. I’m pretty \\nsure that data science was the right option for me because I am just so excited to see \\nhow technology can change the way the world works and make everything work better. I \\nfelt like I wanted to be a part of that. I decided that in order for me to do this properly, I \\nneeded to be part of a consumer or enterprise technology firm where I was able to help \\nmake a product that empowered people to do things.\\nI also really like the teaching and communication aspects of data science — I found out \\nthat I enjoyed it when I got to help teach Statistics 110 at Harvard. Data Science has a lot \\nmore of this teaching and communication going on — often in quantitative finance all \\nyou need are your back-testing results.\\nI want to be some sort of evangelist for data, and convince people that data is useful. I feel \\nthat there’s a lot more potential to do this in the tech sector. For tech, data is very new, \\nwhile for finance, data is very old. I just found it exciting to be part of something where \\ndata was just getting a foothold. I wanted to be a part of something where technology is \\nused to empower people and make the world better.\\nWhen you have domain knowledge, \\nyou have an advantage in that you \\ncan make better hypotheses on what \\nyou’re curious about before you even \\nlook at the data.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 283}, page_content='ABOUT THE AUTHORS\\nCARL SHAN is a Data Science for Social Good Fellow in \\nChicago, where he works with President Obama’s former \\nChief Scientist on applying machine learning and data \\nscience to pressing policy issues. He’s written extensively \\non his website  about his experiences in applying machine \\nlearning to social issues. An avid reader, he co-authored \\nThe Data Science Handbook to help bring stories and \\nwisdom from pioneering data scientists into the lives of as \\nmany readers as possible. When not mired in data, Carl can \\nbe found at a pool table, or pretending to know the lyrics of \\nthe latest hit pop song. \\nCarl holds an honors degree in Statistics from UC Berkeley.\\nHENRY WANG  is an investment analyst with New \\nZealand’s sovereign wealth fund, where he focuses on \\nprivate investments in alternative energy technologies. He is \\ninterested in the intersection of data science and traditional \\ncapital intensive industries, where data driven techniques \\ncan be used to better inform operational and investment \\ndecisions. Henry is a simple guy who enjoys simple things \\nlike traveling, reading, and making delicious instant ramen.\\nHenry holds a Bachelors in Statistics from UC Berkeley.\\nWILLIAM CHEN  is a data scientist at Quora, where he \\nhelps grow and share the world’s knowledge. He is also \\nan avid writer on Quora, where he answers questions on \\ndata science, statistics, machine learning, probability, and \\nmore. William co-authored this book to share the stories \\nof data scientists and help others who want to enter the \\nprofession. For fun, he enjoys speed-solving Rubik’s cubes, \\nbuilding K’NEX ball machines, and breaking out from \\n“escape rooms”. Check out his recent projects (like The Only \\nProbability Cheatsheet You’ll Ever Need) on his website.\\nWilliam holds a Bachelors in Statistics and a Masters in \\nApplied Mathematics from Harvard.\\n'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 284}, page_content='280\\nMAX SONG  is a data scientist currently working on \\nsecret projects in Paris. Previously, he was the youngest \\ndata scientist at DARPA-backed startup Ayasdi, where he \\nused topological data analysis and machine learning to \\nbuild predictive models. He wrote a popular post about his \\njourney to become a data scientist  on Medium, and enjoys \\nthe craft of writing.  He co-authored the Data Science \\nHandbook to share the the wisdom of pioneers for those \\nlooking to trailblaze their own data science journeys. When \\nnot feverishly coding, he can be found playing improv games \\nand seeding an intellectual gathering ( Salon) in far-flung \\ncorners of the world. \\nAt the time of writing, he is on leave from Applied \\nMathematics-Biology at Brown. \\nBRITTANY CHENG is an Associate Product Manager at \\nYelp who recently launched Yelp in Taiwan. She created the \\nlayout design of The Data Science Handbook and has also \\nworked on layout designs for 120 Data Science Interview \\nQuestions and The Product Manager Handbook . When \\nshe isn’t designing handbooks, she likes to eat, talk about \\neating, drink tea, and rant about umbrellas. Read her Yelp \\nreviews to see what she’s been eating recently.\\nBrittany holds a degree in Electrical Engineering and \\nComputer Science from UC Berkeley.\\nABOUT THE AUTHORS\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98657958-0f7e-4879-b1b4-63e31179c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "\n",
    "text_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e7f5ce-a958-489e-925b-51bc562525af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 0}, page_content='THE\\nDATA SCIENCE  \\nHANDBOOK\\nADVICE A ND I NSIGHTS FROM   \\n25 AMAZING DA TA SCIEN TISTS\\nDJ Patil, Hilary Mason, Pete Skomoroch, Riley Newman, Jonathan Goldman, Michael Hochster, \\n George Roumeliotis, Kevin Novak, Jace Kohlmeier, Chris Moody, Erich Owens, Luis Sanchez, \\n Eithon Cadag, Sean Gourley, Clare Corthell, Diane Wu, Joe Blitzstein, Josh Wills, Bradley Voytek, \\n Michelangelo D’Agostino, Mike Dewar, Kunal Punera, William Chen, John Foreman, Drew Conway\\nBY M AX  S ONGHE N RY  W ANG WI LL IA M  C HENCA R L  SHAN\\nFOREWORD BY JAKE K LAMKA\\nSold to\\nmenogetusername@gmail.com'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 1}, page_content='To our family, friends and mentors. \\nYour support and encouragement is the fuel for our fire.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 2}, page_content='CONTENTS\\nPreface by Jake Klamka, Insight Data Science     1 \\nIntroduction            4\\nChapter 1: DJ Patil, VP of Product at RelateIQ\\nThe Importance of Taking Chances and Giving Back    6\\nChapter 2: Hilary Mason, Founder at Fast Forward Labs\\nOn Becoming a Successful Data Scientist      17\\nChapter 3: Pete Skomoroch, Data Scientist at Data Wrangling\\nSoftware is Eating the World, and It’s Replacing it With Data  27\\nChapter 4: Mike Dewar, Data Scientist at New York Times\\nData Science in Journalism        40\\nChapter 5: Riley Newman, Head of Data at AirBnB\\nData Is The Voice Of Your Customer       49\\nChapter 6: Clare Corthell, Data Scientist at Mattermark\\nCreating Your Own Data Science Curriculum     56\\nChapter 7: Drew Conway, Head of Data at Project Florida\\nHuman Problems Won’t Be Solved by Root-Mean-Squared Error 64\\nChapter 8: Kevin Novak, Head of Data Science at Uber\\nData Science: Software Carpentry, Engineering and Product  76\\nChapter 9: Chris Moody, Data Scientist at Square\\nFrom Astrophysics to Data Science       84'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 3}, page_content='CONTENTS\\nChapter 10: Erich Owens, Data Engineer at Facebook\\nThe Importance of Software Engineering in Data Science  95\\nChapter 11: Eithon Cadag, Principal Data Scientist at Ayasdi\\nBridging the Chasm: From Bioinformatics to Data Science  102\\nChapter 12: George Roumeliotis, Senior Data Scientist at Intuit\\nHow to Develop Data Science Skills       115\\nChapter 13: Diane Wu, Data Scientist at Palantir\\nThe Interplay Between Science, Engineering and Data Science 123\\nChapter 14: Jace Kohlmeier, Dean of Data Science at Khan Academy\\nFrom High Frequency Trading to Powering Personalized Education  130\\nChapter 15: Joe Blitzstein, Professor of Statistics at Harvard University\\nTeaching Data Science and Storytelling      140\\nChapter 16: John Foreman, Chief Data Scientist at MailChimp\\nData Science is not a Kaggle Competition     151\\nChapter 17: Josh Wills, Director of Data Science at Cloudera\\nMathematics, Ego Death and Becoming a Better Programmer 169\\nChapter 18: Bradley Voytek, Computational Cognitive Science Professor \\nat UCSD\\nData Science, Zombies and Academia      181\\nChapter 19: Luis Sanchez, Founder and Data Scientist at ttwick\\nAcademia, Quantitative Finance and Entrepreneurship   191\\nChapter 20: Michelangelo D’Agostino, Lead Data Scientist at Civis Analytics\\nThe U.S. Presidential Elections as a Physical Science   202'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 4}, page_content='CONTENTS\\nChapter 21: Michael Hochster, Director of Data Science at LinkedIn\\nThe Importance of Developing Data Sense    213\\nChapter 22: Kunal Punera, Co-Founder/CTO at Bento Labs\\nData Mining, Data Products, and Entrepreneurship   227\\nChapter 23: Sean Gourley, Co-founder and CTO at Quid\\nFrom Modeling War to Augmenting Human Intelligence  245\\nChapter 24: Jonathan Goldman, Dir. of Data Science & Analytics at Intuit\\nHow to Build Novel Data Products and Companies   266\\nChapter 25: William Chen, Data Scientist at Quora\\nFrom Undergraduate to Data Science     272\\nAbout the Authors          279'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 5}, page_content='PREFACE\\nIn the past five years, data science has made an impact in almost every major area of \\nhuman endeavour. From commerce, to education, to energy, and of course, software and \\nthe Internet, data science has created immense value across the world. In fact, in early \\n2015 the President of the United States announced the new role of Chief Data Scientist \\nto the White House and appointed DJ Patil, one of the interviewees in this book, to the \\nposition.\\nLike many innovations in the world, the birth of this industry was started by a few \\nmotivated people. Over the last few years, they founded, developed and advocated for \\nthe value that data analytics can bring to every industry. In The Data Science Handbook, \\nyou will have the opportunity to meet many of these founding data scientists, hear first \\nhand accounts of the incredible journeys they took, and read where they believe the field \\nis headed.\\nThe road to becoming a data scientist is not always an easy one. When I tried to transition \\nfrom experimental particle physics to industry, resources were few and far between. In \\nfact, although a need for data science existed in companies, the job title had not even \\nbeen created. I spent a lot of time teaching myself, working on various startup projects, \\nand later saw many of my friends from academia run into the same challenges.\\nI observed a groundswell of incredibly gifted and highly trained researchers who were \\nexcited about moving into data-driven roles, yet were missing key pieces of knowledge \\nabout how to do so. As a result, they had trouble transferring their incredible quantitative \\nand data analysis research skills to a career in industry. Meanwhile, having lived and \\nworked in Silicon Valley, I also saw that there was very strong demand from technology \\ncompanies who wanted to hire these exact people. \\nTo help others bridge the gap between academia and industry, I founded the Insight Data \\nScience Fellows Program in 2012. Insight is a training fellowship that helps quantitative \\nPhDs transition from academia to industry. Over the last few years, we’ve helped hundreds \\nof Insight Fellows, from fields like physics, computational biology, neuroscience, math, \\nand engineering, transition from a background in academia to become leading data \\nscientists at companies like Facebook, Airbnb, LinkedIn, The New York Times, Memorial \\nSloan Kettering Cancer Center and nearly a hundred other companies.\\nIn my personal journey to both entering the technology field as well as creating a \\ncommunity for others to do the same, one key resource I found to be tremendously useful \\nwas conversations with those who had successfully made the transition. As I developed \\nInsight, I have had the chance to engage with some of Silicon Valley’s best data scientists \\nwho are mentors to the program:'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 6}, page_content='2PREFACE\\nJonathan Goldman created one of the first data products at LinkedIn—People You May \\nKnow—which transformed the growth trajectory of the company. DJ Patil built and grew \\nthe data science team at LinkedIn into a powerhouse and co-coined the term “Data \\nScientist.” Riley Newman worked on developing product analytics that was instrumental \\nin Airbnb’s growth. Jace Kohlmeier led the data team at Khan Academy that helped \\noptimize learning for millions of students.\\nUnfortunately, it’s hard to get face-to-face time with these remarkable people. At Insight, \\nto maintain an exceptionally high quality and personal time with these mentors, we \\nselect only a small group of talented scientists and engineers three times per year. \\nHowever, The Data Science Handbook provides readers with a way to have these in-\\ndepth conversation at scale.\\nBy reading the interviews in The Data Science Handbook, you will have the experience \\nof learning from the leaders in data science at your own pace, no matter where you are \\nin the world. Each interview is an in-depth conversation, covering the personal stories of \\nthese data scientists from their initial experiences that helped them find their own path \\nto a career in data science.\\nIt’s not just the early data science leaders who can have a big impact on the field. There \\nis also new talent entering, with the opportunity for each and every new member to push \\nthe field forward. When I met the authors of this book, they were still college students \\nand aspiring data scientists, full of the same questions that those beginning in data \\nscience have. \\nThrough 18 months of hard work, they have done the legwork in seeking out some of the \\nbest data scientists around the country, and asking them for their advice and guidance. \\nThis book is the result of that work, containing over 100 hours of collected wisdom with \\npeople otherwise inaccessible to most of us (imagine having to compete with President \\nObama to talk with DJ Patil!).\\nBy reading these extended, informal interviews, you will get to sit down with industry \\ntrailblazers like DJ Patil, Jonathan Goldman and Pete Skomoroch, who were all part \\nof the early, core LinkedIn data science teams. You will meet with Hilary Mason and \\nDrew Conway, who were instrumental in creating the thriving New York data science \\ncommunity. You will hear advice from the next generation of data science leaders, like \\nDiane Wu and Chris Moody, both Insight Alumni, who are now blazing new trails at \\nMetaMinds and Stitch Fix. \\nYou will meet data scientists who are having a big impact in academia, including Bradley \\nVoytek from UC San Diego and Joe Blitzstein from Harvard. You will meet data scientists'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 7}, page_content='3\\nin startups, such as Clare Corthell from Mattermark and Kunal Punera of Bento Labs, \\nwho will share how they use data science as a core competitive advantage.\\nThe data scientists in the Data Science Handbook, along with dozens of others, have \\nhelped create the very industry that is now having such a tremendous impact on the \\nworld. Here in this book, they discuss the mindset that allowed them to create this \\nindustry, address misconceptions about the field, share stories of specific challenges and \\nvictories, and talk about what they look for when building their teams. \\nI hope that by reading their stories, hearing how they think, and learning their vision for \\nthe future of data science, you will come to think of ways you can have an impact, and \\nperhaps even advance the field yourself.\\nJake Klamka\\nFounder\\nInsight Data Science Fellows Program\\nInsight Data Engineering Fellows Program\\nInsight Health Data Science Fellows Program\\nPREFACE'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 8}, page_content='INTRODUCTION\\nWelcome to The Data Science Handbook!\\nIn the following pages, you will find in-depth interviews with 25 remarkable data \\nscientists. They hail from a wide selection of backgrounds, disciplines, and industries. \\nSome of them, like DJ Patil and Hilary Mason, were part of the trailblazing wave of data \\nscientists who catapulted the field into national attention. Others are at the start of their \\ncareers, such as Clare Corthell, who made her own path to data science by creating the \\nOpen Source Data Science Masters, a self-guided curriculum built on freely available \\ninternet resources. \\nHow We Hope You Can Use This Book\\nIn assembling this book, we wanted to create something that could both last the test of \\ntime as well as address your interest in data science no matter what background you may \\nhave. We crafted our book so that it can be something you come back to again and again, \\nto re-read at different stages in your career as a data professional. \\nBelow, we’ve listed the knowledge our book can offer. While each interview is fascinating \\nin its own right, and covers a large portion of the knowledge spectrum, we’ve highlighted \\na few interviews to give you a quick start: \\n• As an aspiring data scientist  - you’ll find concrete examples and advice of how to \\ntransition into the industry.\\n• Suggested interviews: William Chen, Clare Corthell, Diane Wu\\n• As a working data scientist - you’ll find suggestions on how to become more effective \\nand grow in your career.\\n• Suggested interviews: Josh Wills, Kunal Punera, Jace Kohlmeier\\n• As a leader of a data science team - you’ll find time-tested advice on how to hire \\nother data scientists, build a team, and work with product and engineering. \\n• Suggested interviews: Riley Newman, John Foreman, Kevin Novak\\n• As an entrepreneur or business owner - you’ll find insights on the future of data \\nscience and the opportunities on the horizon.\\n• Suggested interviews: Sean Gourley, Jonathan Goldman, Luis Sanchez\\n• As a data-curious citizen  - you’ll find narratives and histories of the field, from \\nsome of the first data pioneers.\\n• Suggested interviews: DJ Patil, Hilary Mason, Drew Conway, Pete Skomoroch\\nIn collecting, curating and editing these interviews, we focused on having a deep and \\nstimulating conversation with each data scientist. Much of what’s inside is being told \\npublicly for the first time. You’ll hear about their personal backgrounds, worldviews, \\ncareer trajectories and life advice.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 9}, page_content='5INTRODUCTION\\nIn the following pages, you’ll learn how these data scientists navigated questions such \\nas:\\n• Why is data science so important in today’s world and economy?\\n• How does one master the triple disciplines of programming, statistics and domain \\nexpertise to become an effective data scientist? \\n• How do you transition from academia, or other fields, to a position in data science?\\n• What separates the work of a data scientists from a statistician, and a software \\nengineer? How can they work together? \\n• What should you look for when evaluating data science roles at companies?\\n• What does it take to build an effective data science team? \\n• What mindsets, techniques and skills distinguishes a great data scientist from the \\nmerely good?\\n• What lies in the future for data science?\\nAfter you read these interviews, we hope that you will see the road to becoming a data \\nscientist is as diverse and varied as the discipline itself. Good luck on your own journey, \\nand and feel free to get in touch with us at contact@thedatasciencehandbook.com!\\n— Carl, Henry, William and Max'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 10}, page_content='DJ PATIL VP of Product at RelateIQ\\nSomething that touched a lot of people from your presentations is your speech \\non failure. It’s surprising to see someone as accomplished as yourself talk about \\nfailure. Can you tell us a bit more about that?\\nSomething most people struggle with when starting their career is how they enter the \\njob market correctly. The first role you have places you in a “box” that other people \\nuse to infer what skills you have. If you enter as a salesperson you’re into sales, if you \\nenter as a media person you’re into media, if you enter as a product person you’re into \\nproducts etc. Certain boxes make more sense to transition in or out of than other ones. \\n \\nThe academic box is a tough one because automatically, by definition, you’re an \\nacademic. The question is: Where do you go from there? How do you jump into a different \\nbox? I think we have a challenge that people and organizations like to hire others like \\nDJ Patil is co-coiner of the term ‘Data Scientist’ and co-\\nauthor of the Harvard Business Review article: “Data \\nScientist: Sexiest Job of the 21st Century.”\\n \\nFascinated by  math at an  early age, DJ completed a B.A. \\nin Mathematics at University of California, San Diego and \\na PhD in Applied Mathematics at University of Maryland \\nwhere he studied nonlinear dynamics, chaos theory, and \\ncomplexity. Before joining the tech world, he did nearly a \\ndecade of research in meteorology, and consulted for the \\nDepartment of Defense and Department of Energy. During \\nhis tech career, DJ has worked at eBay as a Principal \\nArchitect and Research Scientist, and at LinkedIn as Head of Data Products, where he \\nco-coined the term “Data Scientist” with Jeff Hammerbacher and built one of the premier \\ndata science teams. He is now VP of Product at RelateIQ, a next generation, data-driven \\ncustomer relationship management (CRM) software.  Most recently RelateIQ was acquired \\nby Salesforce.com for its novel data science technology.\\n \\nIn his interview, DJ talks about the importance of taking chances, seeking accelerations in \\nlearning, working on teams, rekindling curiosity, and giving back to the community that \\ninvests in you. \\nSince we interviewed him, DJ has gone on to be appointed by President Barack Obama as the \\nfirst United States Chief Data Scientist.\\nThe Importance of Taking Chances and Giving Back'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 11}, page_content='7\\nthemselves. For example, at Ayasdi (a topological machine learning company) there’s a \\ndisproportionate amount of mathematicians and a surprising number of topologists.\\n \\nFor most people who come from academia, the first step is that someone has to take a \\nrisk on you. Expect that you’re going to have to talk to lots and lots of people. It took me \\n6 months before eBay took a chance on me. Nobody just discovers you at a cafe and says \\n“Hey, by the way you’re writing on that piece of napkin, you must be smart!” That’s not \\nhow it works, you must put yourself in positions where somebody can actually take a risk \\non you, before they can give you that opportunity.\\n \\nAnd to do that, you must \\nhave failed many times, \\nto the point where some \\npeople are not willing to \\ntake a risk on you. You \\ndon’t get your lucky break \\nwithout seeing a lot of \\npeople slamming doors in \\nyour face. Also, it’s not like \\nthe way that you describe yourself is staying the same; your description is changing and \\nevolving every time you talk to someone.  You are doing data science in that way. You’re \\niterating on how you are presenting yourself and you’re trying to figure out what works.\\n \\nFinally someone takes a chance on you, but once you’ve found somebody, the question \\nis how do you set yourself up for success once you get in? I think one of the great things \\nabout data science is it’s ambiguous enough now, so that a lot of people with extra \\ntraining fit the mold naturally. People say, “Hey, sure you can be a data scientist! Maybe \\nyour coding isn’t software engineering quality coding, but your ability to learn about a \\nproblem and apply these other tools is fantastic.”\\n \\nNobody in the company actually knows what these tools are supposed to be, so you get \\nto figure it out. It gives you latitude. The book isn’t written yet, so it’s really exciting.\\nWhat would you suggest as the first step to putting yourself out there and figuring \\nout what one should know? How does one first demonstrate one’s value?\\n \\nIt first starts by proving you can do something, that you can make something.\\n \\nI tell every graduate student to do the following exercise: when I was a grad student I \\nwent around to my whole department and said, “I want to be a mathematician. When I say \\nthe word mathematician, what does that mean to you? What must every mathematician \\nknow?”\\nDJ PATIL\\nNobody just discovers you at a cafe and says “Hey, \\nby the way you’re writing on that piece of napkin, you \\nmust be smart!” That’s not how it works, you must \\nput yourself in positions where somebody can actually \\ntake a risk on you, before they can give you that \\nopportunity.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 12}, page_content='8\\nI did it, and the answers I got were all different. What the hell was I supposed to do? \\nNo one had a clear definition of what a mathematician is! But I thought, there must \\nbe some underlying basis. Of course, there’s a common denominator that many people \\ncame from. I said, okay, there seem to be about three or four different segmentations. \\nThe segmentation I thought was the most important was the segmentation that gave \\nyou the best optionality to change if it ended up being a bad idea.\\n \\nAs a result of that, I took a lot of differential equations classes, and a bunch of probability \\nclasses, even though that wasn’t my thing. I audited classes, I knew how to code, I was \\nlearning a lot about physics — I did everything I could that was going to translate to \\nsomething that I could do more broadly.\\n \\nMany people who come out of academia are very one-dimensional. They haven’t proven \\nthat they can make anything, all they’ve proven is that they can study something that \\nnobody (except maybe their advisor and their advisor’s past two students) cares about. \\nThat’s a mistake in my opinion. During that time, you can solve that hard PhD caliber \\nproblem AND develop other skills. \\n \\nFor example, aside from your time in the lab, you can be out interacting with people, \\ngoing to lectures that add value, attending hackathons, learning how to build things. It’s \\nthe same reason that we don’t tell someone, \\n“First, you have to do research and then you \\nlearn to give a talk.”  These things happen \\ntogether. One amplifies the other.\\n \\nSo my argument is that people right now \\ndon’t know how to make things. And once \\nyou make it, you must also be able to tell the story, to create a narrative around why you \\nmade it.\\n \\nWith that comes the other thing that most academics are not good at. They like to tell you, \\nrather than listen to you, so they don’t actually listen to the problem. In academia, the \\nfirst thing you do is sit at your desk and then close the door. There’s no door anywhere in \\nSilicon Valley; you’re out on the open floor. These people are very much culture shocked \\nwhen people tell them, “No you must be working, collaborating, engaging, fighting, \\ndebating, rather than hiding behind the desk and the door.”\\n \\nI think that’s just lacking in the training, and where academia fails people. They don’t \\nget a chance to work in teams; they don’t work in groups.\\nUndergrad education, however is undergoing some radical transformations. We’re seeing \\nthat shift if you just compare the amount of hackathons, collaboration, team projects \\nDJ PATIL\\nIt first starts by proving you can \\ndo something, that you can make \\nsomething.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 13}, page_content='9\\nthat exist today versus a few years ago. It’s really about getting people trained and ready \\nfor the work force. The Masters students do some of that as well but the PhDs do not. \\nI think it’s because many academics are interested in training replicas of themselves \\nrather than doing what’s right for society and giving people the optionality as individuals \\nto make choices.\\n \\nHow does collaboration change from academic graduate programs to working in \\nindustry?\\n \\nPeople make a mistake by forgetting that \\ndata science is a team sport. People might \\npoint to people like me or Hammerbacher or \\nHilary or Peter Norvig and they say, oh look \\nat these people! It’s false, it’s totally false, \\nthere’s not one single data scientist that does it all on their own. data science is a team \\nsport, somebody has to bring the data together, somebody has to move it, someone needs \\nto analyse it, someone needs to be there to bounce ideas around.\\n \\nJeff couldn’t have done this without the rest of the infrastructure team at Facebook, \\nthe team he helped put together. There are dozens and dozens of people that I could \\nnot have done it without, and that’s true for everyone! Because it’s a bit like academia, \\npeople see data scientists as solo hunters. That’s a false representation, largely because \\nof media and the way things get interpreted.\\nDo you think there’s going to be this evolution of people in data science who work \\nfor a few years, then take those skills and then apply them to all sorts of different \\nproblem domains, like in civics, education and health care?\\n \\nI think it’s the beginning of a trend. I hope it becomes one. Datakind is one of the first \\nexamples of that, and so is data science for Social Good. One of the ones that’s personally \\nclose to my heart is something called Crisis Text Line. It comes out of DoSomething.org \\n— they started this really clever texting campaign as a suicide prevention hotline and \\nthe result is we started getting these text messages that were just heart wrenching.\\nThere were calls that said “I’ve been raped by my father,” “I’m going to cut myself,” “I’m \\ngoing to take pills,” really just tragic stuff. Most teens nowadays do not interact by voice \\n- calling is tough but texting is easy. The amount of information that is going back and \\nforth between people who need help and people who can provide help through Crisis \\nText Line is astonishing.\\n \\nHow do we do it? How does it happen? There are some very clever data scientists there \\nwho are drawn to working on this because of its mission, which is to help teens in crisis. \\nDJ PATIL\\nPeople make a mistake by forgetting \\nthat data science is a team sport.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 14}, page_content='10\\nThere’s a bunch of technology that is allowing us to do things that couldn’t be done \\nfive, six years ago because you’d need this big heavyweight technology that cost a lot of \\nmoney. Today, you can just spin up your favorite technology stack and get going.\\n \\nThese guys are doing phenomenal work. They are literally saving lives. The sophistication \\nthat I see from such a small organization in terms of their dashboards rivals some of the \\nmuch bigger, well-funded types of places. This is because they’re good at it. They have \\naccess to the technology, they have the brain power. We have people jumping in who \\nwant to help, and we’re seeing this as not just a data science thing but as a generational \\nthing where all technologists are willing to help each other as long as it’s for a great \\nmission.\\n \\nJennifer Aaker just wrote about this in a New York Times op-ed piece — that the millennial \\ngeneration is much more mission driven. What defines happiness for them is the ability \\nto help others. I think that there is a fundamental shift happening. In my generation it’s \\nruled by empathy. In your generation, it’s about compassion. The difference between \\nempathy and compassion is big. Empathy is understanding the pain. Compassion is \\nabout taking away the pain away from others, it’s about solving the problem. That small \\nsubtle shift is the difference between a data scientist that can tell you what the graph \\nis doing versus telling you what action you need to do from the insight. That’s a force \\nmultiplier by definition.\\n \\nCompassion is also critical for designing beautiful and intuitive products, by solving \\nthe pain of the user. Is that how you chose to work in product, as the embodiment \\nof data?\\n \\nI think the first thing that people don’t recognize is that there are a number of people \\nwho have started very hard things who also have very deep technical backgrounds.\\nTake Fry’s Electronics for example. John Fry, the founder, is a mathematician. He built \\na whole castle for one of the mathematical associations out in Morgan Hill, that’s how \\nmuch of patron of the arts he is for them. Then you can look at Reed Hastings of Netflix, \\nhe’s a mathematician. My father and his generation, all of the old Silicon Valley crew \\nwere all hardcore scientists. I think it just goes on to show - you look in these odd places \\nand you see things you would not have guessed.\\nI think there’s two roles that have been interesting to me in companies: the first is you’re \\nstarting something from scratch and the second is you’re in product. Why those two \\nroles? If you start the company you’re in product by definition, and if you’re in product \\nyou’re making. It’s about physically making something. Then the question is, how do \\nyou make? There’s a lot of ways and weapons you can use to your advantage. People \\nDJ PATIL'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 15}, page_content='11\\nsay there is market assessment, you can do this detailed market assessment, you can \\nidentify a gap in the market right there and hit it.\\n \\nThere’s marketing products, where you build something and put a lot of whizbang \\nmarketing, and the marketing does phenomenally. There are engineering products which \\nare just wow — you can say this is just so well engineered, this is phenomenal, nobody \\ncan understand it, but it’s great, pure, raw engineering. There is designing products, \\ncreating something beautifully. And then, there’s data.\\n \\nThe type of person I like best is the one who has two strong suits in these domains, not \\njust one. Mine, personally, are user experience (UX) and data. Why user experience and \\ndata? Most people say you have to be one or the other, and that didn’t make sense to me \\nbecause the best ways to solve data problems are often with UX. Sometimes, you can be \\nvery clever with a UX problem by surfacing data in a very unique way.\\n \\nFor example, People You May Know (a viral \\nfeature at LinkedIn that connected the social \\ngraph between professionals) solved a design \\nproblem through data. You would join the \\nsite, and it would recommend people to you \\nas you onboard on the website. But People \\nYou May Know feels creepy if the results are \\ntoo good, even it it was just a natural result of an algorithm called triangle closing. They’d \\nask, “How do you know that? I just met this person!” To fix this, you could say something \\nlike “You both know Jake.” Then it’s obvious. It’s a very simplistic design element that \\nfixes the data problem. My belief is that by bringing any two elements together, it’s no \\nlonger a world of one.\\n \\nAnother way to say this is, how do you create versatility? How do you make people \\nwith dynamic range, which is the ability to be useful in many different contexts? The \\nassumption is our careers are naturally changing at a faster rate than we’ve ever seen \\nthem change before. Look at the pace at which things are being disrupted. It’s astonishing. \\nWhen I first got here eBay was the crazy place to be and now they’re on a turnaround. \\nYahoo went from being the mammoth place to now attempting a turnaround. We’ve had \\ncompanies that just totally disappeared.\\nI see a spectrum of billion dollar companies coming and going. We’re seeing something \\nvery radical happening. Think about Microsoft. Who wouldn’t have killed for a role in \\nMicrosoft ten years ago? It was a no brainer. But not anymore.\\n \\nBecause of the pace at which the world changes, the only way to prepare yourself is by \\nDJ PATIL\\nBecause of the pace at which the \\nworld changes, the only way to \\nprepare yourself is by having that \\ndynamic range.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 16}, page_content='12\\nhaving that dynamic range. I think what we’re realizing also is that different things give \\nyou different elements of dynamic range. Right now data is one of those because it’s \\nso scarce. People are getting the fact that this is happening. It gives a disproportionate \\nadvantage to those who are data savvy.\\n \\nYou mentioned earlier that when you were looking to become a mathematician you \\npicked a path that optimized for optionality. As a data scientist, what type of skills \\nshould one be building to expand or broaden their versatility?\\n \\nI think what data gives you is a unique excuse to interact with many different functions \\nof a business. As a result, you tend to be more in the center and that means you get \\nto understand what lots of different functions are, what other people do, how you can \\ninteract with them.  In other words, you’re constantly in the fight rather than being \\nrelegated to the bench. So you get a lot of time on the field. That’s what changes things.\\n \\nThe part here I think people often miss is \\nthat they don’t know how much work this is. \\nTake an example from RelateIQ. I’m in the \\nproduct role (although they say I’m supposed \\nto be the head of product here, I think of \\nthese things as team sports and that we’re \\nall in it together), and I work over a hundred \\nhours a week easily. If I had more time I’d go \\nfor longer hours. I think one of the things that people don’t recognize is how much net \\ntime you just have to put in. It doesn’t matter how old you are or how good you are, you \\nhave to put in your time.\\n \\nYou’re not putting in your time because of some mythical ten thousand hours thing (I \\ndon’t buy that argument at all, I think it’s false because it assumes linear serial learning \\nrather than parallelized learning that accelerates). You put in your time because you can \\nlearn a lot more about disparate things that fit into the puzzle together. It’s like a stew, \\nit only becomes good if it’s been simmering for long time.\\n \\nOne of the first things I tell new data scientists when they get into the organization is \\nthat they better be the first ones in the building and the last ones out. If that means four \\nhours of sleep, get used to it. It’s going to be that way for the first six months, probably \\na year plus.\\nThat’s how you accelerate on the learning curve. Once you get in there, you’re in the \\nconversations. You want to be in those conversations where people are suffering at two \\nin the morning. You’re worn down. They are worn down. All your emotional barriers \\ncome down and now you’re really bonding. There’s a reason they put Navy Seals through \\nDJ PATIL\\nOne of the first things I tell new data \\nscientists when they get into the \\norganization is that they better be \\nthe first ones in the building and the \\nlast ones out.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 17}, page_content='13\\ntraining hell. They don’t put them in hell during their first firefight. You go into a firefight \\ncompletely unprepared and you die. You make them bond before the firefight so you can \\nrely on each other and increase their probability of survival in the firefight. It’s not about \\nbonding during the firefight, it’s about bonding before.\\nThat’s what I would say about the people you talked to at any of the good data places. \\nThey’ve been working 10x harder than most places, because it is do or die. As a result, \\nthey have learned through many iterations. That’s what makes them good.\\nWhat can you do on a day-to-day basis that can make you a good data scientist?\\nI don’t think we know. I don’t \\nthink we have enough data on it. I \\ndon’t think there’s enough clarity \\non what works well and what \\ndoesn’t work well. I think you can \\ndefinitely say some things increase \\nthe probability of personal success. \\nThat’s not just about data science, \\nit’s about listening hard, being a good team player, picking up trash, making sure balls \\ndon’t get dropped, taking things off people’s plates, being there for the team rather than \\nas an individual, and focusing on delivering value for somebody or something.\\n \\nWhen you do that, you have a customer (could be internal, external, anybody). I think \\nthat’s what gives you the lift. Besides the usual skills, the other thing that’s really \\nimportant is the ability to make, storytell, and create narratives. Also, never losing the \\nfeeling of passion and curiosity.\\n \\nI think people that go into academia early, go in with passion. You know that moment \\nwhen you hear a lecture about something, and you’re saying, “Wow! That was mind \\nblowing!” That moment on campus when you’re saying, “Holy crap, I never saw it \\ncoming.” Why do we lose that?\\n \\nHere is a similar analogy. If you watch kids running around a track, and the parents want \\nto leave, the kids always answer, “One more! One more!” You watch an adult run laps, \\nand they are thinking, “How many more do I have to do?” You count down the minutes \\nto the workout, instead of saying, “Wow, that was awesome!”\\n \\nI feel that once you flip from one to the other you’ve lost something inherently. You have \\nto really fight hard to fill your day with things that are going to invigorate you on those \\nfronts. One more conversation, one more fight, one more thing. When you find those \\nDJ PATIL\\nIf you watch kids running around a track, and \\nthe parents want to leave, the kids always \\nanswer, “One more! One more!” You watch \\nan adult run laps, and they are thinking, “How \\nmany more do I have to do?”'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 18}, page_content='14\\nenvironments, that’s rare. When you’re around people who are constantly inspiring you \\nwith tidbits of information, I feel like that’s when you’re lucky.\\n \\nIs all learning the same? What value can you bring as a young data scientist to \\npeople who have more knowledge than yourself?\\n \\nThere’s a difference between knowledge and wisdom. I think that’s one of the classic \\nchallenges with academia. You can take a high school kid who can build an app better than \\na person with a doctorate who works in algorithms, and it’s because of their knowledge \\nof the app ecosystem. Wisdom also goes the other way: if you’re working on a very hard \\nacademic problem, you can look at it and say, “That’s going to be O(n2)”.\\n \\nI was very fortunate when I was at eBay, as I happened \\nto get inserted in a team where there was a lot of \\nwisdom. Even though eBay was moving very slowly in \\nthings we were doing, I was around a lot of people who \\nhad a disproportionate amount of wisdom, so I was the \\nstupidest guy with the least amount of tours of duty. But at the same time, I was able to \\nadd value because I saw things in ways that they had never seen. So we had to figure out \\nwhere that wisdom aligned and where it didn’t.\\n \\nThe other side of that was at LinkedIn, when you’re on that exponential curve trajectory \\nwith a company. People say, “Well you were only at the company for three plus years,” \\nbut I happened to be there when it grew from couple hundred to a couple thousand \\npeople. Being in a place where you see that crazy trajectory is what gives you wisdom, \\nand that’s the type of thing that I think compounds massively.\\n \\nMany young people today are confronted with this problem related to knowledge \\nand wisdom. They have to decide: Do they do what they’re deeply passionate \\nabout in the field they care most about? Or do they do the route that provides \\nthem with the most immediate amount of growth? Do they go compound the \\nknowledge of skills, or do they build wisdom in that domain? \\n \\nIt’s a good and classic conundrum. I’ve gone with it as a non-linear approach: you go \\nwhere the world takes you. The way I think about it is, wherever you go, make sure you’re \\naround the best people in the world.\\n \\nI’m a firm believer in the apprentice model, I was very fortunate that I got to train with \\npeople like James Yorke who coined with the term “chaos theory.” I was around Sergey \\nBrin’s dad. I was around some really amazing people and their conversations are some of \\nthe most critical pieces of input in my life, I think I feel very grateful and fortunate to be \\nDJ PATIL\\nI’m a firm believer in the \\napprentice model'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 19}, page_content='15\\naround these people. Being around people like Reid Hoffman, Jeff Weiner is what makes \\nyou good and that gives you wisdom.\\nSo for that tradeoff, if you’re going to be around somebody that’s phenomenal at \\nGoogle, great! If you’re going to be around someone super phenomenal in the education \\nsystem, great! Just make sure whatever you are doing, you’re accelerating massively. The \\nderivative of your momentum better be changing fast in the positive direction. It’s all \\nabout derivatives.\\nWhat do you think about risk taking, and defining oneself?\\n \\nEveryone needs  to chart their own destiny. The only I thing I think is for certain is \\nthat as an individual, you get to ask the questions, and by asking the questions and \\ninterpreting the answers, you decide the narrative that is appropriate for you. If the \\nnarrative is wrong, it’s your narrative to change. If you don’t like what you’re doing, you \\nget to change it.\\n \\nIt may be ugly, maybe hard or painful but the best thing is when you’re younger, you \\nget to take crazy swings at bats that you don’t get to take later on. I couldn’t do half the \\nstuff I was doing before, and I’m very envious of people who get to. And that’s a part of \\nlife, there’s the flip side of when you do have \\nfamily, or responsibilities, that you’re paying \\nfor that next generation. Your parents put a \\nlot on the line to try to stay in a town with \\ngreat schools, and they may not have taken \\nthe risk that they would’ve normally taken to \\ndo these things.\\n \\nThat’s part of the angle by which you play. It’s also the angle which is the difference \\nbetween what it means as an individual and team player. Sometimes you can’t do the \\nthings that you want to do. It’s one of the reasons I’ve become less technical. Take \\nsomeone like Monica Rogati or Peter Skomoroch, two amazing data scientists and \\nengineers at LinkedIn. What’s a better use of my time? Taking a road block out of their \\nway or me spending time debugging or coding something on my own?\\nIn the role I have, in the position and what was expected of me, my job was to remove \\nhurdles from people, my job was to construct the narrative to give other people runway \\nto execute, their job was to execute and they did a hell of a good job at it.\\n \\nYou have talked about your research as a way to give back to the public that \\ninvested in you. Is there an aspect of the world that you feel like could really use \\nDJ PATIL\\nIf the narrative is wrong, it’s your \\nnarrative to change. If you don’t \\nlike what you’re doing, you get to \\nchange it.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 20}, page_content='16\\nthe talent and skills of data scientists to improve it for the better?\\n \\nI think we’re starting to see elements of it. \\nThe Crisis Text Line is a huge one. That’s why \\nI put a lot of my time and energy into that \\none. But there are so many others: national \\nsecurity, basic education, government, Code \\nfor America. I think about our environment, \\nunderstanding weather, understanding those elements, I would love to see us tackle \\nharder problems there.\\n \\nIt’s hard to figure out how you can get involved in these things, they make it intentionally \\nclosed off. And that’s one of the cool things about data, it is a vehicle to open things up. I \\nfell into working on weather because the data was available and I said to myself, “I can do \\nthis!” As a result, you could say I was being a data scientist very early on by downloading \\nall this crazy data and taking over the computers in the department. The data allowed \\nme to become an expert in the weather, not because I spent years studying it, because I \\nwas playing around and that gave me the motivation to spend years studying it.\\nFrom rekindling curiosity, to exploring data, to exploring available venues, it seems \\nlike a common thread in your life is about maximizing your exposure to different \\nopportunities. How do you choose what happens next?\\n \\nYou go where the barrier of entry is low. I don’t like working on things where it’s hard. \\nMy PhD advisor gave me a great lesson — he said only work on simple things; simple \\nthings become hard, hard things become intractable.\\n \\nSo work on simple things?\\nJust simple things.\\nDJ PATIL\\nOnly work on simple things; simple \\nthings become hard, hard things \\nbecome intractable.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 21}, page_content='HILARY MASON Founder at Fast Forward Labs\\nWhat do you do as a data scientist in residence?\\nI do three things. First, I occasionally help the partners talk through an interesting \\ntechnology or company. Second, I work with companies in the Accel portfolio. I help \\nthem when they run into an interesting or challenging data question. Finally, I help \\nAccel think through what the next generation of data companies might look like.\\n \\nDo you expect this to be a growing trend, the fact that VC firms are hiring data \\nscientists in residence?\\n \\nWe’re at a point where there are very few people who’ve spent years building data science \\norganizations in a company or building data-driven products. Having people with even \\njust a few years of expertise in doing that is valuable.\\n \\nI don’t expect that this will be nearly as difficult in the future as it is now. Because data \\nscience is so new — there are only a few people who have been doing this for a long time. \\nTherefore it really helps a VC firm to have access to someone who they can send to one \\nof their companies when that company has some questions. Right now, the expertise \\nis fairly hard to come by, but it’s not impossible. In the coming years, I think more and \\nmore people will take this expertise for granted.\\n \\nWhat can you tell our readers about the data community in New York City?\\n \\nWe’re not a tech city. We are a city of finance, publishing, media, fashion, food and more. \\nIt’s a city of everything else. We see data in everything here. We have people in New York \\nHilary is the Founder of Fast Forward Labs, a machine \\nintelligence research company, and the Data Scientist in \\nResidence at Accel. Previously, she was the Chief Scientist \\nat bitly, where she led a team that studied attention on the \\ninternet in realtime, doing a mix of research, exploration, and \\nengineering. She also co-founded HackNY and DataGotham, \\nand is a member of NYCResistor.\\nOn Becoming a Successful Data Scientist'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 22}, page_content='HILARY MASON\\n18\\ndoing data work across every domain you can imagine. It’s absolutely fascinating.\\n \\nYou’ll see people who talk about their work in the Mayor’s office, people talking about \\ntheir academic work, people in health care using data to cure cancer, and people talking \\nabout journalism. You can see both startups and big companies all talking about how \\nthey use data.\\n \\nDataGotham is our attempt to highlight this diversity. We started it as a public flag that \\nwe planted and said, “ Whatever you do, if you care about data, come here and meet other \\npeople who also feel the same way.” I think we’ve done a good job with that. The best way \\nto get a sense of New York’s data community is to come.\\nHow else do you think data science will change? What will happen to data science \\nin the next five years?\\n \\nFive years is a long time. If you think back five years, data science barely existed, and it’s \\nstill evolving rapidly. It will change a lot in these next five. I’m not going to say what is \\ncertain to happen in the next five years, but I’ll make a few guesses.\\n \\nOne change is that some of the \\ndelightful chaos will go away. I know \\nfantastic data scientists who have \\ndegrees in computer science, physics, \\nmath, statistics, economics, psychology, \\npolitical science, journalism and more. \\nPeople have switched to data science \\nwith a passion and an interest. They didn’t come from an academic program. That’s \\nalready changing — you can enroll in Master’s degree programs in data science now.\\n \\nPerhaps some of the creativity that happens when you have people from so many different \\nbackgrounds will result in a more rigid understanding of what a data scientist actually is. \\nThat’s both a good and bad thing.\\n \\nThe second change is, well, let’s just say that if I’m still writing Java code in five years \\nI’m going to punch a wall! Our tooling has to get a lot better, and it already is starting to. \\nThis is a fake prediction because I know things are already happening in this area.\\nFive years ago, the most interesting data companies were building infrastructure, \\ndifferent kinds of databases. They were working on special tools for managing time \\nseries data. Now, the base infrastructure is mature and we’re seeing companies that are \\nmaking it easier to work with those pieces of infrastructure. So you get a great dashboard \\nWe see data in everything here. We have \\npeople in New York doing data work \\nacross every domain you can imagine. \\nIt’s absolutely fascinating.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 23}, page_content='HILARY MASON\\n19\\nand you can plug in your queries, which go behind the scenes and run map-reduce jobs. \\nYou won’t be spending 40 hours manually parallelizing algorithms and hating your life \\nanymore. I think that will continue to expand.\\n \\nCulture is also a big part of the practice. I think data culture will continue to grow, even \\namong people who aren’t data scientists. This means that within lots of companies, \\nyou will begin to see people whose job titles don’t say “data scientist,” but they will be \\ndoing very similar things. They won’t need to ask a statistician to count something in a \\ndatabase anymore — they can do it themselves. That’s exciting to me. I do believe that \\ndata gives people the power to make better decisions, so the more people who have \\naccess to it, the better.\\n \\nHow do you think the role of a data scientist will change in a world where every \\ncompany has data-minded people?\\n \\nData scientists will keep asking the questions. It’s not always entirely obvious what \\nyou should be counting, even for fairly trivial business problems. It’s also not entirely \\nobvious how to interpret the results. Data scientists can become the coach, the person \\nwho really understands the problem they’re trying to solve.\\n \\nData scientists and data teams do a variety of things beyond just business intelligence. \\nThey also do algorithmic engineering, build new features, collect new data sets, and \\nopen up potential futures for the product or business. I don’t think data scientists will \\nbe out of work anytime soon.\\n \\nYou emphasize communication and storytelling a lot when you talk about data \\nscience. Can you elaborate more on this?\\nA data scientist is someone who sits down with a question and gathers some data to \\nanswer it, or someone who starts with a data set and asks questions to learn more about \\nit. They do some math, write some code, do the analysis, and then come to a conclusion. \\nThen what?\\n \\nThey need to take what they’ve learned and communicate it to people who were not \\ninvolved in the analytical process. Creating a story that’s compelling and exciting for \\npeople, while still respecting the truth of the data, is hard to do. This skill gets neglected \\nin many technical programs, as it’s taken for granted that if you can do something you \\ncan explain it. However, I don’t think it’s that easy.\\nWhy isn’t it easy? Why is explaining something in a simple manner so difficult?\\n \\nIt’s hard because it requires a lot of empathy. You have to understand something that’s'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 24}, page_content='HILARY MASON\\n20\\nvery technical and complex, then explain it to someone who doesn’t come from the same \\nbackground. You have to know how they think so you can translate it into something \\nthey can understand. You also have to do it for people who generally have short attention \\nspans, who are impatient, and who are not ready to spend hours studying.\\n \\nSo you need to come up with a solution \\nthat uses language or a visualization \\nto facilitate their understanding after \\nyou’ve invested all of this time building a \\ncomplex model. When you think about it, \\nit’s amazing that we can take our complex \\ntechnical understanding of something \\nand then write it down in such a short, concise way to communicate it to someone who \\ndoesn’t share the same knowledge or interests. That’s amazing.\\n \\nWhen you think of it that way, it’s not a surprise at all that storytelling is hard. It’s like \\nart. You’re trying to take a really intense emotion or complex phenomenon and express \\nit in a way that people will understand intuitively.\\n \\nYou’ve said before that some of the most exciting data science opportunities are in \\nstartups. Given your experience with Bitly and advising startups, can you elaborate \\nmore on that?\\n \\nI’ll explain with the disclaimer that I’m obviously slightly biased. The most exciting data \\nopportunity is when you have the flexibility to collect data. Often you’re collecting data \\naccidentally as a side effect of another product you were trying to build.\\n \\nBitly is the classic example of this — short URLs make it easy to share on social networks. \\nYou end up collecting this amazing data set about what people are sharing and what \\npeople are clicking on across all these social networks. But nobody really set out in the \\nbeginning to build the world’s greatest URL shortener to discover how popular Kim \\nKardashian is. Bitly’s founder John Borthwick calls this accidental side effect “data \\nexhaust,” which is a lovely phrase for it.\\n \\nThat said, if you’re in academia, you don’t have the benefit of having a product there \\nalready collecting data. There’s an extra project to do before you even do the work you \\nactually care about. You have to struggle to collect your own data, or go to a company \\nand beg for their data. That’s really difficult, because most companies have no incentive \\nto share data at all. In fact, they have a very strong disincentive given privacy liability. \\nSo, as an academic, you find yourself in a difficult position unless you’re one of those \\npeople who are able to build good partnerships (which some people are).\\n \\nI do believe that data gives people the \\npower to make better decisions, so the \\nmore people who have access to it, the \\nbetter.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 25}, page_content='HILARY MASON\\n21\\nIf you’re at a larger company, the data you have is probably either stuck in a bunch of \\nincompatible databases or so highly controlled that it will take a huge political effort to \\nget the data into a place where it becomes useful.\\n \\nStartups are the perfect place where you have a product that’s generating it’s own data. \\nAs a data scientist you have input into how the product changes, so you can ask, “Can we \\ncollect this other thing?” or “Do you think if we tried this we might learn something else?” It’s \\nvery open as to what you do with it.\\n \\nI love that aspect that we can learn something interesting from the data. It’s a fun process \\nand a good place to be.\\nWhat advice would you give our readers who are interested in joining a data science \\nstartup? How should one choose where to work at?\\n \\nTry to learn more about the startup \\nculture. Startups generally have great \\ncultures — one reason is because \\nstartups are much more free to have wide \\nvariability in those cultures. You’ll find \\nthat some startups might be a great fit for \\nyou, while some of them might feel uncomfortable. There’s nothing wrong with you, it’s \\njust a company that’s not a good match.\\n \\nThis is just good advice in general. When you’re looking at working in a small company, \\nmake sure it’s a group of people that you’re comfortable working with and that the social \\nenvironment is one that you’re going to feel happy and comfortable in.\\n \\nThat said, a lot of companies are hiring their first data scientists. Most data scientists \\nhave no experience in a job, so it’s very hard to find someone who can come in and do a \\njob well that nobody has done before. I would make sure that whoever you’re working for \\n— whether it’s your COO, CTO or CEO — has a pretty clear understanding of what they \\nwant you to do. At least they should be someone you think you could collaborate with in \\nfiguring out where you should invest your time.\\n \\nCan you elaborate more on prioritization and investing time?\\n \\nYou’ve got an infinite list of questions you can look into — how do you pick the ones \\nthat are going to have the biggest impact? How do you do that in an environment where \\nyou might have your CEO demanding slides for a board meeting, your head of sales \\ndemanding data, etc., and you have a project that you think is really exciting — but no \\nStartups are the perfect place where \\nyou have a product that’s generating \\nit’s own data.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 26}, page_content='HILARY MASON\\n22\\none else quite gets it yet because they haven’t really sat with you and gone into the data?\\n \\nIf you’re looking for your first job as a data scientist, I would make sure you have a \\nmanager who can manage that process with you. If you’re going to be that manager, it’s \\nnot as easy as it looks from the outside. That is a skill you have to develop. If you’re going \\nto be a manager, I’d recommend that you think about those sets of problems -- how to \\nprocess them and how to communicate them in a way that fits with the process that the \\nrest of the company is using.\\n \\nWhat other advice do you have?\\n \\nLook for good data sets. When I interview people for a data science job, they will already \\nhave spent a few hours with people on the team. I’ll say, ‘Y ou know what we do now. \\nWhat is the first thing that comes to your mind when you’re thinking ‘why haven’t these guys \\neven thought about this?’” I don’t really care what the answer is, but I want to know that \\nthey’re capable of thinking about what the data set is and coming up with ideas on their \\nown for what they would like to see.\\n \\nMost of the answers I’ve have to that question were things we had already thought of. I \\ndon’t expect people to come up with genius ideas in the interview, but just to show that \\nthey have that creative ability can be really helpful. If you’re looking at a company or \\nproduct to potentially work for and you can’t come up with things you would want to \\nwork on, that’s a problem. You should find something you’re a little more excited about.\\n \\nDo you have more advice on prioritization and making an impact within a company?\\n \\nDuring my time at Bitly and in general, \\nwe have a series of questions we ask \\nabout every data project we work on. \\nThe questions would help not just with \\npersonal prioritization but also with \\nhelping other people in the company \\nunderstand what was going on.\\n \\nThe first question is, can we define the question we’re interested in? You’d think it would \\nbe obvious that it’s helpful to write down the question in plain language so that anyone \\ncan understand what you’re trying to do.\\n \\nThe second question is, how do we know when we’ve won? What are the error metrics by \\nwhich we evaluate our solution to this question? If we’re working on an algorithm where \\nthere are no quantitative error metrics, you at least have to write down that there are \\nnone.\\n \\nYou’ve got an infinite list of questions \\nyou can look into — how do you pick \\nthe ones that are going to have the \\nbiggest impact?'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 27}, page_content='HILARY MASON\\n23\\nThe third question is, assuming we can solve this perfectly, what’s the first thing we \\nwill do with it? I ask that question to ensure that every project is immediately relevant \\nto the business or product. It’s not just an irrelevant exercise because we’re curious \\nabout something. The first thing you’ll do with it should also have some longer term \\nimplications about what you understand about the data.\\n \\nFor each data project you’re working on, you need to ask yourself these questions: what \\nare you working on? How will I know when it’s done? What does it impact? If you ask \\nyourself these questions, you always know you’re making a good decision about how \\nyou’re spending your time.\\n \\nDo you have an example of using these questions to understand a project?\\n \\nOne project you might be working on might be, “ Does our user behavior in Turkey differ \\nfrom user behavior in the United States?” That might be an immediately relevant question, \\nmaybe because of a sales deal with someone in Turkey.\\n \\nThe longer term goal would be to understand if geography affects user behaviour, and \\nif so, how? You should always be balancing those near-term and long-term rewards, \\nbuilding your library of information of what you know from your data.\\n \\nThe last question is, assuming that everything works perfectly and everyone in the world \\nuses our solution, how does it change human behavior? That question is important \\nbecause I want to make sure that people are always working on the highest-impact \\nproblems.\\n \\nAnother question I ask sometimes is, what is the most evil thing that could be done \\nwith this? If I were an evil mad scientist in my volcano lair and I had this technology or \\nknowledge, what could I do with it? You get way more creative ideas for what to actually \\ndo with it, very few of which are evil. That’s a fun thought experiment to do. \\n \\nYou’ve given great advice on how data scientists can choose a startup. I wanted to \\nflip that question around — what general advice would you give to new startups \\nthat are building their data science team?\\nThis is always a challenge, and often, people have different ideas of what a data scientist \\ncoming into the company will do. So this means that first the founders and management \\nteam should really understand what they need now.\\n \\nYou’re sure that you want some business analytics, product analytics, and metrics. \\nMaybe you have an idea to do something cool with the data — perhaps something that’s'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 28}, page_content='HILARY MASON\\n24\\nFor each data project you’re working \\non, you need to ask yourself these \\nquestions: what are you working on? \\nHow will I know when it’s done? What \\ndoes it impact?\\nwell understood like a recommendation engine, or maybe even something that’s more \\ncreative. But it’s hard to find someone who can do all of these things and potentially can \\ngrow to manage a team of people.\\n \\nThe things you can do when you’re hiring is look for people who learn quickly, are really \\ncreative, are flexible, and who can work with your engineering team because that’s \\nwhere they’re going to sit. They need to \\nbe best friends with whoever is running \\nthe infrastructure that holds the data, \\nand they need to be able to work with the \\nproduct and business side as well.\\n \\nThat means that you might want to hire \\nsomebody who doesn’t have 20 years of \\ndata experience but who you think can \\nlearn really quickly and grow with the product, with the understanding for that person \\nthat eventually a team might come around them or they might hire a manager.\\n \\nSo much of hiring well in small companies is finding the right person at the right time \\nfor that company. There’s no one formula that really describes it — it has to be a good \\nmatch on both sides.\\n \\nWhat advice do you have for students who are choosing between smaller companies \\nand larger companies?\\n \\nI would say it’s worth looking at the smaller companies. The advice I have there is find \\nsomeone who you’ll work for who you think would be a great mentor for a year. Don’t \\njust go to a small company because it sounds good. Go to one where you think, “ This is \\nsomewhere I can learn from for a year. I think I’ll be happy here for about that long.”\\n \\nThen after a year, you can re-evaluate. Am I still learning? Am I doing work that I love? \\nAnd if not, you can move on to your next learning opportunity. But the first few years out \\nof school will help you learn the skills you’ll need later. Go to places where you can learn \\nthings. That’s the best way to think about it.\\n \\nWhat other advice do you have for students choosing between companies?\\n \\nI know when you look at job offers, it’s really easy to evaluate them based on how much \\nmoney you’re going to make and where you’re going to live. I’m a big fan of living \\nsomewhere you like, because otherwise you’re miserable all the time, because it’s not all \\nabout the money. It’s most important to be working in an environment where you have'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 29}, page_content='HILARY MASON\\n25\\nchallenging work with people you can learn from.\\n \\nFor example, I once did an internship in AT&T Labs Research, and I loved working there. \\nIt was an amazing place full of really amazing people. But I hated living in New Jersey \\nand commuting on the Garden State Parkway. You need to find that right balance of \\nmaking sure you’re in a place where you’re going to be happy, but also learning a lot.\\n \\nWhether you’re making 10 or 20 grand more now, versus years later, it doesn’t make \\na difference. As long as you’re making enough to have a decent place to live, eat well, \\nenjoy your life when you’re not at work, I wouldn’t pay too much attention to the salary.\\n  \\nWhat advice would you give to aspirational data scientists?\\nA lot of people are afraid to get started because they’re afraid they’re going to do \\nsomething stupid and people will make fun of them. Yes, you will do something stupid, \\nbut people are actually nicer than you think and the ones who make fun of you don’t \\nmatter.\\n \\nMy recommendation is that if you’re interested in data science, try it! There are a lot \\nof data sets out there. I have a Bitly list of about 100 public research-quality datasets, \\nwhich you can see here: bitly.com/bundles/hmason/1. You also have access to a bunch of \\npublic APIs. You can be creative.\\n \\nTry to do a project that plays to your strengths. In \\ngeneral, I divide the work of a data scientist into three \\nbuckets: Stats, Code, and Storytelling/Visualization. \\nWhichever one of those you’re best at, do a project \\nthat highlights that strength. Then, do a project \\nusing whichever one of those you’re worst at. This helps you grow, learn something new, \\nand figure out what you need to learn next. Keep going from there.\\n \\nThis has a bunch of advantages. For one thing, you know what data science is actually \\nlike. A lot of data scientists spend their time cleaning data and writing Hadoop scripts. \\nIt’s not all fun — you should experience that.\\n \\nSecond, it gives you something to show people. You can tell people what cool things \\nyou’re trying out — people get really excited about that. They’re not going to say you \\ntried and you suck, they’re going to say, “Wow, you actually did something. That’s cool!” \\nThis can help you get a job.\\n \\nA great example of this is my friend Hilary Parker who works at Etsy on their analytics \\nGo to places where you can \\nlearn things.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 30}, page_content='HILARY MASON\\n26\\nteam. Before she got the job there, she did this fantastic analysis of how Hilary is the \\nmost poisoned baby name in U.S. history. The popularity of the name Hilary was growing \\nuntil Bill Clinton got elected, when it just plummeted. Slowly now it’s getting more and \\nmore popular again (obviously I love this example because my name is also Hilary). She \\nput it on her blog and ended up getting published in  New York Magazine — I believe it \\nreally helped her land a job by showing that she really knew what she was doing.\\n \\nI really just encourage people to start putting things up on their blogs and on Github, \\nand not to be discouraged. It takes optimism and stubbornness to do this well.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 31}, page_content='PETE SKOMOROCH\\nPrincipal Data Scientist at Data Wrangling\\nYou’re one of the people who’ve been around data science since the beginning. \\nHow have you seen it evolve?\\nThe creation of the data scientist role was originally intended to address some challenges \\nat large social networks. Many software companies at the time had separate teams. \\nThere were production engineers, research scientists writing papers and developing \\nprototypes, and data analysts working with offline data warehouses. The classic R&D \\nmodel required a lot of overhead as ideas were passed from one team to another to be \\nre-implemented. The latency to get an idea into production and iteratively improve it in \\nthis way was too high, especially for startups.\\n \\nThe data scientist role was intended to bridge the gap between theory and practice \\nby having scientists who could write code and collaborate with engineering teams to \\nbuild new product features and systems. At LinkedIn, we wanted to hire scientists and \\nengineers who could develop products and work with large production datasets, not just \\nhand off prototypes. I think the original concept has evolved over the last few years as \\norganizations found it difficult to hire candidates with the full skill set. Simultaneously, \\nas data science became more popular, it evolved into an umbrella term that describes \\na large number of very different roles. In my case, I was a Research Engineer at AOL \\nEver since he was young, Pete Skomoroch was interested \\nin science. This led him to double major in mathematics \\nand physics at Brandeis University, where he discovered \\nhe enjoyed tinkering with mathematical models and \\nengineering. After graduating, Pete honed his technical skills \\nat Juice Analytics, MIT Lincoln Laboratory and AOL Search.\\nPete eventually ended up as a Principal Data Scientist at \\nLinkedIn, where he led teams of Data Scientists focused \\non Reputation, Inferred Identity and Data Products. He \\nwas lead Data Scientist and creator of LinkedIn Skills & \\nEndorsements, one of the fastest growing new products in \\nLinkedIn’s history.\\n \\nHe is also the founder of Data Wrangling, which offers consulting services for data mining \\nand predictive analytics. \\nSoftware is Eating the World, and It’s Replacing it With Data'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 32}, page_content='PETE SKOMOROCH\\n28PETE SKOMOROCH\\nSearch and was originally hired as a Research Scientist at LinkedIn before my job title \\nwas changed to Data Scientist. In the following years, many business analysts and \\nstatisticians also rebranded as data scientists.\\n \\nToday, depending on the company, a data scientist could be a person who fits that \\noriginal hybrid scientist-engineer role, or they could be statisticians, business analysts, \\nresearch scientists, infrastructure engineers, marketers, or data visualization experts. \\nIn some organizations, things have come full circle as these skills are held by separate \\nspecialized individuals that work together on a data team.\\n \\nThere is nothing wrong with \\nany of these roles and you need \\nall of them for a large modern \\norganization to get the most \\nout of data. That said, I think \\nthere is value in having people \\nwho fit the original definition, \\nwho are interdisciplinary, and \\ncan cross boundaries to build \\nnew products and platforms. \\nConfusion often arises when companies either don’t know which type of role they need \\nfor their organization or which type of data scientist they are interviewing.\\nCan you talk about your story, and how you ended up where you are?\\nI was really interested in science from an early age. When I started at LinkedIn, I was a \\nresearch scientist, and before that, I had been a research engineer at AOL Search. The \\nflavor of that role was more like the R&D labs that were doing machine learning research \\nand crunching search query data, but there was a strong pull for us to do more production \\ncoding involving product.\\n \\nI remember a talk that Jeff Hammerbacher gave in which he mentioned that what he \\nreally wanted on his team was a MacGyver of Data Analysis who could work with data, \\nwrite code in Java and actually implement the algorithms, do some statistics, and really \\nhave a good intuition of what would drive strategic objectives.\\n \\nI think that was the kernel of the idea that Data Scientist is a different role.  When we \\nare interviewing, we don’t want to select for people who are just business analysts who \\ncan’t code, and we don’t want people who are pure engineers who don’t have any science \\nor math background. We want people at that intersection. I think that was really the \\ngenesis of data science, it is cross-disciplinary.\\nWhat [Jeff Hammerbacher] really wanted on his \\nteam was a MacGyver of Data Analysis who could \\nwork with data, write code in Java and actually \\nimplement the algorithms, do some statistics, \\nand really have a good intuition of what would \\ndrive strategic objectives.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 33}, page_content='PETE SKOMOROCH\\n29\\nSome of your undergrad research was about neuroscience, can you tell us a bit \\nmore about that?\\n \\nI was really interested in neuroscience, and physics and electronics. When I went to \\nBrandeis, I found that I actually liked mathematical modeling, data crunching, cracking \\ncodes, building models and programming versus doing lots of bio lab work. I felt my real \\naptitude was digging into the data and coming up with theoretical models, which is what \\ndrew me to physics.\\n \\nI graduated college in 2000 while the \\ndotcom boom was still happening. My \\nfamily was just scraping by financially, \\nso it was really compelling for me to \\ngo into industry although I ultimately \\nplanned to go back to grad school. I had \\nused Matlab, Mathematica, some C, and \\nAssembly in physics classes and learned Visual Basic in an internship, but I wasn’t a \\nstrong programmer at that point. In retrospect, that is one thing I would have done \\ndifferently in undergrad. If I had taken more computer science classes, I probably would \\nhave ramped up faster at startups.\\n \\nWhen giving advice on undergraduate coursework, I’d echo Yann Lecun, who is now \\nheading AI Research at Facebook and did pioneering work in neural networks. I agree \\nwith his advice to take as many physics and math classes as you can, but also learn some \\ncomputer science.\\n \\nHow did computer science play into your post-college job?\\n \\nA big piece of what a data scientist is really doing is creating models. It’s not just about \\ntaking data and loading into a black box machine learning algorithm and running it, \\nbut actually modeling something about an organization, a company or a product. It’s \\ndifficult to find the underlying factors and phenomena that are really predictive and \\nprescriptive vs. something that is just a correlation.\\nSo, when I was looking at jobs coming out of college in 2000, I interviewed at a few \\nplaces, and one that looked really interesting was a small startup in Kendall Square \\ncalled Technology Strategy Inc., which eventually rebranded as ProfitLogic, Inc. Our \\nearly clients included casinos and some of my coworkers were working on interesting \\nprojects optimizing slot machines or spotting cheaters. In the early days we did a lot of \\nconsulting work and as it turned out there was a lot of interest from fashion retailers, \\nwho wanted things like better inventory allocation and markdown price optimization.\\n \\nWhen giving advice on undergraduate \\ncoursework... [I’d say] take as many \\nphysics and math classes as you can, but \\nalso learn some computer science.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 34}, page_content='PETE SKOMOROCH\\n30\\nWhat we were doing was essentially an early version of data science. We would get tapes \\ndelivered weekly from big retailers like Macy’s or JC Penny or Walmart, and the data \\nwould be loaded into our own data warehouses. Then we would run statistical models \\nusing a combination of C++ and Python to adjust prices and build predictive sales \\nforecasts at the item level. The ultimate idea was that you could save a lot of time and \\nmaximize profit by automatically setting prices using a data driven approach. By taking \\nthese optimal price trajectories instead of relying only on intuition, you could make \\nmore profit and get more inventory through the system.\\n \\nMy initial role there was similar to a grad student in a research lab. Eventually, I \\nbecame a hybrid product manager and engineer on the data and algorithm side. I would \\noften be in the office all night, making sure that the weekly model run was working, \\nscrutinizing thousands of charts and logs for model issues. Over time, I started to see \\nareas for improvement and develop my own algorithms for seasonality and other forecast \\nimprovements. I was working with people across the engineering teams, the database \\nteam and research scientists. That’s where I first encountered this pain point of bridging \\nbetween those areas.\\n \\nIn my case, what I found was that I needed to build up my programming and computer \\nscience skills to become more self sufficient. I started out as an analyst building models \\nand then moved into the software engineering organization. \\nHow did you get good at these things? Did you take your own time to learn, or is \\nit more like you just embedded yourself within the groups at the company that you \\nwere doing these things at?\\n \\nI think the only way to excel is to take the extra time. I would go home and read every \\nO’Reilly book I could get my hands on, working through textbooks and side projects. \\nI would do what I could to learn at work, and I was always pushing to work on areas \\nbeyond what I was doing before. I’d advise people to take the time to level up early on in \\ntheir careers, maybe sleep a couple hours less while you can handle it.  \\n \\nAs I was reading and building models, it \\nseemed like machine learning was a better \\nanswer than heuristics or other approaches \\ncommonly used in forecast models. I was \\nlearning that on my own, but I felt like the \\nonly way to level up was to do real coursework \\nand be around people who were actually doing it. There was a job opportunity at MIT’s \\nLincoln Lab working in biodefense, and a big benefit for me was that I could also take \\ngraduate courses in that role. I took a fantastic neural networks course with Sebastian \\nThe only way to level up was to \\ndo real coursework and be around \\npeople who were actually doing it.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 35}, page_content='PETE SKOMOROCH\\n31\\nSeung, the author of Connectome, and a machine learning course with Leslie Kaelbling, \\nalong with some math courses and an optimization theory course. \\n \\nMy story during that time period is a bit of an unusual one. I would often wake up, go \\nto work in Lexington, go to the MIT library, stay up all night eating from the vending \\nmachines and working on problem sets, and go back to work the next day without \\nsleeping. Then I would go home and crash, and then I would repeat that process. I was a \\nzombie for a couple of years and if I could do anything differently, I would balance that \\nmuch better. Yes, you have to put in your time, but try to balance it. Staying up all night \\ncoding is the same thing. Sometimes you maybe have to do it but if you’re doing it all \\nthe time, you are eventually going to burn out and you are nowhere near as effective as \\nyou think you are.\\n \\nThat said, I don’t want to make it seem like there is a magic path through this. To get to \\nthe point where you can gain the right skills this field does take a lot of hard work and I \\nwouldn’t minimize that.\\nThe amount of stuff you have done is unbelievable. I think telling the story of how \\nhard everything was, it’s not that you had everything handed to you. That is critical \\nin communicating how people think.\\nI think there are two parts. Being smart only gets you so far. You have to work hard \\nbecause anything worth doing is worth doing well and you’re better off just digging in. \\nThere is this psychological factor of grit that is important.\\n \\nThat is what I would encourage people \\nto think about. Stretch yourself, \\nbecause if you only work on things \\nthat you know well, you’re going to \\nplateau. That is part of what makes \\ndoing a new startup so appealing. If \\nyou go into management, I advise not giving up coding completely. Own a feature or \\nsomething that keeps you in the loop, so that you’re up to speed with the development \\ntools, the build process, the code base, the latest tricks and languages. All these things \\nare important because the further you get from the nuts and bolts, the harder it is to \\nmake intelligent decisions. The technology changes rapidly, especially in data science.\\n \\nCan you talk about your experience at Lincoln Lab? What was it like, especially as \\nyou were moving there from the private sector?\\n \\nThere was a mixture of biologists, physicists, hardware engineers and software engineers. \\nIf you go into management, I advise not \\ngiving up coding completely. Own a feature \\nor something that keeps you in the loop.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 36}, page_content='PETE SKOMOROCH\\n32\\nI’ve always been drawn to the intersection of fields.  One project involved a machine \\nlearned model for a biosensor. It started as a simple threshold alarm algorithm, and I \\ntook it a step further to mathematically model the biochemical processes statistically \\nand apply machine learning on top of that parameterized model.\\n \\nAnyway, I thought it was interesting that machine learning doesn’t just have to be a \\nblack box. You can get better results if you have a more intuitive sense or physical sense \\nof what you are modeling and build those features into the model. Often, a custom model \\nis what you need to really nail it. On the other hand, if the answer only has to be 80% \\naccurate, you may want to do something more lightweight.\\n \\nAfterwards, I moved to DC while my wife was in grad school, but after a few years in \\ndefense I wanted to try a job in consumer internet.  The most interesting role around \\nDC in terms of machine learning at the time was at AOL Search. The experience working \\nwith large datasets at MIT helped me land a role on a great team there mining search \\nquery data, and many of my coworkers from that team went on to work at Twitter via \\nthe Summize acquisition. There were a lot of management changes at AOL during that \\ntime, and I did my best to adapt while things were uncertain, installing an early Hadoop \\ncluster there and experimenting with mapreduce techniques.\\n \\nThere were all these interesting things developing around the same time in the startup \\nworld, including the early development of Amazon EC2 and Hadoop, and so I viewed \\nthat lack of direction as an opportunity. AOL was very much a content company and I \\nwanted to look at how they could do better in terms of content based on data: Based on \\nsearch data, what can we decipher about what people are actually interested in, what’s \\ntrending? And so the first step is to assess, how are you doing versus your competitors? \\nAOL grew through acquisitions, so it wasn’t like everything was on a central system.  I \\nactually had to crawl internal AOL properties and external sites as well.\\n \\nExternally, there were signs that data was going to be a big deal, but internally they were \\ndismantling the R&D team, so I knew that wasn’t a good place to stay. Another company \\nthat I had been talking to in the area was called Juice Analytics. They were primarily \\nknown for data visualization, but it was an appealing opportunity to me because I could \\napply this intersection of skills I’d been developing to product development. So I joined \\nJuice, and we built and shipped a SaaS software product built on Django and EC2. It \\ntook about a year, and we were crunching search queries and doing some clustering and \\npattern recognition to come up with a better picture of your site’s search topics instead \\nof just the top ten queries or whatever you got at the time in Google Analytics. That was \\na great experience of end-to-end product development.  \\nUltimately, I think it was a failure in terms of product-market fit, but I learned a lot from'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 37}, page_content='PETE SKOMOROCH\\n33\\nthat process. As a data scientist in an engineering driven company, you probably go \\nthrough engineering boot camp, get up to speed with the tech stack, and then you can \\nactually do some engineering to solve your own data problems. When you think about it, \\nthat’s the way you get leverage in the world that we live in now.\\nWhat do you mean when you talk about leverage?\\n \\nImagine you have an idea on how to improve your company’s product. Say you come in \\nand say, I have this great idea. Everybody will love it and it will make billions of dollars \\nand improve the lives of millions of people. But if you are just describing the idea and you \\ncan’t implement at least some rough version of it, you are at a disadvantage. That’s why \\nI think one of the highest leverage things you can do right now is gain some engineering \\nand computer science skills.\\nSo how did you move from Lincoln Lab to Silicon Valley?\\n \\nAfter the experience at ProfitLogic, I was bit by the startup bug and ultimately planned to \\nmove out to California. After my wife completed her master’s in 2009, we said okay, we’re \\njust going out there. The previous year \\nin DC, I became increasingly active on \\nTwitter and I found it really fantastic \\nfor finding people with similar \\ninterests, especially when you were \\noutside the Bay Area. For data, one of \\nthe key people I met was named Mike \\nDriscoll. He’s the CEO at Metamarkets, but at the time he had a blog called Dataspora \\nand he did data-related consulting. We contemplated doing an O’Reilly book back then \\ncalled Big Data Power Tools to a) survey these different tools that you should know and \\nb) offer case studies with tips and tricks for practitioners. My vision was that you would \\nhand that book to a new hire and just have them read through it and be ready to hit the \\nground running. Fast forward to today, and it’s really great to see that this is actually \\nhappening through a variety of courses, textbooks, meetups and data science bootcamps \\nlike the Insight Data Science Fellows program.\\nI think that now a lot of large Fortune 500 companies see the success of consumer \\ninternet companies like Google, Facebook, Twitter, Amazon, etc., and they say, “I’m not \\nsure what they are doing, but it seems to be working. I want that. How do I innovate and \\nbuild products like that?” I think there is a bit of a misconception out there that building \\ndashboards of business metrics like Google will turn you into Google, when really it was \\na huge amount of engineering infrastructure and algorithmic product development that \\ngot them to where they are today. I think a lot of the people who want to get into data \\nOne of the highest leverage things you can \\ndo right now is gain some engineering and \\ncomputer science skills.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 38}, page_content='PETE SKOMOROCH\\n34\\nscience say, “That is really amazing, how does Google know everything?”.\\nOr, perhaps “How does Target know I’m pregnant?”\\n \\nThat’s a darker version of that question, but even there it’s interesting to note that the \\nalgorithms were really just detecting people following instructions from other software \\nsystems. If you are pregnant, there are tons of websites and medical guides that tell you \\nexactly what to purchase and which vitamins to take each week. When you know that, \\nit’s not so surprising that such regimented purchase patterns are detectable. \\nThat said, a lot of data science does seem like magic. How do they create these magical \\nexperiences? Even Uber seems like magic (I know that isn’t all necessarily data science), \\nbut there is something impressive about getting the cars there fast enough when you \\npush a button that it feels like magic. Fortune 500 companies and big organizations want \\nthat magic. And they have some sense that it is happening through data, but they’re not \\nquite sure how. I wasn’t sure either when I started in the field, but it was just clear to me \\nthat we were just scratching the surface of what we can do involving engineering and \\ndata.\\nWhat sort of opportunities did you find at LinkedIn that took advantage of your \\nquantitative background?\\n \\nThe younger a company is, the easier it is to propose new things. When I started working \\nthere, LinkedIn had some structured data around titles and companies and company \\npages, but they didn’t really have any notion of topics or skills. I had just done a bunch \\nof Wikipedia topic mining to build a site called trendingtopics.org, and I thought, with \\nall of these member profiles, I should be able to do some topic mining of the skills that \\npeople have. And then I’ll have that structured data set. I thought you should be able to \\ntag people like websites in del.icio.us (which I was a big fan of) and then we would have \\nall this rich data to do better recommendations and matching.\\n \\nI made a quick proposal to my manager DJ Patil, and I got a time window of six to seven \\nweeks to crank out a prototype. This was back in 2009 and at first, I didn’t think that \\nLinkedIn would have enough data in the connection graph to say how good somebody \\nwas at something. But even in early versions, there was a lot of signal in the data and \\nthe project was green lighted based on that prototype. At that point, my picture of where \\nthis thing was going evolved and I thought that the ultimate value was going to be in the \\nreputation data tied to each skill.\\n \\nWhat ultimately led to further enhancements like endorsements was the overarching \\ngoal to develop products that fulfilled strategic goals to get people back on the site,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 39}, page_content='PETE SKOMOROCH\\n35\\ngrow engagement, grow profile data, and help improve job matching, ad matching, and \\nother algorithms. The ultimate goal for me was to add a layer of links anchored by skills \\nacross profiles, and do for the social and professional graph what Google had done for \\nweb pages, allowing people to find and by found.\\nCan you talk more about what it’s like developing new features or products at \\nlarger established companies, versus the startups you’ve worked at in the past?\\n \\nThere was a formal process to bringing new ideas to production at LinkedIn because there \\nmay be a big difference between the technologies you used to prototype your idea, and \\nthose that LinkedIn is built with. The same thing likely applies for any big tech company \\nat this point. You have to get projects approved and they have to get a budget because \\nyou need specialized people on the projects in different organizations: web designers, \\nweb developers, frontend engineers, ops people. It takes more of cross-team village to \\nbuild a product versus a startup where you are a small group wearing a bunch of different \\nhats doing a bunch of different things.\\n \\nThe spirit at the time during when we built the first \\nversion of skills was still that we would try to wear many \\nhats. That said, we wanted to ship product quickly and \\nthe way to get that done is to get the right resources \\nlined up so you can really execute. I think one of the \\nworst things you can do is sign up for a project when \\nyou know you are not set up for success and you are not resourced properly.\\nAnother important reality to face is that you need to hit product-market fit. You could \\nhave a very smart idea as a data scientist, but there is more to succeeding than just having \\na smart idea.  One common problem is that the idea might not align with the company \\nobjectives. Another is that many startups that just fail because they are a technology \\nin search of a problem. When you hear there is a shortage of data scientists, I actually \\nbelieve the most difficult people to find are those that have a more human, intuitive \\nsense of the customer and knack for getting to product-market fit.\\nHow do you develop this “intuition” for product-market fit?\\n \\nWhen I interview people, it often manifests itself in somebody who is driven and who \\nhas done some novel, creative side projects. When you are building stuff on your own, \\nyou often see that your original idea doesn’t actually have enough thought put into it. \\nI also like to see when people have worked either in different disciplines or in different \\nareas of domain expertise. An example of a concrete question that would come up in an \\ninterview to test for this intuition would be: “If you had access to all of our data, what \\nwould you do?”\\n \\nThe younger a company is, \\nthe easier it is to propose \\nnew things.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 40}, page_content='PETE SKOMOROCH\\n36\\nI think that rather than going from the bottom up and thinking, “What is something cool \\nI can do with this data?” it is sometimes a better approach to think strategically from the \\ntop down. “What are the top priorities for this company and what are we going after? \\nWhat technology or product trends are opening up new opportunities? Who are our \\ncustomers? What is the market, and how could I do this differently with data?”\\nThis seems to capture the sentiment expressed by Steve Jobs when he said, “People \\nthink focus means saying yes to the thing you’ve got to focus on. But that’s not \\nwhat it means at all. It means saying no to the hundred other good ideas that there \\nare.”\\n \\nRight, and the same thing goes for managing a data team. In the same way, when you’re \\nstaffing or building a product, think about how well it matches the priorities of the \\ncompany. LinkedIn could do a million different things, but you want to focus on things \\nthat actually align with the strategic goals of the company. There are many things that \\nwould align with the vision, but that doesn’t mean it’s the right thing to do. So you \\nneed to prioritize, and you need to do it in the context of all the other things you could \\npossibly do.\\nIt sounds like a great deal of understanding the ins-and-outs of data science is \\nlearning how to focus.\\n \\nYes. It may not take seven years of focus like a PhD, but you probably need at least a \\nyear to do anything of really significant value. If you are coming out of school and you \\nwant to work on a data team, you need to find good mentors. You need people who are \\ntraining you up on the engineering stack, who are sharing the common tools, and helping \\npush projects through management layers. I hear a lot of complaints where lone data \\nscientists feel like they have no support structure. It is really hard to operate without a \\nteam on your side, because I think the personality type of scientists is often not the most \\nassertive when dealing with business stakeholders.\\nCan you talk more about the growing importance of data science within companies?\\n \\nI think data teams are building really important things. They are actually going about \\nit in a very deliberate way and they’re using reason, theory and evidence. People from \\nscience backgrounds are well suited for this, because you’re building up a theory of what \\nyou think will happen if you were to make certain changes to the product. I think that \\nthat is really at the core of the skillset that you want in engineering product development \\nand data science to make informed decisions.\\n \\nI think that data science is going to become this discipline that drives decision-making'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 41}, page_content='PETE SKOMOROCH\\n37\\nand product development. In order for data to have the biggest impact, it needs to be in \\nthe early phases of product development rather than just added as an afterthought.\\n \\nIt also involves giving feedback to the product and engineering team about the quality, type \\nand quantity of data that will be collected and affected given certain product decisions. \\nIt’s incredibly important to have someone sitting in the room and advocating for the \\ndata team every time a new product \\nfeature is proposed. That may be easier \\nif data science itself rolls up within the \\nengineering or product organization, \\nor has an advocate reporting to the \\nCEO like a Chief Scientist or Chief Data \\nOfficer.\\nOf the people we have talked to, you can offer a unique perspective on how to \\neffectively manage a data science team because you are so engineering focused as \\nwell. There are a lot of managers who are very people focused or they sort of try \\nto massage the politics of the company to get things done, but you seem to want \\nto stick very closely to the nuts and bolts of a company. So what do you find to be \\neffective in creating a data science team?\\n \\nJeff Weiner had this framework for prioritizing decisions around vision, strategy, mission \\nand objectives. He used it as a leadership framework and a way to rally people behind a \\nvision. Of the things that I think an effective engineering manager needs to have, one \\nof them is expertise. If you don’t understand what the people on your team are doing, \\nyou’re going to have a hard time making the right calls. Beyond that, you need to be an \\nadvocate for what is right for the company and by proxy what’s right for your team.\\n \\nA good leader for a data science team understands some data science, has some vision \\nto see what the right path is, brings the right people in, gets the resources, and then gets \\nout of the way and gets other people out of their way. If your team is being thrashed \\naround and pulled in different directions, it will be hard to stay focused.\\n   \\nThere’s a great talk by an MIT professor named Fred Kofman who has a book on business \\nstrategy called Conscious Business. He says when most people are asked what their job \\nis, they reply with their job title. But that’s a very limited way to think about the role \\nyou play within a team or company. If you use the analogy of a soccer team, the various \\nplayers all may have different roles. For example, as the goalie your job is to simply stop \\nthe ball. As an attacker your goal is to score the most number of points. But if you are \\ncompletely optimizing for these local metrics, your team still might not win! So I think \\nthat what can really make teams successful is everyone really believes in what they’re \\ndoing, believes in the mission and feels like they’re enabled to accomplish that.\\nIf you are coming out of school and you \\nwant to work on a data team, you need to \\nfind good mentors.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 42}, page_content='PETE SKOMOROCH\\n38\\nHow did your perspective change throughout your own life?\\n \\nEarlier in my career, I thought what was blocking me from more success was not having \\nthe engineering skills. Over time, as LinkedIn went from 300 to 5000 employees, what’s \\noften difficult for organizations at that scale is communication and coordination issues. \\nWhat I often would see blocking people was of that nature. It was less pure engineering \\nability, and more: “How do you get stuff to ship? How do you get resources? How do you \\nget priority?” If I were given total freedom, I would actually just enjoy building stuff \\nand building algorithms, but when you want to maximize impact and success at the \\ncompany, I think more of what was blocking me at that stage was having to navigate \\nstructure within the company.\\n \\nMy two cents of advice on that \\nwould be engineering, engineering, \\nengineering. Because in that \\nenvironment, or at Facebook or \\nGoogle, optimizing and getting that \\nright is really going to enable you \\nmuch more than other alternatives.\\nIn a larger company, you’re always going to have challenges of organization and your \\nthroughput isn’t going to be as high by definition. That’s why startups exist.\\nI really like what you said about the fact that even if you wanted to build, build, \\nbuild, it would be more effective for a team to unblock their processes. That tied \\nin very closely with the analogy you have with soccer players. Some soccer players \\nwant the personal glory but the best soccer players are the one who realize it’s the \\nteam winning that is more important than fulfilling their own goals.\\n \\nI think it’s a balancing act, and I would add one other thing. My opinion has been the best \\nway to show the way is just to do good work. But it’s not enough to just do good work; \\nyou also have to talk about it. That’s something else you can pull from science because \\na big part of science is communicating. There’s value in that, both from a recruiting \\nrespective, but also for training the next generation. I think that’s the way we build and \\nweave on top of each other’s experiences, it’s all connected. I would balance talking \\nabout your projects with building. I would say work hard, work for a long time, and then \\ntalk about what you did and go on to the next step.\\nGiven all of your experience and perspective, what do you think is going to be the \\nfuture of how data is used in the world?\\n \\nFour to five years ago, I think investors were a good proxy for the future. They might not \\nHe says when most people are asked what \\ntheir job is, they reply with their job title. \\nBut that’s a very limited way to think about \\nthe role you play within a team or company.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 43}, page_content='PETE SKOMOROCH\\n39\\ncome up with all the ideas, but they hear a lot about what people think and are cued into \\nwhere things are headed. It was very early for the data space and people were building \\nlow-level backend technologies. Over time, interest started to shift to what gets built on \\ntop of these backend technologies.\\n   \\nI think what people are really thinking about now is how to replicate the Google and \\nNetflix approach and map it onto the rest of the world. There is a much bigger wave \\ncoming of building tools and applications on top of all of this data and infrastructure. \\nThere now exist data companies in oil & gas, and health care and other areas, taking on \\nsorts of different verticals.\\n \\nI’m looking forward to seeing a set of data companies like this. I think all the data \\ncompanies that are building better platforms and better tools are making everyone’s life \\neasier and I want to see more of that, but I also want to see more industries disrupted in \\na way where it makes society more efficient and people’s lives better.\\n \\nI think the other wave we’re hitting is that of social data. All the social data that is \\nbeing generated is really instrumenting the world and people’s behaviors in an entirely \\nnew way. Everyone has a Facebook account, a LinkedIn account or a Twitter account, \\nwhich provides immediate context about the person. We’re never lived in a time where \\nthere’s so much context about you readily available to make your daily experience better. \\nThe other key component of this is that we all have mobile computers in our pockets, \\ngenerating all this ambient data.\\n \\nWe’re going to see more smart software at the intersection of those two trends. For \\nexample, why does it take four hours to book a flight right now? There are all these \\nworkflows, suboptimal systems, and paperwork which could be much easier using mobile \\nand social data. In movies like Her, you are starting to see where the rise of Google Now, \\nSiri and things like that could be headed. One thing I think is really interesting is this \\nentire field of intelligent systems. That’s a common thread in things I’ve worked on.\\n \\nI think that having these techniques and this intelligence in that sea of data acting on \\nyour behalf is the next stage. You have context, you have alerting, you have all these \\ndisaggregated unbundled verticals like Pandora, but I think next you’re going to see this \\nreally cool future where you’re going to express a desire and intent and something else \\nis going to make it happen. I think that’s what I’m most excited about, and why I think \\nfor data scientists, the world is your oyster.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 44}, page_content='MIKE DEWAR \\nData Scientist at The New York Times R&D Lab\\nCan you trace your career path for our readers? What got you interested in data \\nscience? What got you interested in bitly and The New York Times, and what \\nprojects have you done that you can share with our readers?\\nI got my PhD in Modelling Complex Systems from the University of Sheffield in the UK. \\nThe department is called Automatic Control and Systems Engineering, which in the US \\nis sometimes called Controls or Cybernetics — it’s the study of feedback, modelling, and \\ncontrol.\\nMy PhD looked at modelling spatial-temporal systems. The idea is that you would collect \\ndata from the physical space and then build dynamic models of how the system evolved \\nthrough time using the data you collected.\\nThen I did a few postdoctoral positions. I did a post-doc at the University of Sheffield for \\na year. We worked with Unilever and I looked at modelling how people were brushing \\ntheir teeth. By attaching sensors to a toothbrush with accelerometers and positional \\nsensing, they collected all this data about how people brushed their teeth — it was a very \\nstrange gig.\\nI did that for a year, spent some time writing up the papers for the PhD, and then I \\ndecamped to Edinburgh University, where I worked in the School of Informatics, studying \\nMike Dewar is a Data Scientist at the New York Times R&D \\nLab. Mike holds a PhD from the University of Sheffield, UK, \\nwhere he studied the modelling of complex systems using \\ndata. His current work now focuses on building tools to \\nstudy behaviour.\\nBefore joining The New York Times, Mike worked at the \\nNew York tech company bit.ly, and completed postdoctoral \\npositions at Sheffield, Edinburgh and Columbia Universities. \\nIn this interview, you’ll read Mike’s stories about fruit fly \\nnecrophilia, how The New York Times looks into the future \\nand ways that data science is affecting journalism.\\nMike is a data ambassador for the non-profit organization DataKind, and has published \\nwidely on signal processing, machine learning and data visualization.\\nData Science in Journalism'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 45}, page_content='MIKE DEWAR 41\\nthe behaviour of fruit flies. The biologists would alter the brain of the fruit fly and observe \\ntheir changes in behaviour. In courtship behavior, specifically, the changes were easy to \\nsee. If you place a male fruit fly in a small space with a female fruit fly, even the dead \\nbody of a female fruit fly, it will mate with her. Well, it will definitely try at least, which \\nis a bit grim.\\nSo, there were loads of fun modelling of sequences and some nice machine learning. I even \\ngot to learn how to prepare mutant fruit flies. Most of this work was done at Edinburgh but \\nalso included a little bit of work at Harvard, at the Longwood Campus. Then I got the gig \\nat Columbia, which was in the Applied \\nPhysics and Applied Math Department. \\nThat was with Professor Chris Wiggins, \\nwho you might have come across in your \\nstudies of data science.\\nHe and Hilary Mason wrote a blog post \\nwhich outlined various steps of data \\nscience, namely: “Obtain, scrub, explore, \\nmodel, interpret.” The steps outlined this idea of a data science flow being practical and \\nproducing tangible outputs. Chris was thinking a lot about that with Hilary while I was \\nstudying T-cells.\\nThere are lots of different types of T-cells - the population of these different T-cells \\nin your body changes before, during and after an infection (this is how immunization \\nworks). So after an infection, you have “memory” T-cells in your body. The group at \\nColumbia was very interested in how T-cells change to this “memory” state.\\nThey collected lots of genetic data and looked for different genes that were responsible \\nfor changing the state of these populations of cells. You’d be working with 8 microarrays, \\nbut each microarray would have 25,000 genes on it. You had a very strange machine \\nlearning problem, whereby you had very little data to go on but it felt like you had a lot \\nbecause of all the features.\\nIt was through Chris Wiggins that I met Hilary Mason, who was my boss at Bitly. I had also \\nbecome engaged to a girl who lives in New York, so when it came time to start thinking \\nabout what was next after my post doctorate at Columbia, it was important to me to \\nstay in New York. But life as a postdoctoral student in New York sucks because it’s quite \\nexpensive here. At the same time, the idea of “big data” was just coming to the forefront. \\nThere were numerous social media companies that were just starting to think about \\nwhat they might do with all their data. I was interested in behaviour and making tools \\nfor studying behaviour, so Hilary showed up at just the right moment when I wanted to \\nEssentially, leaving academia is a moment \\nwhere you have to decide if you want \\nto be a professor or not, and I think I’d \\nalready decided that was not quite what \\nI wanted to do.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 46}, page_content='MIKE DEWAR\\n42\\npay the rent, stay in New York, study behaviour, and use lots of data while doing it.\\nSo I jumped ship and went to Bitly as a data scientist. I think I’m probably amongst the \\nfirst people who had that title. I made tools at Bitly for studying very large numbers of \\npeople’s behaviour and trying to build interesting, potentially profitable streams.\\nBitly ran its course. I was there for about a year and a half. We did lots of interesting \\nthings, but it became time to move on. About that time, a position at The New York Times \\nR&D Lab showed up, which was somewhere I’d wanted to work for years, so I moved over \\nto the lab where I’ve been now for about two years doing all sorts of interesting things.\\nEssentially, leaving academia is a moment where you have to decide if you want to be a \\nprofessor or not, and I think I’d already decided that was not quite what I wanted to do. I \\nlike coding and making things, but I don’t enjoy talking all day, so that was the decision \\nI made.\\nWe’ve been talking to a lot of people who decided to jump ship from academia. \\nIt seems like a lot of them have been citing reasons such as the lack of dynamism. \\nThey felt that data science was much more interesting and fast paced. Did you feel \\nthat as well?\\nNo, not really. Academia was very fast paced and very intense, with cutting edge \\nresearch. The stuff I got to work on was amazing. Watching the very modern imaging of \\nT-cells changing and learning about viruses was overwhelmingly fascinating. When the \\npractical wasn’t going quickly, the theoretical was going quickly, and there were always \\nten different things to do.\\nI had a very interesting time in academia. Postdoctoral positions are great fun. Lecturing, \\nhowever, didn’t look like so much fun. I wanted to hold onto the fun bits of academia and \\nget paid, which is no small thing when you are starting a family. When staying in New \\nYork, which is a bizarrely expensive place, a certain set of constraints comes your way. In \\nshort, academia was amazing.\\nIt seems like from your academic background you learned a lot from looking at a \\ncomplex system, a mass of data, and extracting stories and hypotheses from that. \\nYou talk about how the unifying theme in data science is actually just identifying \\nmassive behavioural phenomena. What is your advice for identifying the questions, \\ntelling the stories, and identifying the hypotheses in the data set; especially since \\nyou say data science is all about abductive reasoning, finding stories, and learning \\nfrom data? What is your advice for learning which story to tell with data and what \\nto look at?'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 47}, page_content='MIKE DEWAR\\n43\\nThe key piece of advice is always to draw lots of pictures and draw them very quickly. \\nDraw pictures of how things work, even just flow diagrams or engineering block diagrams. \\nMake very rough, quick visualizations of what’s in the data, starting with time series \\nand histograms. Thinking hard about graphical modelling and really trying to get to \\ngrips with the system and data set that’s in front of you helps you think about how the \\nprobabilities fit together.\\nThe danger that I see people getting \\ninto is that the drawing of the picture \\nbecomes the last thing you do, like when \\nyou’re reading an academic paper. The \\nresults and pictures are always at the end \\nof an academic paper, which is a terrible \\nshame. I think the paper should start with pictures of time series and distributions, and \\ngo from there into the theory. That’s often how we work.\\nThat would be my very general advice: to fail early and to fail often. It’s okay to draw lots \\nand lots of pictures that might all be rubbish, but if you draw pictures quickly and really \\nstart to understand what’s actually going on, you begin to get much deeper ideas of what \\nthe right questions are, than if you just start with a classifier.\\nCan you elaborate on drawing pictures a bit more?\\nI learned a lot at Edinburgh about graphical modelling, which is a very simple technique \\nfor exploring conditional probabilities and trying to explore how random variables in a \\nsystem affect one another. The beautiful thing about graphical models is that if you start \\ndrawing them, you are, at the very same time, beginning to explain your assumptions \\nabout the system. Also, you’re starting to do quite a mathematical task of imposing \\nsome structure that you can then test. I really enjoy quickly trying to show whoever I’m \\nworking with a graphical model of how I think things work. The conversation gets going \\nvery quickly and it leads to testable hypotheses, which is great.\\nThe other interpretation of drawing things quickly is to get immediately into the data \\nset. As soon as someone hands you a data set or gives you access to a stream, the very first \\nthing to do is to find an interesting variable in the data set and plot it. If it’s over time, \\nplot a time series. If you’ve got lots of samples of that variable then plot a distribution. If \\nit’s both then plot both. You can do that using Python, or R, or Tableau, or Excel. Do that \\nfirst and don’t waste time. It takes five minutes to make some plots.\\nThe reason is that it gets you thinking about your assumptions in the same way that \\ngraphical models do. The distributions and the time series get you thinking about the \\nMake very rough, quick visualizations \\nof what’s in the data, starting with time \\nseries and histograms.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 48}, page_content='MIKE DEWAR\\n44\\ndata. Both of those together are the beginning of a modelling process that will see you \\nin good stead. It’s quite an iterative process. If all you’ve got is a Bash terminal, then I \\nwould sort my data and then pipe that to “uniq –c” to get a really cheap histogram.\\nYou say that visualization and communicating data is very important because it \\nhelps other people generate hypotheses and trust the data. What advice do you \\nhave for the best way to approach making visualizations to an internal company \\naudience?\\nOne thing we’ve been doing lately is trying hard to show all the data. I would normally \\nstart by thinking about how a system is working and what I’m trying to get out of a data \\nset. Then I would draw some aggregate visualisations, for example, a histogram if I’m \\ninterested in how things are distributed, or a line plot if I’m interested in a time series.\\nOne thing we’ve tried to do more recently \\nis to draw every single data point in a \\nvisualisation, rather than aggregating, \\njust like in a scatter plot. This is something \\nmade much easier as I now get to work \\nregularly with Nik Hanselmann, who is \\na creative technologist in the lab and is \\nextremely adept at this sort of thing. If \\nyou can make a scatter plot of a large data set interpretable, then that act of showing all \\nof the data points allows people to see a zoomed out view of the whole thing and allows \\nthem to pick on individual data points. They see the outliers and wonder why there’s an \\noutlier there.\\nClusters are another good example. If you’ve done your scatter plot well and people can \\nstart to pick out different features of the scatter plot by looking directly at the bit of data \\nthat you want to show them, then they start to ask questions and start to wonder. That \\nhelps you as the analyst or the data scientist. It helps you in trying to understand what \\nyour audience is actually interested in and how you might help them make decisions. It’s \\nan incredibly difficult thing to do without some sort of interaction like that. Trying to \\nshow all the data points is quite challenging sometimes, but that’s been oddly effective \\nover the last year or so. \\nOther than that, axis labels. I feel old saying it but lots of people don’t put axis labels on \\nthings. You read lots of blog posts about lying with statistics and all that sort of stuff and \\nall the tricks people play, which is fine, but it’s very difficult to get away with those tricks \\nif you label your axes properly. You shouldn’t trust any graph that doesn’t have their axis \\nlabelled properly.\\nAs soon as someone hands you a data \\nset or gives you access to a stream, \\nthe very first thing to do is to find an \\ninteresting variable in the data set and \\nplot it.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 49}, page_content='MIKE DEWAR\\n45\\nHow do you think this whole explosion of data, as well as computational power \\nand analysis on top of that, is going to affect the nature of journalism?\\nThe reason that I ask this question is that where I went to school at UC Berkeley, \\nthere were actually quite a few workshops held for students who wanted to go \\ninto journalism, but these workshops weren’t at all about journalism. They were \\nall about D3, Javascript, Python, and R. To somebody who doesn’t have as much \\nbackground knowledge, how would you describe what’s going on regarding big \\ndata and journalism?\\nThere are a few parts to your question. There have been computer-assisted reporting \\n(CAR) journalists for a long time now. Our computer-assisted reporting desk has been \\naround for many years so the idea that data has been affecting journalism is not a new \\none.\\nThis is how I came to grips with the term “big data.” A friend of mine pointed out that \\nwe should think about big data like we think about punk — a cultural moment that was \\nmeaningfully hyped for a period, which then led to a lasting change in society.\\nI like this idea of “big data” as a cultural \\nmoment because there’s been a definite \\nchange in the amount of data we can \\ncollect and the expectation of collecting \\ndata in the first place. The standard costs \\nof storage, processing, and transmission \\nhave all gone down. There has been, over the last few years, a dramatic cultural shift in \\nand around data storage. That hasn’t gone by journalists — it’s quite the opposite. What \\nthey’re faced with are huge data sets that they think might contain stories. Or it’ll be the \\nother way round where they believe that there is a story and will use the FOIA (Freedom \\nof Information Act) to get data sets.\\nWhen they’re telling a story, or they believe that there’s data associated with the story, \\nthey will search government organizations or FOIA organizations that have worked with \\nthe government and are subject to the Freedom of Information Act. I think the rise of \\nthe FOIA is an interesting response to big data in the sense that a journalist will often \\nassume that there is data associated with a story and will demand to see it.\\nRather than the WikiLeaks style, where there is a huge data dump for one reason or \\nanother, journalists will believe that there is data associated with their story and will \\nuse FOIA data in order to support the story. This is a lot more work, and that work is a \\nlot more laborious. The impact of big data is a culture where we expect there to be data.\\nA journalist will often assume that there \\nis data associated with a story and will \\ndemand to see it.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 50}, page_content='MIKE DEWAR\\n46\\nThe other side of that, which I think is probably a bit sexier, is the WikiLeaks side of \\nthings, where there is a huge pile of data that is being made available - like the Medicare \\ndata. There’s a huge data set that’s been released around how Medicare dollars are spent \\nwith personal information about doctors that receive Medicare funding. There have \\nbeen a lot of stories out of that data set that are very interesting. That’s the other mode \\nthat journalism works in. That’s when people want to use R, or Python, to clean and \\nanalyse the data and d3, ggplot, or matplotlib to build visualizations of that data set. D3 \\nis especially interesting because it’s used to make web and print graphics, which is why \\nyou see it a lot. \\nWhat can you share with us about what you do at the R&D Lab, especially since \\nmost of the people we’ve been talking to work at technology companies, instead \\nof a journalism company with a very strong technology component?\\nThe R&D Lab was set up in 2006 to fulfill a number of roles. Specifically, it tries to think \\nthree to five years into the future, tracking social, cultural and technological trends \\nrelevant to The NYT. That gives us quite a range of possible projects.\\nThe other function of the R&D Lab is \\nessentially to listen. That takes two \\nforms. One is a futurist approach where \\nwe try and watch what’s going on in the \\nblogosphere and watch what’s going on \\nin new technologies. We try and keep an ear out for anything that looks like it might \\nhave something to do with the future. \\nWe also act as a gateway. If someone is developing a new, interesting business software  \\nthat they think The New York Times might be interested in, but there’s not an immediately \\nclear use case, often we’ll speak to them. We’ll ask them some questions and try and \\nunderstand what they think the future looks like. We can think about how that fits in \\nwith how The New York Times thinks about the future.\\nIn terms of projects, it’s quite varied. We’re thinking a lot lately about how to extract \\ninformation from article data. Given an article, can you extract all of the statistics, the \\nquotes, facts and events? This is a tired old problem, so we’re trying to think about other \\nways we might accomplish that. Can we capture information like that during the writing \\nprocess or the editing process or the production process, rather than approaching the \\narticles with an extractive, natural language processing view? It would be much more \\ninteresting to see what metadata we could generate in the first place.\\nThat’s an example of journalistic stuff. Then, we think about how the news might be \\nWe’re thinking a lot lately about how to \\nextract information from article data.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 51}, page_content='MIKE DEWAR\\n47\\npresented in the future. One example is a good idea that the lab had regarding the \\nfuture of tablets. The New York Times R&D Lab had thought about what a tablet reader \\napplication would be like well before the iPad came out. When the iPad did come out, \\nThe New York Times had a head start in understanding how people might interact with \\ntheir tablet and what would be interesting to show on it.\\nWhat advice do you have for other PhD students and people in academia transitioning \\nto data science, especially since you’ve been through this already? What advice \\nwould you give someone interested in transitioning to data science?\\nCode in public, that’s number one. If you’re going to \\nbe a data scientist, you’re probably going to have to be \\nable to program in one way or another. There are lots \\nof different options, but you’re probably going to have \\nto be quantitative and be able to write non-trivial programs on the computer. As you \\ncode, as you practice, as you go to hackathons, as you code for your post doctorate or for \\nyour PhD or for your graduate degree, make sure you do it in public. Put it on Github. \\nTo a certain extent I’m on the other side of it now where I put every thing I think of on \\nGithub, so it’s a bit of a mess.\\nEspecially with PhDs, one of the problems we see is that although they come from \\nimpressive universities, they have impressive resumes, and they’ve written these nice \\npapers, but we still have no idea if they can actually write code. That makes them more \\ndifficult to hire.\\nCoding in public also encourages you to engage with communities that you work with. \\nThere are programming communities that share your languages; academic communities \\nthat might want to use your code to test out your claims; and companies that want to \\nevaluate you and reduce the risk in hiring you.\\nThe other thing is networking. It’s more or less the same thing, but it’s important. In \\nmajor cities it’s very easy for you to get out of your office or house and visit meetups \\nand user groups to give a talk. Giving talks about your academic work to lay people is an \\nincredibly interesting and enlightening experience, one that you should go through. It \\nalso exposes you to the business communities and the various kinds of people that you \\nmight want to get jobs from in the future. It also shows you what other people are up to; \\nit knocks your academic naivety very quickly, which is great.\\nOther than coding in public and networking, try to apply all your work to something. \\nI wrote three papers for my PhD, and they were all about the EM algorithm. There’s a \\nload of spatial-temporal models that I put a lot of work in to. Over 3-4 years, I wrote \\nCode in public.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 52}, page_content='MIKE DEWAR\\n48\\nsome papers, and nobody cared, nobody at all. However, when we applied this theory to \\nmodelling troop movements in Afghanistan, lots of people cared. We won awards. We \\nwrote a book. We were in the news. The idea of taking the advanced things that you learn \\nat school and applying them to something important and meaningful exposes you to a \\nworld that’s difficult to see from the incremental science of being a good student.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 53}, page_content='RILEY NEWMAN Head of Data at Airbnb\\nCan you explain a bit about your background and how you came to Airbnb?\\n \\nI went to college in Seattle where I majored in international politics and economics. \\nHalfway through my time there, I realized the value of statistics for understanding social \\ntrends better. This was something I deepened in grad school, and wanted to pursue in a \\nPhD, but I had joined the Coast Guard in undergrad to pay for school and they called me \\nback from the UK after my master’s. So I came home to the Bay Area with the plan to get \\nsome experience working with data while completing my Coast Guard obligation and \\nthen planned to head back to the UK for the PhD.\\n \\nI spent three intensive years working with a group of economists that were modeling \\nthe 2008 recession. One of them had a degree in computer science and taught me the \\nvalue of automating analytical processes, which I found intriguing. When the time came \\nto leave for the PhD, I was torn — I only wanted to do it for the technical training; my \\nheart wasn’t in academia, and I was a bit tired of consulting. Serendipitously, I met the \\nfounders of Airbnb through a mutual friend, right as I was struggling with this.\\n \\nThere are a couple of things about Airbnb that resonated with me. First and foremost, \\nthe concept behind the company. In undergrad, I read a lot about globalization and the \\ngrowing interconnectedness of the world; also about the fundamental sustainability \\nissues associated with this trend. Airbnb struck me as a solution — it would facilitate more \\ntravel and bring international communities together without requiring the construction \\nof additional structures.\\nRiley Newman paid his way through college at the University \\nof Washington by being part of the US Coast Guard. After \\ngraduating with degrees in economics and international \\nstudies, Riley pursued graduate studies in the UK at the \\nUniversity of Cambridge, before he was called back to the \\nUS by the Coast Guard.\\nAfter working for a few years in economics consulting, \\nRiley met the founders of Airbnb, and was drawn to their \\nvision and focus on culture. He ended up joining Airbnb as \\none of the early employees.\\nNow, Riley is the Head of Data Science for Airbnb where he data science teams using data \\ndata to listen to customers’ voices and desires.\\nData is the Voice of Your Customer'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 54}, page_content='RILEY NEWMAN\\n50\\n \\nI was also attracted to the founders’ focus on culture. This is something I hadn’t \\nexperienced in previous roles. They placed so much value on the sense of camaraderie \\non the team — more so than high school and college lacrosse teams, Coast Guard units, \\nor the consulting firm — and the impact that brings to our work. Looking back, I think \\nthis is the “secret sauce” of Airbnb’s success.\\n \\nFinally, I was excited about helping to build \\nsomething. As a consultant, I had exposure \\nto a wide variety of problems but, at best, we \\ncould convince the client that our work was \\nactionable. At Airbnb, I would be able to follow \\nthe analysis all the way through to impact. And \\nstartups are fast-paced environments where \\nyou can see the impact of your work on a daily basis. That was really exciting to me.\\n \\nHow does this tie into the industry buzz around ”Big Data”?\\n \\n“Big Data” is such a common term these days. I heard a joke recently, “What do big data \\nand teenage sex have in common? — Everybody is talking about it. Nobody knows what \\nit is. All their friends say that they do it, so they say that they do it too.”\\n \\nLike all buzzwords, Big Data is getting tiring. But I met with a more seasoned data \\nscientist recently who described the field in the ‘80s and ‘90s — there was much less \\ndata so they needed to use advanced statistical methods to identify simple trends. These \\ndays, with the volumes of activity web companies are able to generate, and the depth \\nof storage facilitated by technologies like Hadoop, we’re able to gather and make use of \\nmuch more data. So it’s more of a question about how to sift through it all. I think this \\nhas made computer science degrees that much more valuable.\\n \\nI have a data scientist friend whose resume begins with three things he firmly believes: \\nmore data beats better models; better data beats more data; and the 80/20 rule. I couldn’t \\nagree more.\\n \\nI think that is a really good introduction as to what you think data science is. I want \\nto go back to something that you mentioned earlier; your Master’s degree was in \\nEconomics, is that right?\\n \\nYes, I was in the applied economics department at Cambridge. My research was in the \\nfield of economic geography/spatial econometrics.\\n \\nThey placed so much value on the \\nsense of camaraderie on the team. \\nLooking back, I think this is the \\n“secret sauce” of Airbnb’s success.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 55}, page_content='RILEY NEWMAN\\n51\\nMany people we’ve interviewed have their PhD or Masters in physics, statistics, \\nmath, or computer science. You’re one of the few data scientists we’ve talked to \\nwith an economics background. Do most people on your team tend to come from \\nbackgrounds in the hard sciences or are the social sciences represented as well?\\n \\nEveryone on the team has some degree of \\nquantitative training but I like having a wide \\nvariety of backgrounds because this brings \\ndifferent skill sets and approaches to solving \\nproblems. For example, computer scientists \\nare great at scripting automated solutions and \\nproductionizing models; statisticians ensure our models are rigorous; physicists are \\nvery detail-oriented; and economists can build frameworks for understanding problems. \\nAirbnb is particularly interesting to economists because of our two-sided marketplace, \\nwhich lends itself to modeling supply and demand, and looking for ways to make our \\nmarkets more efficient.\\n \\nBut the key thing is that everyone on the team is able to drive impact in the company \\nthrough the cultivation of insights drawn from data. I’m less interested in what people \\nstudied in undergrad than in their ability to do this successfully. However, this requires \\na solid grasp of statistics, experience in coding, and great communication and problem-\\nsolving. Our interview process exposes these skills very well, so we’re able to consider \\npeople from less traditional backgrounds.\\n \\nI agree with you that there isn’t necessarily one particular field that data scientists \\ncome from. However, it does seem like most people come from certain fields that \\ntend to teach some of the most relevant skills. Building on that, what would you \\nsay are some of the most valuable or relevant skills that someone in academia \\nshould build right now?\\n \\nMany people coming into data science from academia have honed their ability to think \\nmathematically or statistically and, to some extent, work with data. The big division that \\nI see is the ability to lend those skills towards problems that will result in an actionable \\nsolution. In other words, the types of questions they ask are as important, or more, than \\nthe methodology behind solving them. In their research, they focus on why something \\nis the way it is or how it works; in industry we’re more interested in what we should do. \\nIf the how or why lends itself to answering this, great. But if nothing changes as a result \\nof your work, then it wasn’t that valuable.\\n \\nWhen we ask other data scientists that question, we hear about technical skills like \\nPython and programming. We don’t hear as much about extracting actionable insights.\\n \\nMore data beats better models; \\nbetter data beats more data; and \\nthe 80/20 rule.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 56}, page_content='RILEY NEWMAN\\n52\\nI’m not saying that those aren’t relevant; I’m presupposing that anyone hoping to \\ngenerate actionable insights from data has the ability to work with the tools of the trade. \\nAt Airbnb, we mostly use Hive, R, Python, and Excel.\\n \\nWhen we interview people, our process is \\nvery transparent (see Quora post on this, \\nhere). We give candidates a day to solve a \\nproblem similar to something we’ve faced, \\nusing real (but anonymized) data. They \\nspend the day seated with the team and \\nare treated like anyone else, meaning they \\ncan collaborate with anyone. At the end of \\nthe day, we have them walk us through what they found and tell us what we should be \\ndoing differently as a result. This is too tight of a timeframe for someone to learn a tool \\nwhile trying to use it to solve the problem. Their time needs to be completely focused on \\ngetting to that actionable insight.\\n \\nContinuing along that vein, you’ve been talking a lot about data scientists coming \\nfrom a Master’s or a PhD. I’m also wondering about your opinion of people coming \\nin with a Bachelor’s in a quantitative field or similar?\\n \\nPeople can absolutely break in with just a Bachelor’s. We shifted to the interview model \\nI described earlier because we realized our image of a data scientist was yielding false \\nnegatives. If you have the right mindset, a decent understanding of statistics, and can \\nuse SQL and R, you’ll be able to get a job.\\n \\nThis is particularly true in younger startups. When I think back to the early days of \\nAirbnb, we were able to squeeze a lot of growth out of a simple ratio. If I spent a month \\nbuilding a perfect model, I would have wasted 29 days. As a company matures, so does \\n(hopefully) its understanding of its ecosystem. So there’s a need for more sophisticated \\napproaches.\\n \\nYou started at Airbnb when it was in a really early stage. Now you’re at the point \\nwhere it’s growing very fast — it’s become a large company. What are some of the \\nways you’ve seen that transitioning into the work that you actually do?\\n \\nI see this transition shaping our work in two ways. First, the team is big enough now that \\nwe’re able to go much deeper into problems. In the past, we were jumping from one fire \\nto the next, so we weren’t able to invest large amounts of time into a single problem. \\nAnd that’s natural for a startup. But as the team has grown, we’ve been able to focus on \\nsome of the key topics for the business and understand them more deeply. We also now \\nWhen we ask other data scientists that \\nquestion, we hear about technical skills \\nlike Python and programming. We \\ndon’t hear as much about extracting \\nactionable insights.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 57}, page_content='RILEY NEWMAN\\n53\\nhave people on the team building data products, which is exciting.\\n \\nSecond is the democratization of information. We’re not the only team that has grown \\nover the last few years and everyone is hungry for data to guide their work. So we have \\nto find ways to remove ourselves from the process of answering basic questions. The last \\nthing you want to be is the gatekeeper of information because you’ll spend all of your \\ntime responding to ad hoc requests. So we’ve invested a lot in the structure of our data \\nwarehouse and the tools used for accessing it so that it’s intuitive to people with less \\nexperience working with data.\\n \\nWhat do you think are some of the most fundamental ways in which data science \\ncan add value to the company?\\n \\nI think data can add value everywhere. It’s the voice of your customer — data is effectively \\na record of an action someone in your community performed, which represents a decision \\nthey made about what to do (or not do) with your product. Data scientists can translate \\nthose decisions to stories that others can understand.\\n \\nWe spend a lot of time with our product \\nteam, which is the most traditional place \\nfor a data scientist. There’s a wide range \\nof work happening here. For example, \\nour trust and safety team builds machine \\nlearning models to predict risk and fraud \\nbefore it takes place. They also have to \\nthink about ways to measure intangible \\nthings, like the strength of trust between people in our community so we can identify \\nways to improve this.\\n \\nWe have other people working on matching guests and hosts, improving the model \\nbehind our search algorithm and uncovering new features to improve the match. A while \\nback we published a blog post about this here.\\n \\nWith our mobile team, we try to uncover opportunities for improving the app. One guy \\non the team looked at the probability of performing an action on the app relative to how \\nfar away that feature is from the homepage. This obviously showed that the more buried \\nsomething is, the less likely it is to happen — but it’s a framework the mobile team can \\nnow use to think through the structure of the app.\\n \\nBut we don’t just work with product. We think about user lifetime value and growth \\nopportunities with our marketing team, operational efficiency with our customer support \\nteam, and we’ve even been chatting with our HR team about how they can leverage data \\nWhen I think back to the early days of \\nAirbnb, we were able to squeeze a lot of \\ngrowth out of a simple ratio. If I spent a \\nmonth building a perfect model, I would \\nhave wasted 29 days.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 58}, page_content='RILEY NEWMAN\\n54\\nto better understand recruiting and career growth.\\n \\nI try not to segment our work by stakeholder; rather I look at the key drivers of the \\nbusiness and try to figure out what problems need to be solved in order for Airbnb to be \\nbetter, and then figure out who is in the best position to use that information.\\n \\nAirbnb is a transactional business so \\nthere’s a funnel we can break apart and \\nanalyze. And getting back to the concept \\nof data being the voice of the customer, we \\nalways start by looking to our community \\nfor advice on what to do next. At the top of \\nthe funnel we try to understand how people \\nare hearing about Airbnb. We can use \\nonline and offline marketing to drive this, emphasizing growth where we think there’s \\na strategic opportunity or where we’re seeing positive ROI (return on investment). For \\nthis, we begin by looking to our community for ideas; for example, where many people \\nare searching for places to stay but we don’t have enough supply to accommodate them. \\nIf this isn’t an anomaly (e.g. one-off event), it represents an opportunity for growth.\\n \\nNext is the experience people have when they come to our site. There’s a lot of A/B \\ntesting here, looking for ways to make it more intuitive and satisfying to a person of any \\ndemographic, anywhere in the world.\\n \\nAfter that is the offline experience, which is tricky because the data behind this isn’t \\nas rich as site usage. But we can get a lot from the reviews people leave each other - a \\ncombination of quantifiable ratings and NLP we can perform on the text of the review.\\n \\nFinally, we look at what we can do to get people to come back and try it again. Mostly, \\nthis means improving each of the steps above, but we think about experiences people \\nhave with customer support or community groups as a way of staying connected.\\n \\nThe final thing I would love to get your perspective on is just looking towards the \\nfuture.  Where do you think the future of data science is and where do you think \\nwe are relative to what data science could be in the future?\\n \\nI think we’ll see a lot of growth on the tools front. It’s amazing how quickly Hadoop \\nand Hive have matured just over the last few years and there are new and exciting \\ntechnologies emerging almost daily. So I’m hopeful that we’ll eventually have lightning-\\nfast tools that can work with data of any size.\\n \\nI also think data logging will develop a lot, because people are aware that you only focus \\nSo we’ve invested a lot in the \\nstructure of our data warehouse and \\nthe tools used for accessing it so \\nthat it’s intuitive to people with less \\nexperience working with data.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 59}, page_content='RILEY NEWMAN\\n55\\non what you can measure, and you only measure what you can log. So questions like we \\nhave about the offline experience will hopefully get easier to answer as data becomes \\nmore ubiquitous.\\n \\nEvery now and then I see an article about \\nthe field of data science disappearing to \\nautomation. In effect, the tools get so good \\nthat you don’t even need to analyze data; \\nthe insights are just there waiting for you. \\nWhile this may be partially true with the \\ngrowth of machine learning, I don’t think it will ever fully be the case. Good data science \\nis more about the questions you pose of the data rather than data munging and analysis.\\n \\nBut with that in mind, I can imagine the field of data science opening up to people that \\nare less technical. As tools get more sophisticated and easy to use, we’ll see more people \\ngetting excited to work with data. We’ve already observed this at Airbnb, where we train \\neveryone in the company to use SQL. As I mentioned earlier, you don’t want your data \\nscience team to be the gatekeepers of all information. We want everyone to be able to \\ninteract. I love watching people with no background in statistics or CS wrapping their \\nminds around the basics of working with data. They get so excited, then they get curious. \\nAnd that frees us up to focus on interesting problems that will impact the business.\\n \\nThis sounds like the democratization of data science.\\n \\nExactly. It’s happening today at Airbnb, and I bet we see a lot more of it in the future.\\nGood data science is more about the \\nquestions you pose of the data rather \\nthan data munging and analysis.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 60}, page_content='CLARE CORTHELL Data Scientist at Mattermark\\nWhat was your background, before you began the Open Source Data Science \\nMasters and before your role at Mattermark?\\nI’m a product person and an entrepreneur. I fell in love with startups long before I \\nattended Stanford, where I designed a degree in a then-obscure program called Science, \\nTechnology & Society. You get to marry two engineering tracks, so I ended up designing \\na degree in product design and digital development, which then got me started working \\non product with early stage companies.\\nBefore the OSDSM (Open Source Data Science Masters), I was designing and prototyping \\nproducts for an early stage education technology company in Germany. Designing from \\nuser anecdotes alone became difficult when you only pull from anecdotes, so I started \\ndigging deeper into analytics and customer profiling. I started thinking about observing \\nmeta-trends among users instead of studying their behavior with a clipboard from \\nbehind a one-way window. What if I just ran several tests on two different prototypes? \\nThen we would have data to tell us which one to develop! But as with many European \\nstartups, the company didn’t get funded, so I had a few weeks to think about how this \\nnew perspective fit in. On a long layover in Barcelona, I ordered an espresso and wrote \\nAfter graduating from Stanford, Clare Corthell embarked on \\na self-crafted journey to acquire the knowledge and skills \\nto understand and analyze macro-behavioral trends. One \\nthing led to another, and her collection of resources turned \\ninto the Open Source Data Science Masters - a curriculum \\nof online courses, books and other resources that one could \\nuse to learn the mathematical and programming foundation \\ncrucial to a data scientist.\\nClare took a risky move by crafting her own degree program, \\noutside of traditional educational institutions. She faced \\nskepticism of a self-taught individual in a job that is typically \\ninhabited by PhDs, but also found a community of supportive colleagues.\\nOvercoming these challenges, Clare completed her Open Source Data Science Masters and \\nfound herself as a data scientist at Mattermark, a venture-backed data startup working with \\nlarge datasets to help professional investors quantify and discover signals of potentially \\nhigh-growth companies.\\nCreating Your Own Data Science Curriculum'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 61}, page_content='57CLARE CORTHELL\\ndown the technical skills I would need to dissect meta-trends and understand user data. \\nThat list laid out 6 months of full-time work, after which I’d really be able to do some \\ndamage. This became the Open Source Data Science Masters.\\nAs with any story, it \\nis now retrospectively \\nclear that I would \\nsecretly fall in love with \\nan applied statistics \\nclass I cheekily called \\n“Exceltastic.” We \\nworked with Bayes’ \\nTheorem and Markov Chains in the business context, figuring out things like how many \\ncars can pass through two toll booths per hour. Everyone else sulked and moaned through \\nmunging spreadsheets while I harbored a dirty secret: I loved Excel models! Even so, I \\ndidn’t know when my toll booth throughput calculations would be demanded of me, nor \\nwhat class logically comes next. It took getting into industry to shed light on the value \\nof keeping metrics. Things like my Exceltastic class don’t seem to fit into an overarching \\npuzzle, but we believe they shape our path. That’s the power of confirmation bias. One \\nof my favorite designers has this phrase that he prints in various media: “Everything I do \\nalways comes back to me.” I’ve always found that fitting.\\nWhat is the Open Source Data Science Masters? What does its curriculum look like?\\nIt’s a collection of open-source resources that help a programmer acquire the skills \\nnecessary to be a competent entry-level data scientist. The first version included \\nintroductory linear algebra, statistics, databases, algorithms, graph analysis, data mining, \\nnatural language processing, and machine learning. I wrote the curriculum for myself, \\nthen I realized that people all over the internet were asking for it, so I published it on \\nGitHub.\\nIn August, I opened the curriculum for pull requests on GitHub. Without feedback it’s \\ndifficult to know whether you’ve covered the right things. Further, it was an effort to get \\nfeedback on the idea of an institution-free degree, a kind of home-school for advanced \\ndegrees. The internet was astonishingly supportive and excited — and that excitement \\nis addictive. It makes you want to be more transparent, and to become part of other \\npeoples’ wonder in learning new things.\\nHow did you get started with the Open Source Data Science Masters?\\nI knew that a traditional Masters program would take at least the next three years of \\nI started thinking about observing meta-trends among \\nusers instead of studying their behavior with a clipboard \\nfrom behind a one-way window. What if I just ran several \\ntests on two different prototypes? Then we would have \\ndata to tell us which one to develop!'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 62}, page_content='58CLARE CORTHELL\\nmy life, but even more importantly it wouldn’t focus on what is core to the profession \\nI wanted to enter. I knew what I wanted and I was willing to take the risk of a non-\\ninstitution education.\\nI set out for the curriculum \\nto take 6 months to complete \\n(March - August 2013), with a \\nsmall project at the end and \\nvarious programming mini-\\nprojects focusing on scraping, \\nmodeling, and analysis. It was \\namazing how difficult it was \\nto manage myself. School gives you this structure that you don’t have to question or \\ndesign, which you don’t really see until you have to manage your own curriculum and \\ndeadlines. There’s a lot of product management that goes into an educational track like \\nthe OSDSM. I’m grateful to all the people who supported me and helped me throughout, \\neven if they didn’t quite understand the strange and uncharted waters I was braving to \\nget there.\\nHow did you find the resources?\\nI reverse-engineered most of it from job descriptions that interested me. This meant \\ncompanies I believed would grow quickly and provide the most opportunity: mid-stage \\nstartups, 100-200 people, existing data science teams and reverence for the methodology. \\nI didn’t want to be the lone wolf and knew I needed mentorship.\\nPeople tend to frown on centering the goals of the classroom on applicability in the \\nreal world, but a classic liberal educational approach in a technical career pivot won’t \\nserve you. This is a technical vocational degree, so the goal was very concrete. I should \\nbe employable and employed on a data science (or Analytics Engineering) team after \\ncompleting the curriculum.\\nThere was another realization that coalesced very quickly: the act of designing from \\ninsights of single users does not scale. I was also hankering for something more technically \\nand algorithmically challenging. I’d bought this book before I moved to Germany, \\nProgramming Collective Intelligence . I just bought it, I really had no reason to. When I \\nfirst opened it up, I understood next to nothing. But I carried it with me in Germany, and \\nevery time I opened it, something new jumped out and I understood more about scaling \\nuser insight. The book became my cornerstone, how I measured my progress. It’s a bible \\nfor Data Scientists.\\nIt took getting into industry to shed light on the \\nvalue of keeping metrics. Things like my Exceltastic \\nclass don’t seem to fit into an overarching puzzle, \\nbut we believe they shape our path.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 63}, page_content='59\\nI also used the following resources/websites:\\n• Quora: This is a great resource for the Valley — it’s truly navel-gazing, but if that’s \\nwhat you’re doing, it’s useful. People like DJ have answered questions about what a \\nData Scientist does on a daily basis. You can start to discern the technical capacities \\nthat are required of you, mathematical foundations that are necessary, and so forth. \\n• Blogs: Zipfian Academy, a data science bootcamp, had a blog. They had a great post \\non the resources they saw as core to becoming a data scientist: A Practical Intro to \\nData Science\\n• Coursera: I’m Coursera’s biggest fanboy. They’re part of this quietly-brewing \\neducational revolution, which will soon be less quiet. My story is a tremor before the \\nearthquake, I’m just waiting for the ground to start shaking.\\nHow much math (probability, statistics, ML) did you try to learn? How much math \\ndo you think a data scientist needs to know?\\nYou don’t have to know everything. That’s why I’ve tried to keep the curriculum so \\ntightly focused on its goal. Programmers are great at “just-in-time” learning because it’s \\nimpossible to know everything. That’s a great trait. If you have a core set of competencies \\nand understand how to “debug” problems and learn what you need to solve them, you \\ncan do damage. And naturally, you improve over time by recognizing new problems as \\nchunks of old problems you’ve already seen and solved.\\nSo much of this curriculum \\nis abstract, and that’s where \\npeople get scared. People are \\nscared of math because it’s not \\napplied in our education system. \\nBut those scary elements of \\nmath and abstraction diminish \\nwith concrete examples and \\nconversations with others. I had a few phone-a-friend lifelines, and I ate up Khan Academy \\nand Coursera videos. There’s something magical about how much more communicative \\nspoken English can be, especially when you can rewind and digest a concept for the \\nsecond, third, or even fourth time. You can always talk through a problem with someone \\nelse, even if they’re not an expert. Talking through things is synonymous with debugging. \\nOne of my mentors calls this “the rubber ducky method,” because if you talk a problem \\nthrough to a plastic duck, sometimes you start to find the holes in your assumptions. \\nThen you can plug them up.\\nIf you think about people as having different levels of competency in these different \\nrealms, it doesn’t take long to understand that working as a team allows you to stack \\nCLARE CORTHELL\\nThe internet was astonishingly supportive and \\nexcited — and that excitement is addictive. It \\nmakes you want to be more transparent, and to \\nbecome part of other peoples’ wonder in learning \\nnew things.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 64}, page_content='60CLARE CORTHELL\\nyour respective skills on top of one another. Having specialties among the team is really \\nessential to getting things done in a small organization. I was lucky enough to join a \\ncompany where I get mentorship in verticals where I’m middling or even an amateur. It’s \\namazing to learn with other people. Finding a job where you have mentors and training \\nis essential to continue to grow and improve. And if you’re not improving and growing, \\nyou’re dead in the water. So that’s a long-winded way of saying: Working with other \\npeople is essential to working with more complex concepts and systems. Rome wasn’t \\nbuilt by some guy, and probably not at a weekend hackathon.\\nWhat would you do differently if you could redo the Masters?\\nAs Patient Zero of a new type of \\ninternet-based institution-free \\neducation, I didn’t know what \\nto expect. It was impossible to \\nknow how I would be judged and \\nwhether I would benefit from my \\nexperiment. This type of ambiguity \\nusually makes people extremely \\nuncomfortable. It’s like leaving a six-year-old in the library by herself instead of putting \\nher in class with a teacher. What is she going to do? Pull a bunch of books onto the floor \\nand see how high she can stack them? Watch birds at the window and think about how \\nwings work? Or is she going to find something interesting and gather books that will \\nhelp her form her own ideas about the world?\\nI knew that it would be a risk, but I took a leap of faith and left myself alone in the \\nlibrary. In the end, the greatest reward didn’t come from the curriculum, it came from \\nwhat taking a risk demonstrated about me. It led me to a tribe that respected the risk \\nI had taken, and valued the grit that it required to follow through. Many people were \\ndispleased that I let myself into the library without an adult. But I’m not interested in \\ntaking the recommended path and clinging to a librarian. I have no interest in small \\nambition.\\nWhat’s the difference between data science job descriptions & day-to-day role at \\nMattermark?\\nOur CEO Danielle was once asked how many data scientists we have at Mattermark. \\nWe’re all data scientists, she thought — we all use, manipulate, and analyze data on a \\ndaily basis to make our customers happier and more profitable. We even all write SQL! \\nThat’s not something you see every day at a company, but it’s essential when you’re \\nbuilding and selling a data product. I build products as an engineer, anything from fitting \\nYou don’t have to know everything. That’s why \\nI’ve tried to keep the curriculum so tightly \\nfocused on its goal. Programmers are great at \\n“just-in-time” learning because it’s impossible \\nto know everything.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 65}, page_content='61\\nclustering algorithms, building automated analyses, designing UIs, acquiring new data \\n— it’s a startup. It’s all hands on deck.\\nIt’s not clear that data science is a job title to stay yet. For example, do we know if growth \\nhacking is a subset of data science? We don’t. There will always be a top-level salary for a \\nperson who can turn chaos into insights. That won’t change. Data Scientist is a title we’ll \\ncontinue to use while we figure it out.\\nWhat could someone in school, or otherwise without too much background in \\nindustry learn from your experience?\\nThe ability to evolve my own career with a self-designed curriculum begins to outline \\nthe immense cracks in the foundation of higher education*. The deconstruction of this \\nsystem was very long in coming, but it’s happening now. The lesson is the following: if \\nyou take initiative and acquire skills that increment your value, the market is able and \\nwilling to reward you.\\nThough people continue to believe and \\nespouse old patterns of education and \\nsuccess, these patterns do not represent \\nrequirements or insurance. The lack of \\nany stamp of approval is a false barrier. \\nThere are no rules.\\nIt’s important to understand the behavior of the market and institutions with regard to \\nyour career. When breaking out of the patterns of success, know that people will judge \\nyou differently than others who have followed the rules.\\nThere are two very discrete things that I learned: The market is requiring people to \\nperform tryouts for jobs instead of interviews, and most companies don’t hire for your \\npotential future value.\\nTryouts as Interviews: The economy has set a very high bar for people coming into a \\nnew profession. Job descriptions always describe a requirement for previous experience, \\nwhich is paradoxical because you need experience to get it. Don’t let that scare you, \\nnot for a minute. Pull on your bootstraps and get in the door by giving yourself that \\nexperience — design and execute on a project that demonstrates your ability to self-\\nlead. Demonstrate that you can take an undefined problem and design a solution. It \\nwill give you the confidence, the skills, and the background to merit everything from \\nthe first interview to the salary you negotiate.\\nCLARE CORTHELL\\nThe ability to evolve my own career \\nwith a self-designed curriculum begins \\nto outline the immense cracks in the \\nfoundation of higher education'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 66}, page_content='62CLARE CORTHELL\\nEven more concretely, work with a non-profit organization (or another organization \\nthat doesn’t have the economic power to hire programmers or data scientists) to create \\na project that is meaningful for the organization and also shows off your skills. It’s a \\ngreat way to do demonstrative and meaningful work while also aiding an organization \\nthat could use your help, and likely has problems people are paying attention to \\nsolving. Win-win.\\nCurrent Value vs Potential: Look for \\ncompanies that will hire you for your \\npotential. It’s important to be upfront \\nabout your grit, self-sufficiency, and \\nability to hit the ground running. \\nLuckily, with disciplines like data \\nscience, the market is on your side. \\nSometimes companies can spring for a Junior Data Scientist and invest in your growth, \\nwhich is really what you wanted from the beginning.\\nEveryone will tell you this, but I work on product so I’ll underline it even more \\nstrongly: Learn to write production-level code. The more technical you are, the more \\nvaluable you are. Being able to write production code makes you imminently hirable \\nand trainable.\\n[*NB: Don’t think for a minute that I don’t believe in the tenets of a true liberal education - \\nquite the contrary. I continue to read philosophy and history, in part because we cannot draw \\nfully upon the knowledge of man without doing so. These are essential elements to being a \\npurposed, ethical, and effective person - but they don’t directly accelerate a career. The true \\nliberal education has nothing to do with market forces, and never should. Higher Education \\nas it exists today and Liberal Education should be held as wholly uniquely-motivated \\ninstitutions.]\\nHow was your self-taught path to becoming a data scientist received by company \\nrecruiters? What advice would you share with entrepreneurial individuals who are \\ninterested in the field?\\nTalk with people who can recognize hustle and grit, and not necessarily those who are \\nlooking to match a pattern drawn from your previous experience. Often, these kinds of \\npeople run startups.\\nRecruiters gave me a very real response: They didn’t see my course of self-study as \\nlegitimate. It’s hard to give yourself a stamp of approval and be taken seriously. I wouldn’t \\nrecommend that just anyone do what I did — it will take a while for autodidactism to \\nTalk with people who can recognize \\nhustle and grit, and not necessarily those \\nwho are looking to match a pattern \\ndrawn from your previous experience.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 67}, page_content='63\\nbecome more accepted, and maybe it will never be a primary pattern. But maybe people \\nlike me can help expose this as a viable way to advance professionally. I know that great \\ncompanies like Coursera will continue to innovate on these new forms of education, \\nkeep quality high, and democratize access.\\ntl;dr\\nIf you want to get to the next level, wherever your next level may be, it’s possible to pave \\nyour own road that leads you there. It’s a monstrously tough road, but it’s your road.\\nCLARE CORTHELL'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 68}, page_content='DREW CONWAY Head of Data at Project Florida\\nYour data science Venn diagram has been widely shared and has really helped \\nmany people get an initial sense of what data science is. You created it a long time \\nago, back in 2010. If you had the chance to create it again today, would you change \\nany part of it?\\nQuite a lot. I can speak a little bit about the history of it which I think is probably less \\nglorious than people know. \\nI was a graduate student at NYU and was a teaching assistant for an undergraduate class \\nin Comparative Politics. As a teaching assistant in those classes, your mind wanders \\nbecause you already know the material. \\nIt was 2010, and the idea of data science was much more primordial. People had less of a \\nsense of what data science was. At that time I was thinking about the definition of data \\nscience. I had been speaking to people like Mike Dewar, Hilary Mason and some other \\npeople in New York and was influenced by their ideas and some of my own and came up \\nwith the definition while sitting there in class.\\nThe original Venn diagram I made on data science, which ended up becoming quite well-\\nknown, was drawn using GIMP as the editor — the simplest, cheapest program in the \\nworld. But I’m very happy that it seems people have attached themselves to it and it \\nmake sense to them. \\nAfter graduating with degrees in both computer science \\nand political science, Drew found himself working at the \\nintersection of both fields as an analyst in the U.S. intelligence \\ncommunity, where he tried to mathematically model the \\nnetworks of terrorist organizations.\\nAfter spending a few years in DC, Drew enrolled in a political \\nscience PhD at New York University. It was here that he \\ndrew up his famous Data Science Venn Diagram. It was also \\nduring this time that he co-founded Data Kind, a nonprofit \\norganization which connects data experts with those who \\nneed help. After a stint at IA Ventures as their Data Scientist \\nin Residence, Drew joined Project Florida as Head of Data, where he uses data science to give \\nindividuals better insights into their health.\\nDrew is also the co-author of the O’Reilly book, Machine Learning for Hackers.\\nHuman Problems Won’t Be Solved by Root Mean-Squared Error'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 69}, page_content='65\\nWhat has become more apparent to me as the years have passed is that the thing missing \\nfrom it is the ability to convey a finding, or relevant information once an analysis is \\ncomplete, to a non-technical audience. A large amount of the hard work that most data \\nscientists do is not necessarily all data wrangling and modeling and coding. Instead, \\nonce you have a result, it’s about figuring out how to explain that result to people who \\nare not necessarily technical or who are either making business decisions or making \\nengineering decisions. \\nReally, it’s all about conveying a \\nfinding. You can use words to do \\nthat, you can use visualization \\nto do that, or you can develop \\na presentation to do it. A well-\\nrounded data science team \\nwill have someone who is \\nvery competent at this. If your \\norganization is making decisions \\nbased on your analysis, you need to be sure they understand why.\\nThis echoes parts of what we’ve heard when we talked with Hilary Mason and \\nMike Dewar. Both of them emphasized the storytelling part and how to carefully \\ncommunicate the analysis part.\\nIt’s something that receives the least amount of thought, but turns out to be one of the \\nmost important things once you’re doing this in the wild. Even the people who have had \\nsuccess in data science up to this point have just been naturally good at it, whether they \\nwere blogging about it or giving good presentations. Both Mike and Hilary are examples \\nof people who are good at doing that. They are naturally good at it. People who are not \\nnaturally good at it can learn about it through coaching, and mentorship.\\nIn just the same way, if you’re not a good coder you can become a better coder through \\ncoaching and mentorship.\\n \\nYou said on a Strata panel: “Human problems won’t be solved by root mean square \\nerror.” What did you mean by that?\\n \\nI think when people think about data science, or even machine learning applied to data \\nscience, people think that we have a well-defined problem, and we have our data set. We \\nneed to find a way of taking that problem and that data set and producing an answer that \\nis better than the one that we currently have.\\nDREW CONWAY\\nA large amount of the hard work that most data \\nscientists do is not necessarily all data wrangling \\nand modeling and coding. Instead, once you have \\na result, it’s about figuring out how to explain \\nthat result to people.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 70}, page_content='66\\nFor example, Kaggle does a really good job of finding a problem definition, finding the \\ndata set, saying that it’s connected to that problem and ramping up to a competition. That \\nway people can try and achieve a very specific thing such as having a better predictor, or \\nhaving a better classifier so your errors are small.\\nBut the really hard problems are ones for which we don’t have good well-defined \\ndefinitions for yet. Or we recognize the problem but it’s not obvious how to find the \\nrelevant data that goes with it. Those are really hard problems to me. I’m a social scientist \\nby training, so I think about how human behavior could be observed, what it is that I \\nwant to learn about institutions or policies or government and interventions to help \\nkeep a lid on our lives.\\nThose problems are very hard to model. So they require more creative thinking. \\nParticularly at first, or at the onset where you have no idea if there’s even any relevant \\ndata out there. You might have to go on and run an experiment, run a data collection \\nexperiment. Then try from there. “Ok, what are the models and methods that might work \\nin this context?” At the end, you’re going to spend a lot more time thinking, “ Alright, \\nwhat are the intended and unintended consequences that might result by implementing \\nmy idea?”\\n \\nTake New York City, for example. Let’s say you wanted to optimize the snow removal \\nroutes in New York City when there’s a snowstorm. Those who were in New York when \\nthere was a big snowstorm might remember — there were a lot of people who complained \\nbecause the snow ploughs couldn’t get to certain neighborhoods fast enough.\\nSo technically it’s probably a pretty easy problem to solve. It’s like a rough optimization \\nproblem. You could do that. But if you take a snow plough that’s expected to be in one \\nplace and reroute it to another place, the people who live in that block will have a negative \\neffect on optimization. Or at least there will be a perceived negative effect.\\n \\nThis is a long-winded answer, but it’s much easier if you’re only thinking about minimizing \\nerror. If you have a broader perspective on how your application or your problem or \\nthe solution to it actually impacts people, it becomes harder and therefore much more \\ninteresting and useful to the discipline of data science.\\nHow have you found working at the intersection of social science and data science? \\nWhat are the problems that you’ve really chewed on and how did you come to \\narrive at those sorts of problems?\\n \\nFor me, it started where you are, in my undergraduate times. I was a computer science \\nstudent but I went to a liberal arts college so I got to take lots of other classes. I always \\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 71}, page_content='67\\nfound questions that were being asked in my political science or sociology classes to \\nbe the ones I was really interested in: “How do groups of people make choices? How do \\nmarkets move? Why is one group of people making different choices than another group \\nof people? What motivates people to do bad things? What motivates people to do good \\nthings?” These sorts of questions were much more interesting to me at the time than \\nwriting a faster compiler or a different programming language.\\n \\nAt that stage I actually \\nended up double majoring \\nin Computer Science and \\nPolitical Science so I had to \\nwrite two theses. My political \\nscience thesis was back in \\n2004. Keep in mind that when I \\nwent to college, 9/11 was a big \\npart of my experience. So I became really interested in terrorism and terrorist groups. I \\nwas reading trying to learn more about it. At the time peer-to-peer file sharing networks \\nwere still prominent. I was reading about how those file-sharing networks were used \\nand the way data went through them and I observed that they were structured in very \\nsimilar ways to nefarious networks or terrorist networks. I wrote my thesis on mirrors \\nbetween these two things. There are weaknesses in the file-sharing network. If it was \\npossible to replicate those weaknesses in a human network, maybe you could exploit the \\nsame weaknesses that people use to try to intercept communications on a file-sharing \\nnetwork.\\n \\nI actually got invited to present that paper at West Point when I was a senior. This set me \\non the first part of my career path. I started my career in the intelligence community and \\nthere were people at the conference from various intelligence agencies who were really \\ninterested in the idea that you could model human behavior in the same way you model \\ncomputer traffic.\\nPart of it for me was that I felt a connection to the 9/11 event and I was interested \\nin learning more about why people would do that. So between the knowledge that I \\nhad learned in Computer Science and my interest in Social Sciences, I landed a job \\nas a computational social scientist working inside the intelligence community. The \\nproblems I was working on there were exactly an extension of the work that got me \\nthere: understanding networks, working out how people make choices in non command-\\nand-control structures.\\n \\nEver since then, I’ve always been fascinated by computer science, math, and statistics as \\na tool belt. I find these technical things really interesting to apply to human problems. \\nDREW CONWAY\\nIf you have a broader perspective on how your \\napplication or your problem or the solution to it \\nactually impacts people, it becomes harder and \\ntherefore much more interesting and useful to the \\ndiscipline of data science.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 72}, page_content='68\\nI’m not working in the intelligence community any more, but since then, I’ve worked on \\nmy Ph.D. and have done research in the space, and have even started an organization \\nlike Data Kind, which tries to scope out the intersection of where the human problems \\nare, where the technical talent is and then put them together. And now at Project Florida, \\nI’ve always wanted to do take these learnings and apply them within the sensor market \\nand with healthcare. It’s always been the classic problem that’s excited and motivated \\nme.\\n \\nHow is it that you were able to come straight out of undergrad and begin working \\nin this domain?\\n \\nFor me, I’m not sure my career path is one that I would recommend for other people. I \\nloved my career, I can’t complain about any step. But we’ll call it an outlier situation. \\nI was working with a lot of “reformed” academics. The people who were mentors to \\nme had been professors at big research universities and it was very multidisciplinary. \\nI had colleagues and bosses who were PhDs in math, computer science, economics and \\nsociology. I was working with a large group of really smart people.\\n \\nI started my career as a very junior analyst. The way that DC works, in a sense, is that \\nin order to reach the next “level” you have to have at least a Masters degree. Well, I got \\nto that point around 2007, so I was thinking about what I wanted to do. I was reaching \\nout to my colleagues and mentors for advice. They sat me down and they said I had two \\nchoices: “You can do the typical DC thing which is to go to night school, get your Masters \\ndegree and then do the next thing. Or you could think about becoming a professional \\nresearcher. Go back to school full-time, see if you’re interested and do a doctorate.”\\nFor me they were saying, “We know you, we know what you like doing. You should really \\nconsider the Ph.D. because we think it would be good for you.”\\n \\nTo be honest, I didn’t really want to do it. It’s such a huge opportunity cost. If I did it, \\nthat was five years I could have been making money and building a career. However, on \\ntheir counsel I started looking around at some programs. I knew I didn’t want to go back \\nto school for a computer science degree or a math degree, because I definitely wasn’t the \\ngreatest computer scientist or mathematician that ever lived. And also, at the end those \\nare not the problems I want to solve. If you’re going to do a PhD., you have to contribute \\nback to the discipline. I wasn’t interested in contributing back to those two disciplines, \\nso I thought about various Political Science programs. I wanted to find one that was very \\nquantitative. I ended up at NYU Political Science, which was one of three or four political \\nscience departments in the world that was heavily quantitative right from the start.\\n \\nIt was also in New York.\\n \\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 73}, page_content='69\\nI felt that being in New York and in a large urban area opened up a lot of different things \\nand wouldn’t limit me to focusing specifically on my academic endeavor. I could be \\nexposed to other things while I was there.\\n \\nI also decided that I wanted to talk more publicly about the work I was doing. Part of this \\nis colored by the fact that for years, by being in the intelligence community, I couldn’t \\ntalk at all about the work I was doing. So moving on from there, I was really eager to start \\nblogging or going to the media to talk about the work.\\n \\nAs soon as I got to graduate school, I started doing those things. That helped balance \\nthe work I was doing as a graduate student with running the Meetup in New York, giving \\ntalks, advising start-ups and getting involved. That doubled my work but it was all fun \\nwork and I really loved it.\\nThe decision to go back to school was basically, “Well, I think this would be good for my \\ncareer.” I didn’t even really know if I wanted to be a professor. It was something I was \\ninterested in, but I knew if I was going to become a professor I was going to be the kind \\nof professor that had one-and-a-half foot in the university, and the other half foot out \\ndoing stuff.\\n \\nFrom my experience at graduate school I decided I definitely didn’t want to be a professor. \\nMy father was a professor so I’m sort of a university brat. I know the lifestyle is fantastic \\n— there’s nothing wrong with it. However, the realm of a university is teaching and \\npublishing and not building software or data science.\\n \\nGiven that you had the experience of working in industry before going back to \\ngraduate school, do you feel that you had a significantly different perspective? \\nWere you looking at the academic problems you were facing in grad school \\ndifferently because you’ve had a chance to dig your teeth into them already in the \\n“real world”?\\n \\nOne thing I always say, and I tell this to people all the time, is that I highly recommend \\nnot going directly from undergraduate to graduate school. Even if it’s just to work for a \\nyear, I think it provides you so much more insight and experience in the kind of problems \\nthat are interesting to industry versus the problems that are interesting to researchers.\\n \\nMy early industry experience was unique in that the work I was doing in the intelligence \\ncommunity was split between two halves. One half was the classic intelligence aspect: \\nstudying people for short-term projects that have to be turned around in a very narrow \\ntime window.\\n \\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 74}, page_content='70\\nI highly recommend not going \\ndirectly from undergraduate to \\ngraduate school.\\nThe other half of my job looked much more academic. These were long-term research \\nprojects; we were working with specific agencies that had the capacity to do high-risk \\nresearch. Through that experience I decided that I really enjoyed and was interested \\nin solving hard problems. One of the problems we worked on is how to enable non \\ncommand-and-control structures (e.g., organizations without coherent org charts) to \\nmake choices.\\n \\nFor example, in a command-and-control \\norganization like the army, if you’re \\nLieutenant Colonel and you’re promoted to \\nfull Colonel, everybody understands how \\nthat works. However, when you’re in a non \\ncommand-and-control structure, different \\npeople in each part of the network have different responsibilities. One does fundraising, \\none does surveillance, and one does operations. Suddenly there’s a person from the \\noperations cell who gets captured; how does that operations cell make a choice about \\nwho will become the new leader? Or does someone get taken from another cell and \\nworked through the system that way?\\n \\nWe’ve thought a lot about how to solve that problem and we didn’t solve it at all. \\nHowever, I got really excited about the thought of solving longer-term problems. So I \\nhad another reason to go to graduate school. There was a lot of freedom to think about \\nsolving problems that I found interesting.\\n \\nI think the basic difference there is in industry is that it’s about always solving someone \\nelse’s problem for them. Now, that’s not an absolute truth, but certainly when you’re \\nstarting your career you’re almost always solving someone else’s problem. Then when \\nyou get to graduate school, you get to think of those problems on your own. The issue \\nis sometimes those problems are really boring or they’re not interesting because you \\ndon’t have enough experience or enough knowledge to recognize good problems. That’s \\nwhere mentorship as a graduate student becomes important.\\n \\nIf you’re going to go to graduate school, you’ve got to trust in and work really hard with \\nyour advisor because if you don’t, you’re probably going to produce bad research. It’s \\nway easier to produce bad research than it is to produce good research. In industry the \\nobjective function is set by someone else; that objective function typically is profit and \\nthe problems are usually smaller and more attainable.\\nSo if you have experience on either side of that, you can be more reflective about how \\nit might be on the other side. I think that there is a certain strictness versus a freedom \\ncomponent and there’s positives and negatives on both sides. It’s really about what \\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 75}, page_content='71\\nmotivates the person doing the work, what kind of stuff you like to do, and how you see \\nyour own self-worth measured in terms of what you’re contributing. Because in either \\ncase, you’re never truly independent. That’s a fallacy that’s built in at graduate school.\\n \\nIn reality, you’re the furthest possible from being autonomous during graduate school. \\nYou’re certainly more autonomous than you would be working for a big company on a \\nteam. But you have many masters as a graduate student, the least of which is yourself, \\nand you have to be really good at maintaining your own schedule and solving a problem \\non your own.\\nYour book “Machine Learning for Hackers” is in the canon of data science now. \\nGiven that, can we talk about the tools that you have found to be useful in your \\ncareer and also while doing data science? How do you discover useful tools for \\ndata science work?\\nPersonally, I am not as much a lover of languages as some computer scientists are. Have \\nyou ever heard of the Strange Loop Conference in St Louis? It’s in St Louis every year; it’s \\na fantastic conference and I highly recommend it. But it’s for people who love tools and \\nlove programming. So I went there and was doing an introduction to machine learning \\nprogramming. I found I was very much a fish out of water there. I was surrounded by \\npeople who I respect and who do interesting work and all they cared about talking about \\nwas the hot new programming language.\\nSo my approach to tools is: is the cost-benefit of me taking the time to learn the tool going \\nto have a significant impact on getting my work done more efficiently or effectively?\\n \\nFor example, I’m now known as an R programmer because my book heavily uses R. \\nThe truth is, I’d never written a line of R code before I got to graduate school. I was a \\nJava, Python, command line programmer from undergraduate, along with a little bit of \\nMATLAB. When I went to graduate school all the statistics classes were taught in Stata. \\nIt’s a point-and-click statistics program and you have to play by the rules. Eventually \\nwhat the program allows you to do is, you have to use this highly stylized, domain-\\nspecific language for Stata called Mata. During graduate school, we were writing our own \\noptimization functions in Mata. I was looking at the syntax and I didn’t know how I was \\ngoing to do it. It was so far afield from any relevant training I’d had in computer science. \\nSo I raised my hand and asked, “Can we do our problems in R?” And the guy teaching the \\nclass said, “Sure, I don’t care.”\\n \\nSince I’d never programmed anything in R, I set out to teach myself how to program in R \\nsimply so I could finish my problem sets for my Intro to Statistics class. For me, once I’m \\ncommitted to doing it I really want to learn it all and go really deep.\\n \\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 76}, page_content='72\\nI want to point out that I’m building up a little bit and giving you a false sense of the \\nbinary nature of this tool choice. I’d known for a while that R was a language that had \\na lot of things in it that would be very useful for me. But it has a very tricky syntax \\nand it’s not designed well as a language. So it’s a little bit of a steep learning curve at \\nthe beginning, but once you get over the hump you can do these wonderful things very \\nquickly.\\n \\nIt was the same thing for me with \\nJavaScript. No one in their right \\nmind will ever ask me to build a \\nwebsite. I don’t do that, it’s not \\nwhat I’m good at. But, I got to \\nlearning it eventually when I was \\nblogging more often. I was so \\ntired of posting an image file of a graph I’d drawn; it would be much more interesting \\nto have some interactivity where the image or the graph wouldn’t just answer the first \\norder question: what is the structure of the data? But that it could also answer the second \\norder questions: Who is this point? Why do we see what we see? \\n \\nMy entire motivation for learning JavaScript was so that I could use d3. All I cared about \\nwas being able to create interactive visualization. There’s a useful tool out there that I \\ndon’t understand how to use, so I’m going to learn it so that I can use it. And now, for \\nme, — the worst JavaScript programmer in the world — everything to me is a d3 problem. \\nYou could ask me to create a simple online form where I’m collecting your address and I \\nwould use d3. I don’t really understand any other way.\\nI learn something through trying to solve a problem. In that process I brute-force my \\nway into having a better understanding.\\n \\nI’m the same way with mathematics and statistics: I learned probability theory, calculus \\nand linear algebra. I was interested in solving a problem and those were the tools I needed \\nto learn. I didn’t have a pure love for those things. Some people love math and love to \\nlearn about math. I think it is beautiful, but I’m not an artist. I’m more of a mechanic.\\n \\nI think that’s powerful and pertinent for people who feel they can’t get started doing \\nthe things they want because they haven’t checked all the technical boxes. It seems like \\nanother way to do it is actually go into what is the problem you want to solve. Since we \\ncannot solve the problem because of a particular tool or medium of expression, then go \\nand learn how to do a particular part. You’re always told to solve the problem first.\\n \\nThat was our motivation for “Machine Learning for Hackers” too. People who are sitting \\nDREW CONWAY\\nIn New York, the anchor industry has always \\nbeen finance, media, advertising, entertainment \\nand to a certain extent, higher education. Those \\nanchor industries have always been about data.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 77}, page_content='73\\nin a job who are now being asked to run a classifier are asking themselves: What’s a \\nclassifier? One way to learn what a classifier is, is to go and read Hastie and Tibshirani, or \\nsome classic machine learning text, and try and beat yourself up over all the notation in \\nthat book. 90% of people don’t have the time or don’t want to have to read that. A better \\nway would be to say, “Here’s a problem you’re trying to solve. Here’s how you solve it. \\nHere’s a tool that will help. Let’s open up that black box a little bit. Explain to you a little \\nbit. Not talk about the math. If you care to learn there are other references, you can go \\nto. But it’s not a must. So “Machine Learning For Hackers” is written around 12 problems \\nthat we try to solve. That was the motivation. It was like writing a book that I wish I’d \\nhad before I went to graduate school.\\n \\nI will say it’s an exciting time. There’s a lot of opportunity for people to build that \\nlandscape. It’s very early days; people still don’t know what we’re talking about when we \\nsay data science exactly so there’s a lot of opportunity.\\n \\nWhat are the exciting data-related things that you’re seeing right now in NYC? \\nHow’s the data ecosystem evolving in New York, and what are the parts of it that \\nyou find exciting?\\n \\nI’m very biased in thinking that New York is the best place in the world to be doing \\nthis work. The reason I think that is, if you look at the history of any big city, they have \\nanchor industries that by and large define the city itself. You can look through a list of \\nAmerican cities and see that. If you look at Silicon Valley — the technology industry \\nhas always been the anchor for Silicon Valley. There, the focus has been on innovation, \\nsoftware engineering, hardware engineering and how to build better machines, better \\npieces of software.\\n \\nIn New York, the anchor industry has always been finance, media, advertising, \\nentertainment and to a certain extent, higher education. Those anchor industries have \\nalways been about data. As a result, what started as a nascent community in New York \\nhas gotten bigger and bigger and has been heavily influenced by the fact that everything \\naround you that’s happening is pivoting off of data; that’s how everyone in the city \\nmakes their money. So there’s billions and billions of dollars that go through New York \\nCity every day that are really a function of data science.\\n \\nThus, the data science community in New York benefits incredibly from its history. Now \\nwe have people who care about writing software, which is different from the same anchor \\nindustries that have existed in New York. However, these people still benefit from the \\nhuge talent pool and the huge amount of money in the city. Therefore it’s no surprise \\nto me that the data science community is growing very, very quickly. People are moving \\nhere to do this work because in a sense it’s always been here, it’s just now that people \\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 78}, page_content='74\\nare paying attention to it more, because it’s not the boring anchor industry that we’ve \\nalways known about.\\n \\nThe other piece that I’ll say for New York as opposed to other places is that we benefit \\ntremendously from our geography. For better or worse, Manhattan is a tiny island that \\nseven million of us live on. It was easy for me when I was in NYU to take a subway up \\nto Columbia or walk up to Union Square. It really galvanized our community because \\npeople were just close to each other. I could have lunch with Mike Dewar if I wanted. \\nThat’s great.\\n \\nWhereas if you go to other places, particularly Silicon Valley, it’s just so geographically \\nspread out that if I worked in San Francisco and I wanted to go out for lunch with someone \\nfrom Mountain View, it’s an hour-long drive.\\n \\nLikewise, if I wanted to go to a meetup \\nin San Jose but I worked in the Mission \\ndistrict, it’s a pain in the ass. You can’t \\ndo that. So it becomes much more \\ndisparate out there. If you look at the \\ncommunity as it exists out there, it is \\nvery broken up. I think that hurts them \\nbecause community for data science is really all about sharing ideas.\\n \\nIt’s much more collaborative in that way. I think New York has had a history of that \\nthrough different industries.\\n \\nRight. The density of the networks that you are interacting with is a huge factor in \\nterms of the information exchange of ideas and how cross-disciplinary you can be.\\n \\nWe tried to institutionalize that with Data Gotham in a sense. Data Gotham is the \\nconference that Hillary and I were doing, and people seemed to like that. Now there are \\nother geographies that are trying to do a similar thing. For example, DC has got one. \\nSimilarly, there are big data science conferences in Silicon Valley.\\nYou gave a talk recently where you made people stand up and promise to hire \\nmore social scientists. What advice do you have for people who have both a social \\nscience and a computer science background and who want to go into data science?\\n \\nThe piece of advice that I would have would be to continue following this track. You’re \\na social scientist and you care about human problems and the specific genre of those \\nproblems that triggers your interest. If you have a desire to solve a problem from the \\nSometimes others say to me, “You’re \\nso unique, no one else can make the \\ntransition from social science to data \\nscience today?” That’s absolutely wrong.\\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 79}, page_content='75\\nworld of social science using the skills of your computer science, you need to dive pretty \\ndeep into whatever the technical tool is that you care about. I talk to a lot of social \\nscientists who are thinking about learning Python or R and they’re not sure which one \\nto pick up, but just dive deeply into one of them.\\n \\nIt doesn’t make any difference. Just pick one, use it and learn from your mistakes, but \\nmake sure you’re asking intelligent questions.\\n \\nYou’re either trying to learn something new or you have an interview or a question that \\nyou ask that you don’t know the answer to and you can say, “I tried this, but I wasn’t \\nquite sure so I went back and tried something different.”\\n \\nA piece of motivation I would give people is that sometimes others say to me, “You’re so \\nunique, no one else can make the transition from social science to data science today?”\\n \\nThat’s absolutely wrong.\\n \\nThe problems that you care about, people will pay you lots of money to work on. Every \\nway that an internet company makes money is by humans making choices; the choice \\nto buy something, the choice to click on something, to share something, to connect with \\nsomeone.\\n \\nAll those things are questions that are fundamental to the social sciences. So you already \\nhave all of the training necessary to identify the problems that are out there in the real \\nworld. Now all you have to do is figure out how to solve them using the tools from an \\nindustry.\\n \\nDon’t think you can’t do it because, the reality is that you’re already way ahead of the \\ngame. Now you have to learn the easy stuff. The hard stuff you already know. Go learn \\nthese things, and then get better at it.\\nDREW CONWAY'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 80}, page_content='KEVIN NOVAK Head of Data Science at Uber\\nLet’s start off by talking a little bit about your background.\\nI am a Senior Data Scientist at Uber and run the dynamic pricing group today. I have \\nworn a lot of hats during my time at Uber and have been with the company for about 2.5 \\nyears. I’m the second full-time data person and 20th employee at Uber.\\n \\nWhat were you doing before Uber?\\nBefore Uber, I was a Ph.D. candidate in nuclear physics at Michigan State University. \\nI was there working on the cyclotron in the theoretical physics department. Anything \\ntheoretical, but especially physics, requires a lot of computer programming.\\n \\nIt’s a whole, long involved process, but essentially involves using statistical methods \\nto evaluate theoretical models for nuclear interactions. We then evaluated the models \\nbased on the output data from the particle accelerator.\\n \\nWe evaluated if models can be confirmed by experimental data.\\n \\nWhat got you interested in data science?\\nI always have been the bad physicist. I have always used computing tools versus using \\nan experimental setup. In undergraduate studies, I wrote a program to build computer-\\nKevin trained as a theoretical nuclear physicist where he \\nused statistical methods to evaluate theoretical models for \\nnuclear interactions. It was during graduate school that \\nKevin realised that he liked solving difficult problems, but \\nnot in an academic environment. A friend from undergrad \\ncame calling and soon Kevin found himself applying his \\nskill-set to solving the mathematics of logistics.\\nToday, Kevin is the head of data science at Uber, where he \\nleads a team collecting and analysing a vast array of data \\nwithin the Uber global network to inform product decisions \\nand better serve clients. He talks about the importance of a \\nrelentless curiosity to solve problems, and the need to develop a well-rounded suite of skills \\nacross engineering, data, and product.\\nData Science: Software Carpentry, Engineering and \\nProduct'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 81}, page_content='KEVIN NOVAK 77\\ngenerated holograms. As a physicist, I was always a bit different and did a mix of theory \\nand computer science.\\n \\nWhen I went to graduate school, I quickly realized that academia wasn’t the best fit for me. \\nAcademia wasn’t what I wanted to do for a career. I wanted to do something different, but \\nmy background was weird during those times when I had a highly specialized focus and \\na wide suite of computer programming skills. It \\nwas hard for the middle 80% of companies to \\nfind a good fit for the skillset that I brought.\\n \\nI got a call from a roommate in undergrad, \\nwho was an early engineer at Uber. The job \\ndescription required the ability to write \\nproduction code and to be good at mathematics. \\nIt was the perfect fit for someone with my \\nbackground and so I decided to join immediately in June 2011.\\n \\nYou mentioned earlier that the role at Uber required a mix of computer science \\nand mathematics, and that other companies simply didn’t know where to put you. \\nCould you elaborate on this?\\n \\nIt was hard for most mainstream companies to justify hiring a nuclear physicist for a \\njob that is not nuclear physics. That’s true in most specialties. I didn’t even know it was \\ncalled data science when I started out, and realized that data science was a buzzword \\nthat was rapidly growing up.\\n \\nData science encapsulates a skill set and a style of background. Almost everyone at the \\nUber data team is from a nontraditional background. Everyone here was doing something \\ndifferent at some point in their lives.\\n \\nThis unconventional transition for most data scientists may change in the future, but \\njust having the hackerish mentality and flexibility is very relevant for aspiring data \\nscientists. This ability to cross-pollinate ideas is especially relevant for startups where \\nyou are expected to wear different hats.\\n \\nSo you mentioned a little about what you think data science really is. If you had to \\nboil down the role and purpose of a data scientist, what would that be?\\n \\nData science is rapidly becoming a buzzword with all the positives and negatives \\nassociated with that. It helps to encapsulate a series of broad ideas as a rallying point for \\nindividuals like myself.\\n \\nIt was hard for most mainstream \\ncompanies to justify hiring a \\nnuclear physicist for a job that is \\nnot nuclear physics. That’s true in \\nmost specialties.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 82}, page_content='KEVIN NOVAK\\n78\\nAt the same time it can be easy to hype a concept without actually having a strong \\nunderstanding of what it is. In my opinion, the field of data science really has two main \\nspecialties. One is the concept of “big data”, where large amounts of information are \\nprocessed to derive mathematical insights. For example, Twitter and Facebook are \\nfamous for the products they’ve developed using this work style. \\nThe opposite specialization in data \\nscience (probably closer to my job) is \\na more highly specialized predictive \\nmodeler, where there is a need to \\nmake quantifiable decisions based on \\nheterogeneous pieces of information. \\nFor instance, predictions based on \\nincomplete information from a sales \\nrepresentative and information from another company which had done this before. \\nThese sort of predictions require a considerable amount of programming, statistics, and \\nmathematical intuition.\\n \\nHow much of your time is spent cleaning data vs. doing actual analysis?\\n \\nCleaning data is very different for the two branches of data science that I just mentioned. \\nOn the larger end, some statistical errors are negated by the virtue of having a lot of \\ninformation — the Law of Large Numbers. Everything converges on a normalized \\ndistribution; statistical anomalies will very rapidly disappear.\\n \\nOn the other end, when you are trying to do predictive modeling based on a small set of \\nincomplete information, one outlier can quickly throw your prediction off if you do not \\nhave a solid understanding of the process or problem that generated it.\\n \\nThe cleaning process is very different between these two regimes. On the smaller end, it \\nis more a matter of evaluating the confidence one has in one’s data, while on the bigger \\nscale, it is more about building up a more homogeneous data set to feed into algorithms.\\n \\nOne of the most rapidly changing areas of the field is cleaning data. There are more data \\nscience and numerical computation toolkits out there than there were 18 months ago. \\nWhere these toolkits shine is in their simplicity in allowing large amounts of information \\nto be thrown at them.\\n \\nThe operations are fairly simple in terms of cleaning data, but what’s challenging is \\nscaling these solutions to very large data sets.\\n \\nThis unconventional transition for most \\ndata scientists may change in the future, \\nbut just having the hackerish mentality \\nand flexibility is very relevant for aspiring \\ndata scientists.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 83}, page_content='KEVIN NOVAK\\n79\\nWhat are some of the most valuable tools and the most valuable skills that someone \\nshould have if he/she wants to work in data science?\\n \\nA lot of people have this biased emphasis on algorithms and programming languages. A \\nlot of the programming languages and problems that we worked on 20 years ago are very \\nsimilar to the problems that we face today. In the big data regime, algorithms that can \\nscale to massive data sets to deliver quick \\nfeedback already exist in closed form. So \\nthe algorithmic solutions already exist. \\nWhere you get paid as a data scientist is \\nthe skill in constructing a data pipeline \\nto feed into algorithms and knowing \\nhow to apply those algorithms in specific \\ncontexts. These skills are all derived from \\nmathematical and statistical intuition.\\n \\nSo a rudimentary understanding of mathematics and statistics will get you 85% of the \\nway there, while the last 15% will come from basic coding skills. A statistical background \\nand intuition will get you a long way. We’re not in academia anymore and can just skip \\nquickly to the solution.\\n \\nYou just mentioned this 85/15 split and for a lot of people that we’ve spoken with \\nthat have the adequate background, there’s this fear that they are not adequately \\nprepared in terms of programming and work experience. A lot of people are \\nconcerned that they don’t have the relevant practical skills to transition into data \\nscience. Could you speak a little to their experience?\\n \\nDifferent companies have a different opinion about what engineering and statistics \\nbackground is required for data scientists. At Uber, the data team is fairly engineering-\\noriented and we do a lot more implementation than a typical data science team. At a lot \\nof companies, data scientists are part of the business or product team and as a result \\ntheir work is a lot more qualitative, which obviously informs the job requirements.\\n \\nWe have to be able to write computer code in order to solve mathematical problems \\non a computer. Having the ability to write professionally organized software code is a \\nsecondary skill for data scientists at Uber.\\n \\nWhenever I talk to other data teams, I always ask where the data team is on the organization \\nchart, and that will tell you a huge amount about the implicit skillsets they expect you to \\nhave. Software engineering is a non-trivial part of our job as a data scientist.\\n \\nSo a rudimentary understanding of \\nmathematics and statistics will get you \\n85% of the way there, while the last \\n15% will come from basic coding skills. \\nA statistical background and intuition \\nwill get you a long way.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 84}, page_content='KEVIN NOVAK\\n80\\nBoth a statistical and programming background are valuable in different ways. You are \\nhired for the programming, but the statistical background is relevant for elevating you to \\nthe next level. So it’s really a tradeoff between these two skills which are both valuable.\\n \\nYou recommended for people to take a look at where data science sits in the \\ncompany structure. So here at Uber, what is it that you do that creates value to the \\ncompany?\\nWe are at our core an engineering team. In most startups, that setup is fairly common. \\nA lot of what we do technologically is backstopped by data. At the end of the day, Uber \\nis a company about logistics, about \\ngetting stuff to people quickly; all \\nof that is a math problem.\\n \\nOn the flip side, the data scientists \\nat Facebook or LinkedIn are a part \\nof their product teams. At the \\nend of the day Facebook is about \\nconnecting people and while the \\ndata component is a nice add-on, it \\nis not a core functionality of the company. Data informs how they scale the company, but \\nit’s not an engineering problem. So the requirements for a data scientist are different \\nbetween a company like Uber and a company like Facebook.\\n \\nSo how do you define personal success?\\n \\nI’m a data scientist and I’m also an engineer. At the end of the day I want to solve problems. \\nSo if I can solve problems today better than I could yesterday, then that’s a success.\\n \\nFor somebody who gets into data science and realizes that it’s not for them, what \\ncan these people transition into?\\n \\nA solid understanding of what’s not working will inform the direction of transition \\nbetter. Data science is at the confluence of computer programming, mathematics and \\ncommunication as part of the work structure.\\n \\nIf you don’t like mathematics, a better and more obvious role is to get into business \\ndevelopment of product.\\n \\nOn the other hand, if you like the mathematics but don’t like programming, an analyst \\nposition may be more suitable. Some people are arguing that a data scientist is an evolution \\nWhenever I talk to other data teams, I always \\nask where the data team is on the organization \\nchart, and that will tell you a huge amount \\nabout the implicit skillsets they expect you \\nto have. Software engineering is a non-trivial \\npart of our job as a data scientist.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 85}, page_content='KEVIN NOVAK\\n81\\nof the analyst, but I believe these two roles are on fundamentally divergent paths. An \\nanalyst is someone who is answering more financial or quantitative information using \\nan existing toolkit. A data scientist is more of a mix of software carpentry, engineering \\nand product.\\n \\nIf you are good at mathematics and engineering, but not good at communication, I \\nwould recommend becoming an engineer. There are a lot of organizational charts in a \\nlot of companies where the engineers are isolated from the other departments. A lot of \\ncompanies can offer that sort of environment where an engineer can just focus on the \\nproblem at hand.\\n \\nSo you’ve been at Uber for more than two years now and you mentioned this \\ndivergent path between the data science and the analyst roles. It sounds like you’ve \\nhad a lot of time to see how it evolves. Broadly speaking, what are the qualities \\nthat separate the amazing data scientists from the rest?\\n \\nI’m amazed by people who are intuitive about problems they have just heard about. For \\nexample, Josh Wills is a guy who has never seen my data set, and has only ever heard of \\nmy problems through media sources. Josh is someone who can come in and, off the top \\nof his head, reverse engineer the statistics of how people are behaving.\\n \\nHaving that sort of intuitive problem \\nskill is very important and on top of the \\napproximation skills will get you 90% \\nof the way there to being a top data \\nscientist. The other interesting skill set is \\nthe ability to work and execute on largely \\nopen green-field projects which would \\ntake an average team much longer to do.\\n \\nAgain, a solid understanding of what’s important and how to build your toolkit is the \\nbase for making you a rock-star data scientist.\\n \\nThe open green-field approach sounds a lot like the way in which academic \\nresearchers approach open-ended problems. What is the difference here in data \\nscience versus academia?\\n \\nThe perceived limitation of academia is that they don’t have the flexibility to go ahead \\nand do it. At the end of the day, academia is about understanding problems whereas data \\nscience is about solving problems and moving on.\\n \\nHaving that sort of intuitive problem \\nskill is very important and on top of the \\napproximation skills will get you 90% \\nof the way there to being a top data \\nscientist.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 86}, page_content='KEVIN NOVAK\\n82\\nWhat attracts me to data science is the ability to step on the gas and just go. I can \\nsolve a problem and move on as long as the relevant people involved in the decision-\\nmaking understand the solution. The approach is more like ready, fire, aim versus a more \\nmethodical process in academia.\\n \\nIn academia, one can work on open-ended problems indefinitely with no expectation \\nof results. How have you made the transition from the academia mindset to a more \\nresults-driven environment?\\n \\nThere are deadlines and very non-trivial \\nones. I have personally been blessed by \\nhaving one of the most leading CEOs in \\nthe industry. Travis is a data-nut, he loves \\ntalking about all sorts of problems. Early \\non he instilled a very experimental culture \\ntowards data science implementations.\\n \\nOne of the examples of this was an \\nexperiment we wanted to run where I \\nwanted to build a test bed to test out \\ndifferent hypotheses. Travis told me to put it into production to test it. That to me \\nexemplifies the entrepreneurial attitude compared to academia and speaks to the whole \\nready, fire, aim concept in entrepreneurial environments.\\n \\nIn academia, the approach would have been to spend a large amount of time doing \\nmeticulous contingency testing in order to come up with the best solution.\\n \\nMore forward looking, for you personally, what would you say are your personal \\ngoals as a data scientist over the course of the next year?\\n \\nI think we are at a pretty cool time in data science, where data science is on everyone’s \\nradar and we are over the initial wave of hype associated with the industry. We’re still at \\nthis phase where 80% of the promise of data science is still unfulfilled.\\n \\nThe leading companies in data, at least in terms of public perception, are still involved \\nin the social space. In my case it is the problem of “how do I give you a car faster?” In the \\ngrand scheme of things, the problem space that is being tackled with data science is still \\nvery open and expanding.\\n \\nAt Uber, we are solving the mathematics of logistics, but one can easily port the same \\nsolutions to solving the logistics problems of the world. For instance, what if one could \\nWhat attracts me to data science is the \\nability to step on the gas and just go. \\nI can solve a problem and move on as \\nlong as the relevant people involved \\nin the decision-making understand the \\nsolution. The approach is more like \\nready, fire, aim versus a more methodical \\nprocess in academia.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 87}, page_content='KEVIN NOVAK\\n83\\nuse data science to give you an ambulance to your location much faster than before? \\nSo when one takes a step back there are immense opportunities in the direction we’re \\nmoving in for data problems.\\n \\nSo the promise of data science is still very much the tip of the iceberg and that to me \\nis very exciting. To me the first part of unleashing this promise is to start building a \\ncommunity of data scientists to enable sharing of ideas.\\n \\nYou mentioned that we are on the tip of the iceberg in terms of applying data \\nscience to solving problems. What are some developments in the field that you \\nthink are emblematic of this trend?\\n \\nEvery person in data has their own pet project — something they love which they \\nalways talk about. I was talking to someone about genomics. There’s a really exciting \\ndevelopment with algorithms where we can analyze genomes literally as quick as they \\ncome out of the machine. The speedup in analyzing genomes is hugely exciting in terms \\nof the possibility of understanding our world.\\n \\nProblems in the healthcare space represent a \\nhuge data promise. It would be amazing if a doctor \\ncould just diagnose a patient without waiting for \\na lab test that takes two weeks.\\n \\nAnother exciting area is logistics, we touched \\nupon it with the ambulance example, but what if \\none could get an instant delivery without having \\nto wait 3-5 weeks for it to get shipped?\\n \\nAre there any other final pieces of advice which you would share with people \\nlooking to transition from academia to the data science industry?\\n \\nNothing convinces like success. If you can find a problem and solve it, or even implement \\nyour own solution to common problems, that is how you get people excited. Trying to \\npigeonhole it to specific problems is not the point.\\n \\nJust solve problems. Start applying data to real life and the rest will follow.\\nNothing convinces like success. \\nIf you can find a problem and \\nsolve it, or even implement \\nyour own solution to common \\nproblems, that is how you get \\npeople excited.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 88}, page_content='CHRIS MOODY Data Scientist at Square\\nThank you very much for being with us, Chris. Can you tell us a little bit about your \\nbackground?\\n \\nI went to Caltech as an undergrad to study Physics. There, I had projects that were largely \\ncomputational. \\nFor example, a project I was involved in was looking at dark matter simulations. Basically, \\nwe don’t know that much about dark matter, but we can guess at things that it could \\npossibly do. One of those things is that it could decay. If it decays, the dark matter particle \\ngets a kick, and it goes off in a random direction at a random speed. Galaxies are sitting \\nat the bottom of a gravity well; they’re like bread crumbs in a big bowl of dark matter. If \\nthe dark matter were spontaneously decaying and getting lots of extra energy, it could \\npopcorn out, and totally change the profiles of galaxies in an essential way. This was a \\nstrongly computational project that taught me many skills.\\n \\nAfter Caltech, I came to Santa Cruz for graduate studies, still working in computational \\nastrophysics. While I was there, I was doing all sorts of things pertaining to galaxies. We \\nwould look through the Hubble Space Telescope at the youngest galaxies in the universe \\nand notice that they were not at all like the galaxies today. Galaxies today are beautiful \\nspiral structures. But when you look back at the youngest galaxies, they are lumpy and \\nclumpy... they look like soup.\\n \\nSo, one of the questions was: Does that mesh well with our ideas of how our universe \\nChris Moody started off his journey towards data science \\nby peering off into distant galaxies, studying computational \\nastrophysics at UC Santa Cruz as a graduate student.\\nAs the data revolution hit the fields of science, however, \\nChris found himself having to learn how to use more \\nsophisticated tools that could process more data. He dove \\ninto programming and contributing towards open-source \\nastrophysics projects.\\nAll this culminated in a data science fellowship at Insight \\nData Science. After completing his Fellowship, Chris joined \\nSquare’s Data Science team. After leaving Square, Chris is now a data scientist at Stitch Fix, \\na fashion startup.\\nAstrophysics to Data Science'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 89}, page_content='CHRIS MOODY 85\\nformed? We started to look at the simulations and realized that what we observed through \\nthe telescope is what we were seeing in our simulations. We were super surprised at \\nthese theoretical predictions coming true!\\n \\nThe next part followed the \\nstandard trajectory of a lot \\nof businesses. We got one or \\ntwo really positive examples \\nof galaxies matching our \\npredictions, and were very \\nexcited about the progress. But \\nit was only one or two examples; \\nwe wanted to know if this was statistically significant, and so we started to scale up our \\ndata. We exploded from 100 gigabytes to hundreds of terabytes of data. This all started \\nat the NASA Ames supercomputer.\\n \\nIt turns out that it’s really hard to answer simple questions when those questions don’t \\nfit onto one computer. So we had to scale up a lot of our algorithms, and build our own \\ninfrastructure and framework. It was at that point that we started to get really interesting \\nresults. We started to see that this is generally true, and this attracted a lot of people \\nto our project, scaling up our people power. So we’d get other new graduate student \\nastronomers and explain, ‘This is how we work; this is how you can be efficient.’\\n \\nI think the romantic, public idea of a scientist is that you jump into a cave and then \\nfive months later, you have a ”Eureka” moment and you come out. Then it’s glorious. \\nBut that’s not really how it works. The reality is: you have lots of bugs, you make lots \\nof errors, and you have to work as a team, which means you have to be able to work \\nefficiently. You have to know how a pull request works. You have to know how commits \\nwork. You have to know how to document. You have to file bugs and report to issue \\ntrackers. You have to do all of these things.\\n \\nAt the end of all that, I realized that I most liked working with data. I liked working with \\nalgorithms. Actually, I absolutely loved working with algorithms. \\nI spent more time reading about how the algorithms worked and how they found all this \\ntruth, despite all the noise and red herrings in the data. I loved doing that and working \\nwith people on a project together. It was great. I thought galaxies were cool, don’t get me \\nwrong, but I liked algorithms more.\\n \\nIt sounds like you spotted a project, saw that it was interesting and used your \\nexperience of working on it to explore your interests. How did your background in \\nI think the romantic, public idea of a scientist is \\nthat you jump into a cave and then five months \\nlater, you have a ”Eureka” moment and you come \\nout. Then it’s glorious. But that’s not really how \\nit works.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 90}, page_content='CHRIS MOODY\\n86\\nscience inform your work as a data scientist?\\n \\nScience is getting harder to do. It’s harder to do it individually and it has to happen as \\npart of a team; a collaborative effort, so we can measure different things. Looking at \\npapers from 50 years ago: having a paper with 50 authors on it was ridiculous, that just \\nnever happened. Half the papers out there were published with only one or two authors \\non them. \\nNow, that’s ridiculously absurd. I \\ncan’t remember the last time I read \\na paper with only one author on it.\\nIt’s just because the instruments \\nyou have to use are larger. We end \\nup having to use supercomputer \\nresources or we have to use the \\nHubble Space Telescope to get somewhere. This means that the data and ideas are \\nstarting to grow much larger than one person can manage. In turn, it means that you \\nhave to learn how to work with other people. So that’s a paradigm shift of science, and \\nalso something that I think industry has been familiar with for a much longer period of \\ntime.\\nAt the same time, a lot of my exposure to things like software engineering best practices, \\nor even computer science, was completely self-taught. I didn’t take any formal classes \\nin these fields.\\n \\nThat’s really interesting that it worked out so well, and also that that didn’t hinder \\nyou.\\n \\nI think that’s actually pretty normal. Look at some start-ups. They’re really interested in \\nfinding someone who can actually do the work; someone who is trying to find and build \\na whole community and foster that growth. Take that person from the 90th percentile \\nand just teach them the remaining 10% of the small skills needed. These startups are \\nbasically instilling habits; thinking about what you’re going to do and how it’s going to \\nreflect on everyone else in the network, instead of being an isolated person.\\n \\nSometimes, that has to happen as a feedback reflex. You have to think of how you’re \\ngoing to fit in with everything else. You have to think about how your code is going to be \\nused by others. I was lucky in that I had a community leader in my project who was really \\ninterested in teaching everyone else how to work together, and I learned a lot from him.\\n \\nThis means that the data and ideas are \\nstarting to grow much larger than one person \\ncan manage. In turn, it means that you have \\nto learn how to work with other people. So \\nthat’s a paradigm shift of science.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 91}, page_content='CHRIS MOODY\\n87\\nOf your friends and peers from Caltech, many of whom have also gone on to do \\nheavy computational physics research, have you found that a substantial portion of \\nthem are heading towards industry?\\n \\nYes, especially in astrophysics. I can’t tell you how many plots I have seen in the last year \\nwith the number of faculty jobs remaining constant, or maybe even slightly decreasing \\nwith time, compared with the sky-high number of post doctorates. That means that the \\nlikelihood of a post doctorate job opening is going down at a ridiculous rate. Even when \\nI was in graduate school, the expected number of postdoctoral candidates went from two \\nto three. If it kept going at that rate, by the time I’d finished my first post doctorate, the \\nexpected rate would be four postdocs to every one position.\\n \\nClearly, there’s a huge supply of post doctorates and not that many positions within \\nacademia.\\n \\nHow much did those academic job statistics influence your decision on what you \\nwanted to do after graduate school? Did you feel you could get the same intellectual \\nstimulation from problems in industry as you received in academia?\\n \\nYes, it was a hard decision, but you look at it and think, ‘How many times do I really \\nwant to roll the dice? How much do I really like this?’ That fear of not finding a job really \\ndestroys a lot of the romance of science. I feel like a lot of people start doing science \\nbecause they have this romantic notion of becoming the best scientist, or contributing \\nin a noble way. But the truth is that science is a shitty ride.\\n \\nYou can do a lot of the same things that science will let you do, but you don’t have to do \\nthese things in the world of academia. You can work on science in industry. When I made \\nthat realization, and understood I could do a lot of the science, and be involved in a lot of \\nthe cool stuff I’d tried to do in the first place, it made me realize that I could switch to a \\nnew job outside of academia. At the same time, I didn’t feel that I was giving up on what \\ndrove me initially. There are a lot of startups that are changing the world, so instead of \\ntrying to define clumps and galaxies, I could try to actually work with somebody, and try \\nto change the world. I thought this was really cool and super exciting.  \\nSo then you joined Insight — a six week long Fellowship for PhDs looking to enter \\nthe field of data science. How much of what the Fellowship taught you would you \\nsay was new to you?\\n \\nAll of it. There’s a paradigm shift from science and industry. Everything in science is about \\na fully detailed presentation of an idea; exhaustively explicating all of the caveats. All \\nof the communication is bordered on fully defined facts, or at least as much as possible.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 92}, page_content='CHRIS MOODY\\n88\\nYou look at the borders of your project, the borders of the results, and you know the \\ndownsides and you know the upsides, and that’s because you’re terrified that someone \\nwill find a deficit in your project, and then nail you for it.\\n \\nBut then the opposite is true in business. The biggest problem is that people have very \\nlimited bandwidth. It takes a lot of effort, and there are a lot of people demanding it. So \\nthe crux of everything in business is actually being able to move all of your results in as \\nterse and precise a fashion as possible.\\n \\nYou don’t need to delineate all of the possibilities, you just need to say what is the major \\npoint, and you can go on from there. So, a lot of what Insight taught me was that you \\nneed to condense all of your results down as quickly as possible. You get someone’s \\nattention and you go; that’s the hardest part. As scientists, we were taught to give an \\nhour-long lecture on our project. We didn’t have to consider whether our audience was \\nbeing entertained or not. If they’re not interested, you don’t care. They’re not your \\naudience if they weren’t interested in the first place.\\n \\nIt’s the opposite idea during the Insight Data \\nScience Fellowship. You have to go out and \\nyou have to make every single connection for \\nyourself. You have to boil it down and make it \\ncompletely convincing that everything you’re \\nsaying is relevant to them, and you have to do it in \\n5 seconds. Everything is an elevator pitch. Every \\nYC Company has to give demos in 180 seconds. So Insight is all about building a demo in \\nthose 6 weeks, and then pitching it in 180 seconds. You’re basically pitching yourself as \\na candidate to those companies. You’re saying, ‘Don’t look at me like a graduate student. \\nI’m actually super goal-orientated, or systems-orientated. I can take all this data, apply \\nthese algorithms, and give you some amazing results.’ That’s what those three minutes \\nare for, and that’s the whole paradigm shift. Now, the focus is not so much on the new \\nidea or how much you’ve added to the body of knowledge. The focus is what can you tell \\nme in 100 seconds. That’s all the CEO has time for.\\nIn scientific lectures, you’re not trying to reach a super-broad audience. In the case of \\nscience, you’re trying to deliver an idea, and then you try to back it up in 15,000 words. \\nYou need to do that in business as well. You need to be able to take your idea and defend \\nit. The thing is that, here, you’re no longer trying to defend it to the CEO, you’re no \\nlonger trying to defend it to anyone else. You just need to defend it to yourself, and then \\nyou need to give them the ideas; there’s an implicit trust there.\\n \\nNo one else is going to check your work and no one else should check your work. You \\nEverything in science is about a \\nfully detailed presentation of an \\nidea. But then the opposite is \\ntrue in business.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 93}, page_content='CHRIS MOODY\\n89\\nneed to be an independent party and you need to break it down as to what is important.\\n \\nYou have to build up small kernels of truth, and that’s all you can deliver. A lot of the \\ntime, people find it distressing, but I thought it was great. I thought it was an awesome \\nchallenge to be able to compress my message down and figure out what all the tidbits \\nare. It’s like a whole design philosophy. I liked the idea of throwing out everything except \\nfor what you need to function. I like it from a designer standpoint and also from an \\nalgorithms and data analysis standpoint. I think that embodying that philosophy was \\nthe single most successful part of the Insight Fellowship. \\n“Data science” has now become a very common phrase in many business sectors. \\nYet, it’s still nebulous and no one is really sure what it means. So, what does data \\nscience mean to you? How would you break it down?\\n \\nIt means a lot. It always means to measure data, being able to make sense of that data, \\ncreate models of that data, and most importantly, to be able to communicate what that \\ndata means.\\n \\nI think data science splits into two fields, and I believe a lot of hiring companies are \\nstarting to reflect this. Data science is starting to break off into descriptive analytics and \\npredictive analytics.\\n \\nDescriptive analytics is, ‘we saw this trend.’ Or, for example, ‘We saw this spike or dip… is \\nthat because our service crashed? We saw this huge spike…is it a multiplicity of things?’ \\nIt’s always asking questions of dynamics, and then asking what is going on. So the raw \\ndata comes back, and then you make something useful — actionable business intelligence \\n– from that data. That’s descriptive analytics, taking data that has been produced and \\ntrying to make head or tails out of it, to drive some decisions out of it. So that might \\nmean, ‘We saw some really exciting events in Bulgaria, but why is our site exploding in \\nBulgaria and nowhere else?’ You may find out that it’s not really from Bulgaria, or that \\nit’s raining everywhere else, or a volcano just went off and everybody’s Tweeting about \\nit, or something ridiculous like that.\\n \\nThe other side of data science is predictive analytics; being ahead of the game. This is \\nwhere you’re shifting towards machine learning algorithms. You’re looking at things \\nsuch as fraud, where you’re trying to predict whether a transaction is fraudulent or not. \\nOr, you’re trying to figure out security applications: is this malevolent activity? But \\nthat’s what it is, fundamentally. It’s pattern finding within all the data, in real-time, \\nwhich adds additional constraints on computational complexity.\\n \\nData science rapidly becoming something concrete, especially as it becomes a more well-'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 94}, page_content='CHRIS MOODY\\n90\\ndefined field. But it’s definitely splitting off into those two directions of data, analyzing \\nit and figuring out underlying trends. If there are multiple trends, maybe it’s multiple \\nelements stacking up to produce the signal you’re looking at. Maybe it’s not really a \\nsignal at all, and it’s a bug somewhere, so you have to look at the data.\\n \\nThe other side is not just trying to make heads or tails of the data, but also making \\npredictions. Which city are we going to open up in next? What are the relevant quantities? \\nA lot of business is driven by intuition and gut feelings, and this scares a lot of people. \\nCEOs are trying to pitch entire companies on feelings, essentially. They’re trying to drive \\nhome their points on a colloquial basis. The whole field of data science is trying to turn \\nthat feeling into something a little more rigorous; trying to deliver on something that’s \\nnot intuition, and finding something \\nthat you can ground yourself on. \\nThat gives your business a lot of \\nstability, especially when there’s a lot \\nof startups and they’re all thinking \\nof great ideas, but only some of them \\nare really as great as they believe, \\nand most of them won’t pan out.\\n \\nYou engage a data scientist at the point when you’re looking to add an incremental \\nvalue. That’s not going to make your business take off, it’s not guaranteed. But at least it \\nwill give you something that’s not solely based on a feeling.\\n \\nOf the two different types of data science you articulated, do they also require \\ndifferent skills?\\n \\nFor the most part, they require a lot of the same core skills. Predictive data science \\nrequires a little more machine learning type skills, and descriptive probably requires a \\nlot more statistical skills. But then, in predictive data analysis, you might be using a lot \\nmore random forests or neural networks – all these really cool algorithms.\\n \\nWhich side of data science, from your physics background, seems more intuitive \\nwith you?\\n \\nI started learning programming In high school, because I wanted to play around with \\ngenetic algorithms. So that’s been a long running interest. Even though I went off and did \\nexperimental physics and computational astrophysics, I’ve always had this background \\nof really wanting to do machine learning. That appeals more to the predictive side than \\nthe descriptive side. Both of them have a lot of overlap. There’s not a wall between the \\ntwo, but you can start to see the continuum of data science. So, I think I’m far more \\nI think data science splits into two fields, \\nand I believe a lot of hiring companies are \\nstarting to reflect this. Data science is starting \\nto break off into descriptive analytics and \\npredictive analytics.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 95}, page_content='CHRIS MOODY\\n91\\nattracted to the predictive side. Neural networks I just think are really cool because \\nyou’re essentially training artificial intelligence. You’re taking these tiny artificial brains \\nand making a decision with them. You’re actually turning a whole company based on \\nthat.\\n \\nWhat do you feel are the defining qualities of a top-notch data scientist, compared \\nwith someone who is merely good?\\n \\nI think it deals with communication. I think that’s the difference between the good \\nscientists and the great. Both are going to know a lot about statistics, the techniques \\nthey can use, and how to design, implement, and execute an experiment. Those things \\nare all important. The biggest thing, though, is that you need to be able to communicate \\nthose results. That’s a lot harder than it looks.\\n \\nI think the easiest thing for a graduate student to do, coming into this field, is to gloss \\nover it, but that’s the single most important thing. Most people complain that graduate \\nstudents don’t have a great programming background. All of their other intuitions, well \\ndesigned experiments, caveated results, are sound. But I think that a lot of people believe \\nthat a programming background is not necessary.\\n \\nSo, maybe it is programming for a lot of people, but if you’re already pretty good, then \\nyou’re probably already a good programmer. The last step is just communication. People \\nneed to sense the passion inside of you. This defines the most successful people. It’s the \\nrealization that you are working with other people, and for a lot of scientists, I think \\nthat’s quite a shock. It really goes against this notion of romantic science.\\n \\nIsaac Newton spent three years in a shack during the plague. He didn’t want to get the \\nplague and he hated talking to everyone. Granted, he was possibly autistic in some ways, \\nbut I think a lot of people follow that archetype of going back and living by themselves, \\nand then they emerge with all of their findings. But in reality, it needs to be a much \\nmore continuous process. It needs to be a much smoother process than just coming back \\nand reeling off a list of accomplishments. So it’s always communication, but that’s the \\neasiest part to skip over.\\n \\nWhat do you see as the promise with data science, and also the interplay between \\nmathematics and computer science, that really speaks to you? Where does your \\npassion lie?\\n \\nWe’re living in a really exciting time because I think what were formerly highly theoretical \\nprinciples are finally having an impact on the world. Before, I was looking at clumps and \\ngalaxies. To do that I needed to run clustering algorithms. I needed to be able to run'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 96}, page_content='92CHRIS MOODY\\ndistributed frameworks on thousands of nodes to answer basic questions.\\n \\nNow, I can do almost the same stuff, and I can tweak a learning algorithm that teaches \\nstudents in the best way they can learn. There’s a whole feedback system that says, “you \\nshould answer these questions, and then five minutes from now, we’ll come back and \\nrepeat it, and then we’ll come back a week later and repeat it again.”\\n \\nThe wonderful thing is that those \\nalgorithms, that whole pattern, is \\nbeing replicated from galaxies to \\npsychology and cognition. All of \\nthese high topics of knowledge are \\nbeginning to trickle down, and they’re \\nactually making a real impact on day-\\nto-day interactions. There is not a single company on NASDAQ that doesn’t use some \\naspect of this. Your Facebook Newsfeed is highly tweaked to give you everything that \\nyou think is relevant, and new content to test your preferences.\\n \\nLinkedIn is using all kinds of graph networks. Square is using all these fraud detection \\ntechniques. HealthTap is fielding all of these questions, and training a computer to \\nunderstand what these questions are. And there really are doctors who will be answering \\na lot of those medical questions.\\n \\nThe cool thing here is that they can take a doctor and clone him virtually. He can answer \\na question, and that might reduce patient time in a hospital somewhere. And when you \\ntake that power, and you multiply it by the number of patients in the whole world — it’s \\na huge number. These are real things. We’re not limited to theoretical worlds. You really \\ncan go out and have awesome effects immediately, and they’re tangible. We’re collecting \\nmore and more data, to the point that there are not that many aspects of life that aren’t \\nbecoming data driven. So it’s super exciting.\\n \\nImagine if you were able to go back to the beginning of your graduate school \\ncareer, and you meet yourself coming in the corridors and you have a five minute \\nwindow to speak to yourself. Would you tell yourself to do anything differently?\\n \\nA lot of it would have centered on working more with people. I joined an open source \\nproject, and that was the single best decision in all of graduate school. I learned how to \\ncode in a collaborative way.\\n \\nThe second most important thing probably would have been communication. Every \\nweek, I would deliver a presentation on my results during the past week, and usually, it \\nI joined an open source project, and \\nthat was the single best decision in all of \\ngraduate school. I learned how to code in a \\ncollaborative way.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 97}, page_content='CHRIS MOODY\\n93\\nwould boil down to giving a two or three minute feedback session at the end of that. So I \\nwas already doing a lot of communication and I wouldn’t have changed that.\\n \\nMy programming context was great; maybe I should have started that earlier and taken \\nmore formal programming classes. If you were to design the curriculum, I’d say you have \\nto have a lot of programming. A lot of classes are like, ‘go and do this assignment.’ The \\nreal world is, ‘go do this assignment but you only have to do this module, and someone \\nelse will do the next module. You guys need to be working collaboratively.’\\n \\nThey should also be doing lots of statistics, and they should be able to do it as quickly \\nas possible. People love to talk about this Pareto Principle, where 80% of the outcomes \\nresult from 20% of the effort. The hard part is trying to figure out where that 80% line \\nactually is, and once you realize you’re at it, stop.\\n \\nHow can people find open source projects to participate in?\\n \\nA lot of the time, they already exist. You probably already know what they are because \\nyou hear about them. The biggest thing is not to be shy about it, and not to be scared \\noff. It took me a long time to work up the courage to actually push code back out and \\nbe able to take the criticism. No matter where you’re working, there are other people \\nworking with similar problems. Just go out and search for them. If they haven’t solved \\nyour specific niche problem, join the effort. It’s a worthwhile process. It’s really hard to \\nconvince graduate students about this, who are already overwhelmed with a lot of other \\nthings, but it is definitely the best part of those five years.\\n \\nYour advisor is going to be \\npushing you for results, and \\nmy advisor said it had been \\nyears since he’d written any \\ncode. So you might not realize \\nhow important this is. But in \\na world that is becoming way \\nmore team-based, both in \\nindustry and science, it’s super important to push everything into a team-based context.\\n \\nAlso, if you’re in science, you’re all about trying to communicate your results. One of the \\nbest ways to do that is through your open source network. They have an audience there, \\nwaiting for you, and they might be really interested. A lot of it is, ‘I built this feature onto \\nthis project.’ They’ll go try it out and maybe they’ll write a paper about it, and then you \\nget an extra citation.\\n \\nIt’s a little unfortunate that the primary currency \\nof science is citations and not source code, even \\nthough that’s a big infrastructure push. I think \\nthat will have to change going forward because \\neverything is being done in a team-based context.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 98}, page_content='CHRIS MOODY\\n94\\nThere are a lot of extra indirect effects. The direct effect is that you’ll be better. The \\nindirect effects are that there are a lot of other people who will benefit, and that will \\nreflect very well on you.\\n \\nIt’s a little unfortunate that the primary currency of science is citations and not source \\ncode, even though that’s a big infrastructure push. I think that will have to change going \\nforward because everything is being done in a team-based context. To do science more \\nefficiently, it has to be that way. There’s no other alternative.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 99}, page_content='ERICH OWENS Data Engineer at Facebook\\nPlease talk a little about your background and how you ended up at Facebook?\\nI studied mathematics and applied mathematics during college. I started with a focus on \\nmathematics and physics at a small liberal arts college called Albion. I then transferred \\nto Columbia University where I obtained a bachelor of science in applied mathematics.\\n \\nI worked at the Stanford Linear Accelerator and the Nasa Jet Propulsion Lab doing basic \\nresearch in materials science and systems engineering. I then transitioned to a Ph.D. \\nprogram in applied mathematics at Brown University, but dropped out after two years \\nwith a masters degree as I couldn’t see myself spending seven years on partial differential \\nequations.\\n \\nI moved out to California to work for startups. I realized that the most exciting thing for \\nme was data science and machine learning. I spent two years at startups called Quid and \\nNewsle and then joined Facebook four months ago as a software engineer with a bent \\ntowards machine learning and data science.\\n \\nIt sounds like you have this background in mathematics and you mentioned that \\nyou wanted to do more machine learning. Could you talk a little bit about how you \\npicked data science versus the other things you could’ve done in industry?\\nI guess when you’re a student at Columbia or Brown and you’re looking at what kind of \\njobs there are, finance is a recurring theme. You go and interview for quant jobs and you \\nErich sits at the intersection of data science and engineering, \\na role derived from his unique experiences across academia, \\nquantitative analysis and software engineering. After \\ntraining as an applied mathematician at Brown, Erich cut \\nhis teeth at Quid analysing an eclectic set of data. From \\nQuid, he moved on to Facebook where he currently works \\nas as data-centric software engineer — combining his \\ndeep theoretical understanding of mathematics with good \\nsoftware engineering skills.\\nHe stresses the importance of coalescing different silos of \\nknowledge and working with a business owner mindset to \\nprioritise important pieces of work.\\nThe Importance of Software Engineering in Data Science'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 100}, page_content='ERICH OWENS\\n96ERICH OWENS 96\\nrealize how there is this massive glut of smart people learning how to game arbitrage \\nwith marginal returns. In the grand scheme of things, finance just seemed fruitless.\\n \\nCompare that to the Bay area, where you have people learning how to build recommender \\nsystems, teaching systems to learn and that to me is very exciting. I think personally that \\nmove seemed accessible to someone with a mathematics background. It required heavy \\nuse of high dimensional vector spaces, linear programs, kernel methods, etc., which was \\na language I spoke already.\\n \\nOn the contrary, server client protocols and the more computer science concepts were \\nforeign to me.\\n \\nYou mentioned this a little bit earlier concerning your move into machine learning \\nand data science. Now that you’re at Facebook, what would you say is the value \\nthat you add as a data scientist?\\nIn the case of Quid, they had a whole team of data analysts who were interested in having \\nhumans label training data. For them to scale, it wasn’t about hiring hundreds of more \\npeople, but it was about teaching an algorithm to do what the analysts did. Their move is \\nlargely emblematic of the growth potential of Silicon Valley, where you get exponential \\nreturns by scaling hardware instead of people.\\n \\nI think finding people who could play around in Python and C++ and build these learning \\nsystems was hard.\\n \\nBriefly going back to your previous experience in academia, what would you say \\nwere your biggest challenges in doing research positions at SLAC or your Ph.D. \\nprogram to your roles at Quid, Newsle or Facebook?\\nAcademics don’t really learn to code \\nthe way engineers in the Bay Area \\ndo. You learn as an academic to hack \\ntogether code to produce results for \\nyour research. There is no incentive \\nto learn to code well or maintainably. \\nYou don’t think about object orientation, functional programming or other techniques \\nin the academic environment, which can be an impediment.\\n \\nWearing a business hat also provides a higher-level end goal which is sometimes not \\npresent in the academic environment.\\n \\nWearing a business hat also provides a \\nhigher-level end goal which is sometimes \\nnot present in the academic environment.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 101}, page_content='ERICH OWENS\\n97\\nHow did you overcome these challenges?\\nI first joined Quid as a quantitative analyst and I had a very basic level of Python skills \\nfrom academia. Fortunately some engineers at Quid took me under their wings and \\ntaught the basics of good software engineering.\\n \\nI think when you are a student in mathematics or physics, you think vector is a vector or \\na matrix is a matrix, but you don’t really think about how those representations tie into \\nthe computer. You don’t think about sparsity, run-time, etc., which are very important \\nin industry.\\n \\nThroughout our conversations we’ve talked to many people about their data \\nscience background because there is such a diverse set of ways for people to get \\ninto the field. What would you have done differently through school and work \\ngiven the experiences you’ve acquired?\\nI wish I plunged in more to build things, building websites or projects. When you’re \\ncomfortable writing things on a whiteboard, you get scared of code. I think iterating a \\nlot on a prototype is really empowering and lets you learn programming and languages.\\n \\nI wish I had programmed more, \\nbecause when I first moved to Silicon \\nValley, lack of coding skills was a big \\nstumbling block. I think my roles at \\nthe earlier startups also demanded \\na lot of iteration and prototyping, \\nwhich helped me learn a lot. The pressure to see results in industry made the learning \\nprocess a lot quicker compared to if I were learning in school.\\n \\nWhat would you say is the value that you bring to Facebook as a data scientist?\\nThe value I bring is not so much as a data scientist, but as a software engineer. Although \\nI borrow the tools of data science in terms of clustering , data analysis and classifiers, \\nI have the ability to build a scalable full-stack system. So I am not just building stand-\\nalone models which are pretty to look at which I’ll write a paper about, but where I add \\nreal value is by incorporating that model into a scalable system.\\n \\nIt’s really interesting that you say that because we’ve talked to people who say \\nthat their main value is not software engineering, but rather their quantitative \\nskills. Of the people you’ve worked with, how many tend to come from the math \\nto engineering transition and vice-versa?\\nI wish I had programmed more, because \\nwhen I first moved to Silicon Valley, lack of \\ncoding skills was a big stumbling block.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 102}, page_content='ERICH OWENS\\n98\\nFacebook has its own data science team which is full of brilliant academics. I talk to \\nthem to get advice on what features to build and what algorithms.\\n \\nHaving that isolated academic data science team is really useful for an engineer like me. \\nWe wouldn’t be as successful without them.\\n \\nI sit at the intersection of data science and engineering.\\n \\nCan you talk a little bit about where data science in Facebook sits in the organizational \\nchart or the product pipeline?\\nI’m on the public content ranking team. We want \\nto connect you to content that you may like. So in a \\nsense we’re working on a content delivery system.\\n \\nIn order for that to work, you really have to \\nunderstand how newsfeed-ranking algorithms \\nwork and what the goal for that team is. It’s one thing to rank and display your friends’ \\ncontent which is quite a finite problem, it’s another to aggregate all content on Facebook \\nat a given time to enable content discovery. The problem is much broader than that.\\n \\nData science at Facebook is a stand-alone organization, but I’ve met several data \\nscientists who have been embedded in different groups. So the structure depends on the \\nproduct. On some teams, data is used to inform product decisions, on others data is a \\ncore component.\\n \\nIn some ways these silos of data science remind one of Bell Labs, where you build great \\nthings and are not so worried from week to week about the details of short-term projects \\nor metric gains.\\n \\nSo you’re more insulated from the hard product deadlines and have more freedom \\nto explore?\\nThat would be my guess, but I am a software engineer. I think that would be accurate as \\nthe data science team does publish a lot of papers with the data Facebook collects.\\n \\nYou’ve been in a lot of roles from startups to Facebook, and you’ve surely met a \\nlot of data scientists along the way. What would you say are some of the qualities \\nthat separate the best data scientists from the rest?\\nThe brilliant ones I’ve seen at the few companies I’ve worked at were the ones who \\nThe value I bring is not so \\nmuch as a data scientist, but as \\na software engineer.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 103}, page_content='ERICH OWENS\\n99\\ncould read papers, prototype and then turn it into a scalable system. I’ve met quite a few \\npeople who would have a great idea, but would then take forever to implement it even \\nin Matlab.\\n \\nSo I think strong programming skills \\ncoupled with systems-level thinking \\nis very important. Building scalable \\nsystems may limit your ideas, but \\nit makes them that much more \\npowerful in terms of impact. At Quid, \\nfor instance, there were engineers \\nwho could build systems on their \\nown and think theoretically. In my opinion, the combination of strong theory and the \\nability to implement that in a scalable manner are makes a data scientist stand out.\\n \\nAre there any developments in the field of data science and machine learning that \\nreally excite you?\\nI like the idea of wearable computing, for instance Google Glass. Say you’re in this \\nneighborhood and you want coffee, but Glass could recommend a nearby art gallery. I \\nlike the idea of life recommendations, the idea of personal assistance, the idea of picking \\nup on personal signals and making recommendations.\\n \\nMore advanced algorithms based off linear separations like support vector machines \\n(SVMs) or deep neural networks that could learn intermediary steps or do automated \\nfeature engineering are very exciting.\\n \\nSay at some point that you would like to move on; do you think that your background \\nwould facilitate an easy transition to another field?\\nI’ve thought about hypotheticals, where say in 10 years I’ve built a great career at \\nFacebook and might go back to school to study quantum computers or some exciting \\ntechnology at the time.\\n \\nHaving a strong mathematical background really emboldens you to do these things. \\nThe nature of hiring at that age is different as you would no longer be a fresh college \\ngraduate, but an experienced hire. At that point, you may also have enough experience \\nto start your own company in an adjacent field.\\n \\nHow do you approach problems? What’s a mathematical way of approaching data \\nscience problems and how do you use that framework to solve other problems?\\nI think strong programming skills coupled \\nwith systems-level thinking is very important. \\nBuilding scalable systems may limit your \\nideas, but it makes them that much more \\npowerful in terms of impact.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 104}, page_content='ERICH OWENS\\n100\\nI’ll give you an example. When looking at time series of data, one usually opts for \\nanalyzing the entire data set which requires a large amount of memory to store, which \\nwill impede actual analysis.\\n \\nHaving learned mathematics and signal theory, I could use a low-pass filter and just keep \\na small buffer to learn the exponential moving average at any given time. You see how \\nan analog-to-digital converter can be useful in analyzing social data. I think spotting \\nanalogous metaphors between fields is the most useful thing someone from a rigorous \\nbackground can do.\\n \\nJust building off analogous metaphors — simulated annealing was inspired by \\nmetallurgy. How have you found your background in mathematics useful in cross-\\npollinating ideas to your current role at Facebook?\\nWhen it comes to recommendation systems, people will often use singular value \\ndecomposition (SVD) to do dimensionality reduction. For me that makes sense from \\na mathematical background, but I’ve seen stumbling blocks when talking to engineers \\nabout why that concept would be useful.\\n \\nThe ability to read a paper and understand \\nit is also very useful. For instance there is \\nthis beautiful technique called random \\nprojections where you populate a random \\nprojection matrix using ones, zeros and \\nminus ones, scaled by some normalization \\nterm. You can throw such a projection \\nmatrix against a high-dimensional vector and map it to a lower-dimensional space. \\nAccording to the Johnson Lindenstrauss lemma, you can guarantee with high probability \\nthat the interpoint distances will be mostly consistent. It’s a remarkable property because \\nyou basically scatter your data into the wind, but it’s still useful with the added benefits \\nof easier implementations and lower runtimes. It makes sense in terms of probability, \\nbut it seems really non-intuitive otherwise.\\n \\nWhat advice or feedback would you give to people who are just starting out on \\ntheir transition to the industry?\\nI think the most useful thing about being in college and graduate school for so many \\nyears was that I was learning for the sake of it and it was just very interesting. When I \\nwas doing applied mathematics I ironically wasn’t that interested in applications. When \\nI asked myself what I wanted during graduate school, I would say that I wanted the \\nI think spotting analogous metaphors \\nbetween fields is the most useful thing \\nsomeone from a rigorous background \\ncan do.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 105}, page_content='ERICH OWENS\\n101\\nautonomy to work on some really big and hard problems. That was as concrete as my \\ncareer goals were.\\n \\nI’m really lucky that the whole data science and machine learning industry existed when \\nI got out of school. I worry that if I were pragmatically focused on learning certain things, \\nI might miss more abstract concepts which have greater implications later.\\n \\nSo I guess I would encourage people to study what they like, but the way that worked out \\nfor me may not work for others. It’s difficult to give very specific advice.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 106}, page_content='EITHON CADAG Principal Data Scientist at Ayasdi\\nCan you talk a little bit about your background?\\n \\nI double degreed at the University of Washington in Business and Informatics; the latter \\nis a specialized degree that focuses on data architecture and how people interact with \\ndata and information. \\nI originally thought of Computer Science as a major, but took a few classes and realized \\nI didn’t want to be coding all at the time. So I opted for an option that potentially didn’t \\ninvolve significant programming, but did involve many things that you would typically \\nsee when working on applied technical problems.\\n \\nMy undergrad focus was on Ubiquitous Computing, and my undergrad capstone project \\nwas on embedded barcoding and handheld computing. I can attribute this to my first job \\nduring college, which was at Intel Research in Seattle. At the time, the Lab’s stated focus \\nwas on ubiquitous computing; this means embedding computing into your environment \\nor finding ways of using computing in ways well-integrated to the environment.\\n \\nI worked on two research projects there: LabScape and PlaceLab. LabScape asked the \\nquestion, “How can we embed computing systems within research laboratories to help \\nscientists?” Basically, we’d develop studies on how scientists actually use software in \\nthe lab. PlaceLab, the second project, asked “Can we utilize WiFi devices to triangulate \\nposition and provide location-specific information to a user?” Have you ever heard of \\nAfter dual degrees at the University of Washington followed \\nby a PhD in Biomedical Informatics, Eithon came to data \\nscience through a focus on machine learning applied \\nto biology. Although initially disinterested in low level \\nprogramming, Eithon came to see the powerful application \\nareas during his research and wrote a pipeline that is still used \\nto identify pathogenic proteins for structure crystallization. \\nAfter graduating, he worked on defense projects for various \\nUS government agencies, before striking into the heart of \\nSilicon Valley. At the time of this interview, Eithon was a \\nmanager and principal data scientist at topological machine \\nlearning company Ayasdi, where he led analytical efforts in \\nthe healthcare and pharmaceutical space. In this interview, Eithon talks about his personal \\njourney to data science mastery, and the joy of being insatiably curious. \\nBridging the Chasm: From Biomedical Informatics to \\nData Science'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 107}, page_content='EITHON CADAG\\n103\\n“wardriving”? Wardriving is basically driving around town with a computer whose Wifi  \\nscanner is on. You combine that with GPS, so you know the strengths of various signals \\naround your current location; this can be coupled with contextual information, such as \\nstores or services nearby. Then you triangulate that information that so when you or \\nsomeone else is in that area again, you can provide information on what’s nearby purely \\nfrom Wifi signal. Both of these were fun projects and I got to work with some really smart \\npeople at the lab.\\n \\nDid you learn how to write code during these projects?\\nI wrote very little code initially. I wasn’t a really good programmer at the time, and was \\nnot terribly attracted to coding, and for both projects I worked on the user side of the \\nresearch, such as usability and user testing. I didn’t become interested in programming \\nuntil a later experience in biomedical science where I saw code development as another \\ntool to accomplishing my goals.\\n \\nLater as an undergraduate, I interned at Seattle Biomedical Research Institute under \\nPeter Myler. My lab worked on infectious diseases, and my first project was to build \\nsoftware to identify genes. This experience got me really interested in biology and \\nresearch in general. \\n \\nThere’s a problem in biology which is pretty fundamental: you have a series of sequences, \\nDNA, and want to identify the location of genes. At a simple level you can find stop \\ncodons, which are short sequences that suggest the end of a gene. One challenge is \\nworking out where these stop codons start, as they sometimes have many potential \\nstarting points. Over the course of a summer, I built software that used a combination \\nof different methods to determine optimal starting position. I then used additional \\nbiological information specific to the species of parasitic genomes we were studying, to \\nfurther enhance the technique. \\n \\nWas that project the catalyst for you going to graduate school?\\n \\nYes, it’s also the project where I realized that coding wasn’t as bad as I thought, and \\nbegan to appreciate the importance of computer science in modern biological research. \\nAt the time, all the computer science classes I took were taught in C, which is probably \\none reason I was a little turned off to the field; I wasn’t great at pointers or deallocating \\nmemory. But this was a great project because it had an application. I got to see what \\nwas going on, how it had an effect, and it made me interested in learning more about \\nsoftware engineering as applied to science.\\n \\nI had a good understanding of the computational aspects because I’d encountered a \\nproject like that very early on.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 108}, page_content='EITHON CADAG\\n104\\nHow did you choose graduate school and also how did you choose what projects \\nyou wanted to work on?\\n \\nI started with a Masters. I was very interested in just learning more about computing \\nand biology, and I knew my school actually had a degree that was specific for this kind of \\nfocus so I opted to stay there. I went to the University of Washington for my Masters in \\nBiomedical and Health Informatics.\\n \\nMy focus was actually just the next step in the procedure of finding the genes. Now that \\nwe’ve found the genes, can we make a best guess about what it is actually doing in the \\nbiological system it operates?\\n \\nI used logic and data integration to annotate the genes; biology is full of databases that \\nhave information about genes. The problem is they’re so disconnected and fragmented \\nthat it’s difficult for someone to make sense of it. What we had was essentially a system \\nfor collecting this information wholesale and then federating them under some uniform \\nschema. This schema says: “Here’s a gene. It translates to a protein. Here is some \\ninformation associated with the gene.” \\n \\nI worked on this with my advisor Peter Myler and the head of my department, Peter \\nTarczy-Hornoch. Essentially, our solution was to treat these sources as a large database. \\nWe mapped the information of data sources in an automatic fashion to the contents \\nof the schema. Now you can start to ask things like, “What are the functions to which \\nthis gene maps?” We used logical inference to resolve these questions. Part of this was \\ndoing some shallow NLP , allowing us to parse the gene functions and other descriptors. \\nIt worked pretty well in comparison with human scientists doing manual annotation.\\n \\nThat was my Masters thesis. After that I wanted to work on something a little bit different \\nfor my PhD.\\n \\nWhile there is a lot of biology in your research, there also seems to be a strong \\ntheme of building and engineering systems. Did you continue this intermixing of \\nbiology and engineering in your PhD?\\n \\nWhile there was a heavy component of engineering, I wasn’t the only person working \\non the software platform on which my Masters project was built. There were a number \\nof other folks in the lab that were working on variations of the same data integration \\nmethodology to solve different kinds of problems. In my PhD, I thought what I was doing \\nwith logic was great but there was something unsatisfying about doing something that’s \\na series of conditional rules. I wanted something more unified.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 109}, page_content='EITHON CADAG\\n105\\nI started to read a lot about newer statistical methods. I thought we could apply some \\nof them to federated data for protein characterization. Data integration generated a ton \\nof information, and statistical techniques seemed to provide a more efficient way of \\nmaking sense of that information without requiring curated logic. So that’s essentially \\nwhat I did for my PhD. I took proteins and developed and applied a way of assigning \\nfunction to them using data integration and statistical learning. Luckily, William Noble, \\none of the early researchers who helped pioneer machine learning techniques in biology \\nwas a professor at UW so I was able to get his help.\\n \\nI focused primarily on pathogenic \\nproteins; these are proteins \\nin bacteria that tend to cause \\ndisease. An example would be one \\nthat facilitates the invasion of a \\nbacterium into the host cell; another \\ncould be a protein that helps the bacteria attach to the host cell. All these functions were \\nparticularly critical for a consortium run by my advisor, the Seattle Structural Genomics \\nCenter for Infectious Disease. The Center’s mandate was to characterize and crystallize \\nas many new proteins as possible from neglected pathogens.\\n \\nThe overall result was an approach that gathered heterogeneous and noisy data from \\nmyriad biological sources, unified them, and then used statistical methods to determine \\nthe likeliest protein functional class. We used the method that I developed to help \\nprioritize and classify proteins for wet lab investigation. Even now, I will get an email \\nfrom my old collaborators every so often saying, “One of those proteins that you selected \\nin your system was just crystallized, it has a structure we’ve never seen before.” It’s \\nwonderful and gratifying to see that my work is having a direct effect on the advancement \\nof life science.\\nGraduate school was a really fulfilling time for me, because I was able to spend time \\nexploring and found the specific niche in which I was really interested. If you have a \\ngood advisor and you have good support, it’s easy to do have this type of experience. The \\nproblem is that a lot of it depends on the luck of the draw. Did you pick the right advisor? \\nDid you pick the right project? It’s especially true in the sciences where if you pick the \\nwrong project, it might not bear fruit and you feel like you lost time. So I was lucky in the \\nsense that I had great advisors and really great research projects to work on.\\n \\nIt seems like although you didn’t necessarily concentrate in CS in undergraduate, \\nwhat you did for your master’s project and also your PhD was just as extensive \\nof an education in data integration, software engineering and machine learning \\nalgorithms. How did you learn these topics without a background in them?\\n \\nI took proteins and developed and applied \\na way of assigning function to them using \\ndata integration and statistical learning.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 110}, page_content='EITHON CADAG\\n106\\nI think I was fortunate at the very least. Even though I did not start with a lot of hardcore \\nprogramming skills, I did have a component of them from classes an undergrad.\\n \\nBut I think the biggest thing that contributed to my skill set was doing graduate school. \\nTypically, graduate school is taking a few core classes followed by going deep into \\nsomething you’re really interested in. As you go deep you are forced to learn the things \\nyou need to know along the way. So you end up taking extra classes, reading a lot, and \\nmeeting people who are experts in their fields because the goal is eventually to become \\nan expert in your own field; you have to know quite a bit to advance science even just a \\nlittle. At the time, as I learned more technical and analytical skills, it wasn’t learning just \\nfor learning sake, but as a means to an end. For me, this perspective made the learning \\nmuch more interesting.\\n \\nFor example, one of the things I ended up doing as an aside with some colleagues was \\nNatural Language Processing (NLP). We ended up organizing an NLP conference and \\nworkshop in my last year of graduate school. My role there was developing a quick software \\nsystem for annotating medical notes used by workshop participants, and designing the \\nstatistical technique to evaluate results. \\nIt was a competition. We had people from across the country submit their programs \\nand their methods to pull out information from natural language text, which is actually \\npretty hard. Not only did they have to extract the medication, but they had to report \\nthe route and dose for the medication, all from transcribed medical narratives. This was \\na nice opportunity for me to work more on both my software skills and my statistical \\ncapabilities. These are the sorts of opportunities available in research, and especially in \\ngrad school, that helped hone my skills in research execution.\\n \\nDid you also enroll in graduate coursework, or were you completely self-taught?\\n \\nI took quite a few CS and other classes where there was some significant programming \\ninvolved. Also, in my Masters program I worked a lot on a large code base. It was a fairly \\nsignificant repo, with multiple people checking in/out code. So I had to really know my \\nway around code and know that other people were going to be reading my work; I had \\nto write decent comments and know what’s going on. Also, it was all in Java, which is a \\nlanguage that somewhat enforces structured overhead to begin with.\\n \\nIn addition, I worked very briefly for Cerner Corporation; they make one of the largest \\nelectronic medical record systems (EMR) in the US. I actually got to work on pretty \\ncool R&D projects for their medical informatics group, and I had to keep the code well \\ncommented. Part of the exercise there was learning what is standard acceptable practice \\nfor software engineering. So that was a good opportunity to get an understanding of how \\nengineering is done in a much larger ecosystem.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 111}, page_content='EITHON CADAG\\n107\\nI think the nice thing about software development in general is that you don’t necessarily \\nhave to focus on it to pick it up. Reading is a pretty important component, both online and \\nin books. There’s a canonical book on software engineering with regards to generating \\nprogramming patterns. I read the whole book during the summer while I was working \\nfor that company. However, I don’t think there’s any better way than actually looking at \\nother people’s code and writing code yourself. I had some really brilliant colleagues who \\nwrote awesome code. So getting to see what they did and learning from them was a huge \\nbenefit.\\n \\nWe talked to several other people and it seems like your graduate experience was \\nvery extensive. Not only did you work on these two awesome projects but also \\nyou just found time to do extra bits.\\n \\nI hardly slept in my last year! You realize when you’re in graduate school that as soon as \\nyou’re finished, it’s the real world. So I wanted to cram as much opportunity to learn as \\npossible within the last couple of years there.\\n \\nThe other thing was that I got a scholarship \\nfrom the Department of Defense to finish \\nwithin a certain amount of time, because \\nafter that I’d get a job with the government \\nas a civil servant. So if I didn’t graduate in \\ntime I’d get a penalty of more time in the \\ngovernment, which was not necessarily bad, but I wanted the option to leave whenever \\nI wanted. My Masters was two years, a standard Masters. My PhD was about three and a \\nhalf. When the US government can come after you for not finishing your degree when \\nyou said you would, that’s pretty good motivation to finish on time!\\n \\nSo immediately after graduating, did you have any thoughts about staying in \\nacademia?\\n \\nYes, I always considered it. But I had this obligation to the government to finish first. \\nBecause they paid for my last half year so I owed them the same amount in service.\\n \\nOne of the things that come up when people are thinking of leaving academia is that \\nthey feel isolated, whereas the draw of industry is that it’s intensely collaborative. \\nWhat was your experience like?\\n \\nA computational biologist will often work in conjunction with other scientists. If you \\nthink about a modern biological lab, you have a Principal Investigator, a number of \\ntechnicians, wet lab scientists, people doing data management and then you might have \\nI don’t think there’s any better way than \\nactually looking at other people’s code \\nand writing code yourself.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 112}, page_content='EITHON CADAG\\n108\\na set of computational biologists. I think in modern biology you have a multidisciplinary \\nteam working on the same general problem where each person has their own task. One \\nperson designs experiments, another person does the data management. A different \\nperson follows up and sees if the results corroborate with models.\\n \\nSo in some sense it’s a squad. Each person has a specialized role and has ownership. \\nIt’s also very humbling because even for your small piece, you often realize there is \\nsomething you didn’t take into account. That’s just biology: unless you have a gigantic \\nmemory capacity, you’re never going to commit the entire breadth of the field to recall.\\n \\nAfter your stint with the government, what were your thoughts on what to do \\nnext?\\n \\nOne thing about science PhDs is typically you have to do a postdoctorate. I liked working \\nfor the government because of the emphasis on application; what I did there was being \\nused to make decisions. So I wanted to find a postdoctorate that would give me that \\nsimilar experience while still considering government as a field of work. I ended up \\ncoming over to Lawrence Livermore National Laboratory in Livermore, California, to \\nwork as a postdoctoral scientist.\\n \\nIt was perfect because it gave me options. I could stay in government because it was still \\na government institution. However, it was also a postdoctorate so it meant I could go \\ninto academia afterward. Finally, it put me within striking distance of Silicon Valley. I \\nfelt it maximized my opportunities at the time.\\n \\nAfter finishing your postdoctorate you had the chance then to look for academic \\npositions, but also you were really close to Silicon Valley so there were a lot \\nof startups and industry opportunities. So how did this influence your thought \\nprocess?\\n \\nI have to admit that I probably wasn’t as committed to doing academia at that point. \\nI think if someone is so close to everything that’s going on in Silicon Valley you’d be \\nremiss to not at least think about it. My postdoctorate was about to end, and the funding \\nwas lacking for this project. So there was uncertainty with regards to the likelihood of \\nfinding another project in my field there. Biodefense funding in government tends to \\ncome in waves of feast or famine.\\n \\nI happened to be contacted by a recruiter out of the blue, who mentioned some mobile \\ngame companies that were really interested in finding someone to do data analysis and \\nsoftware engineering. So I thought, “I’m actually interested in biology and medicine, \\nso if there’s anything there that would be a better fit.” She called me back later, tells'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 113}, page_content='EITHON CADAG\\n109\\nme about this company, Ayasdi, and sent me a summary of what they were doing. It \\nlooked quite interesting, and ended up interviewing and joining. I think I was the 15th \\nemployee of the company. \\nAnd you’ve seen Ayasdi grow from a 15-person company to now many multiples \\nlarger. You’ve worked in many different settings, including very applied projects, \\nthat eventually led you to the exciting world of startups, although it was never \\nyour direct intention. Do you think yourself very fortunate?\\n \\nLet me just step back a little bit. When \\nyou pick a major in undergraduate, part \\nof that decision is thinking about what \\nkind of job you want after you graduate. \\nAn important part of that question is: \\nwhat are the skills that you want to pick \\nup along the way? I don’t think graduate \\nschool is any different. I think one thing \\npeople in grad school have to be aware of is if they’re not fully committed to academia, \\nyou have to make sure that you’re building enough of a general skill set that you still \\nhave plenty of non-academic options open.\\n \\nTake my grad work in data integration. I wouldn’t call myself a world expert in it, but \\nI also know it’s a challenging problem that’s important for people to pick up and am \\nfortunate to have gained valuable experience in it. In many cases, it’s a neglected area of \\nexpertise. So you want to be able to pick up things that you know are going to be useful.\\n \\nBeing able to pick that up and learn from smart people and get their advice was extremely \\nvaluable. Domain and skill don’t necessarily have to be completely intertwined. You can \\nhave a domain focus (in my case it’s biology and medicine), but you can still continuously \\npick up skills that are applicable to that domain but also have broad generalizability to \\nothers. I’m thinking about not just undergraduate but also graduate school going forward. \\nMaybe you have a domain, but it’s important to understand that there are things that \\naren’t necessarily specific for that but are worth learning.\\n \\nFor me it’s been tremendously worthwhile. While developing the next iteration of \\nAyasdi’s software, we were at a little bit of a loss for how to figure out what to do with \\nregards to the usability. I actually got to leverage undergraduate experience to help our \\nteam fix some of the early difficulties with usability.\\n \\nAnother example is just general analytical capabilities. The challenge in science is \\nthat statistics isn’t something with which many researchers are very adept. In many \\nEach person has a specialized role and \\nhas ownership. It’s also very humbling \\nbecause even for your small piece, you \\noften realize there is something you \\ndidn’t take into account.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 114}, page_content='EITHON CADAG\\n110\\ncases designing an experiment, even a computational experiment comparing methods, \\nrequires just basic statistics — enough that you can write a paper that confirms you’ve \\nvalidated the results and you know that one method is likely better than others. \\n \\nAlso, I think breadth in our field is just as important in many ways as depth. Because \\nif you’re touching all this data of various size and form, it’s important to have a good \\ncharacterization of what you know and what you don’t know. The more broadly you have \\nthat, the better, but it’s also good if you have an area where you can go really deep. For \\nme that’s biology and medicine.\\nSo with all this in mind, when you joined Ayasdi, did you ever think, “Wow, this is \\nreally different from my previous roles”? And were there places where you thought, \\n“Wow I’m really glad I had x, y, z experiences because this feels exactly the same”?\\n \\nThis is a very interesting position in the sense that a lot of it is actually working directly \\nwith people. If I look back at my background it’s mostly been head down working-on-\\nnumbers research. So having this component of it is quite unique for me. We are doing \\nthat heads down and work part, but there’s also a very significant part that involves \\nworking with new customers and understanding what their current challenge is, and \\nhow best to convey a solution. One of the biggest challenges I had to overcome was to \\nsuppress my introversion enough that I could speak without stumbling over my words. \\nIt was a big hurdle initially, but I’ve had plenty of practice now and eventually got \\ncomfortable with it.\\n \\nSkill-wise, one of the key conditions when you’re looking at pharmaceutical data is that \\nyou have to be particularly rigorous about the statistics. This is a realm where we don’t \\nnecessarily want faster machine learning. We just want traditional, well-understood \\nmethods so that we know with some level of confidence that the results make sense. \\nFortunately, I’d had plenty of exposure during my graduate and undergraduate studies \\ndoing statistics and designing computational experiments.\\n \\nA lot of emphasis is placed on the use of more advanced methods when in many cases \\nhaving just a sound foundational understanding of basic statistics is more critical. It gives \\nyou grounding to look at an experimental design and understand at a very simple level \\nwhy it was design in that way. Why are these the main effects? Why are they characterizing \\nsomething this way? Why did they select these number of replicates? Using more exotic \\nmachine learning is great too and is often appropriate for contemporary data problems, \\nbut at the end of the day there are some really basic things that everyone has to know.\\n \\nWhen we say data science, most people think about just data but less about science. \\nA lot of people who do data science in industry start with the methods themselves'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 115}, page_content='EITHON CADAG\\n111\\nand never really ask the questions such as: “What is causing the phenomena in the \\nfirst place? How do I test that rigorously?”\\n \\nI think one of the good things in biology is you’re forced to ask those questions. Typically, \\neven simple methods can do quite well in biology under certain circumstances. I think \\nin some sense what we have at this company is a fairly simple method, and I think that \\nsupervised methods typically are a great way to start and a great way to start to get into \\nmore detail. But, at the same time you just have to guard against this desire to go after \\nthe most interesting method when sometimes the simplest thing will give you the best \\nand most explainable answer. As a scientist, I always want to be able to go back and \\nunderstand the underlying principles. But if you’re looking at prediction, maybe that’s \\nless important.\\n \\nYou’ve worked at Ayasdi for a few years now, but you’ve seen the injection of \\ndata science into the general vernacular of the technology companies. How do you \\nmake sense of what people are doing with the term “data science” today? How do \\nyou think Ayasdi fits into this ecosystem?\\n \\nI didn’t even know this term existed until I got this position. I didn’t know data was a \\ndiscipline of science. I thought it was a prerequisite for science, not a study unto itself. \\nI’ve heard the definition, “It’s someone who’s better at coding than a statistician, and \\nsomeone who’s better at statistics than a programmer.” In some ways you can turn it on \\nits head: it’s someone who’s worse at coding than a software engineer but is worse at \\nstatistics than a statistician! I’m joking of course, but that’s how I feel about it sometimes \\nsince I’m well aware of my own shortcomings.\\n \\nA lot of people that do this role have very interesting backgrounds. You don’t have a \\nhuge majority of people coming from a specific discipline; it’s mixed. When you look \\nat something like computational biology, we’re used to dealing with messy, noisy, ill-\\nformatted data. There are quite a few people who come from a biology background that \\ndo data analytics and data science. Maybe they picked up data wrangling skills along the \\nway to do extract-transform-load.\\n \\nThe other component that is also pretty critical is some kind of statistical training. At the \\nend of the day, the term data science means you’re a scientist, and you have an obligation \\nto deliver results correctly. If you’re not happy with it you go back to the drawing board. \\nThere’s an important ability to understand and be able to evaluate whether or not what \\nyou’ve done makes sense from a statistical standpoint.\\n \\nThen there is the domain expertise aspect. In many cases, we’re tackling problems that \\nare fairly difficult and that require a lot of knowledge of a particular area. Moreover,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 116}, page_content='EITHON CADAG\\n112\\nbeing able to go to subject matter experts and speak the same language goes a long way \\nto gaining credibility and trust from the person with whom you’re working.\\n \\nI think many of the applied science areas \\nof study, and certainly things that involve \\nexperimentation, are where many people \\nget a lot of broad experience. Graduate \\nschool is great for giving you that deep \\ndomain knowledge and then hopefully \\nalong the way you’ve picked up sufficient \\namounts of statistics or mathematics to \\nspeak coherently about what you’ve generated, as well as the technical chops to execute.\\n \\nSometimes it’s just practice. For example, maybe you won’t know having certain data in \\na specific way is a problem, unless you’ve seen it before and have done the repetitions \\nto deal with it in a very fast way. If you do this enough, even a massive data set can be \\nturned over very quickly because you’ve seen it before and you know exactly what to do. \\nIn some sense a lot of it is as much pure practice as it is science.\\n \\nYou answered the first part of my question. The second part is: “How do you see \\ndata science in general?” Do you feel like Ayasdi is doing something different from \\nthe mobile apps companies? And if so, what is that special something?\\n \\nWhen you look at what a lot of places are doing, it’s variations on the same theme. \\nWhich isn’t to say that’s bad or wrong; sometimes that’s what you have to do and there’s \\na big market in making that better and faster. In many cases there are tools and methods \\nright off the shelf that one can adapt. Often, these were things that were developed just \\nfor those problems.\\n \\nThere’s been a big focus on supervised methods. However, as data grows, there are \\npotentially many outcomes of interest — for some problems, we may have little idea of \\nwhat to train for or what the expected outcomes even should be. It’s not that our current \\nmethods are deficient, but that with so much data, the number of potential questions \\nwith valuable answers grows very rapidly and cannot be enumerated by humans alone. \\nCan we take advantage of very basic ideas in mathematics, such as distance metrics, and \\nunderstand better where direct our attention?\\n \\nWhat we do at Ayasdi is a very interesting way of looking at the large data problem. \\nOur method applies well to high dimensional challenges or in many cases where people \\nare completely inundated with data but have no idea where to search for potentially \\nhigh impact discoveries. I can’t tell you how many times I’ve been in a meeting where \\nBeing able to go to subject matter \\nexperts and speak the same language \\ngoes a long way to gaining credibility \\nand trust from the person with whom \\nyou’re working.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 117}, page_content='EITHON CADAG\\n113\\nsomeone says, “We have a lot of data, we know there’s something awesome in it that we \\ncan use to optimize our process/business/medicine/drug. But we don’t know where to \\nstart.”\\n \\nBeing able to elegantly and mathematically tackle this is going to be extremely useful \\nas this becomes a very common problem. We’re already seeing this in many different \\nbusiness areas. Speaking just from my experience in biology and medicine, I see a lot of \\nopportunity as more genomic and health information is collected and stored. There is \\na huge amount of value in just asking the right questions; the problem is that human \\nability to formulate reasonable hypotheses is finite and limited. So being able to identify \\nand prioritize those questions in a data-driven way is going to be extremely important \\ngoing forward.\\n \\nWhat do you see coming out of the pipeline in the next three to five years in \\nmedicine and computational biology that you’re excited by, and that wouldn’t be \\npossible without the new data tools and techniques being developed?\\n \\nMedicine is a very interesting field. It’s a field where you need a lot of domain expertise \\nto be really proficient. Take a physician for example who has to go through many years \\nof school, sometimes more than a PhD, to be really good at what they do. How do they \\ndo that? They don’t do that by reading formulas or theorems. The biggest and most \\nimportant component of their training is going to the hospital and seeing patients. \\n \\nThat’s how medicine is. But I think as we move forward it’s going to be critical to inject a lot \\nof data there. To capture data, understand what’s going on, understanding how different \\npractices affect results and outcomes. That’s not even touching the genomic aspect and \\npersonalized medicine. There’s so much information, there’s so much variability in how \\npatients get treated across the board. How do we help make this more uniform?\\n \\nOptimizing patient outcomes is a very interesting problem because it’s something \\nthat’s always been there and surprisingly, we do all these things with data but that’s still \\nsomething that everyone wants to solve. I think that’s one area in medicine where where \\ndata science can help to make a positive and lasting impact.\\n \\nI think that one of the things you mentioned very early on that doesn’t get talked \\nabout much is just how much work it takes to be really good at something. When \\nyou first started working, you worked very late into the night, most nights doing \\nanalysis. What drove you, and drives you as a data scientist today?\\n \\nI think probably the biggest thing was curiosity. That’s actually a huge component. When \\nI’m up late and trying to figure out a problem, my personal goal is to better understand'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 118}, page_content='EITHON CADAG\\n114\\nwhat is driving whatever phenomena I am observing. I just want to find out. I’ve had \\nthis plenty of times here when working at Ayasdi, where I find myself facing a problem \\nthat is just driving me bonkers because I want to understand it better. Maybe I found \\nthis pattern and that pattern, and they all point to the same thing, but the outcome is \\nthe inverse of what I thought! So I want to dig deeper and know why. I think like any \\nscientist the thing that drives me the most and really compels me to work late into the \\nnight until the sun comes up is curiosity.\\nIf you could catch yourself in graduate school walking out of a lab at 3 a.m. and had \\na chance to speak to yourself, what would you have told yourself? How would you \\nhave lived life differently? Or would you have chosen anything different?\\n \\nIn terms of general direction, I probably \\nwouldn’t change very much. I love \\nbiology and medicine, and the work is \\ntremendously fulfilling. For the benefit \\nof people who are interested in the field \\nand doing data science as a career though, \\nI would definitely say take as many \\nstatistics courses as possible. If anything, I would have told myself, “Hey! I know you \\ndon’t want to take that statistics genetics course because you have a completely full \\nload, but take it anyways because you’ll end up using that information in your career at \\nsome point.” I end up having to look back at scattered notes or books because I didn’t \\ntake that statistical genetics course. Take more statistics courses, and take more math \\ncourses; though focus on statistics more than anything.\\nI think like any scientist the thing that \\ndrives me the most and really compels \\nme to work late into the night until the \\nsun comes up is curiosity.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 119}, page_content='GEORGE ROUMELIOTIS \\nSenior Data Scientist & Data Innovation Leader at Intuit\\nCould you start off by telling us a little bit about yourself?\\n \\nI’m originally from Australia, where I completed an undergraduate degree in applied \\nmathematics at the University of Sydney, and began a Ph.D. in physics which I completed \\nin the U.S. My focus was on theoretical and computational plasma astrophysics. More \\nspecifically, I investigated the physics of solar flares. I was a Senior Research Scientist at \\nStanford for several years before I realized that getting a tenured academic position was \\ngoing to be difficult -- there were so few spots in my sub-discipline. Around the same \\ntime, I started getting very interested in business applications of applied mathematics, \\nand eventually I decided to make the leap out of academia and into business.\\nIn the course of my research, I had developed Bayesian image processing techniques for \\nastronomical images, which led me into machine learning, which in turn led me into \\nonline learning. Now, those were the days when everybody was starting a company, so I \\ndecided to join the party. I co-founded Dynaptics with a few business partners, raising \\nabout $5M. This start-up pioneered the development of adaptive learning systems \\nto optimize online advertising. A non-technical marketing manager could “release” \\nmultiple advertisements into the system, and the system would learn in real-time \\nGeorge arrived on the fabled Stanford campus in the early \\n90s as a postdoc from Australia. After a couple of years \\ndoing research in theoretical and computational plasma \\nastrophysics, the beating drum of the tech boom of 90s drew \\nGeorge into the unconstrained world of dotcom startups.\\nUndeterred by the Dot Com Crash, George went on to found \\nJRG Software, which provided scheduling software for the \\nfood and beverage industry. His time as an entrepreneur \\nproved to be an invaluable experience in making him a \\nholistic Data Scientist.\\nToday, he is a Senior Data Scientist & Data Innovation Leader at Intuit, a leading provider of \\npersonal finance and tax software. His interview touches on the minutiae of the hard technical \\nskills, but also the macro and people skills which combine to make a holistic Data Scientist. \\nGeorge has since taken a role as a Distinguished Data Scientist at Walmart.\\nHow to Develop Data Science Skills'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 120}, page_content='GEORGE ROUMELIOTIS\\n116\\nwhich site visitor should be exposed to which advertisement in order to continuously \\noptimize the revenue stream. As the site visitor behavior changed over time, the system \\nwould automatically adapt. Those were very exciting days, and our customers included \\nMSN, eBay, and Cisco. Not so exciting was the Dot Com Crash in 2001, when the doors \\nfor additional funding slammed shut overnight. It was like nuclear winter for venture \\ncapital. We could not scale down our operations fast enough, so we had to shutter the \\ncompany and sell off the technology and intellectual property.\\nUndeterred, I went on to found another start-up, JRG Software, with another set of \\nbusiness partners, this time raising about $10M. That start-up was in a completely \\ndifferent domain, namely factory scheduling for the food and beverage industry. The \\nproblem we solved was to enable factories to rapidly adapt to changing demand without \\nholding a lot of inventory. One of our early customers was General Mills, which still uses \\nour system to schedule all West Coast production of Cheerios! The business challenge \\nwas how to penetrate the headquarters of large companies like General Mills where SAP \\nwas firmly entrenched. We were eventually acquired by a public company that added our \\nscheduling system to their product line.\\nAt that point, my wife said something along the lines of, “ Perhaps you should look at \\ndoing something other than a start-up next,” and I eventually arrived at Intuit as one of its \\nfirst Data Scientists.\\n \\nYou were at Intuit before people started calling themselves data scientists, right?\\n \\nThat’s right. And it’s been a fascinating journey.\\nAlong with the rest of the world, over the past five years Intuit has dramatically evolved \\nits thinking regarding the applications of big data and advanced analytics. Five years \\nago, the focus was entirely on marketing optimization. Then, starting about three years \\nago, the scope increased to include improving the user experience by analyzing how \\nusers are interacting with our products. Now, the focus is squarely on leveraging big data \\nand advanced analytics to create new products that solve important problems for our \\ncustomers. Our unique aim is to deliver “ Big Data for the Little Guy , which empowers \\nindividuals and small businesses by allowing them to benefit from the power of their \\nown data as well as the collective wisdom of millions of fellow Intuit customers. This \\nmeans that small businesses now have access to insights that were once only available \\nto big, multi-million dollar companies, and enables consumers to put their own data \\nback to work for them.\\nYou worked at Intuit before there was a lot of hype and discussion about this term \\n“data science”. As someone who’s been in this field for awhile, what are the myths'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 121}, page_content='GEORGE ROUMELIOTIS\\n117\\nand what are the truths when people talk about big data and data science?\\n \\nYou might have heard the joke, “What is a Data Scientist?” The punchline is, “ A Data \\nScientist is a data analyst, who just happens to live in California.” I think the hype \\nwill go away, but Data Science will be a permanent feature of the business landscape. \\nData Science is its own unique discipline, combining elements of applied mathematics, \\ncomputer science, business consulting, and, increasingly, new product development. I \\nconsider a good Data Scientist to be \\nlike a Swiss army knife, competent \\nacross all these areas, with deep \\nexpertise in one or two of them.\\nMore specifically, the technical \\ntable stakes for a Data Scientist \\nare advanced statistics, machine \\nlearning, SQL and Hadoop, and a mainstream programming language like Java. So there’s \\na combination of applied mathematics and computer science. But of equal importance \\nare business consulting skills. These are often overlooked, or added as an afterthought, \\nbut they are critical. Business consulting skills can be the difference between a Data \\nScientist and a Data “Gopher”.\\nA Data Gopher is someone who responds to incoming requests for analyzing this or that, \\nbut who never has a seat at the table when the business decisions are being made. On \\nthe other hand, a Data Scientist with business consulting skills is like a senior McKinsey \\nconsultant, who can translate fluently between business and technical domains, and \\nwho is a trusted advisor to business leaders. Those are highly non-trivial skills.\\n \\nWhen you talked about skills required in data science, you talked about three things: \\nclassical statistics or machine learning, computer science and business consulting \\nskills. What suggestions would you make to someone looking to build those skills?\\n \\nIn terms of database skills, it is essential to feel completely comfortable with SQL and \\nHadoop. If you are still on campus, for goodness sakes take advantage of that by signing \\nup for relevant basic courses that include a major project component. \\nIn terms of programming skills, learning R is very important. It is kind of ugly, but it is \\nthe lingua franca. Personally, I would stay away from proprietary, commercial statistical \\nprogramming languages. You know the ones I’m talking about. And certainly you need \\nto learn a mainstream programming language like Java or C++. Learning a mainstream \\nscripting language like Python or Perl also comes in handy.\\nI consider a good Data Scientist to be like a \\nSwiss army knife, competent across all these \\nareas, with deep expertise in one or two of \\nthem.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 122}, page_content='GEORGE ROUMELIOTIS\\n118\\nIf I had to assign a weight to help someone prioritize all this learning, it would look \\nsomething like this:\\nSQL      40%\\nHadoop     30%\\nR      1 5 %\\nMainstream programming language 10%\\nMainstream scripting language   5%\\nIn terms of acquiring business skills, you have \\nto get creative. At Stanford there was a fabulous \\nentrepreneurship course tailored to engineers and \\nscientists. Simply listening to lots of entrepreneurs \\ntell their story is very helpful. Subscribe to The \\nHarvard Business Review.  Talk your way into a \\nchallenging internship that presents you with an open-ended problem. Above all, just \\nstart an online business. It doesn’t need to be the next Google. Give yourself the challenge \\nof starting with $100 and seeing how much you can make it grow in a month. That can \\nbe quite eye-opening. Don’t become a Data Scientist who has never operated as much as \\na lemonade stand.\\n \\nYou have a very unconventional experience in that you left your postdoctorate \\nposition to found companies. Not only did transition from a postdoctorate to a \\nbusiness environment, but you jumped into the deep end and decided to start your \\nown company. What types of thinking did you feel like you benefited from during \\nyour experience in academia and what are the things that you felt were hindrances \\nto you when you entered the business world?\\n \\nHaving the foundation of applied mathematics was extremely useful, because then I \\ncould pick up other math-based bodies of knowledge very easily. On the Ph.D. side, I \\nmainly learned persistence.\\n \\nWhat certainly didn’t help me, and what I had to unlearn, was how academics present \\ntheir results to others. As academics, we’re trained to take an axiomatic approach. “Here \\nat the start of the presentation are my axioms, and here in the middle are the detailed steps \\nthat I took, and then here at the very end are my results. ” But if you do that in a business \\nmeeting, and you hand out copies of your slides beforehand, you’ll observe that the first \\nthing the business leaders do is flip to the back of the deck to see your conclusions. They \\njust don’t care about the detailed reasoning, because that is your job, not theirs. I have \\nfound it much more effective to start with “the bottom line up front” and then show the \\nthought process if there are questions. This is a very different mindset from academia. \\n \\nDon’t become a Data Scientist \\nwho has never operated as \\nmuch as a lemonade stand.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 123}, page_content='GEORGE ROUMELIOTIS\\n119\\nAlso, in academia you get kudos and endorphins from doing something novel. But in \\nbusiness it’s all about the efficiency with which the company can transform money into \\nmore money. So a Data Scientist needs to resist the impulse to solve problems ab initio, \\nor to spend time going from the 80% percent solution to the 90% solution. That effort \\nsometimes doesn’t make much business sense. You’ve got to think about allocating your \\ntime as though you were the owner of the business.\\n \\nIntuit is a very data-centric and financial-centric company.You didn’t start out in \\na business context, so what framework do you use to evaluate the success of \\npotential ideas at Intuit?\\n \\nThe way I look at business has definitely evolved, \\nespecially from being at Intuit. I’ve learned to \\ntake a hypothesis-driven, experimental approach \\nto developing solutions to business problems. We \\nshould all feel passionate about the problems we \\nare solving, but we must not fall in love with our \\nsolutions. We design experiments to let the customers choose between Solution A and \\nSolution B, rather than that choice being made by “the loudest voice in the room.” That’s \\na mistake I made in start-ups, and one that I saw a lot of other people make as well. We \\nwere all convinced that of course we knew what the market wanted, and we proceeded \\nto spend a lot of time building it. The way I work now, and the way I would have advised \\nmy younger self to work, is to create minimalist prototypes and test them out on real \\ncustomers. Don’t fall in love with your own ideas. Market feedback is the only thing that \\nmatters. You’ve got to do experiments, and you’ve got to be ruthless about changing \\nyour ideas based on the results of those experiments.\\n \\nWe’ve interviewed people who have recently made the transition to data science, \\nbut as someone who’s seen the growth and development of younger data scientists, \\nwhat are some of the mistakes often made by younger hires?\\n \\nFirst, you have to proactively build relationships with your non-technical colleagues. \\nData Scientists are often by temperament introverts, but if you want to be effective and \\nsuccessful, you need to step outside that comfort zone. Email a non-technical colleague \\nyou’ve never met, and ask them to lunch. Make it your responsibility to form such \\nrelationships before you need them.\\nNext, practice viewing the world in terms of business processes. What’s a business \\nprocess? It’s a foreign concept to many new Data Scientists coming directly from \\nacademia. A business process encompasses the people, systems and steps involved in a \\nbusiness activity. Generally speaking, a Data Science project has the goal of improving \\nDon’t fall in love with your own \\nideas. Market feedback is the \\nonly thing that matters.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 124}, page_content='GEORGE ROUMELIOTIS\\n120\\nsome existing business process. The truth is, it’s really difficult to change a business \\nprocess. \\nFor example, it took me a long time to grasp that improving the efficiency of a business \\nprocess might actually be perceived as threatening to someone’s job, and the natural \\nreaction of that person might be to consciously or unconsciously undermine any progress. \\nSo you have to develop deep empathy for the people involved in business processes, and \\ncreate solutions that help those people transition to higher-value work. That sounds like \\na lot of responsibility for a Data Scientist, but if you don’t think about things like that, \\nyour ideas might never be implemented in the real world.\\n \\nBeyond these three attributes, what does it take to be a successful data scientist, \\nin your opinion?\\n \\nA successful Data Scientist changes \\nthe world around them. It comes \\ndown to mindset. One mindset is that \\nyour responsibilities are to analyze a \\nsituation, construct a solution, and then \\npass along that solution to others for \\nimplementation. But that is a recipe for \\nfrustration for anyone who is interested \\nin moving the needle in the real world. A \\nbetter mindset is to think of yourself as \\nthe business owner who is responsible for changing how the business works. That’s a \\nwhole different mindset, one of taking ownership for how your ideas are going to be \\nimplemented and measured. The additional skill you need is influence without power. \\nHow do you influence others to move forward with your recommendations when they \\ndon’t report to you?\\n \\nHow do you influence others without power?\\n \\nIt is not easy, that’s for sure.\\nAs I said earlier, it starts with being proactive in forming relationships with your non-\\ntechnical colleagues, because people want to work with those they know and like.\\nIt is also important to go for small wins before trying to hit the ball out of the park. Small \\nwins prove that you are a reliable partner.\\nAnd you have to make the connection between your recommendations and the bottom \\nIt took me a long time to grasp that \\nimproving the efficiency of a business \\nprocess might actually be perceived as \\nthreatening to someone’s job, and the \\nnatural reaction of that person might \\nbe to consciously or unconsciously \\nundermine any progress.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 125}, page_content='GEORGE ROUMELIOTIS\\n121\\nline. Yes, that’s often very hard. There are usually many links in the chain between your \\nwork as a Data Scientist and the outcome for the business. But nobody else will do that \\nanalysis if you don’t. It goes back to having the mindset of the business owner.\\nWhen you’re looking for data scientists, do you feel there is a necessity for having \\nany form of senior academic credentials? A lot of the data scientists we’re seeing \\nnow have a Ph.D. background, but do you think this trend will continue into the \\nfuture?\\n \\nBack in the day, when relational \\ndatabases were brand new to the \\nworld, the folks who were most \\ncomfortable with that technology \\nwere at IBM Research. It is not \\nsurprising that the first relational \\ndatabase experts in industry had \\nPh.Ds, but over time the barrier to \\nentry has obviously been reduced. Data Science might be like that. Maybe. On the other \\nhand, Data Science might be more like brain surgery than SQL. I think it is too early to \\ntell. The well-rounded Data Scientist is competent in applied mathematics, computer \\nscience and business. Such people don’t exactly grow on trees. \\n \\nWhat distinguishes a data scientist from someone who works as a data analyst \\nin a traditional business intelligence role, or a statistician with programming \\nknowledge? How deep do these distinctions go?\\n \\nStatisticians might be steeped in mathematical tools for inference and prediction, but \\nthat alone is not going to make them an effective Data Scientist. They also need to be \\ncompletely self-sufficient in extracting and manipulating large data sets that are usually \\nfound in legacy systems, and which are often a noisy mess. They need SQL, NoSQL, and \\nprogramming skills to do that. And even if they have all the programming skills, but \\nthey don’t have superb consultative skills, they will have very limited influence. I think \\na Data Scientist is a very different animal from a statistician. But that’s just my opinion. \\nI’m not interested in getting into a religious argument about what constitutes a “real” \\nData Scientist.\\n \\nYou were the CTO of the first startup you founded and that seems to suggest \\nthat in addition to being an excellent physicist, you’re also quite skilled at building \\nsystems that provided software solutions built off your interests in image processing \\nor scheduling. Were those programming skills something you picked up during the \\ncourse of your graduate degree or was that more born out of need?\\n \\nIt is not surprising that the first relational \\ndatabase experts in industry had Ph.Ds, but \\nover time the barrier to entry has obviously \\nbeen reduced. Data Science might be like \\nthat.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 126}, page_content='GEORGE ROUMELIOTIS\\n122\\nI found that software engineering courses at Stanford taught you how to write a program, \\nbut they did not necessarily teach you how to work in teams, or with diverse systems that \\nyou have to integrate. And they did not teach you how to build, deploy and maintain \\ncomplex software. All that relates to project management and people skills which are \\nusually not addressed in computer science programs. So I learned those skills via trial \\nand error. Lots of error!\\nI acquired software engineering skills by actually building the Version 1 solutions at the \\ntwo startups I co-founded. I think it’s very hard for Data Scientists to work effectively \\nwith software engineers if they haven’t done any software engineering themselves. I \\ndon’t think a Data Scientist necessarily needs to be a production software engineer, which \\nis a different mindset yet again. But basic fluency — knowing how to write, document \\nand test code, and how to create components that are used in larger systems, that’s \\nimportant.\\n \\nWhere do you think data science is headed?\\n \\nI think we are going to see an explosion \\nof both consumer and enterprise \\nproducts that are made possible by \\nData Science — that is, by the creative \\nmelding of big data and advanced \\nanalytics. To achieve that, some \\nData Scientists will need to become \\nproduct designers, adding the skill of “design thinking” to their toolbox. Deep customer \\nempathy, rapid iterative prototyping, and in-market experimentation will be essential to \\nthis emerging sub-type of Data Scientist. Or maybe we’ll need a new name. Data Product \\nDesigner, anyone?\\nI don’t think a Data Scientist needs to be \\na production software engineer, which is \\na different mindset yet again. But basic \\nfluency ... that’s important.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 127}, page_content='DIANE WU Data Scientist at Palantir\\nTo start off with, how did you get started in data science?\\n \\nI did my undergrad in computer science and became interested in biological problems, so \\nI transitioned to bioinformatics and did a PhD in (Computational) Genetics at Stanford. \\nWhile I was there, I started taking classes in the CS department, in part out of interest \\ndue to my CS background, in part because I loved interdisciplinary approaches, but also \\nbecause these were rumored to be the most challenging classes.\\n \\nI took Machine Learning with Andrew Ng, Probabilistic Graphical Models with Daphne \\nKoller, Data Visualization with Jeff Heer, and Mining Massive Data Sets with Jure \\nLeskovec. I took these out of interest and because I thought they would be applicable to \\nwhat I was doing; sequencing and essentially going through terabytes of DNA sequences \\nto make sense of them. I was doing a lot of time series clustering, predictive modeling, \\nand building Bayesian models. I took these courses because I thought they would be \\nrelevant to my research, but what I didn’t realize through the entire process was that I \\nwas basically doing data science in biology.\\n \\nWhen I finished my PhD and decided I didn’t want to be in academia, I stumbled across \\nthe Insight Data Science program, specifically designed for helping PhDs transition into \\nWhile studying computer science at Simon Fraser \\nUniversity, in Canada, Diane became interested in biology. \\nAfter graduating, she began a PhD in genetics at Stanford \\nUniversity, where she also dabbled in courses in computer \\nscience and machine learning. Diane’s background in \\ngenetics naturally prepared her to working with large \\nvolumes of data, leading her to realize that the work she \\nengaged in at Stanford naturally belonged in the realm of \\ndata science.\\nAfter graduating, Diane became part of the Insight Data \\nScience Fellowship program where, as a Fellowship project, \\nshe built recipe searching site that used clustering to organize recipes by ingredients.\\nWhen we interviewed Diane, she was a data scientist at Palantir. She has since started a \\nnew role as a Senior Data Scientist at MetaMind.\\nThe Interplay Between Science, Engineering and Data \\nScience'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 128}, page_content='DIANE WU\\n124DIANE WU 124\\nindustry. Through this program, I realized that most of the training through my PhD was \\nessentially just data science. So the transition for me was very natural. I’m doing a lot of \\nthe same things, just not thinking about cells or biology! However, the same tools and \\nchallenges apply.\\n \\nSo after bridging this gap, where are you as a data scientist right now?\\nI work as a data scientist at Palantir — a \\ncompany that builds a platform that helps \\nintegrate data for our customers from the \\nmultiple disparate databases that they have, \\nand makes associations and inferences from \\nthese data. We work with customers from the financial sector, the medical space, \\ngovernment and local law enforcement. One of my jobs as a data scientist at Palantir is \\nto help create value out of their data and identify a human-computer symbiotic approach \\nto machine learning.\\n \\nGiven that you’re working with these large institutions, what is the scale of the \\nproblems you’re tackling?\\nThere’s a wide range. Some of our customers have hundreds of terabytes of data and \\nsome have a few megabytes. Some customers require a streaming solution while others \\nwant a static model based off all the information in their databases. The number of \\ndatabases we work with can also vary between one to many dozens.\\n \\nHaving worked as a data scientist for a while, what would you say are the main \\nresponsibilities and goals of data scientists at Palantir?\\nData science itself is a very strange term. It’s an umbrella term. In some companies and \\nin some roles, being a data scientist means to be a software engineer, building machine \\nlearning models in the back end. In this role, your success is very measurable--it is usually \\nthe accuracy or precision/recall of your model performance. At other companies or in \\nother roles, being a data scientist means that you’re an analyst working with engineers \\nto help them determine what features to build and how users are interacting with them. \\nIn this role, your success is less measurable, and it is up to you to find the right questions \\nto answer and then to try to make impact with that answer.\\nAt Palantir, we work with customers from a diverse number of sectors, with a wide \\nspectrum of problems that we solve by deploying our platforms against their data. One of \\nour core company missions is to pick incredibly difficult problems at institutions where \\nwe would provide the most value, and put our full force into solving these problems. \\nData science itself is a very strange \\nterm. It’s an umbrella term.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 129}, page_content='DIANE WU\\n125\\nSometimes, this means developing new capabilities in the platform. Sometimes these \\ncapabilities require data science techniques (machine learning, statistics, mathematical \\nmodeling), and that’s where we come in. I’m on the machine learning team at Palantir, \\nand we’re dedicated to enabling customer data science needs via our products. To this \\nend, we work closely with customers to help them scope their problems and turn an \\noften poorly defined, qualitative problem into a quantitative one. The process involves \\nidentifying an actionable goal or desired insight, evaluating the form, scale, reliability \\nand availability of the data, and building custom machine learning algorithms to solve \\nthe problem. And then we iterate. Always iterate.\\n \\nSome requests we get involve translating from qualitative problems to quantitative \\nones (identifying good proxy metrics to reach the right conclusion), statistics (doing \\nthe calculation on the data), and communication (presenting the data in a digestible \\nmanner). In most cases, however, our customers are requesting a predictive analytics \\napproach to a specific type of problem. They present a very difficult problem where a \\npredictive modeling component may be needed. Fraud detection is one of those problems, \\nfor example. It is clear that a computational algorithm could aid fraud detection by \\nidentifying patterns and outliers, but the problem is complex enough that it will likely \\nalways involve a strong human component. In such cases, it is not clear how we should \\nbreak up the tasks between the human and the computer. One of Palantir’s core values \\nis human-computer-symbiosis: let the computer do what it does best (crunch models, \\ncalculate metrics, etc.) and let the humans do what they do best (interpret patterns and \\nmeaning, make accountable decisions, especially with respect to the rights and well-\\nbeing of other humans). One of the overarching goals of our team is to figure out what \\nan ideal predictive analytical solution should look like and where on the spectrum it \\nshould lie.\\n \\nFinally, we also do data science internally, and often want to use product metrics to \\ninform business decisions. Engineers like to build cool things. It’s not intuitive to them \\nto think about things in a scientific way. I think that’s one of the reasons books on lean \\nproduct development are so popular. It’s because these are not intuitive concepts for \\nengineers. The role of a data scientist is to do the stuff that is a pain for engineers (but \\nfun for us), and help engineers make more data driven product development decisions.\\n \\nIt sounds like data scientists are evangelizing the scientific method to engineers!\\nIn a way, I guess that’s true. It’s intuitive to me to think in the scientific mindset because \\nI’ve been trained as a scientist for the past 4 years. It’s very natural for a scientist to ask \\nwhy, to dive into a problem, scope the hypothesis landscape and then perform tests. \\nHowever, scientific thinking is a double-edged sword, and is in some ways the opposite \\nof the engineer mentality. Scientists ask why something is the way it is before reaching \\na conclusion, while engineers execute on assumptions and watch to see if things break.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 130}, page_content='DIANE WU\\n126\\nOne of the hardest things in recruiting for data scientists is to find candidates who have \\nthe right balance of both scientific and engineering mentality. Almost always, with real \\nworld problems, there is no time to ask why and figure everything out before executing, \\nand you often have to act with incomplete knowledge. However, engineering without \\ndata science is like building a bridge without ever fail testing it. There is a delicate \\nbalance to be struck.\\n \\nWhat are some challenges and some of the things you’ve found easy in making the \\ntransition from PhD to Data Science?\\nThe reason why programs like Insight have been successful is because PhDs have been \\ntrained with a quantitative method of thinking. They’re also prone to ask “why” and \\n“how” rather than “what”. I think that most PhDs understand the presence of errors, and \\nhow to reduce a complex problem to a smaller problem with a quantifiable solution.\\n \\nOn the other hand, PhDs \\nare often stereotyped to \\nask “why” too often and \\nare sometimes caricatured \\nto have their heads in the \\nclouds. So if I find a PhD who \\nis also a hacker, then it is the \\nbest of both worlds. Indeed, \\nsome of the most effective \\ndata scientists I’ve seen have \\nbeen PhDs who worked on a number of side coding projects during their academic career.\\n \\nThe challenge for a lot of people is the ability to apply these insights into value. Not all \\ninteresting problems can produce insights, and not all interesting insights can inspire \\naction that causes change.\\n \\nDid you have any challenge in communicating your value as a data scientist?\\n \\nWhat I have learned in working with many different customers is that when people \\nrequest data science, they really just want magic. They want you to use all the data to \\npredict everything. When they approach data science, they often don’t actually know \\nwhat they want.\\n \\nThat’s the thing about being a data scientist in this time. It’s so new and sort of overhyped, \\nthat most people just know they want in on the excitement but don’t know how. They \\nwant things, but they have no true idea about what they want.\\n \\nOne of Palantir’s core values is human-computer-\\nsymbiosis: let the computer do what it does best \\n(crunch models, calculate metrics, etc.) and let the \\nhumans do what they do best (interpret patterns and \\nmeaning, make accountable decisions, especially \\nwith respect to the rights and well-being of other \\nhumans).'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 131}, page_content='DIANE WU\\n127\\nPart of the job is really use-case discovery. It’s not always about crunching the right \\nalgorithm. It’s about asking the right questions and framing the questions for yourself. \\nAnd once you do that, the problems tend not to be statistically or algorithmically hard.\\n \\nOn the other hand, there are people who think it’s overhyped and want you to prove that \\ndata science is worth their investment.\\n \\nSo in your experience, what distinguishes the best data scientists from the rest?\\n \\nThat’s a very good question. \\nThere are statisticians and there are computer scientists and designers. And then, there \\nare people who are very good at all of these things. The reason why this role — data \\nscientist — was created, and the reason why it’s a little bit undefined, is that it requires \\nthat you’re good at many different things. You have to think about problems, both as an \\nengineer and also as a statistician. You have to know what tests are right, how to approach \\nthe problem, how to engineer the solution and how to sift through large datasets.\\n \\nAnd then afterwards, you have to present your findings in a clear way. This might require \\nyou to create visualizations. Having an understanding of graphic theory and the language \\nof visualization is useful. This ties into communication because as a data scientist you’re \\ncommunicating with someone who doesn’t have a ton of time to analyze data. They look \\nat the figure and want to be able to extract meaning from it in a few minutes.\\n  \\nFinding someone who’s a good engineer and a good communicator is incredibly difficult. \\nYou don’t need to be the best at everything, but some people who are great communicators \\nneed to learn how to be great engineers and vice versa.\\n \\nIn academia, there’s a focus on open-ended problems. How have you made the \\ntransition to industry where there’s an environment to deliver on prompt deadlines?\\n \\nI think in an ideal world there should be a fusion of the two. In academia, it behooves one \\nto work with deadlines; most PhD students would probably tell you that if it weren’t for \\npublication deadlines and the fear of being scooped, we might never publish. Open-ended \\nproblems need to be scoped also, and often a 20% solution will get you 80% towards your \\ngoal. In industry, sometimes people can get too “hacky” and deliver v1 solutions all the \\ntime, and that can be bad too. Sometimes it’s good to step back and try our hand at some \\ncrazy ideas. I think that’s the inspiration behind company internal hackathons and why \\nthey’re so popular in the tech industry.\\n \\nWhat skills beyond what you’ve already mentioned (hypothesis testing, \\ncommunication) would you recommend to someone interested in data science?'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 132}, page_content='DIANE WU\\n128\\nIt’s about asking the right questions and \\nframing the questions for yourself. And \\nonce you do that, the problems tend not to \\nbe statistically or algorithmically hard.\\nAs a preface, I think the skills you need to learn largely depend on what you want to do.\\n \\nI would put this into three categories:\\n1. Predictive Modeling: here, algorithms and some complex mathematical modeling \\nare required. Visualizations are probably not as heavily emphasized.\\n2. Business Intelligence: here you engage frequently with SQL and some scripting, but \\nyou don’t need great skills in computations and algorithms.\\n3. This is a spot in the middle: this is more science-y and R&D. Here you want to ask \\nmuch deeper questions about user behavior. You want to model user interactions and \\napply computational algorithms to gain business insights. This is a mesh between \\ntwo extremes. You need some computational background, and some aspects of \\ncommunication, etc.\\nBut ultimately, to answer this question requires you to think about what type of job you \\nwant, and realizing that you can’t be qualified for everything. You have to pick your best \\nshot and hone your skills there.\\n \\nBuilding off of that, what have you found to be useful in building those skills and \\nunderstanding which position you want to pursue?\\n \\nTalking to people is important. I don’t mean that in the way of networking, but in the \\nway of understanding what people are looking for. Insight Data Science brought me a lot \\nin this direction.\\n \\nLooking at folks who have moved \\ninto data science, I’ve noticed that \\nthe Coursera course by Andrew Ng \\nhas been very popular. This ties into \\nthe general skill of being driven \\nenough to simply pick up books and \\nstart learning. A lot of aspiring data \\nscientists also play around with some Kaggle competitions to get their hands on real \\ndata and practice their engineering and analytical skills.\\n \\nIn fact, most data scientists I know are self-motivated, they’ve taught themselves the \\nrelevant tools and skills to help them manipulate and understand data. In my opinion, \\nit doesn’t take that long to learn these skills. So if you pick up these things after work, I \\nthink you can take advantage of the large demand right now in data science.\\n \\nKevin Novak, another data scientist we spoke with at Uber, believes that we’re at \\nthe tip of the tip of the iceberg when it comes to data science. Do you agree with'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 133}, page_content='DIANE WU\\n129\\nthat? And if so, what are the exciting and promising things on the horizon of data \\nscience?\\nI agree with that. I think that data science is largely undefined. Being a data scientist in \\nthis time is exciting because you have a lot of potential to define what data science is \\nfor the next 10 years. What’s exciting is being able to explore this frontier. You’re also \\nlearning a great deal about very different fields intersecting with each other. I really like \\nthis position because I’m learning so much and I’m not just honing one skill.\\nI’ll predict that in 10 years we’ll use more defined terms than data science because people \\nwill realize what it is that they’re looking for (analysts vs. predictive modelers).\\n \\nAre there any final thoughts or parting feedback you’d give to someone just getting \\ninto the field right now?\\n \\nDon’t be afraid!\\n \\nMarch forward and learn what you have to learn. Many people who come into data science \\nare overwhelmed. They look at the list of ”requirements” and think that because they’re \\nnot a wizard at engineering, or a statistician and a visualizer, that they’re not qualified.\\n \\nI think they shouldn’t underestimate themselves. I think you should approach things in \\nthe T-Shaped model, where you accumulate a great deal of breadth and a concentration \\nin one skill that gives you depth.\\n \\nSo be confident and pick up skills; you’ll be surprised at how much value you can add \\nimmediately.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 134}, page_content='JACE KOHLMEIER \\nDean of Data Science at Khan Academy\\nYou’re currently the Dean of Data Science at Khan Academy. What is your background \\nand experience up to this point?\\n \\nI was a math and computer science dual major in undergraduate school, and I also did a \\ncouple of internships in the software industry. I then entered a PhD program in computer \\nscience at Princeton, where I intended to focus on theoretical computer science.\\n \\nBut that was about 1999 and it was at the height of the Dot-Com hysteria. At Princeton, I \\nmet some people involved in the startup space and decided to take academic leave after \\nonly one semester. I went to an incubator in New York to start a software company. The \\nventure ultimately didn’t turn out to be commercially successful, but after experiencing \\nthe entrepreneurial process, I learned something tremendously valuable — I learned \\nthat entrepreneurship was more appealing to me than working on theorems for five to \\nsix years.\\n \\nAs an undergraduate student in Kansas, Jace wasn’t \\nexposed to the ins-and-outs of high-powered finance. Little \\ndid he know that within a few years of graduating, he’d be \\nworking at one of the largest hedge funds in the world.\\nAfter receiving degrees in math and computer science, Jace \\nwent off to Princeton for a PhD in theoretical computer \\nscience. There, he was lured into the startup space at \\nthe height of the 1999 bubble, where he learned that he \\npreferred the entrepreneurial process to proving theorems. \\nAfter leaving Princeton, Jace joined Citadel, where he \\nworked for 7 years before starting his own trading firm.\\nHis time in finance incubated an idea of “high frequency education.” After leaving the world \\nof trading, Jace looked towards a different field: education. After hearing Salman Khan’s \\nTED talk, Jace felt compelled by Sal’s vision and joined the Khan Academy as the Dean of \\nData Science.\\nFrom High Frequency Trading to Powering \\nPersonalized Education'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 135}, page_content='JACE KOHLMEIER\\n131\\nWhat were some of the key differences between your computer science graduate \\nstudies and the accelerator? What did you find that changed your mind about \\nindustry versus academia?\\n \\nThe question should be: “Why the heck did I ever think grad school was right for me?” \\nBecause in retrospect, grad school, or specifically PhD studies in grad school, were wrong \\nfor me in just about every way. I had always been pretty commercial. I got my first job as \\na programmer when I was fifteen. I’ve always loved markets. When I was a boy, I scoured \\nmy monthly baseball card price guides with great enthusiasm. And while I do love math, \\nmy experience in grad school was fairly solitary. I found it to be mostly time spent with \\nmy head in a book, sitting in a library or literally in a windowless basement trying to \\nprove math theorems. \\nIt was lonely and slow and felt kind of devoid of any exciting risk. My experience in \\nNew York was just the opposite. It appealed to my commercial senses and I loved the \\nintensity and time frame of trying to get software shipped or a product developed before \\nthe money ran out. I enjoyed the camaraderie and the teamwork, and basically just felt \\nfar more excited and alive.\\n \\nSo what did you do with these realizations after the incubator in New York?\\n \\nWhat I chose to do was to go back \\nand finish my Master’s degree \\nat Princeton and then look for \\nsomething more commercial. \\nLiving in New York had given me \\nopportunity to meet some people \\nin quantitative finance, which up \\nuntil then I didn’t understand or even know existed. As a kid from Kansas, I had no idea \\nthat people were combining math and computer science in awesome ways and applying \\nit to finance.\\n \\nThis is something that really opened my eyes. Rather than trying to work at the very \\ndepths of one particular subject, like computational complexity, quantitative finance \\nseemed like the combination of all three of my main interests--the market, computer \\nscience, and math. The chance to take three of my loves and package them perfectly into \\na professionally rewarding space was a no-brainer for me.\\n \\nI went back to Princeton and through on-campus recruiting, landed a job at Citadel — \\none of the world’s largest hedge funds.\\n \\nFor years when I was working in finance, I’d \\nbeen fostering an idea about “high frequency \\neducation,” of using rapid feedback loops to \\ntest educational content and pedagogy.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 136}, page_content='JACE KOHLMEIER\\n132\\nWas that your first full-time job? What was that like at Citadel?\\n \\nI joined Citadel as my first full time job out of college. I had a good experience there and \\nafter about 2-3 years, a few other people and I started a new business within Citadel that \\ncentered on high frequency trading. We traded a range of securities via sophisticated \\nstatistical models and algorithms. That internal group turned out to be very successful, \\nand after 7 years at Citadel, I was able to start another trading firm with a partner.\\n \\nGiven that Citadel was your first full-time role after college, how did you approach \\nlearning new things in quantitative finance?\\n \\nMy job at Citadel was probably the \\nfirst time that I really needed and \\nwanted to learn about how to build \\nempirical models. That was not \\nsomething that I had ever really \\nstudied in school. Maybe in passing \\nI came across a regression model in \\na statistics class, but basically, I was \\nstarting from scratch at Citadel. My \\napproach — which may not have been optimal — was to start reading books. Sadly, there \\nwere not the great online resources that exist today, which is what I would now advise. \\nI read books and I tried to pick the brains people around me that were doing the quality \\nof work that I wanted to do. I hung off of every word that they would tell me or give me \\nin terms of mentorship, which I sought. There’s no doubt that my most essential lessons, \\nfor both hard and soft skills, were learned from my mentors.\\n \\nSo how did you eventually end up turning to education?\\n \\nAfter co-founding a trading firm, I decided to seek another challenge and at that point, \\nI was looking for something different. Education was something that I had always been \\ninterested in and it also runs in my blood. My father was a high school teacher; my sister \\nwas a high school teacher and is now a professor of education. For years when I was \\nworking in finance, I’d been fostering an idea about “high frequency education,” of using \\nrapid feedback loops to test educational content and pedagogy. \\nSo that was a pet vision of mine; how we could port key ideas I had used within high \\nfrequency trading to education? As I was looking for what I wanted to do next, I explored \\nvarious options. I even volunteered in a Chicago South Side school and took the exam to \\nbecome certified as a teacher in Illinois. But when I came across Sal Khan’s TED talk in \\n2011 where he was describing a system of exercises and videos to optimize education, I \\nwas interested right away.\\n \\nThe coding side of it pervades all of this work. \\nThe faster you can code, the faster you can \\nimplement ideas. If you have a good sense of \\nbuilding systems, you can scale what started \\nout as a research project into something \\noperational.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 137}, page_content='JACE KOHLMEIER\\n133\\nLet’s talk about the questions that you attack at Khan Academy. What are the \\nalgorithms and problems like? How do you measure improvements to learning \\nfrom Khan Academy’s platform?\\n \\nOftentimes, we know the thing that we want to measure and so we can apply statistical \\ntechniques to try to measure it very efficiently. Occasionally, we ask the user a question \\nfrom a distribution that we control, but there are costs to that because the question we \\nwant to ask may not be what the individual wants to learn. So combining knowledge \\nfrom information theory or graphical modelling, we can treat the answers as evidence \\nand try to elicit the most information for a minimum cost to the user. This approach \\nrequires that you are fairly conversant with quantitative techniques.\\n \\nThe coding side of it pervades all of this work. The faster you can code, the faster you \\ncan implement ideas. If you have a good sense of building systems, you can scale what \\nstarted out as a research project into something operational. We can work much faster if \\nwe are data scientists and engineers. We can build algorithms and models right into the \\nproduct, but that obviously requires that we be competent in the product’s engineering.\\n \\nOf the people whom have applied for a data science role at Khan, what really \\nstands out to you as being fundamentally core skills and what are the skills which \\ncan be learned on the job?\\n \\nThe hardest thing to teach on the job is a \\nstrong quantitative aptitude. Most people \\nwho apply would probably rank highly in that \\nregard. They’ve been studying mathematics \\nsince they were 5 or 6 years old, and continuing \\nthrough college, so it’s taken a long time for \\nthem to build up their knowledge base. These \\nquantitative skills are definitely the hardest to \\npick up on-the-fly given the amount of time that needs to be invested, but I also don’t \\nthink that picking it up on the job is impossible. \\nWe have developers or other quantitative scientists who may not think of themselves \\nas being experts in machine learning, but who are clearly very technically minded and \\nsharp. So, I don’t mean to say it’s impossible to learn quantitative aspects on the job, but \\nsimply it is the hardest thing to pick up on the fly.\\n \\nSomewhat similar is coding experience, which is a productivity gauge. If you’re 30% \\nslower at coding, you have less time to focus on other aspects and your productivity will \\ngo down. We look for fluency in coding.\\nAs we built our team, I became \\nincreasingly skeptical of finding \\nthe perfect data science “unicorn” \\n— someone that is world class in \\nall of these categories.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 138}, page_content='JACE KOHLMEIER\\n134\\nThe hardest thing to pick up when interviewing candidates is a person’s aptitude for \\nexperiment design (model design) and how these experimental outcomes will impact \\nyour organization. We’ve experimented with bringing people in for on-site interviews \\ninvolving projects. Another initiative we have tried is to put candidates through \\ncollaborative exercises as well.\\n \\nAs we built our team, I became increasingly skeptical of finding the perfect data science \\n“unicorn”— someone that is world class in all of these categories. By definition there are \\nvery few people who are world class in even one of those dimensions, and they are in \\nextraordinarily high demand. So you really want to put together a team similar to the way \\na GM puts together a professional basketball or baseball team. There are fundamental \\nskills that all players share, but the GM puts together a team of complementary members \\nthat specialize in position or area. More and more, that’s the way I think about building \\na data science team.\\n \\nGiven that the background of the ideal data scientist you’re describing implies a deep \\nexpertise within some fields, do you find that the people who are predominantly \\ntrained in these areas come from advanced degrees?\\n \\nI think of team as an ensemble of \\nspecializations. I have seen a PhD \\nexperience be both a benefit or a \\ndrawback in a couple of ways. I’ve seen \\na PhD be a benefit when a candidate \\nor employee has really learned to \\nindependently find their path through \\na nebulously defined problem, or to \\nbe able to craft experiments to get to \\na result that’s going to meaningfully \\nanswer pertinent questions. \\nFor some people, it’s very clear that their PhD led them to develop that skill. On the \\nother hand, some people’s PhD experiences left their pragmatism atrophied. At Khan \\nAcademy, there are no medals or ceremonies if we publish a beautiful research paper. \\nWhat we really want to do is deliver demonstrable value to people trying to learn. A \\ncritical skill for a data scientist is knowing how one’s work fits within a team, and where \\nyour team sits within the concentric circles of an organization. In some cases that can be \\na skill that may have atrophied for someone who comes from a doctoral setting.\\n \\nYou’ve mentioned the importance of programming several times now — for aspiring \\ndata scientists who come from a strong quantitative research field, some might not \\nAt Khan Academy, there are no medals \\nor ceremonies if we publish a beautiful \\nresearch paper. What we really want to do is \\ndeliver demonstrable value to people trying \\nto learn. A critical skill for a data scientist \\nis knowing how one’s work fits within a \\nteam, and where your team sits within the \\nconcentric circles of an organization.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 139}, page_content='JACE KOHLMEIER\\n135\\nhave spent so much time with software engineering. What are some ways for them \\nto increase their programming skills?\\n \\nIn my opinion, to be a great data scientist, you must be a great (or at least a very \\nproductive) programmer. That doesn’t mean that you have to be a savant in computer \\nscience, it just means that you have to be fluent with code and experienced in building \\nreal systems. \\nWhat I would suggest for someone \\nwho’s looking to build skills in \\nthose areas is, number one, you \\njust have to write code and you \\nhave to write a lot of it. There will \\nalways be differences between a \\nfirst year programmer, a fifth year \\nprogrammer, and a tenth year \\nprogrammer, at least for people \\nwho spent those years practicing the right way. The hack to get better faster is to get lots \\nof good feedback. And the best way to get feedback is to find great developers to work \\nwith who will give you code reviews.\\n \\nThe great thing today — which wasn’t available in my day — is you can get involved \\nwith open source projects and get very specific feedback from great developers. This is a \\ntremendous resource and opportunity for people who want to improve their programming \\nskills. So write a lot of code, and make sure you’re getting code reviews from quality \\nprogrammers.\\n \\nOn the process of implementing the machine learning algorithms — how do you \\nlearn more data science on the job?\\n \\nThere is not a steady rate at which you learn new techniques and employ them; it \\ndefinitely comes in waves. When I made the transition into this new domain of education \\nand internet-generated data, I went through a period of needing to learn new modeling \\ntechniques. I wasn’t familiar with probabilistic graphical models; that wasn’t something \\nthat I had used in high frequency trading.\\n \\nOnce I got past that initial learning curve, learning came very much in waves. There \\nwill be a very concrete and motivating need or goal. For example, we’re very focused \\non delivering value to the users and so any new foray into a new modeling technique is \\nusually driven by that goal. Often we will have the necessary knowledge at hand. If not, \\nwe’ll take the time to learn what we need to know. \\n \\nThe great thing today — which wasn’t available \\nin my day — is you can get involved with open \\nsource projects and get very specific feedback \\nfrom great developers. This is a tremendous \\nresource and opportunity for people who want \\nto improve their programming skills.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 140}, page_content='JACE KOHLMEIER\\n136\\nAnother idea that we often hear in our interviews is the importance of communication \\nand how to cultivate more interpersonal skills. Either through their research or just \\nnatural personality, some people might be introverts. What advice do you have on \\nhow to manage communication when work relies on collaboration and teamwork?\\n \\nThat’s a great question and one \\nthat I can relate to profoundly. \\nI would describe myself as \\na pretty hard-core introvert \\nand it’s something that I have \\ncontinuously had to work on in \\nmy career and continue to work \\non to this day. One of the greatest \\nthings that anyone ever did for \\nme professionally was during \\nmy time at Citadel. My boss’s \\nboss, came to me and said, “Hey, we think you have potential but there’s something \\nthat you really need to work on, and it’s your communication skills.” They put me in \\n“communications training”, which was both useful and hilarious. \\nI was videotaped role-playing various business scenarios, which felt totally bizarre. I \\nthought, “I’m a quant, this is ridiculous!” Then I watched the tape and I was appalled \\nby looking at my body language and hearing my verbal mannerisms. I’m still working \\non this today. Despite how silly it seems, I totally recommend that my fellow introverts \\ntry the videotape technique.  Andrew Ng recently shared a great post on how he used a \\nsimilar technique to become a better teacher and presenter. \\n \\nAnother important development for me was partnering with someone who was very \\nmuch an extrovert. That helped me in two ways. It gave me an exemplar for dealing with \\nother people effectively. And, it taught me that it’s OK to lean on a trusted partner at \\ntimes to handle the extrovert work, while I remained focused on my strengths. \\n \\nSo those are a couple of strategies that people can use. Number one, get yourself feedback \\n— possibly through videotaping — and conscientiously work on your communication. \\nSecond, seek partners with extroverted tendencies that can complement your more \\nintroverted tendencies, and build extra close relationships with those people.\\n \\nThat’s fantastic advice. Switching gears to diving into your work, what’s a day like \\nin the life of a data scientist at Khan?\\n \\nIt’s fast paced. The Khan Academy engineering team, in general, is very focused on \\nOne of the greatest things that anyone ever \\ndid for me professionally was during my time at \\nCitadel. My boss’s boss, came to me and said, \\n“Hey, we think you have potential but there’s \\nsomething that you really need to work on, and \\nit’s your communication skills.” They put me \\nin “communications training”, which was both \\nuseful and hilarious.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 141}, page_content='JACE KOHLMEIER\\n137\\nshipping and iterating quickly. We try to ship code everyday. So fitting into that, what I \\nfocus on and what my immediate team focuses on is what we call “learning gain,” and \\nwe try to take a very pragmatic approach to the work. We’re not looking to just produce \\nresearch, we don’t pat ourselves on the back at the end of the day for writing a nice \\nreport or making a pretty graph. What we really want to do, which sounds grandiose, is \\nto change the lives of our users through more effective or increased learning through \\nKhan Academy. That is what we measure ourselves by and the questions that we ask \\nmust relate in some way to that goal, and hopefully, as directly as possible, to the main \\nquestion, “What are we doing to improve learning through Khan Academy?”\\n \\nThe data that we deal with is almost entirely generated from user activities on the website. \\nOccasionally, there are some complimentary external data sets, like geography, but it’s \\nalmost entirely user activity, which forms both their practice and their assessment, so to \\nspeak.\\n \\nA good day is a lot of code writing \\nbecause it’s the most direct way that we \\nbuild value. Then, as a team lead I also \\nneed to make sure our team is in sync \\nwith the organization. I learned some \\nhard lessons during my first couple of \\nyears at Khan on that front: A) make sure \\nthe product design is amenable to the \\nresearch requirements, and B) promote \\nideas for doing experimental research that may not occur to others. For example, we might \\nread something in the science of learning, like there’s strong evidence or justification for \\nthis particular style of learning, and we think it could be studied in this particular way. \\nIf we communicate this to the engineering team, they might be able to add this into the \\nproduct, and we would be able to measure and build off of that.\\n \\nSo a good day is mostly writing code, checking in on the real time results from our A/B \\ntesting dashboard and then doing the interesting work of talking to other teams to \\nunderstand how they are making their decisions, and what can we do to help them. We \\nstay focused on the product because at the end of the day, that’s what the users touch. \\nThat’s our ultimate goal. So if we’re not changing the product and changing it in a way \\nthat delivers better outcomes to users, then we’re not doing our job.\\n \\nLets talk about the future. How do you see the foray of computational statistics into \\ncomputer science? Do you see that data science will also become commoditized? \\nHow do you think data science will evolve?\\n \\nWhen you’re doing analysis, you’re not \\nreally writing code anyway. You are using \\nexisting machine learning libraries and \\nyou’re basically an intelligent matchmaker \\nbetween the data and the appropriate \\nmodel.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 142}, page_content='JACE KOHLMEIER\\n138\\nI agree there’s been a heavier commoditization of big data services, which has reduced \\nthe need for people with data infrastructure backgrounds, though I would argue that \\nthose skills are still very valuable and some of the infrastructure tools are still relatively \\nimmature. I think there’s a lot of improvement to be made there, but you can see it \\ncoming. So that leads to more emphasis on the next layer of actually analyzing the data.\\n \\nIf I have data, and there’s a standard suite of off-the-shelf models, how do I combine \\nthose techniques and know which technique I should use? I think the emphasis will \\nstay in that area for a long time. When you’re doing analysis, you’re not really writing \\ncode anyway. You are using existing machine learning libraries and you’re basically an \\nintelligent matchmaker between the data and the appropriate model. I don’t see that \\nmachines are good matchmakers, because this involves knowing which tools to apply in \\nwhich contexts. It’s a fairly high level process, which for now requires human intuition. \\nSo I think we will need people with those skill sets for a while.\\n \\nYou have done a lot of interesting work in high frequency trading, and now you’re \\nworking in the education space. What excites you about your job and what are \\nsome future prospects that excite you?\\n \\nAt Khan Academy, we give our new hires \\na couple of sci-fi books. One of them is \\nThe Diamond Age  by Neal Stephenson. \\nIn the book, Nell is a young girl who \\ncomes upon a sophisticated guided \\nlearning tool designed in the form of \\na book, and it teaches her skills and \\nknowledge in an interactive way. The \\nauthor even accounts for the presence of human-backed interaction with people called \\n“ractors,” that can bring some essential humanity to Nell’s experience. It’s an amazing \\nvision that seems tantalizingly within reach. None of the material seems far-fetched in \\nthe age of iPads and other educational technologies. \\n \\nStill, one thing that surprises me is how much harder the problems I work on at Khan \\nAcademy are compared to the problems I worked on in high frequency trading. Everyone \\nassumes that developing a model that consistently generates money in the financial \\nworld has to be the hardest thing to do, but I think it’s a different breed of difficulty. \\nThere’s a reason that what we now call data science originated in finance, because \\nfinding signals and knowing what to optimize is so ingrained in the profit and loss \\n(P&L) of financial trading. The signals and optimization objectives are so much less \\nwell defined and quantifiable in the education space, which makes it hard from a value \\ncreation perspective. So the objective function is not as well defined. In education, we \\nStill, one thing that surprises me is how \\nmuch harder the problems I work on \\nat Khan Academy are compared to the \\nproblems I worked on in high frequency \\ntrading.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 143}, page_content='JACE KOHLMEIER\\n139\\nrun into a host of considerations for defining the objective function. Should we optimize \\nfor educational breadth or depth? Is the answer to that question the same for everyone? \\nWhat about their emotional state? How do I incentivize people to stay engaged in \\nlearning? There are more human aspects which blur a well-defined objective, but which \\nalso make the work very challenging.\\n \\nI’ve immensely enjoyed my work at Khan Academy, and I think my dream of achieving \\ntechnology that facilitates completely personalized education is both realistic and \\nepically ambitious. That’s exciting.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 144}, page_content='JOE BLITZSTEIN \\nProfessor of the Practice of Statistics at Harvard\\nHow did you get interested in statistics?\\n \\nI was a math major as an undergrad at Caltech. Caltech doesn’t have a statistics or \\ndata science department, and there are also very few statistics courses there. I went to \\nStanford for graduate school in math. It hadn’t really occurred to me at the time, but \\nStanford has a ton of statistics and data science-type opportunities.\\n \\nI was working on probability for my PhD thesis because I really love it, but I decided \\nthat it’s better if you can have your cake and eat it too. With statistics, you can actually \\ndo cool math and also feel that you’re analyzing interesting data and doing something \\nuseful for the real world. It still has nice mathematical structure and lots of elegant \\nthinking. You can also feel more useful, whereas math, itself, tends to get more and more \\nabstract and disconnected from reality as you progress. Statistics, though, is rooted in \\nthe real world and real data, and data science is a version of statistics.\\n \\nCan you describe for our readers what Harvard’s Data Science course is like and \\nwhat is the philosophy behind it?\\n \\nIt’s a course that I created with Hanspeter Pfister, who is a visualization professor in the \\nComputer Science department. Our goal was to give an accessible introduction to the \\nentire data science process.\\nWe defined that process as a journey, starting from formulating a research question \\nJoe Blitzstein is a Professor of the Practice of Statistics at \\nHarvard, moving to Harvard after obtaining his PhD in \\nMathematics from Stanford. He co-taught the initial offering \\nof Harvard’s inaugural Data Science class, designed around \\nthe Data Science Process. He also teaches Harvard’s popular \\nintroduction to probability class  as well as other statistics \\ncourses. Joe regularly emphasizes intuition and storytelling \\nin his instruction. He tweets at @stat110.\\nJoe Blitzstein is a co-author of the textbook Introduction to \\nProbability.\\nTeaching Data Science and Storytelling'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 145}, page_content='JOE BLITZSTEIN\\n141\\nand gathering data. Then, you clean the data, so there’s some data wrangling. There is \\nexploratory data analysis, which involves looking for problems, biases, weird outliers, or \\nstrange anomalies in the data, as well as trying to get a sense of some possible conjectures \\nyou could formulate.\\n \\nThen, it goes a little bit into modeling. We took a Bayesian approach to that. There are \\nfull courses on Bayesian data analysis, and this was just a short introduction. Then, \\nthere’s communicating and visualizing the results.\\n \\nThe sequence of steps is not linear — you iterate between those steps in a non-linear \\nway. We defined it as the data science process, and we wanted to introduce that process \\nthrough examples. To go into detail, that process would have taken six courses, but we \\nwanted to put them together into one introductory course on how to think like a data \\nscientist. The course needed to include applications that are of current interest like \\npredicting elections, movie and restaurant ratings, and network analysis, rather than \\nusing a lot of canned, stale data sets that no one has cared about in the last 50 years.\\n \\nSo, we wanted interesting data, but that’s not enough. We wanted interesting data but \\nwe also wanted to ask relevant questions about the data.\\n \\nWhy is important for data scientists to understand the data science process instead \\nof just going through the work?\\n \\nI think it’s important in whatever you \\ndo to have a sense of direction, instead \\nof just aimlessly trying things. You want \\nsome sense of where things are going. I’m \\nnot saying it’s not useful to just grab data \\nand hack around with it. You can learn \\nfrom doing that, but in terms of doing \\nsomething that will have long-term scientific value, I think that depend on relevant \\nresearch questions.\\n \\nMuch of statistics is about distinguishing signal from noise, distinguishing valid from \\ninvalid signals, so-called “discoveries”. You need to look for patterns, but you can’t just \\nassume that whatever pattern you find is real. You have to perform some validation, and \\nif you cannot communicate the results in the end, it’s not worth much either.\\n \\nAll of these ingredients are crucial. Different people can specialize in different parts of \\nthe process. No one can be a complete expert at every step, but data scientists in industry \\nare working in teams. To be effective in teamwork, you have to understand some basics \\nWith statistics, you can actually do cool \\nmath and also feel that you’re analyzing \\ninteresting data and doing something \\nuseful for the real world.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 146}, page_content='JOE BLITZSTEIN\\n142\\nof what your teammates are doing. You need to be able to give them feedback, and you \\nneed to be able to understand their feedback about what you’re doing. You have to see \\nhow the various pieces fit together into the overall process.\\n \\nHow did you get interested in data science and teaching this data science class?\\n \\nIt’s probably a combination of a lot of factors. I noticed more and more possible data science \\nideas and applications ever since the Netflix prize and Nate Silver. The combination of \\nso many datasets that were never available before made me really interested, for my own \\nsake, as well as for teaching it to students. I felt some concern that students might not \\nhave the right kind of CS training to be able to participate in all these opportunities. So, \\nI wanted to play a role in fixing that.\\n \\nYour data science class was very popular this year. Did you expect this level of \\npopularity? How many students ended up enrolling in the class?\\n \\nI had guessed there would be 100 or 150 students (which would already be a very large \\ncourse), but we ended up with more than twice that many; we ended up having 350 or \\nso enrollments. We tried to keep the prerequisites reasonable, but it did require at least \\nsome very basic background in Stat and CS. We didn’t want to limit enrollment or do \\na lottery, so we tried to send the message that this was going to be a hard class. You’re \\ngoing to do a lot of work, but you’ll learn a lot. That was the idea, but I didn’t expect it \\nto have that much demand.\\n \\nWhy do you think there was such a large demand for the class?\\n \\nIt’s hard to know. I think there are some students who took Stat 110 and wanted to have a \\nfollow-up, even though the material is different. In Stat 110, we do probability and it’s a \\nfairly mathematical course, but we’re not analyzing data. In a data science course, we’re \\nnot doing math, but we are analyzing data. I see Stat 110 and the Data Science course as \\ncomplementary, in that we are emphasizing stories and a certain way of thinking about \\nthe world in both of them.\\n \\nSo, it’s the applied analog, and I have a huge number of Stat 110 students who were \\ninterested in going further. Then, Hanspeter had a lot of students interested in his \\nvisualization course. The visualization itself is great, but it’s very limited if you don’t \\nactually know how to analyze the data. So, the whole theme of big data attracts a lot of \\ninterest.\\n \\nYou mentioned emphasizing stories when you were comparing Stat 110 and the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 147}, page_content='JOE BLITZSTEIN\\n143\\nData Science course. I want to extend that question: What is the role of storytelling, \\ncommunication, and visualization in data science?\\n \\nI think they’re incredibly important parts of it. Anyone with a basic level of CS can scrape a \\nbig data set and start computing things. And anyone with the right statistics background, \\nif presented with a clear data set, can start running some regression in a mechanical way. \\nI think there’s a real art to getting interpretable results and then communicating those \\nresults, especially in the age of big data where you have thousands of variables. In the \\nold days of regression, you might have two predictors, and it’s a lot easier to see what’s \\ngoing on. Now, we have thousands of variables and some very complicated models, and \\nit becomes very difficult to see what’s going on.\\n \\nI think communication includes communicating with yourself too! You are trying to make \\nsense of the data in a way that human beings can understand. If you attend conferences, \\nit’s generally hard to remember anything from the majority of a presentation. Presenters \\ntend to rush through their slides and try to show a lot of results, but are they really \\nexplaining what the story is?\\n \\nSo, if statisticians (or anyone) \\nare falling to communicate why \\ntheir results are important and are \\nfailing to explain those results in an \\ninterpretable way, that’s just a lot less \\nexciting. Visualization definitely plays \\nan important role in that case. A picture is worth a thousand words. Sometimes instead \\nof staring at a huge table of numbers, a few graphs can give you much more intuitive \\ninformation.\\n \\nDo you have any advice for data scientists or people in the industry who may \\nwant to become better communicators? What kind of philosophy would you like \\nto impart to make them care more about the storytelling and communication part \\nof data science? Why is the teaching part of data science so important?\\n \\nI think it’s an important part of clarity of thinking. As a data scientist, you’re going to \\nneed to collaborate with many different types of people with many different backgrounds. \\nYou have to be able to put yourself in their shoes and explain things in terms of what \\nthey’re interested in and what their background is. In many cases, when you can’t \\nexplain something clearly, it’s a sign that you haven’t thought it through fully yourself. \\nSo, teaching and learning go together. Learning to explain something to someone in an \\ninterpretable way makes it a lot clearer in your own understanding.\\n \\nMuch of statistics is about distinguishing \\nsignal from noise, distinguishing valid from \\ninvalid signals, so-called “discoveries”.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 148}, page_content='JOE BLITZSTEIN\\n144\\nIn terms of concrete advice on developing these communication skills, I think of it in \\nterms of something like the golden rule, which I call the conditional golden rule: try \\nto present the idea in a way that you would have appreciated seeing it presented. It’s \\nconditional because you have to adjust for the fact that as a data scientist who’s been \\nimmersed in a project for months or years, \\nyou have to step back and realize that the \\nperson you’re talking to may have never even \\nheard of what you’re doing. They don’t know \\nany details about the data. They don’t know \\nyour notation, and they may not even know \\nstatistics.\\n \\nAlso, read some of the classic design books by Edward Tufte (he’s a famous example), The \\nVisual Display of Quantitative Information. Try to find and follow good examples.\\n \\nWhat’s your opinion on his book and his philosophy on visualizing information?\\n \\nI really like his books. In a sense, he’s a victim of his own fame, in that these books are so \\npopular that it’s almost a visualization bible. So naturally, there’s going to be a backlash \\nof people asking, “what gives him the right to say what you can or can’t do?” I wouldn’t \\ntake everything he says religiously, but these are important things to think about. Clear \\ncommunication is incredibly important.\\n \\nWhat are your favorite philosophies about visualization? What is your favorite \\npiece of knowledge from this book, and what is your best advice for visualizing \\nquantitative information?\\n \\nI think the best advice is just to think hard about what you want your audience to take away \\nfrom the visualization. It’s sad to think of how many talks I’ve been to, presentations on \\nall kinds of subjects, where the speaker will make ridiculous mistakes, like not labeling \\ntheir axes or having things so small that the audience can’t see what is going on.\\n \\nSometimes, presenters want to show some kind of comparison, but the things they’re \\ntrying to compare are on separate slides. Graphs are effective in showing something \\nchanging over time or a comparison between things, and it is more about relative \\ninformation than absolute information most of the time. You want to make it as easy as \\npossible to see those comparisons. Avoid something that looks really fancy but distracts \\nattention from the fundamental comparison you’re trying to display.\\n \\nCan you tell our readers more about your story behind the conditional golden rule?\\n \\nThere were two course reviews about Stat 110 that went well together. One of them said \\nIn many cases, when you can’t \\nexplain something clearly, it’s a sign \\nthat you haven’t thought it through \\nfully yourself.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 149}, page_content='JOE BLITZSTEIN\\n145\\nI designed the course to the credo that it should be taught in the way I myself would \\nlike to take it as a student, which is the golden rule. Then, the other one, which is a \\ncounterpoint to that, said that the homework only induced pain, not learning. The joke \\nis, that if you combine those two things, it implies that I’m a masochist.\\n \\nObviously, I’m trying to induce learning, not pain, but it does require a lot of hard work \\nto learn all these things. I try to make as many resources available as possible, in terms \\nof having great Teaching Fellows, having lots of office hour times, and having large \\namounts of practice problems. It’s just like if you were practicing a sport or a musical \\ninstrument. It’s something that you need to practice, practice, practice. Just doing a few \\nhomework problems a week is not going to be enough.\\n \\nIt’s like learning a whole new language. Language courses tend to meet every day, and \\nyou have to go to labs. There are tons of things going on, but statistics and data science \\nare new languages, too. They should be approached in the same way. You have to do the \\nmath and CS as well as learning grammar and syntax. You just have to immerse yourself \\nin the learning process.\\n \\nFor my fellow students and me, we’re very fortunate to be in this environment \\nwhere our only duty is to learn. But there are many data scientists out there who \\nfeel like they’re missing some knowledge and are trying hard to fill the gap. My \\nquestion is in reaction to those data scientists. What’s the best way to keep on \\nlearning after university?\\n \\nI noticed that’s a trap that people fall into, \\nthinking, “I’m perpetually feeling unprepared.” \\nIt’s a dangerous way of thinking — that until \\nyou know X, Y, Z and W, you’re not going to \\nbe able to do data science. Once you start \\nlearning this thing, you realize there are four \\nother things you need to learn. Then, you try \\nto learn those things, and you realize you don’t have this, this, and this.\\n \\nYou do need some basic foundation in statistics and CS skills, but both statistics and \\ncomputer science are enormous fields that are also rapidly evolving. So, you need durable \\nconcepts. Right now, for people that want to do data science, I highly recommend learning \\nR and Python. But in 10 or 20 years, who knows what the main languages will be?\\n \\nIt’s a mistake to think, “why am I learning R now? R won’t be used in 20 years.” Well, \\nfirst of all, R might still be used in 20 years, but even if it isn’t, there’s going to be a need \\nfor the thinking that produced R. The people who create the successors to R will have \\nIt’s a dangerous way of thinking — \\nthat until you know X, Y , Z and W, \\nyou’re not going to be able to do \\ndata science.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 150}, page_content='JOE BLITZSTEIN\\n146\\nprobably grown up using R. So, they’re still going to have that frame of reference.\\n \\nYou want the skills that are language-independent. You need fundamental ways of \\nthinking about uncertainty and communicating those thoughts in a way that is not that \\ndependent on any particular programming language. It’s definitely important to have \\nthat kind of foundation, but keep in mind that it’s hopeless for anyone to actually know \\nall the relevant parts of statistics and CS, even for some small portion of data science. It’s \\nnot feasible for anyone, but it doesn’t mean that you can’t make useful contributions.\\n \\nIn fact, I think it’s a good idea to continue \\nlearning something new every day. The \\nway you can learn something, and really \\nremember it, is by using it in your work. \\nInstead of saying, “I need to study these \\nfive books so that I will know enough \\nto become a data scientist,” it should be about getting a basic level and foundation. \\nThen, start immersing yourself in a real, applied problem. You will realize what types of \\nmethods you need. Then, go and study the books and papers that are relevant for that. \\nYou will understand them so much better because they’re in the context of a problem \\nthat you care about.\\n \\nYou have to be energetic and work really hard, but not get discouraged just because you \\ndon’t know everything. And just because you don’t know everything, it doesn’t mean \\nyou can’t contribute useful things while gradually expanding your understanding and \\nknowledge.\\n \\nTo strengthen one’s understanding in a concept, would you also recommend teaching \\nthat concept to other people (stemming back to your philosophy on storytelling \\nand communication)?\\n \\nYes. I think that’s a great way of checking your own understanding. It’s a lot of fun. \\nYou’re helping someone. You have to think about the important things to emphasize, \\nthe common misconceptions, etc. Think back to when you first learned the concept, the \\nobstacles and conceptual roadblocks that you had to get past, and the most important \\nthings to emphasize. That is very useful for everyone.\\n \\nWhat are the parallels between being a data scientist and being an educator?\\n \\nCommunication and feedback. If you’re just lecturing to a class and not paying attention \\nto see if the students are actually understanding, that’s a pretty stupid way to teach. \\nThere’s a story of a professor who got a really poor teaching evaluations, and the \\nYou have to be energetic and work \\nreally hard, but not get discouraged just \\nbecause you don’t know everything.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 151}, page_content='JOE BLITZSTEIN\\n147\\nevaluations said his lectures were very unclear. He said, “My lectures aren’t unclear. The \\nstudents just don’t understand.”\\n \\nCommunication is a two-way street and you have to pay attention in various ways, \\nthrough feedback, watching people’s expressions, trying to get people to speak up and \\nfeel comfortable asking questions. Do whatever you can when you’re teaching to assess \\nwhat people understand and what they don’t. A lot of that information stays the same \\nfrom year to year.\\n \\nThat’s the reason why every week in Stat 110, I ask the teaching fellows for the most \\ncommon mistakes from the homework. I can clarify those things or they can be clarified \\nin the sections for that year. Those things tend to stay fairly constant from year to year, \\ntoo. I don’t have a formal data set, but I am trying to gather as much information as I can \\nabout what the students understand and what they do not.\\n \\nData science is like that, too. You don’t compute something without getting feedback \\non whether it’s working or not. You’re communicating messages to people, but you need \\nfeedback on whether or not that message is getting across.\\n \\nThis is a very important idea in software development, too, with continuous \\ndeployment and instant feedback and quick iterations. It’s nice connecting data \\nscience and software engineering principles. As a data scientist, you’re always \\ngetting feedback and trying to improve.\\n \\nI think that’s extremely important. That’s another mistake I’ve noticed, the tendency \\nin applied problems where new students just want to fit one model and be done with it. \\nBut, the world is too complicated. There are too many challenges with data. We know the \\nsaying, “ All models are wrong, but some models are useful.”\\n \\nIt’s not realistic to expect that the first model you come up with will actually work well, \\nbut if it takes too long to figure out how to fit that model and run the computations on \\nsome massive data set, you may feel that you need to move on.\\n \\nThat’s very unsatisfying. What you need to do, first of all, is get comfortable on Python \\nso that you can fit the models very quickly. If you have a large data set, fit it on a subset \\nfirst so you can quickly get models and better intuition. You have to iterate and build \\nsomething better.\\n \\nYou have to manage your time so that you can actually go through a whole series of \\nmodels and get feedback on which one is actually working through measures of fit or \\npredictive capabilities. Even just explaining or communicating with someone else to try'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 152}, page_content='JOE BLITZSTEIN\\n148\\nto get a sense of whether the model is actually doing something useful and what aspects \\nneed to be improved, is very good.\\n \\nBuilding off of that, what other mistakes do you see made, or what other things do \\nyou think data scientists should improve on?\\n \\nStatistics is just a hard subject and there are all kinds of mistakes made. I think the \\nbiggest one tends to be not thinking enough about sampling. Where did the data come \\nfrom? What do you want to assume about possible selection bias or other forms of bias \\nin the data? If there’s a systematic bias, no matter how large the data set, it still has to be \\naccounted for. It doesn’t wash away in the limit of large data. You can’t necessarily think \\nof the data as being an objective, unbiased portrait of reality.\\n \\nAnother thing is trying to be very clear, at all times, about what the goal is. What are you \\ntrying to estimate? What are you trying to predict?\\n \\nHow can university education better prepare students for opportunities in data \\nscience? What skills are students missing in general?\\n \\nThere are very few data science courses in universities currently. There’s a large number \\nof statistics and CS courses that are closely related, but there are not many courses \\nthat integrate statistics and CS. There are also not many courses on communication, \\nvisualization, and storytelling.\\n \\nI think the problem is that there are not a lot of clear paths to follow. There aren’t data \\nscience majors generally, and even the statistics major is small or nonexistent in most \\nschools. It’s a recent trend that statistics even exists as a major.\\n \\nOne purpose of a major is not just what degree shows up on your diploma. It’s also about \\nproviding tracks, having some coherent path through the material. For data science, you \\ndefinitely want a strong combination of both statistics and CS, and different schools \\ncertainly vary in how much relevant material they have in each of those. I think very \\nfew have developed a road map, a coherent ordering, and a scheduling of how to get the \\nrequisite knowledge.\\n \\nThere are going to be a lot of readers whose schools don’t really offer these kinds \\nof opportunities. How do you feel undergraduate or graduate students can get the \\nrequired data science knowledge when universities don’t offer these specialized \\ntracks and courses?\\n \\nIt may or may not be a formal online course, but there’s a massive amount of excellent'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 153}, page_content='JOE BLITZSTEIN\\n149\\nonline material. I really can’t curate it right now. That’s something I’d like to do at some \\npoint, to try and recommend the most useful online materials, and try to recommend a \\ncurriculum. I know others have tried to do that.\\n \\nThere are a lot of great books, but like I \\nsaid, you don’t just want to read a stack of \\nbooks. Maybe you can read or study a couple \\nof books or do a couple of online courses, \\nbut just try to start doing something like \\nKaggle competitions at Kaggle.com. They \\nhave very interesting data sets and problems, often about predicting some quantity. Try \\nout one of these competitions or find some data you’re interested in and just get a feel \\nfor it. You can look through different resources about regression models and machine \\nlearning. Look at different materials and then try it out on the data set you’re working \\nwith. You’ll get a lot more intuition about which methods work well for which problems.\\n \\nA lot of those things are very hard to teach in a course anyway. Even if universities offered \\nmore data courses, many of these things are best learned through hands-on experience \\nin internships, in competitions, or with just playing around on your own with some data.\\n \\nDo you have any funny or interesting anecdotes to share with our readers?\\n \\nI read an article in Wired recently, about the importance of A/B testing at Google and \\nvarious tech companies, and I thought it was nice that they’re calling attention to \\nthat. The thing that was funny and sad about it was that the article made it sound like \\nthey had never heard of the history of experimental design and randomized controlled \\nexperiments in statistics, which goes back to R.A. Fisher in the early 20th century.\\n \\nThat is 100 years of history on how to efficiently design experiments. For example, if there \\nare many variables you’re interested in, it’s really inefficient to design an experiment \\nin which you only change one thing at a time. You want to have a full factorial design \\nwhere you’re changing different variables at the same time. It’s much more efficient, and \\nthere’s a lot of good theory and application for randomized experiments. Some people \\nconsider randomized experimentation as one of the biggest breakthroughs in medicine \\nin the 20th century.\\n \\nThe article was talking about A/B testing, which is just a trendy word for randomization, \\nwhere you have one treatment group and one control group. The article went on to \\nspeculate, is it even conceivable that we might be able to A/B test the offline world, too?\\n \\nSo, I thought it was funny that, apparently, they never heard of a randomized \\nBut now, in this era of big data, it’s \\neven more important to understand \\nexperimental design.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 154}, page_content='JOE BLITZSTEIN\\n150\\nexperimentation, but also, it was a reminder that data scientists need to be familiar \\nwith traditional statistical concepts, such as experimental design and sampling theory, \\nin order to be able to be much more efficient in how they deal with data.\\n \\nExperimental design was one of the main topics in statistics in early 20th century, and at \\nsome point, it started having a reputation of being a bit old-fashioned. It was only old-\\nfashioned because it was one of the founding topics on which statistics was created. But \\nnow, in this era of big data, it’s even more important to understand experimental design.\\n \\nSo, it’s coming back but with new challenges related to the new types of data sets that \\nwe have. It’s very interesting to see old and new ideas come together.\\n \\nLastly, what advice would you give for undergraduate and graduate students who \\nare interested in going into data science?\\n \\nI just recommend getting a mixture of math, \\nstatistics, and CS background, to build a \\nstrong foundation. Then, concurrently, \\nimmerse yourself in as many real world \\napplications as you can, remembering that \\ndepth is often better than breadth. Immerse yourself into challenging problems that you \\ncan hopefully integrate with your coursework, so that you see some ideas and how they \\nare or are not relevant for particular types of data science questions.\\n \\nWhen you’re learning, constantly question and constantly be critical. Whenever possible, \\nask fundamental questions like, “Who cares?” Constantly think about the motivation. \\nWhy is that relevant? Why is this data set interesting? What questions could we hope \\nto answer? When you’re trying out different statistical methods, don’t just use it like an \\noff-the-shelf, black box type of thing where you just spit out results. Question! Do those \\nresults make sense? How do you assess whether the method you’re using is working \\nwell, or how do you know if it’s actually working better than random guessing or using \\na complicated method? How do you know that it’s better? In what way is it better? Is it \\nbetter than some simple, naïve thing you can try? Constantly try things and compare \\nthem. Question whether or not the results make sense.\\nWhenever possible, ask fundamental \\nquestions like, “Who cares?”'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 155}, page_content='JOHN FOREMAN Chief Scientist at MailChimp\\nCan you start off by talking about your book, “Data Smart”? How did the motivation \\nfor writing it come about, and what type of audience is it for?\\nI felt like there were a lot of business analysts and middle managers in the enterprise \\nworld who were not familiar with “data science” as a practice and set of techniques.  \\nThese folks still lived in a world of “business intelligence” or “business analytics” from \\na decade ago, and I wanted to bring them up to speed on current methods (for example, \\nensemble AI models built on transactional data, data mining in graphs, forecasting with \\nerror bounds). I wanted to get these enterprise readers up to speed, so I needed to find a \\nlanguage and teaching approach that they’d understand.\\nA lot of data science books that were being introduced at the time required learning \\nboth R and techniques at the same time. With a lot of those books, rather than actually \\nlearning the techniques, you just loaded the AI package or the data mining package.\\nInstead, I wanted to write a book that introduced these concepts step-by-step with a tool \\nthe reader knew, and then, once they got it, slowly push them into a programming mode. \\nSo in Data Smart, I explained the gamut of data science techniques by using spreadsheets. \\nSpreadsheets are kind of like a functional programming language and GUI in one, and \\nthey’re actually pretty good for step-by-step model building.\\nAs an undergraduate math major, John thought that he \\nwas going to be a pure mathematician. A few experiences \\nworking as a programmer, combined with a talk with his \\nadvisor, pushed him instead into the world of applied math.\\nAfter a sojourn in academia through MIT’s Operations \\nResearch PhD program, John realized that a long-term \\ncareer in industry would be more interested and fulfilling.\\nJohn held a series of jobs in business intelligence at various \\nconsulting companies, before taking on the Chief Scientist \\nrole at MailChimp, a fast-growing, completely bootstrapped, \\nemail startup based in Atlanta Georgia that boasts over 7 million users.\\nHe is also the author of the book “Data Smart,” which presents an overview of machine \\nlearning techniques, as explained through spreadsheets.\\nData Science is not a Kaggle Competition'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 156}, page_content='JOHN FOREMAN\\n152\\nThe last chapter is an introduction to R, and it harkens back to previous chapters now \\nthat the kernels of understanding had been planted. For example, if you’re doing an \\nexponential smoothing forecast  (which I cover in my book), you should not be doing all \\nthese steps every time. You should be doing it on the shoulders of the giants who’ve \\nwritten the Ph.D. theses you’re using and just open their package.\\nUltimately, people who want to know each little detail of how a boosted tree model \\nworks or how modularity maximization works seem to love the book. Programmers who \\nare used to relying on black-box libraries, functions, etc. aren’t the biggest fans.\\nGiven your interest in opening up black boxes to examine the nitty-gritty of \\ndifferent techniques, did you ever want to write your thesis on a new statistical or \\nmachine learning technique?\\nI started at MIT wanting a Ph.D., but in my first year of graduate work I had the opportunity \\nto do some applied work on Dell’s supply chain, and it showed me that my passion lie \\noutside of academia.\\nYou see, my advisor was really interested in publishing results. Although we came to \\nDell trying to understand how to help the business generate revenue — which I enjoyed \\n— that wasn’t our ultimate goal. The problem with consulting when you have ulterior \\nacademic purposes is that the goal of academic publishing is counter to the goal of \\nhelping a business, because in order to publish, you need something academically new \\nto say. But if it’s a new technique, it is often not maintainable by the business once the \\nacademics leave.\\nThat was a good experience for me, because I realized that I’m not an academic despite \\nthe fact that I like technical things. Rather, I’m an analytics professional who enjoys \\ntailoring technical approaches to business settings where the solutions are sometimes \\ncomplex but often simple, depending not on my needs as a data scientist but on the \\nbusiness’s needs or the customer’s needs.\\nThat ability to think simply and “edit” models is something I just published an article \\non. One thing I reference in the article is a paper from 1993 by Robert Holte titled “Very \\nSimple Classification Rules Perform Well on Most Commonly Used Datasets. ” His basic \\npremise is that simple decision rules – a single rule that splits the data on one feature — \\nare pretty effective compared to more complex models, like a CART model. That makes \\nsense since oftentimes in naturally occurring data sets within the business, you have a \\ncouple of features that are good, and everything else is just icing on the cake.  \\nOne of the things Holte says in the paper is your model complexity has to be justified,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 157}, page_content='JOHN FOREMAN\\n153\\nand that really grabbed me.\\nIt made me think, especially in a business context, what it means to justify your \\ncomplexity. Part of that is the additional expense of keeping the model running versus \\nrevenue. Part of that is the poor sap you’re saddling \\nwith keeping this thing running. And something \\nthat people don’t often consider is the likelihood \\nof abandonment.  \\nOnce you move on, whoever gets saddled with it \\nmight find some organizational reason or anecdotal \\nevidence to ignore it. They may not even tell you or get back to you. Are you going to \\nstick around and babysit all your models? How do you hand them to someone if they’re \\ncomplex?\\nSo to come back around to getting a Ph.D., for me, it was this desire to go out and use \\ndata to serve a business, and to do that using both complex and simple approaches that \\npushed me to leave graduate school early and join the workaday world. I don’t regret it.\\nIt seems like the academics are trying to do the most complex models, and the \\nbusiness decision makers are thinking it may not be all that helpful, that 80% of the \\nway there is good for us already.  \\nCan you talk more about your background? What were you doing before your \\nPhD?\\nMy dad is an English professor so I thought I was going to do English. Slowly, I realized \\nI was pretty good at math. In my undergrad, I studied pure math. I really liked abstract \\nalgebra, and I thought I was going to be a pure math guy. My advisor sat me down and \\nsaid, “You’re alright. You’ll probably go to grad school in a top 10 program, but you’re \\nreally not going to amount to much in the math community.” I felt at the time that it was \\npretty harsh, but it was true. I couldn’t compare myself to other people doing pure math.\\nThe way math works is a lot of people toy with little results for a long time, and suddenly \\nthere are huge jumps from certain people. I would never be that individual who would \\npush the mathematical fossil record forward into a new era. I would be a guy that toys \\nwith smaller results. So it came down to a question of passion: how passionate was I \\nabout pure math?\\nAt the time, I was also doing research for another math professor on knot tying. I got \\nYour model complexity has \\nto be justified, and that really \\ngrabbed me.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 158}, page_content='JOHN FOREMAN\\n154\\npaid as part of this research group to write code that would take two 3D models of knots \\nand join them into a compound knot without crossing over other sections of the knots \\nand forming a new knot type. It was crazy specific, but I learned a lot about Unix and \\nprogramming. I wrote code to do simulated annealing in C. I was getting all sorts of \\nmemory leaks, and I had to do a lot of stuff in the command line with data sets.\\nI didn’t know what that was at the time. I thought it was just math research that involved \\ncode, but I liked it. It turned out to be my most valuable experience as an undergraduate. \\nAfter all, what would a data scientist do without piping in Unix?\\nWhat did you end up doing once you graduated?\\nI did a couple of internships at the NSA over the summers, and I loved the applied, \\nproblem-focused environment. When I did my first summer internship, it was all math \\nstudents hopped up on stories of Bletchley Park, etc. Lots of energy. It was great, but then \\nI did another internship there and they put me in a regular office with regular employees \\nthat had been there for a long time. And that’s what ultimately scared me away.\\nI remember talking to one guy who had a picture of a golf course above his computer. He \\nsaid, “That’s what I’m doing next year when I retire, playing golf.” Everyone was tired, \\nand everyone was burned out. I figured that a government job wouldn’t be exciting for \\nlong, so I began to look at other applied analytics opportunities.\\nSo in graduate school I chose to study operations research where math was applied to \\noptimization modeling. I went to MIT in their Operations Research Center which is an \\ninterdepartmental program between engineering, stats, math and business. It was cool \\nbecause you could take business classes alongside highly technical classes. I got a kick \\ndoing MBA case studies because it was so foreign to a math class. No proofs!\\nI thought the OR program was awesome, so I knew that career-wise I was headed in \\nthe right direction. When I did my graduate research for Dell and was able to use the \\nOR concepts in a consulting framework, though, that’s when it all clicked. I applied to \\nanalytics consulting firms and the rest followed.\\nIs this when you went to Booz Allen? What did you do there?\\nYes. I went to Booz Allen and did a lot of analytics consulting work. I was on a team called \\nModeling, Simulation, Wargaming, and Analysis which exposed me to a huge variety of \\nanalytics approaches, techniques and problems. One month I’d be doing system dynamics \\nmodeling, the next month I’d be building an optimization modeling tool whose GUI was \\na bunch of Gantt charts. You never knew where the next project would lead.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 159}, page_content='JOHN FOREMAN\\n155\\nFrom there, I went on to do consulting at a boutique consulting firm called Revenue \\nAnalytics that does pricing models that adjust prices on hotel rooms, cruises, etc. These \\nmodels are complex IT projects, so most of the clients who had the data to power them \\nand could afford them were Fortune 500s.  \\nDuring this stint, I worked with Coca Cola in Shanghai to build an optimization model \\nthat pulls frozen barrels of orange juice pulp from oranges sourced all around the world \\nand blends them together so that every time you drink one of Coca Cola’s Pulpy drinks \\nin China, the feel of pulp in your mouth is consistent. The project felt like discovering \\nsome bizarro corner of the analytics universe halfway around the world.\\nAll these Fortune 500 projects were really fast-paced. But from there I jumped to \\nMailChimp, which is more of a startup, and nothing in the Fortune 500 world could have \\nprepared me for MailChimp’s pace. We’re on a release cycle where every four weeks, \\nwe’re putting out a new version of the application. That’s light speed for me and, in fact, \\nit’s too fast for a lot of data science projects, especially if you have a lot of infrastructure \\nrequirements. I’m the slowpoke of the organization. That’s an exciting place to be \\nbecause it means people are pushing me.\\nOne fascinating aspect of MailChimp as a startup is that it’s based in Georgia. Not \\nin Silicon Valley or even New York or Boston. What is the startup scene in Atlanta \\nlike? \\nThe startup scene is alright because Georgia Tech produces a lot of talent in the Atlanta \\narea. Some of those folks want to stick around our fair city. But that isn’t to say there \\nisn’t a massive magnet out at the West Coast, because people want to go out to the \\nValley, join a startup, get equity, and see if they can cash in that lottery ticket later.  \\nThat’s a very different culture than what you find in Atlanta.\\nThat’s something that we have to think about when we recruit, so we play to our strengths. \\nWe have some of the most amazing data sets in the world. Two of our domains are in the \\nAlexa 500. We send ten billion emails a month and process another three billion events \\non top of that. We added 200,000 active sending customers this quarter. We’re growing \\nso fast, and the nice thing about that message is it attracts those applicants who want \\ninteresting work rather than those who merely want an opportunity to cash out later.\\nHow does the company think about staying in Atlanta?\\nThere are a couple of advantages in being where we are. What I found is that if you’re in'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 160}, page_content='JOHN FOREMAN\\n156\\nthe Silicon Valley, you can be part of a conversation that’s occurring between all these \\ncompanies, and there are advantages to that because you know where things are headed. \\nThere’s also a disadvantage, because you lose a lot of mental freedom.  \\nIn fact, it can instill a lot of fear.\\nYou hear a lot of what other people \\nare doing, and it’s like being \\non Facebook where everyone’s \\nprojecting the best version of \\nthemselves. This puffery makes \\nyou depressed, and you flail about \\nto technologically keep up with the \\nJones. MailChimp doesn’t have that \\nperspective, because we are slightly \\nisolated. This isolation allows us a \\nlittle breathing room to seriously evaluate technologies, opportunities, markets, trends, \\netc., rather than just jumping head first into something because everyone else is doing it.\\nThat said, the folks at MailChimp get around a lot. I travel nonstop. I speak a lot. I meet \\nwith companies. I have conversations constantly with folks around the world, but it’s \\ntargeted and intentional rather than getting an earful all over the place because you live \\nin Silicon Valley. What that means is that there’s less fear, so we’re not thinking, “We \\nhave to take VC money” or “We have to acquire this start-up.”\\nTalking more about unconventional thinking, you’ve written in the past that “Your \\nmodel is not the goal; your job is not a Kaggle competition.” Can you talk about \\nwhy you don’t think Kaggle is where data scientists should be spending their time?\\nThere’s nothing wrong with Kaggle. I think it’s a great idea. If a company’s at that point \\nwhere they want a model that’s that good and they’re getting a lot of revenue and want \\nto push like Netflix, go for it.  \\nMy one criticism is that the way journalists write about it gives a skewed view of what data \\nscience is. There was an article on GigaOM where the author said, and I’m paraphrasing, \\n“The main thing data scientists do is build predictive models. That’s how they spend \\nmost of their time.” This is a myth that something like Kaggle will perpetuate.\\nBefore you build a model, you need to know what data sources are available to you within \\nthe company, what techniques are available to you, what technologies are available, you \\nhave to define the problem appropriately and engineer the features. Usually, when you \\nWhat I found is that if you’re in the Silicon \\nValley, you can be part of a conversation that’s \\noccurring between all these companies, and \\nthere are advantages to that because you \\nknow where things are headed. There’s also \\na disadvantage, because you lose a lot of \\nmental freedom.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 161}, page_content='JOHN FOREMAN\\n157\\ngrab data from Kaggle, all of these steps are done for you. You don’t have to go around \\nlooking for data. You can’t say something like, “Maybe they left some data behind. Can I \\ncome into your company and look around?”\\nI feel that there’s so many steps before you get to modeling that are crucial. Can I ever ask \\na Kaggle competition, “Is this the competition this company should actually be having?”  \\nThink about the Netflix prize. They were trying to predict what star rating readers would \\ngive a movie given past data, but I think they backed off that a little bit because they \\nnoticed it’s not all about five-star movies. For example, I watch garbage. I will give it two \\nstars, and I will watch it anyway. It’s more about moods. A lot of things drive viewership, \\nsuch as what my friends are watching on \\nFacebook. That’s something Netflix is \\ndoing now — and it’s made their original \\nmodeling endeavor somewhat irrelevant.\\nSo there’s this notion in data science \\nabout whether or not a project should be \\ntackled in the first place that is a priori  \\nignored by Kaggle. And I think a big \\ncomponent of data science is questioning \\nwhy you’re doing what you’re doing — \\nchoosing problems to solve while rejecting other problems that are irrelevant to the \\nbusiness. With Kaggle, for better or for worse, that job is done for you. Kaggle is just an \\nexercise in using a data scientist as model-building machine.\\nI still think that Kaggle competitions are awesome, and I will never match the intellectual \\nability of some of the competitors on that platform. I just like to emphasize the other \\nfundamentals of operating in a data science role at a company. I wish there was more \\nfocus on them, but those aren’t really sexy to talk about in the media.\\nWhat are some of these other fundamentals of operating in a data science role at \\na company?\\nWell, one of the fundamentals that everyone talks about is cleaning and prepping data \\nyourself. Finding, pulling, prepping, cleaning, the list goes on. Data manipulation prior \\nto model building is huge. But let’s go beyond that.\\nFor me, a core skill that any data scientist should possess is the ability to communicate \\nwith the business. It’s dangerous to rely on others at a business to actively identify and \\nthrow problems at the data scientist while he or she passively waits to receive work. \\nThere was an article on GigaOM where \\nthe author said, and I’m paraphrasing, \\n“The main thing data scientists do is \\nbuild predictive models. That’s how \\nthey spend most of their time.” This is \\na myth that something like Kaggle will \\nperpetuate.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 162}, page_content='JOHN FOREMAN\\n158\\nWhen that’s the setup, the business often hands over the wrong problems, because other \\nteams have no idea what data science can help and what it can’t.\\nBut if you’ve got a data scientist who’s good at communicating, then that data scientist \\ncan actively engage in conversations with the business and with executives to prioritize \\nhow to best use analytics.\\nI believe a good data scientist is one who’s engaged enough in conversation with the \\nbusiness to say, for example, “Hey, I know you guys think social data is cool, and I do too. \\nBut only 10% of our customers are on Twitter, and it’s anything but a random sample. \\nHave we considered using this other transactional data source to approximate what you \\nwant instead?”\\nSo now we’ve got two skills that are important other than building models: data \\nmanipulation and communication. What else?\\nThere’s one skill that I like to harp \\non: the skill of editing. People \\nhave a strong desire to distinguish \\nthemselves from the herd by flexing \\ntheir expertise. We see this in all \\nindustries and jobs. If you have a \\nparticular knowledge set, you’re \\ngoing to show that off. In analytics, \\nthe way that tendency manifests is by making models overly complex. And by that, I \\ndon’t mean “using a complex model when a simple one gives the same performance.”\\nNo, I mean “using a complex model that is brittle and overly burdensome for the \\norganization to maintain, i.e. whose likelihood of abandonment is high, when a simpler \\nmodel has a better chance of long-term survival.” Sometimes that means using a simpler \\nmodel even when some performance is lost. That takes an editing eye. And in data science, \\nas in many disciplines whether that be journalism, oil painting, or speechwriting, editing \\ndistinguishes the experienced practitioner from the newbie.\\nOne of the big ideas you mentioned is the fact that complex model-building is not \\nwhat a data scientist spends most of his time on.\\nDo you think, in the future when there are more tools built for data scientists to \\ntake care of all the steps before modeling, data scientists will in fact be spending \\nmost of their time on complex modeling?\\nI think a big component of data science is \\nquestioning why you’re doing what you’re \\ndoing — choosing problems to solve while \\nrejecting other problems that are irrelevant to \\nthe business.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 163}, page_content='JOHN FOREMAN\\n159\\nI think we’re already seeing the commoditization of a lot of these skills. It’s not that \\nhard to read a book on R and learn how to build models. It’s pretty easy, and that’s where \\nonline education can come in and fill in a lot of technical gaps. If that’s all you need \\nas a business, I have faith that not only can cheap labor fill in that gap, but tools are \\neventually going to get there, too.\\nThe part that will be irreplaceable is knowing what’s possible from an analyst’s \\nperspective. So, there are a lot of unsupervised techniques, but knowing these techniques \\nand identifying data and opportunities within the company where those opportunities \\ncan be married with the data is not purely a technical problem. It’s a creative problem. \\nIt’s knowing all these things and being able to connect the dots. I feel like that’s going to \\nbe a very human problem for a very long time.\\nThis is related to what you’ve said before — that a data scientist is a Renaissance \\nfigure because it’s connected to sociology, ecology, business, computer science \\nand math where you put it all together to solve problems.\\nRight. One of the things I’ve noticed \\nwhenever we try to hire data scientists is \\nthat the most effective data scientists are \\nthe ones who can communicate effectively. \\nThey can talk to people. They can \\ncommunicate in writing. They can craft an \\ne-mail. They can craft a document that’s \\ntechnical while also lucidly explaining what they’re doing. They can tell a story. Those \\nare skills that are refined by studying, wrestling with and arguing ideas across disciplines. \\nAnd when I encounter data scientists who often enter the discipline tangentially through \\na variety of other disciplines, I see this breadth and the way it facilitates communication.\\nNow, why do I think that’s important?\\nJust as crucial as data cleaning is to the beginning of a modeling engagement, \\ncommunication in the form of change management is crucial during and at the end of a \\nmodeling engagement.\\nChange management is the idea that after you build a model, how do you get other \\npeople to use it? You don’t just walk into a business and say, “I built you a model. Trust \\nit.” There are issues around working with people, communicating, and understanding \\ntheir context that don’t come from just learning to do data modeling. That’s a completely \\ndifferent skill set and it’s one that the Renaissance person (i.e. an employee with a wide \\nbreadth of study and experience) is more likely to possess. If I’m going to be telling \\nIt’s dangerous to rely on others at a \\nbusiness to actively identify and throw \\nproblems at the data scientist while he \\nor she passively waits to receive work.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 164}, page_content='JOHN FOREMAN\\n160\\nstories and communicating to a wide group of people, I need more training than just \\nbeing siloed in the math department.  \\nSo I try to hire people who look like that. They can do all these things. They can talk \\nto people. They can write spaghetti code. They can push around data. They can build \\nprototypes.  \\nWe’re seeing this Renaissance-person idea, i.e. this multidisciplinary, quasi-quantitative, \\nquasi-liberal arts approach affect a whole host of disciplines. Just look at the new “digital \\nhumanities” movement where things like \\nthe Trans-Atlantic Slave Trade Database \\nare being built that historians, linguists, \\netc. are setting their SQL on.\\nI love that we’re seeing data and the \\nhumanities collide, and that’s happening \\nin business, too. That’s why we have this \\nweird hybrid concept of a data scientist \\nwho’s not really a scientist. When you look at the preeminent data scientists out there, \\nthey are not people who are just in a lab acting out your canonical, stereotypical view \\nof a scientist. A lot of them are writers and speakers and executives and a whole host of \\nother things than your typical white-coated scientist.\\nAt the same time, there exist a lot of the people who are doing that are in a Ph.D. \\nor are considering a Ph.D., and one of the reasons they’re attracted to data science \\nis because they’ve heard that it applies to their researching skills in the industry. \\nGiven all the things you mentioned that couldn’t be acquired by staying in the \\nmath library, do you think this idea of the data scientist as an applied researcher is \\na misconception?\\nThere are certain companies where there’s a resemblance between the two. For example, \\nif I’m going to be doing ad targeting on Facebook, I’m going to be part of Yann LeCun’s \\nnew deep learning lab. I imagine for that type of data science, academics are going to \\nfind that a fine transition.  \\nHowever, there is a vast array of companies now that think they need data science talents, \\nand the data science talent they need is not someone who has been specializing in one \\nparticular academic area for six years of graduate school.\\nThat’s not what companies need. They need someone with a broader skill set.\\nJust as crucial as data cleaning is to the \\nbeginning of a modeling engagement, \\ncommunication in the form of change \\nmanagement is crucial during and at \\nthe end of a modeling engagement.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 165}, page_content='JOHN FOREMAN\\n161\\nI’ve seen too many Ph.D.s go into companies with a not-my-job mindset where they’re \\ngoing to wait for you to bring them a problem that fits perfectly with their expertise. If \\nyou don’t bring them that problem, it’s not their job. I get it — they fought hard for that \\ndoctorate.\\nBut this is a dangerous way of thinking that could sour a lot of people in the industry.  \\nI like people who are more aggressive and want to find problems to solve. Maybe they \\ndon’t get to use the techniques they’ve used in the past, but they know there are a lot of \\nanalogous concepts in these techniques. For example, one of the things I put out in my \\nbook is that machine learning algorithms, whether they’re unsupervised data mining \\ntechniques, AI modeling, or forecasting, all have an optimization component.  \\nThe point I’m trying to make is that even though you are focused on one thing, all these \\nthings are related. All these concepts are related. Cluster detection and outlier detection \\nare two sides of the same coin in a graph, and I try to tie them together to show people \\nthat if you can do one of these things, you can do all of them. You should be excited to \\nlearn all these things and figure out which ones you can use forever.\\nYou’re like a kid in a candy store where you’ve got all these opportunities to do these \\nthings. Those are people I would love to see move into this industry. Some of those folks \\nare Ph.D.s, but sometimes the specialization that comes with too much time in graduate \\nschool can be a burden.\\nAs more people move into and understand data science, do you think that the \\nfuture will bring data, and statistics, literacy for the masses?\\nKnowing how slow academia moves, it’s going to take some time to get there. I went \\nto the University of Georgia, and everyone there had to take a math class where the \\ntextbook had a cover with Waffle House on it, which shows you the level of math they \\nwere learning. I think we’re moving into a world where people need to know more math, \\nand it’s no longer acceptable to say, “I’m not good at math. Math isn’t for me.”\\nEveryone’s going to have to be literate. When I worked in management consulting, I met \\na lot of strategy consultants who came from non-quantitative backgrounds, but every \\nsingle one of them knew how to do a pivot table. They knew how to write a VBA macro \\nand filter data. They knew the basics of how to move data around in a spreadsheet. They \\nwould never call it math or programming, but it’s pseudo-math-programming. Oddly \\nenough though, those simple skills were an essential part of what the client was paying \\nfor.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 166}, page_content='JOHN FOREMAN\\n162\\nI think there’s going to be more of that need in the future. People are going to need to \\nknow how to do things like significance tests, sample size calculations and so on. We \\nneed to find a way to fit this data literacy into a liberal arts curriculum. That requires \\nmotivating the concepts.  \\nIn “Data Smart” I try to motivate people to \\nlearn these techniques as much as possible \\nby showing how to explicitly use them in \\nbusiness. The cool thing with teaching \\npeople later on in life, once they have a job, \\nis that the motivation totally clicks. When \\nit comes to teaching students, especially \\nthose majoring in something else, they’re \\nunmotivated. School’s never really cracked that nut, but I think it’s headed that way. \\nPeople need to be data-literate. There’s no way we’re going to get by without it.\\nAt the same time, there’s a debate in some parts of the Valley. There are people \\nsaying that numbers are pushing out the usage of human intuition, and that there’s \\nan over-usage of analytics, where you’re AB testing every shade of green on your \\nbutton and you go with whichever one performs the best. As the future becomes \\nmore driven, what’s your take on this type of criticism?\\nI do agree, and I think that approach is dangerous. At MailChimp, we often make fun of \\nKey Performance Indicators, aka KPIs, which are the lifeblood of the corporate analytics \\nworld. When we listen in to the quarterly calls our competitors have, we can see they’re \\ndriven by metrics like ARPU (average revenue per user) so much so that they’ve lost \\nsight of things that are not unimportant but are just harder to measure.\\nYou’re optimizing average revenue per user not because it’s the most important things \\nbut because you can measure it and Wall Street can measure it and look at it. That’s a \\nway to grade your company, but what does average revenue per user mean when there \\nare users on your Facebook site saying, “I fucking hate you guys”? That could be a red \\nlight that something is wrong, but you’re not paying attention to it because it’s not a \\nmetric you care about.\\nI think we should leave room for people to be creative and to think about soft things like \\ncustomer happiness. At MailChimp, we purposely don’t measure a lot of metrics against \\nour marketing team. Our marketing team has a budget, but we don’t look at things like \\nconversion. We took out billboards in cities across the US, and the billboards just have \\na picture of Freddie, our chimp mascot, with a blue background and no words at all. \\nThe only people who really understand what it is are already MailChimp customers and \\nmaybe our competitors.  \\nPeople are going to need to know how \\nto do things like significance tests, \\nsample size calculations and so on. \\nWe need to find a way to fit this data \\nliteracy into a liberal arts curriculum.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 167}, page_content='JOHN FOREMAN\\n163\\nWe can’t look at conversion of that, or how it affects revenue. That’s not something we’re \\ninterested in. It’s about giving our users a good experience. They see a billboard on their \\nway to work, and they’re thinking, “ Aww... That’s MailChimp.” And there’s value there. \\nIt’s like an inside joke in a subtle way. I might go to a conference and have a MailChimp \\nuser come up to me who’s excited to meet \\nsomeone from MailChimp. They might say, \\n“I love using your site. It’s so much fun. It’s \\none of the best sites I use for my job.” That’s \\ngreat. That’s a kind of person who’s going \\nto go tell other people about our product, \\nbut we don’t have to measure it.\\nIts better that we just keep delighting customers so they tell other people about the \\nproduct rather than AB-test button colors. I’m perfectly happy to leave things in the \\nhands of talented designers, people who are not quantitative but know what they’re \\ndoing.\\nHave you ever heard of Tony Hsieh, Zappos CEO, Downtown Project in Vegas? He \\nmoved the headquarters of the online retailer from the Silicon Valley to Vegas. His \\nperspective is that it’s important to engender serendipity but not with contrived \\nmethods. Although he runs a tech company, he’s much more open to the intangible \\nthings such as human creativity and experimentation.  \\nIt’s interesting having two well-known companies in very different parts of the \\nworld that are technology-driven but not in Silicon Valley, and as a result they \\nthink of things differently than other firms. Do you think there’s any relationship \\nbetween being not in the Valley and being able to think the manner you described?\\nHonestly, part of that for us is that we are privately owned. We are not seeking to go \\npublic, and we’re not taking funding from any other companies. We have the freedom to \\nbe creative, because there’s no one breathing down our neck.\\nMailChimp’s bootstrapped, and, because of that, we have immense freedom. We’re not \\ntrying to sell the company to someone else. When your goal is to sell your company, \\nthings can get perverse. You get distracted, and that is dangerous from a competitive \\nstandpoint. If we get distracted, we might check out or lose sight of what other competitors \\nare doing. Part of our different perspective is driven by being outside of the Valley. But \\nanother large part of it has been knowing that we’re not taking funding.\\nA lot of people these days are interested in starting companies — being founders, etc. \\nWe at MailChimp are interested in being a company in the long-term. That looks very \\nAt MailChimp, we often make fun \\nof Key Performance Indicators, aka \\nKPIs, which are the lifeblood of the \\ncorporate analytics world.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 168}, page_content='JOHN FOREMAN\\n164\\ndifferent, and I’d argue it’s a better place to be as a data scientist. When you’re a data \\nscientist at a young company looking to go public or be acquired, then your work ends up \\ngetting commandeered for marketing purposes. It becomes difficult to invest in analytics \\nthat might have long-standing customer value versus some short-term wow! factor.\\nWow. That’s a pretty amazing distinction between MailChimp and other tech \\nstartups. I’ve heard of one project at MailChimp called the Email Genome Project. \\nCan you talk more about that?\\nThe Email Genome Project was essentially an infrastructure initiative at MailChimp to \\ncreate a dossier for every e-mail address we’ve ever seen and store data about it. In fact, \\nright now it resides in RAM. It’s one of the largest in-RAM databases in the world. We use \\nRedis to do it, so it’s essentially a big Redis key-value store summarizing interactions \\nwe’ve had with about three billion unique e-mail addresses.  \\nWe built APIs around this data store \\nand use those internal APIs to power \\ndata products. We have an anti-\\nabuse AI model called Omnivore, \\nand that runs off EGP . One of my \\nfavorite internal products is called \\nNotABot. When users sign up for MailChimp, we check NotABot, and if you look legit, \\nwe hide CAPTCHA because of everything we know about you. We say, “We’ve already \\nlooked at your behavior. We know you’re a human, so you’re good to go and we’re just \\ngoing to hide the CAPTCHA.”\\nThe funny thing is that the data science project is not something built in D3. It’s not \\nsomething cool with bubbles. Literally, this data science product is the absence of \\nsomething. All I’ve done is taken CAPTCHA away, and I feel very proud of that. Removing \\nthings improves the user experience; this is one way to make users’ lives suck just a little \\nbit less.\\nWe had CAPTCHA in front of our help form to contact support, but when you want to \\ncontact customer support, you already have a problem. It’s a perfect opportunity to \\nreduce friction for these confused people rather than adding some shitty CAPTCHA icing \\nto their confusion cake. That’s a small project we’ve done, and we’ve done a lot of things \\nlike that using EGP’s internal APIs. We tell people, “Here’s what this API call does. Here’s \\nthe data that backs it.” Then we expose the API call to the devs and see what happens.  \\nWe did another project called Send Time Optimization where we noticed a couple of \\nthings. One was people asking what time they should send. People were going online \\nMailChimp’s bootstrapped, and, because of \\nthat, we have immense freedom. We’re not \\ntrying to sell the company to someone else.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 169}, page_content='JOHN FOREMAN\\n165\\nand just reading anecdotes. It’s not like all your customers go to work from 9 to 5 and \\ntake lunch at noon. But those are the kind of assumptions you’ll see in anecdotes from \\nsupposed marketing gurus.\\nOne of the things data science promises is that we can provide people’s personal \\nexperiences. Using EGP , MailChimp can tell you about your particular subscribers. What \\ndo you know about their behavior? If you’re writing to line cooks who work the night \\nshift, they’re probably not awake at 2 PM. So what Send Time Optimization (STO) does \\nis it pulls all the records for these email addresses (even if we have new e-mail addresses, \\nwe’ve seen them before due to other MailChimp email they’ve gotten), and using those \\nrecords, STO hands you a send-time recommendation. Anecdotes are for chumps.\\nHow does MailChimp then use data science to power these personalized product \\nfeatures?\\nSo far I’ve laid out a few of MailChimp’s data science products: Omnivore for anti-abuse, \\nSend Time Optimization, and NotABot. But we’ve got a lot more. For instance, we use \\nAI models trained on past interactions with customer support to make knowledge-based \\narticle recommendations. We use data mining algorithms to find segments on people’s \\nlists and suggest those segments to them. We use optimization modeling to schedule \\nour customer support employees to meet forecasted ticket demand. We use a lot of Holt-\\nWinters with prediction intervals when making infrastructure forecasts.\\nSome of these products are supervised machine learning products, others are classic ops \\nresearch products, graph mining products, forecasts, etc. We use whatever techniques \\nand whatever data gets the job done.\\nSome products are user-facing, some are internal. Some are big and require tons of \\ninfrastructure. Others, like our likelihood-to-pay model, are nothing more than a logistic \\nregression whose coefficients fit in a single short vector.\\nSo how do we use data science to power these products? Any way we can.\\nThe one common theme these products have is not an approach or a data source or \\na technology. The one common theme is that each product solves a problem for the \\nbusiness or the customer. I run my data science team like an internal consultancy. We’re \\nall about being useful.\\nThere’s this joke going around making fun of data scientists that says that a data \\nscientist is just a statistician who lives in California who calls himself that to get a job. \\nGiven that you’re someone who is both professionally a data scientist, yet at the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 170}, page_content='JOHN FOREMAN\\n166\\nsame time seems to share a sense of skepticism about things that are overhyped, \\nwhat is your take on the burgeoning field of data science?\\nI think the term “data science” is somewhat ludicrous. The phrase “Data science” is two \\nvague words glommed together that don’t actually describe most of how I spend my time. \\nData science as a term may die, nothing but a fad title, but the skill set is so important \\nthat it will spread into many roles within the business. It wouldn’t surprise me if, a few \\nyears from now, most MBAs require a couple of data science-style classes.\\nThe field is just going to get into the water.  \\nThe more you investigate data \\nscience as a category, the more you \\nsee it’s an umbrella term disguising \\ninsane amounts of variety in skill sets \\nand backgrounds. A data scientist \\nis unlike a stonemason in that way. \\nThere isn’t one background for data \\nscientists and there isn’t one thing that we do. We’ve seen data scientists who are more \\ndata engineers. We’ve seen data scientists who are AI professionals. We’ve seen data \\nscientists who are good at visualization and doing front end development.  There are \\ndata scientists like me who are nothing more than embedded strategy consultants who \\nlike math.  \\nThe term could die or fracture into multiple titles, but need for those skill sets won’t. \\nStudents tend to worry about that and say, “People won’t need data scientists by the \\ntime I graduate.” They’ll need something like a data scientist for sure, so just call yourself \\nthat. My past job titles used to include words like “analytics” and “business intelligence.” \\nThat’s fine. The terms come in and out of style, but if you are good at understanding \\nproblems and communicating with people, and answering their questions with data, the \\nneed for you in particular will never go away. You will never be automated. You will have \\nplenty of job security.  \\nDuring a conversation we had with D.J. Patil, he told a story of how, at some point, \\nhe consulted for the US government when they were in Afghanistan. He mentioned \\nhow there was a lot of chaos and everything was going crazy, but there was a lot \\nof opportunity that came out of that chaos and you could influence people because \\nno one knew what was going on.\\nData science seems to be evolving in the same way: where there’s chaos, there’s \\nuncertainty and as a result, plenty of opportunity. Do you think there are going to be \\nThe more you investigate data science as a \\ncategory, the more you see it’s an umbrella \\nterm disguising insane amounts of variety in \\nskill sets and backgrounds.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 171}, page_content='JOHN FOREMAN\\n167\\nlarge opportunities in the future as data and technology become more prevalent?\\nYes. I touched on this in an article I wrote about Disney . The “meat space” world, i.e. \\nthe one not confined to a screen, is full of chaos and uncertainty, and so there’s huge \\nopportunity to take the analytics we’ve been doing for web companies and move it out \\nof that orderly sandbox and into the physical world.\\nObviously, wearables are an immediate example of how that’s happening. But humans \\nare being “cookied” in meat space by more than just wearables. Think about Nest (and \\nhow much Google paid for it). We’re doing all sorts of physical tracking, such as MAC \\naddress tracking in stores and appending demographic data to surveillance video feeds, \\nso we understand a bit about your demographics and what racks you go to in department \\nstores.\\nDisney saw this opportunity when \\nthey introduced a long-range tracking \\ncomponent to their wristbands. They \\ntrack you in physical space so that they \\ncan provide personal experiences in the \\nphysical world and not online. My kids \\nrode “Pirates of the Caribbean” eight \\ntimes at Disney World. Then we visited \\nthis animatronic Mickey and all he would talk about were pirates, because he knew that’s \\nwhat my kids were into based on their transactions in the physical world.\\nThe physical world is messy and chaotic, nonetheless we can understand people’s actions \\nas they move throughout that space. That’s where I see the most opportunity for data \\nscience.\\nIt sounds like the overarching theme is that the personalization of the internet, of \\nvisual space, is going to move towards the personalization of the physical world?\\nIt’s going to merge. In fact, the internet is simpler than the real world because I \\ncan “cookie” you on the internet. We’re going to learn how to cookie people all over \\nthe physical world too, and I think people are freaked out about this from a privacy \\nperspective. I agree and sympathize. There’s a creepy side to the word “personalization.”\\nIt’s a frightening affront to our personal freedom. While I’ve gotta live my work-a-day life, \\nthere will be companies tracking me that will be dedicated to getting me to do one thing, \\nlike opening a credit card or drinking a Coke. It’ll be data-driven asymmetric warfare. \\nThey have my data. They know my issues — financial, personal, etc. Their models will \\nThe physical world is messy and chaotic, \\nnonetheless we can understand people’s \\nactions as they move throughout that \\nspace. That’s where I see the most \\nopportunity for data science.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 172}, page_content='JOHN FOREMAN\\n168\\nknow how to target me. They can pull my strings.\\nI think that is concerning, but, at the same time, we’re doing this to ourselves and share \\nthe blame. I install whatever mobile app I want to and just blaze through the permissions. \\nPeople always say “but it’s my data.” If you give it up in exchange for a free game, it may \\nnot be anymore. The undervaluation of personal data by consumers is endemic today.\\nSo yes, personalization on the internet will morph into personalization everywhere. But \\nwe’ve got to figure out all this creepy stuff as we head in that direction. Part of that will \\nbe cultural, and part of that I’d imagine will be legal and legislative.\\nA term I’ve heard before is “data superhero”, and it’s the idea of putting yourself, \\nas a data scientist, into a position where no one in Congress knows what data \\nscience is. They’ve never read “ Data Smart”, and the superhero is the one who \\nknows what it is and is able to inform people and stand up for the public interest.\\nData scientists have a particular set of skills and knowledge that makes them essential to \\nbusiness today. A lot of that knowledge and skill is being used to blaze new trails for how \\nwe as individuals, consumers, citizens, etc. interact with businesses, our government, \\nour peers. There is abuse and confusion as well as opportunity to fundamentally change \\nentire industries and practices for the better.\\nGiven that, data scientists can take on public-facing roles as subject matter experts. \\nPeople want to know what’s possible with data, both to understand if abuse is possible \\nas well as to understand if progress is possible. Too many people think of data science as \\nmagic, but data scientists can come in and bring the discussion back down to earth. We \\ncan say, “no that’s not possible,” and “yes that’s possible,” and “yes that other thing is \\npossible but you’ll need express legal consent from consumers,” and so on.\\nAnd that’s a role we should take up, because if data scientists don’t engage the conversation \\nthen we should expect voices with less training to fill that information vacuum.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 173}, page_content='JOSH WILLS Director of Data Science at Cloudera\\nTo start the interview, we’d love to revisit your undergraduate days, from when \\nyou were just going into college, to graduate work, and how your experiences led \\nyou to where you are now. \\n \\nI was a math major in college. The funny thing is that I never really liked math when \\nI was growing up, even though I was pretty good at it. I was more into history and \\npolitical science, until I got to high school and discovered calculus. I was enthralled. \\nI loved calculus and felt that it was the first interesting piece of math that I had ever \\nencountered.\\n \\nI was a pretty big nerd in high school, which won’t be shocking to anyone. I did things \\nlike study for AP exams for classes I wasn’t actually taking. During my junior year, I took \\nexams for AP Political Science and Comparative Government without actually taking \\nthe classes. I did well on those exams, so I ended up doing the same for Art History, \\nEconomics, and Physics during my senior year. I also read all of Calculus AB and BC in a \\nsemester, and then I got into multivariate calculus and proceeded to linear algebra, all \\non my own. I was just completely enthralled with the beauty of mathematics, the same \\nway a person would appreciate a beautiful painting or work of art.\\n \\nFascinated with the beauty of calculus at an early age, Josh \\nWills majored in pure math at Duke. His first introduction \\nto statistics was in the final year of university, where despite \\nsome misgivings of it being not nearly as interesting as \\nhyperbolic partial differential equations, he actually fell in \\nlove with the discipline. \\nAfter a brief stint at IBM, he returned to do a PhD in \\nOperations Research at UT Austin, trying to solve NP-hard \\nproblems. Afterwards, he joined the startup world, working \\nas a statistician first at Zilliant, then Indeed and finally \\nGoogle.\\nIn this interview, Josh offers beautiful thoughts on the intersection of literature and data \\nscience, learning through humility and masochism, profound moments in open source \\nprojects, and the deep impact that Google’s engineering had on him. Josh Wills is currently \\nthe Senior Director of Data Science at Cloudera, where, according to him, he “makes data \\ninto awesome.”\\nMathematics, Ego Death and Becoming a Better \\nProgrammer'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 174}, page_content='JOSH WILLS\\n170JOSH WILLS 170\\nI ended up going to Duke University. The best part about Duke was that I got to take \\nwhatever math courses I wanted right away. My first course was graduate level topology. \\nThat was interesting because I was taking it with the other math freshman who \\nwere really good mathematicians. It became apparent to me relatively quickly that I \\nwhile was good, the other freshmen were on another level altogether, which was very \\nhumbling. I think everyone \\nruns into this at some point in \\nlife, and I felt relatively lucky \\nthat I encountered it during my \\nfreshman year because it gave \\nme time to recover.\\n \\nAnyway, I stuck with math, and I thought I was going to become a math professor. \\nBut I was also interested in many little side things- I did philosophy, economics for a \\nwhile, and then  became interested in cognitive neuroscience. I was lucky enough to \\ndo a Research Experience for Undergraduates (REU) fellowship at Carnegie Mellon the \\nsummer after my sophomore year, modeling road and spatial navigation. That was my \\nfirst introduction to real programming in MATLAB, building large models to simulate \\nbrain function. That experience is what got me interested in programming in general.\\nDid this push you to start taking programming classes at Duke as well?\\nYes. I took Duke’s introductory courses in computer science and I learned how to program \\nin C++. I never really studied algorithms or operating systems or other things computer \\nscience majors study. In my professional career, I’ve discovered all of these huge and \\nembarrassing gaps in my computer science knowledge, usually during job interviews.\\n \\nAt the start of my senior year, I decided to put the academic career on hold and go get a \\nreal job. I was interviewing with some startups and accepted an offer, but it was rescinded \\nas part of the whole dotcom implosion thing that was happening in late 2000/early 2001. \\nI wasn’t alone here, and Duke’s recruiting office was really great in helping folks find \\njobs elsewhere. I ended up getting a job in IBM’s Austin office. My first day was June \\n17th, 2001, and the week after I started, IBM announced a hiring freeze, so I suppose I \\nslid in just under the wire.\\n \\nIBM Austin had a hardware group that does chip design and system bring-up, which \\nis where you hack early stage hardware to get around all of the bugs so that you can \\nload and run an operating system. I was managing a MySQL database of test data \\nfor microprocessors. All in all, it was 15 gigabytes of data, which at the time seemed \\nenormous, but now seems laughable — my phone has more storage than that whole \\nvolume of test data! I was building dashboards and running statistical analyses of machine \\nI was just completely enthralled with the beauty \\nof mathematics, the same way a person would \\nappreciate a beautiful painting or work of art.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 175}, page_content='JOSH WILLS\\n171\\nperformance and chip performance; trying to predict how fast a chip would clock based \\non a number of measurements that were made during wafer fabrication. It was classic \\nstatistics, classic data analysis, and just learning how to program. To be honest, it was \\npretty dull, and I got bored with it fairly quickly. I also have this masochistic approach \\nto achievement, and so sometimes I like to do things just to prove that I can do them, \\nregardless of whether or not it’s actually a good idea or not. So in that vein, I applied for \\nand got into the Operations Research (OR) graduate program at the University of Texas \\nat Austin (UT). UT didn’t have a statistics department, which is what I actually wanted to \\nstudy, and OR was as close as I could get without having to leave Austin, which was just \\na really great place to be at the time.\\n \\nAs an undergraduate, I didn’t take any statistics courses at all until my very last \\nsemester, which was really my blow-off semester. It was when I took music appreciation, \\nintroduction to logic (oddly enough, a philosophy course), and introduction to statistics. \\nIntro stats was actually a requirement to graduate, but I felt like it was beneath me after \\nall of the abstract algebra and hyperbolic partial differential equations. And the funny \\nthing is that I completely fell in love with it. A lot of the philosophy and neuroscience \\nstuff I was into were things involving epistemology and symbolic reasoning, about \\nunderstanding how we can say that we know something to be true. \\n \\nAnd statistics is about quantifying uncertainty and what we can’t know.\\n \\nPrecisely! It is the quantification of what is knowable and what is not. Here is your data, \\nwhat can you say that you know? It was deeply appealing to me. Personally, that kind \\nof stuff really winds my clock. I loved statistics. Fast-forward a couple of years, and now \\nI’m at UT and taking a full graduate course load in OR. I did three courses a semester for \\ntwo years to get my Master’s degree, while simultaneously working at IBM. That was a \\nterrible idea. It was absolutely horrible. I had no life.\\nIt sounds like you learned how to do the relatively simple statistical analysis at IBM \\nand thought, “I want to expand my intellectual horizon.”\\n \\nVery much so. My IBM introductory software engineering job was pretty easy, and I wrote \\na bunch of crazy Perl scripts that more-or-less automated my job. But I had this kind of \\nresidual itch from my statistics class and from seeing that statistics was actually pretty \\nuseful to people in the real world. My mental model at the time was that if you wanted to \\nlearn more about something, school was a pretty good place to do it, and so I went back \\nto school.\\n \\nA semester into my graduate program, I made another switch: I changed teams at IBM to \\nbe able to do some “real” programming, not just dashboards and Perl scripts. I switched'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 176}, page_content='JOSH WILLS\\n172\\nto a team did very low level firmware programming in C++. This was basically writing \\nfirmware for hardware systems that didn’t fully work yet because they haven’t debugged \\nall the circuits. I was working as part of a team and learning to use things like source \\ncontrol, write tests, all of those good practices that I never learned in school. More than \\nanything though, the most useful skill I learned was how to debug black box systems. \\nI was trying to run firmware on a piece of hardware that didn’t really work yet, and my \\njob was to figure out a way to make that software run by hacking around whatever bugs \\nI came across in the hardware itself. I didn’t know anything about hardware. I still don’t \\nknow anything about hardware. I can’t even program a VCR. I think that I became a \\nsoftware engineer because I can’t understand any system that I didn’t design myself. \\n \\nAnyway, the black box system is a piece of hardware that doesn’t work. I would give it \\nan input, and it would not give me an output. I had to figure out a hack, some sequence \\nof commands, that would cause this piece of hardware to begin communicating with \\nthe rest of the system. And this skill, the art of debugging something that you don’t \\nunderstand at all, is maybe the most useful thing I learned there.\\n \\nWhat did you end up learning through this experience of debugging black box \\nsystems?\\n \\nI don’t think there’s any secret to it: I’m \\nobsessive. I was one of those kids that played \\nwith Legos for five or six hours straight. \\nI’m still pretty much like that. I was born \\nin 1979, so I’m borderline millennial. It is \\nunacceptable to me for a computer system \\nto not do what I want it to do. I was willing \\nto beat on the black box hardware for whatever amount of time was required to make it \\ndo what I wanted.\\nI’ve had a few instances in my life where I have worked on a very satisfying problem. A \\nsatisfying problem is one where your technical skills are good, but the problem is just a \\nlittle bit too hard for you. You’re trying to do something slightly more difficult than what \\nyou already know how to do, and that is great, great feeling. I can lose myself in those \\nkinds of problems. That’s typically when my personal relationships tend to fall apart, \\nbecause I’m not really paying attention to anything else.\\nThere was this trend for awhile in data science job interviews to have candidates analyze \\nreal datasets during the interview. I’m a huge fan of this practice. I had one job interview \\nwhere they gave me a problem and a dataset and two whole hours of quiet time to just \\nsit and do data analysis. It was maybe the happiest two hours of my entire year. I should \\ndo more job interviews just so I can do that. \\nIt is the quantification of what is \\nknowable and what is not. Here is your \\ndata, what can you say that you know? \\nIt was deeply appealing to me.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 177}, page_content='JOSH WILLS\\n173\\nYou had mentioned how, at one point of your college career, you were burned \\nout from academia. One of the hallmarks of academia seems to be that once \\nyou’ve reached a certain point, you have the opportunity to spend all of your time \\nobsessing over an open problem. Given that your personality type seems to fit \\nthat role, why wasn’t academia appealing to you anymore?\\n \\nAs a pseudo-millennial, I’m not just entitled, I’m impatient. I don’t think the requirements \\nof academia were appealing anymore; there were large sets of things I would have to \\ncomplete before I reached that point of being able to obsess over an open problem.\\n \\nOnce you’re a graduate student, you work for a professor on that professor’s grant, doing \\nlargely what the grant says you’re supposed to do. Then, you do a post-doctorate for a \\ncouple of years and become an assistant professor. You go through that horror, and, after \\n10 years, you get tenure. It’s a really long time to wait before you can have that promise \\nof obsessive problem solving fulfilled. Even then, I don’t feel the promise is fulfilled \\nbecause you have to spend a lot of time working on grant proposals and managing your \\ngraduate students and postdocs.\\n \\nNow I’m 35 years old. Time-wise, I may be roughly at that point in my career now. I have \\na really great job where I get to do what I want and do, whatever is interesting to me. But \\nit’s also a be-careful-what-you-wish-for situation. The freedom to work on whatever you \\nthink is interesting is stressful because there’s no one else you can blame if you’re not \\nworking on the right thing or if you miss a technology shift that has a profound impact.\\n \\nAmr Awadallah (Cloudera’s CTO) wrote a blog post about what a chief technology officer \\ndoes. He was comparing the CTO’s performance to CFO’s performance. The CFO is not \\nresponsible for making the sales numbers every quarter, but if there is a big surprise \\nmiss, the CFO gets fired. Similarly, the CTO is not responsible for shipping products on \\ntime, that’s what the VP of Engineering is for. But if the CTO misses a major technology \\nshift, he or she gets fired. \\nI have a CTO-kind of job right now. I am free in my job to think about analytics, the future \\nof data science, what exactly is coming down the pike. If I miss something, I should be \\nfired because that miss could have profoundly negative consequences for Cloudera.\\n \\nThere’s tremendous pressure that comes with that freedom. Now that I get that, it’s \\nslightly horrifying. I have a fair amount of anxiety about it.\\nCan you talk a little bit more about what happened in between IBM and Cloudera? \\nHow did you get to this point?\\nWe skipped the part of graduate school when I was taking a class in price optimization.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 178}, page_content='JOSH WILLS\\n174\\nOne of my professors worked with a local startup in Austin called Zilliant. I wanted a job \\nfocused on operations research, so my professor hired me to work as a data analyst there. \\nThere, I went back to SAS and R and started doing data analysis and building models for \\nthings like market segmentation and price elasticity.\\n \\nWhen you come from academia, you tend to \\nthink the world is more interesting than it \\nactually is, or that a problem is more complex \\nthan it is. The reason that price optimization \\nhasn’t really taken off as a software discipline \\nis because the primary pricing problem for \\nFortune 500 companies is to sell things for \\nmore money than it costs to make them. If \\nthey don’t know how much it costs to make things, they can’t know how much they \\nshould sell those things for to ensure that they make a profit. It’s not rocket science. You \\ndon’t need a data scientist to do that. You just need good reporting.\\n \\nWhy is it that companies don’t know this bit of crucial information?\\n \\nIt seems like a fundamental component, and yet many of them do not actually know. The \\nproblem is incentives. The person who is selling the deal, the salesman, is going to get a \\ncommission, and his or her income depends on the commission. They’re putting together \\na package of things that are going to be sold as a part of the deal. There’s going to be \\nsome materials and professional services, that’s just text and contracts. These contracts \\nget read and improved, but no one necessarily understands how much it’s going to cost \\nto fulfill these contracts. There’s way too much variance. And people have a tendency \\nto be very optimistic. They don’t think they’re going to have conflicts. They don’t think \\nthey’re going to have errors. They don’t think there are going to be hurricanes.\\n \\nThese aren’t trivial problems, but they’re also not the kind of problems that are amenable \\nto the complicated data analysis techniques that you typically learn in graduate school. \\nThey’re very different kinds of problems.\\n \\nThey are simple problems. They’re simple but not easy. Losing weight is simple but not \\neasy. Most industrial problems are simple but not easy.\\n \\nSo after Zilliant, did you make it your goal to attack the industry problems?\\n \\nI like to be useful more than anything. I like to solve people’s problems. I like to be \\nhelpful. I’m a helpful person by nature. I enjoy abstractions. I enjoy art and weird stuff \\naesthetically, but I would rather have my day-to-day work be more focused on people’s \\nproblems and making their lives better. The beauty and the theory are never so appealing \\nWhen you come from academia, \\nyou tend to think the world is more \\ninteresting than it actually is, or that \\na problem is more complex than it is.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 179}, page_content='JOSH WILLS\\n175\\nthat they manage to draw me away from the real problems.\\nYou worked at a bunch of different startups before Google. Were you solving \\ndifferent initial problems at these startups? What prompted the shift to Google?\\n \\nIt really took me forever to leave Austin. I could make a list of all of the bad financial \\ndecisions that I made because I was too afraid to leave Austin. I had a job offer from \\nGoogle to be an engineering analyst, which I turned down in 2005. I turned down a data \\nscience job at Facebook in 2007. I try not to think about that one too much.\\nThe thing that finally got me to San Francisco was auction theory. I was working on \\nmy PhD at UT and had taken some classes in game theory and mechanism design, and \\nwe covered auction theory. I absolutely loved it; it was beautiful math that could also \\nbe used to create socially optimal outcomes. I was really curious about how auctions \\nworked in the real world, but there weren’t really any places in Austin where I could go \\ndesign auctions for a living. I was fortunate that I had kept in touch with Diane Tang, who \\nhad tried to hire me at Google back in 2005 and was running Google’s ads quality team \\nwhich was responsible for the ad auction. \\nShe’s now Google’s first and only female \\nGoogle Fellow, but at the time, she was just \\nmy friend who hired me to go to Google and \\nwork on auctions full time. She has been \\nan amazing mentor to me, one of the most \\nimportant people in my career.\\nWhat was it like on Google’s ad quality team? Was that a confluence of smart \\npeople who had studied auction theory as well and then implemented it in the real \\nworld?\\n \\nI think the thing to know about Google is that it is smart software engineers with no \\nspecific expertise designed most of the core systems. Eric Veach, who had a PhD in \\ncomputer graphics but no machine learning experience, designed Google’s original \\nmachine learning system. Eric was tasked with the problem, read a book, and came up \\nwith a wholly new solution.\\n \\nI remember when I first got to Google and read about how that system worked. It was the \\nmost brilliant and unique solution to the world’s first truly large-scale machine learning \\nproblem. His original algorithm was really clever and I’ve never seen anything like it \\npublished anywhere, and I don’t think we ever will because, of course, Google has now \\ngone on to even more advanced machine learning systems.\\n \\nEric was also the person who designed Google’s original auction algorithm. Again, Eric \\nThey are simple problems. They’re \\nsimple but not easy. Losing weight is \\nsimple but not easy. Most industrial \\nproblems are simple but not easy.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 180}, page_content='JOSH WILLS\\n176\\nis a graphics guy, he’s not an auction theorist. So he read a book about second-price \\nauctions, and he came up with this very simple generalization that is called the GSP , the \\ngeneralized second price auction.\\n \\nI worked on a number of auction-related features and launches at Google. I really enjoyed \\nit, but at the end of the day, the auction can only be as complicated as the understanding \\nof the auction participants. Advertisers are wonderful, but they’re still just people, while \\nthe really interesting bidding strategies and auction models are so complicated and \\ncomputationally intensive that they require serious software engineering chops just \\nto participate in them. It wasn’t in Google’s interest to have an auction that was so \\ncomplicated that no one besides auction theorists could appreciate it.\\nThis seems to be emblematic of one of the differences between academia and \\nindustry. In academia you’re focused on getting the optimal solution. In the real \\nworld, you find that your implementation priority queue is dominated not only by \\noptimality but also by feasibility and expedience. Was this shift hard for you to see \\nand interact with?\\n \\nI don’t think so. I was fairly lucky. Most of my graduate work in operations research \\nwas working on impossible problems. Operations research consists primarily of very \\nhard problems where you cannot find the optimal answer. The job is to do the best you \\ncan, and I actually love those kinds of problems because the expectations are low. If the \\nproblem is impossible and you are able to do anything even remotely close to a good \\nsolution, it’s kind of amazing.\\nThere is a joke: “If you have a NP-hard problem and you make it slightly better, \\nyour solution is exponentially better”?\\n \\nI could not agree more. It was a good headspace to be in. Operations Research is a very \\npractically oriented science and academic discipline, so transitioning to that industry \\nmindset was not one of my problems.\\nYour story illustrates that to be a great data scientist, you have to be slightly \\nmasochistic. You have to be willing to go out of your way to be in areas where \\nyou’re the least skilled person in that domain and programming. What was your \\ndevelopment like as a programmer?\\n \\nI may not be able to give myself too much credit. I was a pretty good programmer in school \\nwith algorithms and optimization routines, but I wasn’t really a great team programmer. \\nEven at IBM, although I was on a team of four developers, we really didn’t have to work \\nall that closely together. The structure of the software was already well-defined and the \\ninterfaces were clear.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 181}, page_content='JOSH WILLS\\n177\\nWhen I was at Zilliant, the company decided to redo their pricing engine. The data \\nanalysts got together and wrote a spec about what they wanted the pricing engine to \\ndo. It required some domain expertise, and of course I had programmed for many years \\nat IBM. So I was tasked with doing the implementation, but it quickly became clear to \\nbasically everyone that I did not know how to build a real software product from scratch.\\n \\nI give the managers at Zilliant a lot of credit for what they did next: they apprenticed me \\nto a much more senior developer, John Adair, who is another great mentor and friend. \\nFor three months, he implemented the spec, and I unit tested it. I wrote unit tests and \\nintegration tests for his code every single day for three months.\\nIt was the most useful learning experience of my professional life, because John writes \\nbeautiful code. When I describe this experience to people, they always make a face, \\nbecause it sounds tedious and awful and lots of developers hate writing tests. But when \\nit’s your job, and you’re measuring yourself the whole day, it can actually be fun. And I \\nwas just learning so much about how you actually build systems from scratch.\\n \\nI was somewhat involved in writing the spec for what the software was going to do, so \\nI knew both the spec and the software very well. What was interesting was was getting \\nto see how to write code that is designed to be testable. John and I went through a few \\nrefactorings over the course of \\nthe project, but the QA team only \\nfound like two bugs when the \\nsystem was tested. It was the best \\nsoftware I’ve ever been a part of. \\nIt was beautiful code.\\n  \\nAfter I left Zilliant, I did a brief \\nstop at Indeed, the job search \\nengine. There, I was a statistician. \\nI wrote some code, but I was primarily there in my capacity as a statistician. And when I \\nleft Indeed to go to Google, I was also hired as a statistician. For whatever reason though, \\nwhen I actually got in the door at Google, all I did was write code. There was just so much \\ngreat code everywhere that you could read and use and learn from. After nine months \\nat Google, the company changed my job title from statistician to software engineer, and \\neven gave me a promotion. I’ve always felt a little shady about that, because there’s \\nbasically no way I could have ever passed a Google software engineering interview.\\n \\nFor someone like me, I am really just a good mimic, and I can pick things up pretty quickly. \\nBeing inside Google with so much good code, was an absolutely amazing experience. I \\nam 20 times better as a software engineer just because of my time at Google and seeing \\nWhen I describe this experience to people, \\nthey always make a face, because it sounds \\ntedious and awful and lots of developers hate \\nwriting tests. But when it’s your job, and you’re \\nmeasuring yourself the whole day, it can actually \\nbe fun.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 182}, page_content='JOSH WILLS\\n178\\nwhat the people who are really good do. It was an unparalleled experience, absolutely \\namazing.\\nCan you give us specific examples of how you did that? Do you go to the people that \\nwrote code, understand the problem from them, see how you would implement it \\nand read it? What was your procedure for learning all that you did?\\n \\nI don’t know how other places do it, but Google imposes it on you. They force you to code \\nthe way Google codes. Readability standards are a big deal. You have to get readability \\nin any language that you want to be able to commit to Google’s source code repository, \\nor have your code approved by someone who does have readability. To get readability, \\nyou have to write a large chunk in a way that adheres to Google’s coding style, and the \\nprocess of readability reviews is basically hazing for software engineers. I will never \\nforget my readability review for Sawzall.\\n \\nI was writing some code to analyze the ad logs, studying correlations between advertiser \\nbids and various machine learning probabilities that we were calculating. I wrote some \\nbasic correlation routines and then submitted them to the core Sawzall libraries, and \\nit turned out that my code reviewer was Rob Pike. If you don’t know Rob, he’s an old \\nschool AT&T Labs guy. He wrote Plan 9, and he’s the creator of the Go programming \\nlanguage. He also created Sawzall. He’s also the most pedantic code reviewer I had at \\nGoogle, and I’m sure that he will consider that a compliment. I think I went through 26 \\ncode revisions during that review with him, and it was absolutely awful. It was so bad \\nthat I really thought hard about quitting. So, so, so many nitpicky comments. I think that \\nwas a great thing about Google, they tortured me into becoming a better programmer by \\nforcing me to think hard about all of these little decisions. No pain, no gain.\\nThat seems to be one of the nice things about being a data scientist. It’s at the \\nintersection of many fields, so when you’re in a particular field, you can humble \\nyourself by not thinking of yourself as a practitioner of that field and say, “What \\ncan I learn from this person as they are a practitioner of this field?”\\n \\nI think that is a big part of your job description as a data scientist. The reality is that these \\nthings are never one-way streets. For every software engineer who gave me a scathing \\ncode review, another one would come to me later with a data analysis problem, because \\nthey knew me as a statistician who spoke their language and could explain things to \\nthem.\\n \\nIt’s hard to humble yourself, but keep in mind that it almost always comes back around in \\na positive way. It’s good for your career to come in and be seen as an expert in something \\nwho knows how to communicate their expertise.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 183}, page_content='JOSH WILLS\\n179\\nHow did you deal with the transition between a large company like Google, where \\nthere’s so much institutional knowledge to draw upon, and a startup like Cloudera?\\n \\nThere are lots of things I miss at Google. I miss the people. I miss the food. I miss the \\ntoys. They had a lot of great stuff at Google. To the extent that we have a product strategy \\non the data science team at Cloudera, it’s to take stuff that we loved at Google and create \\nopen source versions of it. That’s all there is to it. It’s the easiest product management \\nstrategy in the world. Know what you like and try to improve upon it.\\n  \\nWhen I got to Cloudera, it was roughly \\n85 people. It wasn’t a startup, but it was \\npretty small. I was like, “Hey everybody, \\nI’m the new director of data science. \\nWhat should I be working on?” No one \\nhad any idea, and I didn’t have any idea \\neither. It wasn’t entirely clear to me \\nwhat I was hired to do. I had a couple of \\ndays of tremendous anxiety about that. I was completely useless. At Google, I had 150 \\nemails a day from people who needed stuff from me. Here, I could hear crickets chirping. \\nIt’s that anxiety-inducing freedom we talked about earlier.\\n \\nSo my job at Cloudera was to figure out what I could do that would be useful. I spent a lot \\nof time talking to customers, and I still do a lot of that. I give them advice about building \\ndata science teams or about particular approaches they can take to solving different \\ntypes of problems.\\n  \\nI also started working on problems that customers talked about and various customer \\nengagements that seemed interesting and useful. I was also new to the Hadoop stack, \\nand so a lot of it was just learning what was out there and how things worked. I remember \\none project where I was building a model for detecting adverse drug events using an \\nalgorithm that was created pre-MapReduce but that was really a perfectly MapReduce-\\nable problem. That was the first useful thing I did, and I know that because Mike Olson, \\none of our co-founders, presented the results of my analysis as a five-minute quick hit \\npresentation at a conference and we got a lot of nice press and Twitter coverage for it.\\n \\nA little later, I was working on a problem that required processing lots of seismic imaging \\ndata, which is time series data oil and gas companies analyze to try to figure out where \\noil and natural gas deposits are located under the earth. That was the first time I really \\nmissed FlumeJava. It was the perfect tool to solve the problem I was working on, and so \\nI rewrote enough of FlumeJava to be able to solve my problem.\\n \\nJust because I’m not the best programmer \\nin the world doesn’t mean I can’t contribute \\nuseful things, and the community that has \\nsprung up around Crunch is something I \\nam incredibly proud to be a part of.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 184}, page_content='JOSH WILLS\\n180\\nThat process brought me back to my black-box debugging days at IBM. When I was at \\nGoogle, I had used FlumeJava to write data pipelines, so I knew what the APIs looked \\nlike, but I didn’t really understand how it worked under the covers, only how it worked \\nconceptually. The FlumeJava team had published a paper about the system, and that \\nwas tremendously helpful, but there was still this process of sitting down and saying to \\nmyself, “okay, I know the API worked like this. I don’t know why it worked like that, so \\nlet’s see if we can sit down and figure out what had to be going on so that this thing will \\nwork.”\\n \\nIt really took three times to create the FlumeJava clone that eventually became Crunch. \\nThe first time I wrote it, I really coded myself into a corner; I made some design mistakes \\nthat I just couldn’t unravel. So I started over, but I ended up creating this ridiculously \\nover-engineered monstrosity, and I wasn’t really getting closer to being able to solve \\nmy original seismic data analysis problem. So by the time I started over again, I really \\nneeded to get the thing to work quickly, and fortunately I had learned enough from the \\nfirst two attempts to get something that basically worked together in a week.\\nI probably should have been too ashamed of what I had created to open-source it, but \\nthanks to my time at Google, any sort of ego I had about the quality of my code was \\nbasically gone, and I was more than happy to put it out there for everyone so that other \\npeople would be able to work on it and improve it over time. Just because I’m not the \\nbest programmer in the world doesn’t mean I can’t contribute useful things, and the \\ncommunity that has sprung up around Crunch is something I am incredibly proud to be \\na part of.\\nYou wrote a blog post about building Crunch, and then having someone contribute \\nto the open source project, as this amazing moment. Can you talk a bit more about \\nwhat that was like? \\nIt was about understanding the complicated software written, finding a non-trivial bug, \\nand improving it. I like literature a lot. I like David Foster Wallace, and I’m wearing \\nmy favorite David Foster Wallace t-shirt. It the motto of the Enfield Tennis Academy \\nin Latin. It translates to, “They can kill you, but the legalities of eating your corpse are \\nquite a bit dicier.” \\nWallace writes a lot about loneliness. There’s a character in Infinite Jest called Madame \\nPsychosis which is a reference to metempsychosis. It is a notion of the transmigration of \\nsouls from Greek literature, that’s like a John Malkovich situation of being picked up and \\nstuck in someone else’s head. Gabriel doing that fix was like metempsychosis because \\nI put some aspect of myself into this code and he improved it. That was sublime. I was \\nvery lucky.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 185}, page_content='BRADLEY VOYTEK \\nProfessor of Computational Neuroscience at UCSD, \\nFormer Data Evangelist at Uber\\nHow did you get to where you are today?\\n \\nI started as a physics major at USC in Los Angeles, and I briefly worked in an ultra-low-\\ntemperature physics lab. As a young kid, I thought that physics would be the direction \\nI would go in. But I realized quickly after working in the lab that it wasn’t really what I \\nwanted to do.\\n \\nI didn’t know what to do or what my interests were going forward, but I had taken a \\npsychology class to fulfill a general education requirement, and I became interested in \\nthe topic. Around the same time in college, I started learning to socialize better and \\nalso became more interested in other people. My grandfather, who I had grown up with, \\nhad also gotten sick with Parkinson’s disease. Although he was a really smart engineer, \\nhe started to decline cognitively really quickly. The confluence of all these things that \\nhappened at the same time in my life made me realize that I needed a shift in my long-\\nterm career path, and neuroscience became something that I was interested in.\\n \\nAs an undergrad, I started working in a neuroscience research lab, and the very first \\nproject I was assigned was to take flat text files and copy and paste different parts into \\nExcel to aggregate the data. They gave me two weeks to do this, and I was like, “This is \\nridiculous.” I wrote a simple C++ script to do it for me, and I came back the next day with \\nall of it finished. To the other people in the lab, it was like I had worked some kind of \\nmagic. Programming was this amazing thing that they did not understand.\\n \\nBrad has had an eclectic career. From working in \\nneuroscience and academia, to becoming a world authority \\non zombie brains to contributing to the data science team \\nat Uber as employee number seven, his story is one of \\nembracing learning, overcoming challenges, and cross-\\npollinating ideas from disparate fields.\\nHe is currently a professor of computational neuroscience \\nat the University of California, San Diego (UCSD).\\nData Science, Zombies and Academia'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 186}, page_content='BRADLEY VOYTEK\\n182\\nFrom that point forward, I became the “tech guy”. I started automating a lot of the things \\nthat were going on in the lab. I found my niche there.\\n \\nAfter graduating, I started working at UCLA in the Brain Mapping Center, and I was the \\nPET (positron-emission tomography) scanner operator. PET is a type of non-invasive \\nbrain imaging and I was running the PET scanner and collecting data from people. I \\nstarted doing a little of my own research and used that time to figure out if I wanted to \\ngo to grad school and do my PhD. Through this experience, I realized that computational \\nneuroscience was what I wanted to do.\\nI applied to places in California like \\nUCSD, Berkeley, UCLA, and UC San \\nFrancisco. I almost didn’t get an \\ninterview anywhere because my grades \\nin undergrad were terrible, but I got \\nlucky and got into Berkeley. It was an \\namazing environment with a ton of \\nincredibly smart people. Berkeley has \\njust now started its own data science \\ninstitute, but it was clear when I was there from 2004 to 2008 that this idea of “data \\nscience: was percolating through the Bay area.\\n \\nAt the end of my PhD, I was approached by my friend Curtis Chambers, who was the first \\nhead of engineering at Uber. He was employee number four in the architectural dispatch \\nsystem and was a close friend of mine in high school (I was the best man at his wedding). \\nHe said, “We have a ton of data, and we don’t have anyone to do anything with it. I know \\nyou do this kind of stuff. Would you be interested in working with Uber?” \\nAt that time, I had just finished my PhD, and my initial reaction was, “I don’t think \\nit’s that interesting.” However, as we talked more, I started to get a better idea of the \\ncompany and I decided to go meet with the CEO. I had lunch with Travis Kalanick, the \\nUber CEO, and he wanted me to do a coding challenge to see what I knew. I said to him, \\n“Look, you can have me doing coding challenge games, but how about you give me your \\ndata to play with? If I haven’t done something cool by the end of the day, that will settle \\nit.”\\nTravis liked that, and so they gave me some data to analyze. I sat around and hacked at \\nit for a while and, by the end of the day, I had some analyses and visualizations for them. \\nThat’s how my work at Uber started.\\n \\nYou mentioned that you applied to different graduate programs and only got \\nThey gave me two weeks to do this, and \\nI was like, “This is ridiculous.” I wrote a \\nsimple C++ script to do it for me, and \\nI came back the next day with all of it \\nfinished. To the other people in the lab, it \\nwas like I had worked some kind of magic.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 187}, page_content='BRADLEY VOYTEK\\n183\\naccepted into UC Berkeley, despite your low GPA. What did you do to convince \\nthem that somebody with your unorthodox background could do a PhD there?\\n \\nI don’t know. I wish I had a solid answer. I actually asked somebody very high up in the \\ndepartment how I got into Berkeley when I couldn’t get in anywhere else. The professor \\nsaid very bluntly, “Well, we looked over your application and thought you were a fuck \\nup, but we thought you were a fuck up with potential so we decided to give you a shot.” \\nI don’t know what the potential was. I do a lot of writing and public speaking so I think I \\nam able to communicate ideas clearly, so that might have helped me in my application.\\n \\nI think Berkeley also embraced the Silicon Valley ethos where failure is something that \\nhelps you move forward. In a lot of other places, failure is generally looked down upon, \\nbut I think there’s something to the idea that failure is how you grow. I’ve been embracing \\nthis philosophy for a long time, and I didn’t try to hide anything in my application. I said, \\n“Here’s what happened. It’s not an excuse. This is just what happened. Here’s the story, \\nand here’s what I learned from it.” I think most people didn’t really care, but every now \\nand then, it just takes one person to actually read what you write and appreciate it.\\nNow that I am a professor, I just \\nparticipated in my first rounds of \\nadmissions for the PhD program \\nat UCSD. UCSD’s Neuroscience \\ndepartment is one of the best in \\nthe world. It’s a very competitive \\nprogram, and during the \\nadmissions, there was one person \\nwho I wanted to admit. This person had a low GPA but had strong GREs and an incredibly \\nstrong background. They had thought very clearly to get to the point where they were. \\nThey were slightly older than the other applicants because they had done real world \\nwork instead of going to graduate school directly, so I highly recommended that this \\nperson get accepted.\\n \\nIf you look at other professors’ CVs, listed there will be numerous publications, incredible \\ncompanies they’ve helped fund, students they’ve mentored who are now amazing \\nprofessors, and incredible research grants that they’ve received. I remember looking at \\nthose as a fresh PhD student and thinking “I’m not cut out for this.” I couldn’t even \\nimagine what it took to write a single research paper and get it published. I couldn’t \\nimagine doing that once, and I saw people with over 200 publications.\\n \\nIn my CV, I actually have a section that’s listed as my failures so for every paper that \\nI’ve gotten published, I say how many times it was rejected from different journals. I list \\nI said to [Travis], “Look, you can have me doing \\ncoding challenge games, but how about you \\ngive me your data to play with? If I haven’t \\ndone something cool by the end of the day, \\nthat will settle it.”'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 188}, page_content='BRADLEY VOYTEK\\n184\\nevery grant that I didn’t get which I applied for, every fellowship, and every faculty job \\nI applied for but didn’t receive. Everything that I’ve done that didn’t come true is listed \\nin the failure section of my CV, and I’ve gotten positive feedback from students looking \\nat that because it’s a litany of crap. There were papers that were rejected by 10 journals \\nbefore they got accepted. I think people don’t recognize that behind these incredible \\nCVs of these 60-year old professors, they’ve got 60 years of failures that they had to go \\nthrough in order to do it. I try to be a little honest about that.\\n \\nDJ Patil had this great quote that, to paraphrase, goes something like, “In the very \\nbeginning, in order to do something new, you need to leap across this chasm and \\nyou need someone on the other side to catch you in order to cross it.” \\nIt seems like from your experience in graduate school, you’ve really internalized \\nthat and believe in that. Now you’re on the other side of the chasm, trying to catch \\npeople, hoping that they can make it across despite their unconventional training.\\n \\nDJ is a smart guy and I like that analogy a lot. \\nI come from a pretty low socioeconomic status background. My family’s not well off at \\nall, and to get to where I am today, I can easily name at least a dozen people who gave \\nme lucky breaks. Everybody likes to talk about the value of hard work and work ethic, but \\ngetting to where I am today required tons of luck. It required someone to reach across \\nthat chasm for me, and I don’t know why. I’m certainly on the other side now, trying to \\ndo the same for as many people as I can.\\n \\nWhat was your exposure to computer science and the idea of interacting with \\ndata? How did that evolve as you went through your undergrad research and PhD \\nresearch? \\n \\nIn hindsight, what I did throughout that undergrad project was very simple data munging. \\nUSC didn’t have a neuroscience major at the time. They had a psychology major and a \\nneurobiology major, but I wasn’t interested in neurobiology or cell molecular biology, so \\nI tried to throw together a major on my own.\\n \\nI ended up taking courses like Introduction to AI and C++ programming. I took these \\nclasses because I had several friends who were computer engineering majors and after \\nspending a lot of time talking to these guys, I thought that programming would be a \\nuseful skill to have.\\nWhen I worked in the lab, I realized that my programming skill was applicable to the \\nproblems. For example, the lab I worked in was doing brain imaging, and the analyses that'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 189}, page_content='BRADLEY VOYTEK\\n185\\nthey were doing seemed complicated, requiring the use of obscure programs. I realized \\nat some point  that it was just matrices of data. Once you had the realization that these \\nare just numbers, it allowed me to do a lot more. You can start writing your own analyses \\nand doing things that people may not know or understand. It’s mind boggling because \\nwith two lines of Python, you can do much of data analysis much more efficiently.\\n \\nI told this story once, and someone told me, “In the land of the blind, you are the one-\\neyed man.” That’s essentially all it is. You find that you have a skill set that is valuable \\nto the field that you’re working in that not everyone has. Suddenly, it’s just something \\nmagical that you can do.\\n \\nIn 1999, I imagine that the science lab was not very technical. You coming in and \\napplying programming must have been mind boggling to them. It was something \\nthat you’ve seen in class, but for people who haven’t been exposed to programmatic \\ndata analysis, that must have seemed like magic. Similar to what you do now, \\nat that time you were leading the way and evangelizing the different ways that \\npeople can think about and manipulate data.\\n \\nI remember taking a statistics \\nclass in psychology. They were \\ntrying to use SPSS which is a \\nstatistical package for social \\nsciences. It allows you to do \\nthings like regression analyses, \\nand ANOVA. I remember \\nbeing confounded by the idea \\nof assuming that the data \\nfollowed certain probability distributions. I didn’t quite understand why you’re making \\nassumptions, and I didn’t get the difference between ANOVA and the t-test. Then as a \\ngrad student, I remembered that they were all the same thing. You have a general linear \\nmodel; the t-test, ANOVA, and regressions are just extensions of that.\\n \\nIn my lab right now, I have a lab manager who is a fresh out of undergrad. We were \\ntalking about that, and I described to him how a t-test by drawing it on the board really \\nquickly. He said, “I took a year of stats, and I never got it as clearly as I do now from what \\nyou just drew.” \\n \\nIt’s shocking to me how bad people are at explaining data, data science, and statistics. \\nIt’s not a magical thing. There’s a reason some people are so good at it. It takes some \\ntime internalizing and getting it, but once someone shows you that, it just becomes so \\nclear. \\nIn my CV, I actually have a section that’s listed as \\nmy failures so for every paper that I’ve gotten \\npublished, I say how many times it was rejected \\nfrom different journals. I list every grant that I \\ndidn’t get which I applied for, every fellowship, \\nevery faculty job I applied for.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 190}, page_content='BRADLEY VOYTEK\\n186\\nIt requires you to think outside of preparing for a test, and see how the ideas can \\nbecome an actual tool you can use.\\n \\nRight. I think my failure to become a physicist was that I was too young to get that. When \\nI was taking physics classes, it was memorizing all these different equations and trying \\nto figure out which equation to plug into. That didn’t seem interesting to me. Now, of \\ncourse, I realize it’s not what physicists do. I think if I had figured that out earlier, I could \\nsee my career path diverging.\\n \\nRight now, you’re quite active on Quora. You teach different people about many \\ndifferent concepts, and I see that as being a very important package of being \\nan effective professor or data scientist. Can you talk more about this missing \\naspect of data science that isn’t as heralded, which is the aspect of being able to \\ncommunicate effectively?\\n \\nYes. I always think back to the movie Office Space, which was making fun of the first \\ndotcom industry. In the movie, there’s a great line where they’re trying to figure out who \\nto keep and who to fire in this tech company. They’re talking to this guy who is a product \\nmanager. But since he’s a product manager, he’s not a manager per se, so these guys \\nthat came in to interview him are asking, “What do you do?” He’s replied, “I talk to the \\nengineers, and I learn what they’re doing. Then, I relay the information clearly up to the \\nmanagement.” They said, “Why can’t we just have engineers talk to management?” And \\nhe says, “They need a people person.”\\n \\nI think about that a lot. There’s something very critical about being able to communicate \\nyour ideas effectively. When I came into Uber, one of the things I thought about was that, \\nbefore they got bought by Match.com, OkCupid had a really good data blog. They were \\nusing all of these dating interactions on their website and metadata about people to try \\nto do analyses about what gets people dates and what people find attractive. I read those \\nwell before I was a grad student and well before I got into data science. Everybody loved \\nit.\\nWhen I started working with Uber, I was thinking about how the data can be used to \\ntell an interesting story. Just like writing code, telling a story effectively takes a lot of \\npractice. That’s a part of the reason why I do a lot of writing on Quora. I teach, and I do \\na lot of public speaking at elementary schools, junior high schools, high schools, or at \\na bar to a bunch of drunken aficionados. It’s practice. Just like I have to sit down and \\npractice writing code, I also have to sit down and learn how to communicate the idea.\\nMy wife is actually a very good sounding board. Whenever I write something, I always pass \\nit by her because she’ll read something and say, “You’re making this more complicated \\nthan it needs to be. You can explain this in fewer words. You didn’t connect from A to C.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 191}, page_content='BRADLEY VOYTEK\\n187\\nYou skipped over B.”\\n \\nI remember the first time I took a programming class. It was an algorithms course. The \\nhomework was to write an algorithm for making a sandwich in which you had to explain \\nevery step you took to make a sandwich. You realize so many parts you skip over that you \\nthink are obvious, but if you had to program a robot to do it, simple things like pulling \\nthe knife out of the drawer must be explained. You have to explain exactly how you pull \\nthe knife out of the drawer to spread the mayonnaise.\\nWe skip over a lot of stuff that seems obvious, but it’s not always obvious if you’re not the \\nperson staring at that data all day long. It’s a good point of practice to try to remember \\nhow to be very explicit about every step that you take and connect the dots for people. \\nYou’ve worked with data while at Uber and have an academic background with a \\nlab in UC San Diego. Do you think that your academic background better prepare \\nyou for Uber?\\n \\nAbsolutely. The one thing that you get from an academic PhD in data science is learning \\nto tackle a big problem by breaking it down into bite-sized chunks. When you start a \\nPhD, what you’re doing is saying, “I am entering this 3000-year-old human endeavor of \\ntrying to figure out where we are in the world and what we’re doing, and I think I can add \\nsomething new.” That’s a ridiculous \\nassumption, but people do it head \\non. \\nYou start reading papers, and you \\nknow what you’re interested in. You \\nsee that there’s a hole somewhere, \\nthat there’s something missing. \\nYou think to yourself, “I can add \\nsomething. How do I go about tackling \\nthat, addressing that problem? How \\ndo I define the scope of the problem, and what do I need to do to tackle it?” That’s what \\nyou’re trained to do as a PhD student and is the important skill that you don’t get if you \\nskip academia and go directly to data.\\n \\nIf you are fresh out of your undergrad and go work in a company like Facebook as a data \\nscientist, you’ve got access to two billion people’s worth of data. Unless you had an \\namazing undergrad experience, you don’t know how to begin to tackle that. How do you \\nwrap your head around what kinds of problems to ask, and once you have the problem in \\nmind, how do you tackle it? What do you do?\\nIt’s shocking to me how bad people are at \\nexplaining data, data science, and statistics. \\nIt’s not a magical thing. There’s a reason \\nsome people are so good at it. It takes some \\ntime internalizing and getting it, but once \\nsomeone shows you that, it just becomes so \\nclear.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 192}, page_content='BRADLEY VOYTEK\\n188\\nOne of the things that struck me was that people in research tend to de-emphasize \\nthe infrastructure required to do large-scale analysis. That’s not as sexy as being \\nable to ask the research questions, but it gives you more breadth. You can ask \\nbigger questions if you know how to leverage the industrial tools.\\n \\nYes. It’s helped on every level. When I started in Uber, there were seven of us and we were \\nworking in a co-working space with a bunch of other startups. The hustle of a startup is \\nsomething that a lot of large research institutions don’t have. \\nIn my lab, I do a lot of methods development for analyzing human brain data, but \\npreviously I did that in MATLAB and posted the MATLAB file on my website and linked \\nto it in published papers. It’s complicated and doesn’t really make sense. Now, I’m \\nconverting everything so the code in the notebooks are also tutorials. These are things \\nI’m developing in my lab and growing in the lab culture.\\n \\nA common problem that’s endemic to academic researchers is if some PhD students or \\npost-doctorates do a really good project but have the data backed up on their computer. \\nThen, if they leave or graduate, the data is gone. This happens at least 75% of the time. \\nThese are things that regress in the development of my research lab.\\n \\nOn the actual research side of things, I have learned different ways of looking at data. \\nThere’s a company called Lumosity. They do online brain games, which is interesting, \\nbut the thing that really interests me is that they have more data on human cognition \\nthan have ever been collected in the history of science.\\nWe looked at Lumosity data that measures your distractibility. I looked at the distractibility \\naverage across geolocation areas like California, New Mexico, or Washington. You just have \\nthese aggregate values, and I pulled up these data that estimate country or state-level IQ \\nand GDP . I found that state-by-state and country-by-country estimates of distractibility \\ncorrelate with fatal car accidents. Countries or states where people are more distracted \\nare more likely to have fatal car accidents, which makes sense. It’s statistically robust. \\nIt doesn’t appear to be an outlier. Ultimately I’d like to publish all the scripts I used to \\ngo from raw data to final published figures my research so that anyone who reads the \\npapers can do the same analysis, or build on it.\\n \\nYou’re one of the few people that we’ve spoken with who have gone back from \\nindustry to academia, and it still sounds like you’re playing with private data sets \\nof different companies like Lumosity and Uber. Why did you not choose to stay in \\nindustry? What advice would you have for these PhD students who will read our \\nbook who are trying to leave the more standard track of become a professor for \\nindustry?'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 193}, page_content='BRADLEY VOYTEK\\n189BRADLEY VOYTEK\\nGetting a faculty job is highly unlikely. Ten or 20% of PhD students will go on to get a \\ntenure-track job, so in my lab, I’m trying to train people to be able to do other things \\nbeyond research. We’re doing the research, but we’re also trying to train them in version \\ncontrol, Python, and data analysis to make sure they have a skill set that is transferable \\nif they decide not to go into academia.\\nAs for me, not staying in Uber and \\ngoing into academia was a really \\nhard call. They offered me a full-\\ntime position and a lot of stock. \\nThat was before the stock is \\nwhere it is right now. I was doing \\ngrowth projections early on, and \\nI knew where the company was going. What made it hard was that while Uber was doing \\nsome cool work, at the end of the day neuroscience is where my heart is. I try to refrain \\nfrom using the word “passion” because people have a misunderstanding of passion, but \\nneuroscience what I really want to be doing. It’s more fun and exciting for me at the end \\nof the day.\\nAnother big part is that I’ve gotten a lot of big breaks over the years, much of which has \\ncome through really good professors. I wanted to give some of that back, and academia \\nis one way to do that. \\nFor example, I’m teaching an introductory class on data science at UCSD for the cognitive \\nneuroscience group. \\nStudents don’t understand why they have to do computations, and I’m trying to explain \\nto them that right now part of the criteria of understanding cognition and intelligence is \\ndata. Part of it is my desire to give back through teaching. Part of it is that the research \\nI’m doing has a lot of big long-term potential plans in terms of public health. And I have \\nto say that it feels good.\\n \\nThat’s a really powerful and amazing message to share with people who are going \\nto be interested in your background, that you chose to stay in academia. The final \\nthing I want to talk about is what is up with you and your interest in zombies? \\nWhat’s up with that?\\n \\nHaha, are you asking what’s wrong with their brains? Actually this has been surprising \\nand how much it’s taken off. This goes back to the science, communication, and outreach. \\nIf I go to a high school and talk about how neuronal shot noise and channel leakage leads \\nto an increase in neural noise, or how to estimate areas of communication between brain \\nWhen I started working with Uber, I was thinking \\nabout how the data can be used to tell an \\ninteresting story. Just like writing code, telling a \\nstory effectively takes a lot of practice.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 194}, page_content='BRADLEY VOYTEK\\n190\\nIf I go back to high school and start talking \\nabout zombie brains, show videos of zombies \\neating people, and explain why zombies are \\ndoing that, suddenly people are going to \\nunderstand. It’s Trojan-horse teaching.\\nregions, people’s eyes would glaze over and they’d say, “What are you talking about?” \\nHigh school students don’t care, and quite frankly, most people don’t care either.\\nHowever, if I go back to high school \\nand start talking about zombie \\nbrains, show videos of zombies \\neating people, and explain why \\nzombies are doing that, suddenly \\npeople are going to understand. \\nIt’s Trojan-horse teaching. It’s a \\ngimmick that we used to do science \\ncommunication and outreach, and it took off. People are really into it. I was on some \\nNational Geographic TV show; Princeton University Press recently published our book, \\nDo Zombies Dream of Undead Sheep?, about the zombie brain soon. We got to meet George \\nRomero, the director of the original zombie movie, Night of the Living Dead . There are \\ntons of speaking engagements. I was a guest of honor for a science fiction and fantasy \\nconference in 2014.\\n \\nIt’s a weird shadow career I have, but it’s been a ton of fun. It’s really silly and it works. \\nPeople seem to dig it. It’s nice. It’s powerful and effective communication.\\nOut of all the things you’ve done in your life, the theme here is your willingness to \\nwrite, talk, and teach people. That’s also one of the reasons we’re grateful that you \\ntook time to share with us your stories. \\nThank you for being so honest and willing to share both the stories of success, and \\nfailure and struggle. I think a lot of these stories are going to resonate deeply with \\nthe readers, especially those who branch out from the traditional path.\\n \\nThanks, guys.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 195}, page_content='LUIS SANCHEZ Founder / Data Scientist at ttwick\\nWhere do you work?\\nI am the CEO and Data Scientist of ttwick Inc, a data analytics startup with roots on Wall \\nStreet.\\nWhat was your personal career path like?\\nI started my analytical career as a Civil Engineer specializing in structural engineering, \\nhydraulics and numerical analysis with a degree from a military university in Venezuela in \\n1987. I also obtained a specialization in systems analysis and programming from another \\nVenezuelan institution, but it was the combination of engineering and programming \\nthat put me in the right frame of mind and gave me the skills to eventually evolve into \\na data scientist.\\n \\nIn 1990, I decided to move to Washington, D.C. and begin studying for my MBA on a \\nLASPAU scholarship (a Fulbright scholarship for Foreign Students). My goal at that time \\nwas to get accepted into the World Bank’s Young Professionals Program and work in \\nglobal  infrastructure development. I dreamed about all the data I would have access to \\nat the World Bank, to play with and analyze.\\n \\nBack in 1990, it was not easy to get enough data to analyze, and I used to spend a lot \\nof hours in the computer lab with my newly issued email address and Internet access. I \\nLuis trained as a civil engineer in Venezuela before arriving \\nin the US for his MBA on a Fulbright in the early 90s. Though \\nhe aspired to join the World Bank, Luis found an alternative \\napplication of his data skills in the world of finance.\\nAfter an illustrious career as a quant at AIG and Deutsche \\nBank, Luis found himself structuring exotic asset backed \\nand catastrophe linked securities at Lehman Brothers \\n(you can see his video here), where he worked till the firm’s \\nbankruptcy on September 15, 2008. With plenty of free time \\non his hands, he dabbled in cross pollinating the ideas from \\nhis structuring days to areas of social media.\\nHe is the founder of and data scientist at ttwick, a search engine for social media content.\\nAcademia, Quantitative Finance and Entrepreneurship as a \\nData Scientist'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 196}, page_content='LUIS SANCHEZ\\n192\\nstarted to gather as much data as I could via Gopher, Archie (the first search engine for \\nFTP archives), or whatever I could get my hands on. I then discovered the University of \\nChicago’s CRSP database, which had some securities data available in a monthly format. \\nIn the summer of 1991, I got a 2400 bps modem, which allowed me to access the CRSP \\ndatabases from my IBM PS/2 at home, and finally, I did not have to spend so much time \\nin the computer lab, which always annoyed Gabrielle, my girlfriend at the time. In 1991, \\nit was difficult to obtain large volumes of high-quality data, so I started to explore other \\nmethods such as creating synthetic data via Monte Carlo simulation, which kept some \\nof the features of the original data set. Because of that, I started to do a lot of research \\nin computer science.\\n \\nI never got the job I wanted with the World Bank, but after graduating in 1993 I started \\nworking for a New York-based hedge fund that wanted a quant for its newly established \\nQuantitative Analysis department, to complement the work of analysts doing pure \\nfundamental analysis on securities.\\n \\nBy the way, I ended up proposing to Gabrielle, believe it or not, after writing a program \\nbased on professor Thomas Saaty’s Analytical Network Process. I thought his multiple-\\ncriteria decision algorithms would help me make sure I did not have any inconsistencies \\nin my logic. (Years later, Gabrielle got kind of upset when she learned I based my proposal \\ndecision on an algorithm.)\\n \\nWhat are your responsibilities at ttwick?\\n \\nI found out a lot of the market-based algorithms for allocation of resources I developed \\nand used in finance could also be used to search and organize unstructured data on the \\nweb; to determine if an online ad should be launched today or in a few days; to create real-\\ntime portfolios of content at low cost; to dynamically calculate probabilities of reaching \\ncertain audiences, etc. These algorithms coupled with natural language processing, data \\naugmentation, and other techniques  could be used for many applications, including the \\ndiscovery of arbitrage opportunities in certain financial markets, forecasting of political \\nevents, etc.\\n \\nAs CEO and Data Scientist, I am developing a series of B2B and B2C products and consulting \\nservices  based on the above-mentioned applications, some of which are currently being \\nused and/or tested by hedge funds, advertising agencies and other institutions.\\nWhat is data science to you?\\n \\nTo me, data science is the art and science of extracting actionable intelligence from sets \\nof data, big or small.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 197}, page_content='LUIS SANCHEZ\\n193\\n \\nI call it “art” because there is not really a one-size-fits-all technique that can help \\nyou answer the questions you want to ask your data. You need to be creative and have \\nimagination to see what others don’t see in the data. If you are anything like me, the \\nbest solution to your most challenging \\nproblems has come to you when you \\nleast expected it, in the form of an \\ninspiration. When that happens, I get in \\nthe zone and the solution just comes to \\nme, and I can’t focus on anything else.\\n \\nI call it “science” because you need to know the theory behind what you do and put in \\nyour 10,000 hours of problem-solving so you develop “muscle memory” so to speak, and \\nyou acquire the right foundation to become a good data scientist.\\n \\nOne thing I believe but don’t know if other people would agree with: Good data science \\ncan’t be 100% theoretical or 100% practical. There has to be a mix.\\n \\nSo, in your opinion, what is the goal and purpose of a data scientist?\\n \\nThe purpose of a DS is to extract actionable intelligence from sets of data with the most \\nefficient use of resources and under time constraints. The DS should be able to connect \\ndata together in meaningful ways, to create new knowledge from the combination of \\ndata, to be able to analogize and solve problems in creative ways, and to do all that \\nquickly. Like General Patton used to say: “ A good solution applied with vigor now is better \\nthan a perfect solution applied ten minutes later.”\\n \\nWhat are some past projects you have worked on?\\n \\nAs a financial quant, I worked on many interesting projects, many of them being the first \\never of their kind. Many of the projects on which I worked set the foundations for niche \\nmarkets within structured finance and trading.\\n \\nSome of the most interesting deals were:\\n \\n• First sovereign catastrophic (CAT) bond: Using a parametric structure, I designed \\nan ABS structure that covered the Government of Mexico against the effects of an \\nearthquake. The bond was rated and successfully launched to market.\\n• Weather options:  one of the most fascinating projects during my time at AIG, \\nwhere I was in charge of developing a model to price the risk of extreme rainfall or \\ntemperature in several cities across the world. This topic is extensive, but developing \\nData science is the art and science of \\nextracting actionable intelligence from \\nsets of data, big or small.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 198}, page_content='LUIS SANCHEZ\\n194\\nthe mechanism for a new market and seeing it grow and find participants that included \\nenergy companies, theme parks, airlines, etc., was a fascinating experience.\\n• Music and film royalties:  Have you heard of Bowie Bonds (as in David Bowie)? \\nBasically, the same idea was involved in deals I was pitching while at Deutsche Bank \\nfor some high profile artists. After I left in 2005, I retrofitted my own model to value \\nfilm productions yet to be made, and all of a sudden, I found myself giving speeches \\nat Hollywood events about the use of Monte Carlo Simulations and Bayesian analysis \\nto price film productions.\\n \\nMore recently, as a DS, I demonstrated to a hedge fund that there is a way to gain an edge \\nin the market via non-conventional financial analysis, using non-conventional sources \\nof data and machine learning tools such as those I am developing at ttwick. This sort \\nof analysis, coupled with the right financial derivatives, could generate superior alpha \\nreturns in various market environments.  \\nWhat was your experience like transitioning from academia to industry data \\nscience?\\nThe experience was effortless, with a dash \\nof good timing. As I mentioned before, I was \\napplying the math and coding skills I had \\nacquired as an engineer to solve problems \\npresented as part of the curriculum of my \\nMBA. I found it interesting that only a few \\nof my classmates had any coding skills, so I \\nbecame the “class quant.” Classmates came to me for help with assignments for classes \\nsuch as Strategic Marketing, where data science could be applied to solve marketing \\nproblems. By helping them, I also gained exposure to their areas of concentration.\\n \\nI started to write code for small projects with demos of things for marketing, financial \\ntrading, etc., and towards the end of my MBA, I started to attend specialized seminars in \\nNew York that concentrated on real-life problems about trading non-liquid securities, \\ncorrelation trades, technical analysis, etc.\\n \\nOver several of these seminars, I started to see a core group of people attending the most \\ninteresting ones, whom I later learned were investment managers looking to expand \\ntheir knowledge of the markets, while at the same time scouting talent for their own \\nhedge funds. I met Marc Chaikin, a famous technical analyst who created one of the first \\nplatforms for real-time technical and fundamental analysis of securities, with a huge \\ndatabase of tick-by-tick data.\\n \\nEventually, I ended up working for Marc’s best friend, a smart hedge fund manager, Chris \\nGood data science can’t be 100% \\ntheoretical or 100% practical. There \\nhas to be a mix.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 199}, page_content='LUIS SANCHEZ\\n195\\nCastroviejo, who had left Bear Stearns and teamed up with a group of traders and analysts \\nwho were starting their own group of onshore and offshore hedge funds.\\n \\nMy last job in my over 15-year career as a Wall Street financial engineer was Senior Vice \\nPresident for Lehman Brothers, where I was a Senior Quant.\\n \\nWhat drew you from Financial Quantitative Analysis to Data Science?\\n \\nIt was very simple: after the bankruptcy of Lehman Brothers where I was a Senior Vice \\nPresident, I (as well as many other quants), was in “job limbo,” meaning there were \\npractically no jobs available anywhere, much less for structurers of exotic assets. I \\ntransitioned to Barclays Capital, but by the end of the first quarter of  2009 I was laid \\noff along with most of the senior structurers and bankers who made the transition from \\nLehman.\\n \\nThe general public barely understood what a credit default swap or a credit transition \\nmatrix was, much less credit-linked notes, synthetic CDOs, CAT bonds, Markov-chain \\nMonte Carlo and some of the instruments and techniques I had specialized in over the \\nyears. There was no appetite for any sort of exotic instrument, and no capital available \\nfor anything.\\n \\nIt was very frustrating because precisely then, as a consequence of the credit crunch, \\nsome of the best investment opportunities I had ever seen in my life materialized in the \\nform of “Obama projects,” but I did not have any funds to invest, and they were clearly \\nadvantageous only to the wealthy with knowledge and some political connections.\\n \\nAlong with a couple of my friends from Deutsche Bank and Lehman Brothers, I put \\ntogether a basic  infrastructure to raise capital and invest in such opportunities created \\nby the Obama administration, but we were not able to get any commitments  by the \\ndeadlines set by the programs, and I found myself with a lot of free time, compared to \\nthe 70-90 hours per week I was used to putting in at investment banks.\\n \\nAt the same time this was happening, I found myself improving my programming skills, \\nand learning all I could about data scraping, web crawlers, and artificial intelligence. I \\nwas fascinated by the possibilities. I started experimenting with  spiders to crawl some \\nsites, and all of a sudden I was using the data in creative ways to find solutions to real-\\nlife problems.\\n \\nOne of those problems had to do with valuation of film productions. Years earlier, I had \\ncreated a rather sophisticated valuation model, focused on securitization of film assets \\nfor Hollywood clients. I wondered if, by using comments in social sites, I could improve'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 200}, page_content='LUIS SANCHEZ\\n196\\nthe accuracy of the model. I succeeded, but first had to develop additional algorithms to \\nfilter out the noise.\\n \\nI kept coding and discovering more interesting things about the film industry, but was \\nparticularly attracted to the Internet Information Provider subsector of the tech market, \\nsince I could see analogies in the way Hollywood earns profits from films: you need to \\nbe in content creation, distribution, and advertisement in order to minimize your risks.\\n \\nSo I started reading the 10Ks and 10Qs of Google, Yahoo and other companies in the \\nsector, and doing Monte Carlo simulations to learn about their strengths and weaknesses. \\nI learned a great deal from that exercise.  At that point, I started considering myself a \\nhybrid data scientist/financial quant, which I believe is a rare combination.\\n \\nWhat would you have done differently if you were able to speak to yourself right \\nat the end/middle of your graduate school career?\\n \\nIf I had that opportunity, I think I would just tell my earlier self to code more in languages \\nother than Visual Basic. I would set up a plan for my earlier self to learn Octave and \\nPython, and Java when it came out in 1995.\\n \\nIf I had the opportunity to speak to myself right \\naround the middle of my professional career, let’s \\nsay circa 2001, I would have told myself to stay in \\nNew York as a general quant, instead of moving to \\nLondon to be a front office quant pitching deals \\nto European governments and corporations. Not \\nthat I didn’t do a good job as a structurer and \\nrelationships guy, but an unintended series of events happened around that time which \\nI think could have had a better outcome for me and others, but who knows?\\n \\nMy advice is, focus more on what your own strengths are and less on what is perceived \\nas a cool career path at the time.\\nHow do you describe the value that you and other DS bring to the company?\\n \\nThe value I bring to ttwick is my diversified analytical background and real-life experience \\nin several industries that helps differentiate ttwick from other startups operating in DS.\\n \\nI have been conducting informal job interviews with PhDs  I might eventually hire from \\ndiverse fields such as physics, economics, linguistics, engineering, microbiology, etc. \\nwith amazing potential to become Data Scientists.That is the sort of analytical diversity \\nI want to have at ttwick.\\nFocus more on what your own \\nstrengths are and less on what is \\nperceived as a cool career path \\nat the time.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 201}, page_content='LUIS SANCHEZ\\n197\\nWhat are some surprising things about working in industry vs. academia?\\n \\nI can best answer that question by giving two examples of situations taken from my own \\ncareer.\\n \\nThe first example is the design of a financial structure to cover the government of El \\nSalvador against the effects of excessive rainfall, which has a definitive impact on the \\nGDP of that country. I was given that task in 1998 or 1999, I can’t remember. El Salvador’s \\neconomy is mainly driven by agricultural production, and extreme weather events \\ncould have catastrophic effects on the economy. Conventional countrywide insurance \\nprotection was either too expensive or unavailable, so I started to design a parametric \\nbond-type structure. As usual, data was of the essence.\\n \\nI got the data, but it was terrible, with wild swings in it that could not easily be fixed. The \\ntime-series had a numeric code representing the station, the name of the town/village, \\nand the daily precipitation. The gaps represented a big problem in valuing the risk. But \\nthen I did some interesting data exploration: I asked some of my younger colleagues \\n(Associates and Analysts) to help me gather the geolocations of the stations.\\n \\nThe time gaps corresponded to \\nmore or less well-defined, circular \\nareas, always near a river or \\nstream. I shared the findings with a \\ngovernment official in El Salvador \\nwho confirmed that the time \\nperiods of wild swings or gaps in \\nthe data corresponded more or less \\nto the heights of internal political conflicts in El Salvador. The geographic areas I showed \\nthem represented the geolocations of what later were found to be the main camps of the \\nFMLN (a guerilla coalition at war with the government in the 1980s and ‘90s). By looking \\nat the wild standard deviations and their locations in time and space, you could more or \\nless predict the next hideout of the guerilla leaders, since they seemed to follow a defined \\npattern. It turned out the fluctuations were simply due to the destruction or misuse \\nof pluviometers by the guerrillas, coupled with the fact that data collection was not \\nfrequent. In any case, I came up with a solution for the problem of rainfall measurement \\nat certain points by correlating rain accumulation with water levels of rivers near the \\ndata collection stations, where I had better data.\\n \\nThe second example was from my time at Lehman Brothers. I was analyzing a corporate \\ndeal in an emerging market that involved a commodity as collateral. I had the data I \\nneeded for a conventional type of analysis. But something did not feel right , so I \\ndecided to enlist the help of another colleague, Jami Miscik, also a Senior Vice President. \\nI shared the findings with a government \\nofficial in El Salvador who confirmed that the \\ntime periods of wild swings or gaps in the data \\ncorresponded more or less to the heights of \\ninternal political conflicts in El Salvador.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 202}, page_content='LUIS SANCHEZ\\n198\\nBefore Lehman, Jami ran the National Clandestine Services of the Central Intelligence \\nAgency under George Tenet. Around 2005, she joined Lehman Brothers as Global Head \\nof Sovereign Risk Analysis, and to this day I consider her a very unique type of data \\nscientist.\\n \\nI was fascinated with Jami’s analytical skills for political risk; she’s equally talented in the \\nart and science parts of data science. While at the CIA, Jami ran a complex quantitative \\nand qualitative program to forecast political instability in 40 countries based on 25 \\nindicators, and I was lucky enough to be one of the few executives invited to gather for \\nher weekly world outlook meetings. At the suggestion of the Head of High Yield Trading \\nat Lehman, I enlisted Jami and her team to dig a little deeper on the company I was \\nanalyzing.\\n \\nAfter her report, I decided not to go ahead with the deal (this could be a topic for another \\nbook), and informed Jami of my decision, but in any case, Lehman was already in bad \\nshape. I called to set up a meeting with her to personally thank her for her great work \\nand see if I could discover a little more about her proprietary models and exchange ideas \\non a couple of topics. Both her calendar and mine were free for the same day: September \\n12, 2008, which turned out to be the historic last day of operations of Lehman Brothers. \\nNevertheless, we still kept our meeting and managed to talk for a little while.\\n \\nA couple of years later, I started thinking about creating real-time political risk indicators \\nby tapping and correlating many sources of publicly available data on the Internet, and \\n“calibrating to market.” We did it and now we are successfully using our analysis to \\nadvise a few interesting groups out there..\\n \\nI think the likelihood of getting exposure to the sort of data problems described above is \\nzero or very small if you only have exposure to academia.\\nHow do you measure your own personal career success?\\n \\nA few years ago, I realized I had always been an entrepreneur inside much larger \\norganizations and managed to obtain R&D funding to develop and launch securities \\nthat many times were called crazy or impossible to launch.\\nSo I ended up as a DS because when I started to analyze what my skills were, I realized \\nthat a DS is more or less a financial quant minus the financial knowledge. Remember, \\nfinancial quants come from all fields: computer science, physics, math, economics, \\nfinance, etc.\\nAt this moment, I measure my own personal career success by the fact that ttwick exists,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 203}, page_content='LUIS SANCHEZ\\n199\\nit is funded, and some of my investors are either former bosses or colleagues of mine, \\nand even traders, analysts, and/or executives of well-known financial institutions and \\nmedia companies.\\nHow do you work with other people on your team?\\n \\nI assign tasks to the teams with the most \\nrelevant experience to the problem at hand \\nwhenever possible. Then I have periodic \\nprogress reports to review their work, and if \\nI don’t understand something, or think there \\nmight be a better way to do it, I encourage \\ndiscussion. We have all gained interesting insights from this process, and so far I am \\nsatisfied with the results.\\n \\nI have several machine-learning specialists, data wranglers and general coders on \\nmy team who support what I do in DS. I would like to hire more DSs like me, but it is \\nvery difficult to find “diversified” DS, and even more difficult to find any with financial \\nbackgrounds.\\n \\nEverything we’re doing at ttwick involves multiple disciplines, and my experience with \\nmultidisciplinary teams across several industries allows me to have fluid communication \\nwith my team members.\\nWhat type of careers could people working in DS transition into if they decide DS \\nisn’t for them?\\n \\nBased on my own experience, I would say that financial quantitative analysis would be \\nan option, but a person would have to learn at least some basic finance and get a CFA (or \\nbetter yet, a CAIA) if they want to excel. \\nWhat separates the best data scientist from the merely good?\\n \\nSince I describe data science as the art and science of extracting actionable intelligence \\nfrom data, I would say a good data scientist has an academic and professional background \\nthat makes him or her good in the science part, but the best data scientists are talented \\nin the art part as well.\\nWhat backgrounds do these best data scientists tend to have?\\n \\nI can’t really say, but to me, more than having a particular field of concentration, the \\nbest data scientists probably have experience solving problems for diverse industries. \\nThe best data scientists probably \\nhave experience solving problems \\nfor diverse industries.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 204}, page_content='LUIS SANCHEZ\\n200\\nThat creates the right frame of mind to attack problems from different perspectives; this \\nmight not be obvious to somebody who has only worked in one industry.\\nWho are some DS people you admire? Who are people doing interesting things \\nwith data that you admire?\\n \\nTo me, Hilary Mason is a great data scientist whom I would love to meet someday (and \\nmaybe invite for a cheeseburger). I find her work very interesting, as well as the work \\nClaudia Pelrich at Dstillery has done in the area of detecting fraud in online advertising.  \\nAlso, the work that professors David Cope, Larry Polansky, Peter Elsea and Daniel Brown \\nat the University of California Santa Cruz are doing with artificial intelligence applied \\nto creativity is extremely interesting. I spent a few weeks interacting with them at the \\nUCSC, and what I learned is truly fascinating; for example, the use of non-speech audio \\nto perceptualize data as a complement to visualization techniques, or even as a stand-\\nalone technique.\\n \\nThere is also a group of Wall Street data scientists (or quants) whom not many people \\nknow of outside of trading, structured finance, risk management and/or political risk \\nanalysis. I already mentioned Jami Miscik and Marc Chaikin, but I should also mention \\nJorge Calderon and Phil Weingord (ex-heads of Global Asset Securitization for Deutsche \\nBank and Credit Suisse), Dr. Mark Shi at Citigroup, and Dr. Jose Hernandez and Blythe \\nMasters at JP Morgan. I have worked with all of them, with the exception of Blythe \\nMasters, who almost hired me for her Credit Risk Trading group, but I opted to take \\nanother offer.\\n \\nThe group above created many cutting-edge analytical and computational methods used \\ntoday in financial engineering, risk management, and other fields, but unfortunately, the \\n2008 financial crisis and problems in the risk valuation of many MBS and CDS by rating \\nagencies tainted a big chunk of the industry and overshadowed the work of a lot of good \\npeople.\\nCan you tell me about some of the ways you and other data scientists at ttwick \\nkeep ahead of the curve, education wise?\\n \\nI attend a lot of conferences and meetups, and I read as many books as possible about the \\nlatest findings in artificial intelligence,, financial engineering and many other related \\ntopics.\\n \\nI attended the Strata Conference 2014 in Santa Clara and it was fascinating to learn \\nabout some of the cutting edge initiatives at DARPA in the area of big data, the latest ML'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 205}, page_content='LUIS SANCHEZ\\n201\\nR&D projects at Stanford, and in general, getting a feeling for the general direction of \\nthe industry. I highly recommend it to aspiring data scientists. \\nI also run a meetup group in New York called “ Algorithmic Art - Quadrivium”, where \\nIexplore Machine Learning applied to creative arts, and the legal ramifications of \\nproprietary artificial intelligence code creating content.\\nWhat are your personal 1 and 3-year goals as a DS?\\n \\nMy goals are to complete all the pending projects I have for ttwick, file patents for all the \\ntechnologies we are developing, and help improve the efficiency of a couple of industries \\nin which I have not seen significant improvements in decades.\\nHow do you think DS is changing over the next few years?\\n \\nI expect the biggest advancements to come from high-performance computing and data \\nstorage.\\n \\nDefinitely, there will be more “toolkits” available to do data analysis. Data wrangling will \\nbecome easier and faster (hopefully), data collection systems and sensors will probably \\nhave built-in data cleaning capabilities, or something like that, and testing of different \\nmethods will become faster. Also, I think data scientists will be incorporating a lot more \\nhardcore time series analysis into their work, which I don’t see much outside of finance.\\nWhat are some new developments in the field that you are really excited about?\\n \\nThere are several exciting new ones:\\n• The DeepDive probability inference methodologies that Christopher Ré is building at \\nStanford;\\n• DARPA ’s Memex project;\\n• A few of the developments related to semantic search, coupled with natural language, \\nand the intersection with fintech, including the one in development at ttwick;\\n• The work of some people I know with cryptocurrencies;\\n• Artificial intelligence applied to algorithmic art (music derivatives, visual arts, etc.)\\n \\nI think any progress in any of those initiatives, along with adequate user adoption and \\nnew ethical business models for the data economy — all of these have the potential to \\ndisrupt many industries over the years to come.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 206}, page_content='MICHELANGELO D’AGOSTINO\\nSenior Data Scientist at Civis Analytics\\nCan you talk about your career from undergrad to PhD? How did you transition to \\ndata science and data analysis, and what were your various roles afterwards?\\nMy career has been strange. Sometimes, it feels like a random walk, but it’s more of a \\ngreedy algorithm. Every time I’ve had a choice of what to do, I think about what seems \\nlike the best opportunity, the most interesting thing for me to do. It’s worked out really \\nwell even though there hasn’t been this overarching plan.\\nI started as a Harvard undergrad and studied physics. I always really loved physics, but \\nI also really loved doing other things outside of physics. So, I took tons of literature \\nand history classes when I was an undergrad. I liked working in the lab and doing the \\nresearch stuff, but I always had lots of different interests.\\nI graduated, and I wasn’t sure if I wanted to go to grad school because I wanted to get a \\njob. Looking back on it now, I wish data science existed when I was an undergrad. I really \\nAs an undergrad at Harvard, Michelangelo was fascinated by \\nphysics. He finished his PhD in astrophysics from Berkeley, \\nand developed a love of working  collaboratively on hard \\nproblems with other people while analyzing neutrino data \\nfor the IceCube experiment.\\nMichelangelo started his data science journey as a senior \\nanalyst in digital analytics with the 2012 Obama re-election \\ncampaign, where he assisted in optimizing the campaign’s \\nemail fundraising efforts and analyzed social media data. \\nAfterwards, he worked as Lead Data Scientist at Braintree \\nbefore he rejoined many of his former colleagues from \\nthe Obama reelection team at Civis Analytics. At Civis Analytics, Michelangelo works on \\nstatistical models and writes software for data analysis.\\nMichelangelo has travelled to the South Pole and has written about science and technology \\nfor The Economist.\\n \\nIn his interview, Michelangelo shares his story and offers practical advice on transitioning \\nfrom a PhD into data science. He also shares his thoughts on data science for social good.\\nThe U.S. Presidential Elections as a Physical Science'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 207}, page_content='203MICHELANGELO D’AGOSTINO\\nloved quantitative research. I loved the stuff I did in the lab, but it felt a little distant \\nto me. It didn’t feel connected to the world. I think that’s what always made me a little \\nhesitant about research, but when I graduated from college, there was not really a path \\nfor technical people to do things outside of academia. You could go work in finance, and \\ntons of people I know worked on Wall Street. But outside of that, there wasn’t a clear \\nthing to do. \\nI took a fellowship to go teach physics at \\na boarding school in England for a year \\nbecause I also really loved teaching.  It \\nwas a great way to experience teaching \\nphysics, learn about high school kids \\nand what they’re like, and travel around \\nEurope.  I really enjoyed it, and I could really see myself teaching for a long time, but \\nI started to apply to grad school because I knew that teaching would always be there.  \\nI liked it and I knew I could go do that. I also knew that if I wanted to go back to grad \\nschool, I felt like I had to do that relatively quickly before I got too old and just too tired.\\nI started grad school at UC Berkeley in physics, and I enjoyed the classroom aspect of \\nit.  I started doing research in condensed matter physics.  I enjoyed that, too, but I was \\nbasically in a second sub-basement.  I was doing this condensed matter research, and I \\nhad this feeling that it was detached from the outside world.  Also, it was really solitary.\\nI made a transition and switched research fields to particle physics and astrophysics.  \\nI did my PhD on a neutrino physics experiment that is located at the South Pole.  It’s \\ncalled IceCube, and it’s operating now.  We basically buried sensors in the polar ice cap \\nto measure cosmic neutrinos.  It was a transition for me because, all of a sudden, I was \\nworking with a couple hundred people all around the world. Half of them were in Europe, \\nthe other half in the US spread out across all of these different time zones. It felt like I \\nwasn’t working on something by myself. I was working on really interesting problems \\nwith other smart people and doing really hard work. I think that was what kept me in \\ngrad school — knowing that I was working with other smart people in a collaborative \\nenvironment.  \\nI found out that it suited my personality a lot better than solitary research, and that was \\nwhen I was introduced to everything I know about data science. That’s when I learned \\nmost of the statistical techniques and most of the computer programming I know, and it \\nwas when I started using machine learning techniques.  Basically, the common thing in \\nparticle physics now is you have a big detector, and there are tons of things happening \\nin your detector, the vast majority of which you don’t care about and are not trying to \\nstudy.  But you also have something happening in your detector that you care about.  \\nMy career has been strange.  Sometimes, \\nit feels like a random walk, but it’s more \\nof a greedy algorithm.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 208}, page_content='204MICHELANGELO D’AGOSTINO\\nThe whole game is trying to figure out what is signal and what is background. These \\ndetectors are so complicated, and the signal-to-noise ratios are so low, that techniques \\nfrom computer science and machine learning have really infiltrated physics. It’s \\ninteresting because the old school professors don’t like machine learning.  You go to \\nthese seminars with old guys from the 1960s, and they ask aggressive questions and \\ngive you these looks.  They don’t like these techniques.  They just think they’re black \\nboxes. But for the younger generations, they are common tools to do the most sensitive \\nanalysis of the thing you care about.  \\nThat was how I was \\nintroduced to machine \\nlearning.  For my thesis \\nresearch, I used a lot \\nof neural networks to \\ndo pattern recognition \\nfor a particular kind of \\nneutrino signal in the detector that we cared about.  I found that I liked programming \\nand statistical work and machine learning a lot more than I liked lab research.  \\nThat was how I was introduced to this field, and I finished my PhD.  I did a post-doctorate \\nfor a year in neutrino physics, and this was when the term data science first came out and \\npeople started talking about it.  I started reading lots of blogs about the field, realizing \\nthat this is something I wanted to do and had the right skills for. \\nI started messing around with Kaggle when Kaggle first came around. I started learning \\nR and just took any chance I could get to learn. I went to meet-ups and other things that \\none does to learn these things out of the classroom, started messing with data sets and \\ngoing to hackathons. \\nOne day, as a post-doc, I was in my office randomly reading KDNuggets, which is a blog \\nfor learning data science stuff. They posted an ad for the Obama campaign looking for \\nscientists, statisticians, and computer scientists to go work for the campaign. It seemed \\nlike an intriguing opportunity for me. I had never worked in politics before, but I had \\nalways been interested in it. Because I had been reading a lot about data science and \\nmaking that transition, it seemed like a good opportunity to test out if I was any good. \\nAs it was only a year, this work also seemed like a low pressure way to test out if data \\nscience was interesting to me. I didn’t have to quit my post-doc. But in reality it was \\nactually the opposite of a low pressure environment. \\nI applied. I had an interview, and I got an offer. The funny thing was I assumed that since \\nit was a political campaign, they would pay me so little money that there was no chance \\nI started learning R and just took any chance I could get to \\nlearn — like going to meet-ups and other things that one \\ndoes to learn these things out of the classroom, messing \\nwith data sets and going to hackathons.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 209}, page_content='205MICHELANGELO D’AGOSTINO\\nI would be able to accept the job. It turned out that it was basically the same as my post-\\ndoc salary, which shows you how well-paid academics are. \\nI took the job. I started \\nin November 2011 and \\nworked through election \\nday.  It was a transformative \\nexperience for me in a \\ncouple of ways. First, I \\nrealized that a lot of the \\nthings I was doing were not \\ndissimilar to the things I \\nwas doing in physics. I spent tons and tons of time writing Python code to grab data from \\nAPIs (Application Programming Interfaces - the way one programmatically interacts \\nwith another application or data stream)  or to scrape data. It was a lot like writing data \\nacquisition code in physics. I was doing statistical stuff in R rather than the packages we \\nused in high energy physics, but I was still building statistical models, predictive models. \\nInstead of particle physics models, I was building models to predict how much money a \\nfundraising email was going to make from its early returns.  The question we had was: \\n“If we sent an email asking people to drive to a neighboring state to canvas, who found \\nthe people most likely to respond favorably to that email?” That information allowed us \\nto focus our targeting efforts. \\nI realized that the techniques of working with data, understanding statistics and being \\nable to visualize something and tell a story about it - these were precisely the skills I \\nlearned in physics and carried very well over to the data science context. \\nWe can talk more later about the campaign if you’re interested, but we did lots of \\nmodeling, randomized experiments, e-mail fundraising optimization. It was an amazing \\nexperience. It was actually the first time I felt the technical skills I had could be used to \\naffect the world, to work towards something that could affect the world positively.  That \\nwas really cool.\\nThen, I thought briefly about going back to finish my post-doc afterwards, but I decided \\nthat I really liked working in data science more than I liked working in research. It was \\nlike the feeling I had when I switched to astrophysics. I like working with people a lot \\nmore than I like working by myself.  I like to work on things that have more impact.  You \\nsee a lot more of it in industry, in data science, than you do in research.  I like the pace \\na lot more.  I think research can often be very slow, especially particle physics.  It takes \\n10 years to build an experiment now.  You have to have a monastic personality to be a \\nphysicist nowadays.  \\nThe funny thing was I assumed that since it was a \\npolitical campaign, they would pay me so little money \\nthat there was no chance I would be able to accept \\nthe job. It turned out that it was basically the same as \\nmy post-doc salary, which shows you how well-paid \\nacademics are.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 210}, page_content='206MICHELANGELO D’AGOSTINO\\nI found the pace suited me better, and the work was actually just as interesting or more \\ninteresting to me than a lot of the stuff I was doing in physics.  That’s how I ended up \\nwhere I am.  After the campaign, I went to a startup in Chicago called Braintree, which \\ndoes credit card processing for other startups like Uber, Airbnb, Github, and a lot of other \\ngrowing tech companies. I started the data team there, and it was a really interesting \\nintroduction to the world of startups.  Then, Braintree ended up getting acquired by \\nPaypal in the fall, and for reasons mostly unrelated to that, I decided to make a switch. I \\nwent to work with some old campaign colleagues at a startup called Civis Analytics, that \\nspun out of the analytics shop on the Obama campaign.\\nAt Civis we’re doing really interesting data work for a lot of political clients and campaigns \\nlike we did on the Obama campaign, but we’re also working with some interesting non-\\nprofit and corporate clients.   We’re really trying to do a lot of individual level predictive \\nstuff like we did on the campaign, focused on political and social good work.\\nThat’s my story in a nutshell. \\nYou mentioned that some of the most useful things you did during your time as a \\nPhD were working on hackathons or working on Kaggle or data sets and working \\nwith people.  Do you have more to add to that? What was the most useful part of \\nbeing a post-doc and PhD student for your later data analysis/data science career? \\nI always tell students that I think the most useful skill you learn in grad school is how \\nto teach yourself stuff and \\nhow to figure out things \\nthat you don’t know.  That’s \\none thing.  The second \\nthing is to be stubborn \\nand beat your head on a \\nproblem until you make \\nprogress.  It’s really those \\ntwo things.\\nI feel like grad school gave me confidence.  Physicists tend to be a pretty arrogant \\nbunch.  They think they can learn anything, but that was the lesson I learned in grad \\nschool. I don’t know every programming language in the world, but I’m confident that \\nif I spend a few months, I could pick up a new programming language or pick up some \\nnew infrastructure tool or modeling technique. I can teach myself those things.  I can go \\nout there and read academic papers, read software manuals, and teach myself the tools I \\nneed to get the job done. I think that’s pretty common across grad school fields.  Most of \\nI always tell students that I think the most useful skill \\nyou learn in grad school is how to teach yourself stuff \\nand how to figure out things that you don’t know.  \\nThat’s one thing.  The second thing is to be stubborn \\nand beat your head on a problem until you make \\nprogress.  It’s really those two things.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 211}, page_content='207MICHELANGELO D’AGOSTINO\\nthe things you learn you don’t learn in the classroom.  You learn by completing a project \\nand teaching yourself things.  In data science, that’s a crucial skill because it’s a quickly \\ngrowing field and it encompasses a ton of things.  You can’t finish a degree and know all \\nthe things you need to know to be a data scientist.  You have to be willing to constantly \\nteach yourself new techniques.  \\nThat was one of the things I \\nlearned in grad school.  The \\nother is the ability to work on \\na hard problem for a long time \\nand figure out how to push through and not be frustrated when something doesn’t work, \\nbecause things just don’t work most of the time.  You just have to keep trying and keep \\nhaving faith that you can get a project to work in the end.  Even if you try many, many \\nthings that don’t work, you can find all the bugs, all the mistakes in your reasoning and \\nlogic and push through to a working solution in the end.\\nHaving confidence in yourself is another thing. I think that working on a really hard \\nproblem like in grad school can help you learn that. And then there are just the technical \\nthings like learning how to program, running on large computer clusters. On top of \\nmastering those techniques, the advice I give to grad students is: if you feel like you want \\nto leave grad school and do something else, keep that in mind when picking which tools \\nand techniques you use for a dissertation. If you can write your dissertation in Python \\nrather than some obscure language like FORTRAN, it’s probably going to be better for \\nyou. Try to be as marketable as possible with the things you learn when you’re doing \\nyour PhD.\\nAnd the final thing is that it really helps to have experience working with data. The only \\nway to learn how to work with data is to actually work with data. You can read about it, \\nand people can teach you techniques, but until you’ve actually dealt with a nasty data \\nset that has a formatting issue or other problems, you don’t really appreciate what it’s \\nlike. There is no substitute for the experience of having to merge a bunch of data sets \\ntogether or make a bunch of graphs to sanity check something. Or finding all of a sudden \\nthat nothing makes sense in your distributions, and you have to figure out what’s going \\non. Having those experiences makes you a better data scientist.\\nSo far, you’ve given a lot of advice for graduate students, for example working \\nwith more common tools or working with data. Can you expand on that because \\nyou are a physicist-turned-data-scientist? What is your advice for other physics \\nPhD students or other physicists who are transitioning to data science?\\nMy advice is to recognize the skills that you have. In terms of actually mechanically \\nAnd the final thing is that it really helps to have \\nexperience working with data.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 212}, page_content='208MICHELANGELO D’AGOSTINO\\nmaking that transition, there are lots of ways people can learn more about the field and \\ndemonstrate their interest.  From a hiring perspective, when I talk to PhD students who \\nsay they want to be data scientists, I become skeptical if they haven’t taken any active \\nsteps.  “Hey, I participated in these Coursera courses or these Kaggle competitions.  I’ve \\ngone to the Open Government Meetup and have done these data visualizations.”  Things \\nlike that demonstrate that you can work on problems outside your academic specialty, \\nand they show that you really have initiative.  They also show that you can teach yourself \\nnew things.\\nThe worst thing is when people present the physics job market as terrible, and they say \\nthat’s why they want to get a data science job.  You don’t want to hire someone like \\nthat. You want to hire someone who’s going into data science because of what it’s like, \\nbecause they want to work on data in the real world. You want it to be a positive thing \\nrather than a negative reason that they’re leaving physics.\\nTo be honest, it’s not a terrible \\nreason to want to leave \\nacademia because there’s no \\njob, or because you’re lonely, \\nbecause you’re working on a \\ntiny, tiny problem. Those are good reasons to leave academia. From a practical standpoint \\nthough, when you’re presenting yourself to other people, I think you should focus on the \\npositive reasons that you’re excited to do something else rather than negative thoughts \\nabout about what you’re doing. Having said that, all those things are true, and all those \\nthings are reasons why I also personally decided to leave.\\nThe other piece of advice I always give to job seekers is when people talk about data \\nscience jobs, it can mean so many different things.  At each different place, when they’re \\ntalking about hiring a data scientist, that can mean something totally different.  In some \\nplaces, they just want someone who can run SQL queries and numbers for every report.  \\nIn other places, they want people who are actually going to build data infrastructure. In \\nother places, they want some people who are going to build predictive statistical models \\nand design experiments. In some places they want the unicorn that can do all that stuff. \\nSo it’s really important to ask a lot of questions and figure out what a company really \\nwants when they want a data person. What would someone actually want in that role? \\nAre there other people currently working as data scientists at the company? What are \\nthey doing? Is there an engineering team? Is there a product team?\\nYou mentioned earlier about working with people and making a large impact.  \\nWhat about the future of data science excites you the most?  What are some of \\nI’m excited about future applications where data \\nscience is going to be seen as a positive force.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 213}, page_content='209MICHELANGELO D’AGOSTINO\\nthe positive reasons that you would give to graduate students on why data science \\nhas greener pastures?\\nI’ll leave out all the sociological reasons that I already talked about, why it’s more \\nenjoyable to work in a collaborative, fast paced environment, and to see the impact of \\nyour work.  In academia, you don’t have clients. In physics, I always felt that we had \\nto beg people for money to do what we wanted to do, and that may still be true in data \\nscience, depending on your company. But most of the time, there are people who are \\ninterested in the output of what you’re doing and really appreciate those skills. \\nI also think the work is exciting.  \\nIt’s incredibly exciting, and it’s \\nstill in an early phase.  I’m not \\ngoing to go into the cliché of how \\nmuch data we’re collecting and \\nhow all of these organizations \\nare collecting more and more \\ndata.  Many people have talked \\nmore eloquently than I can \\nabout that.  But it’s true. Organizations have tons and tons of data, and they don’t \\nnecessarily know what to do with it.  They’re starting to think about what to do with it, \\nand they need help from people like us to actually do that work.\\nThis is the reason that I came to Civis. I’m really excited about future data science \\napplications that people are going to look at and think are benefiting society in a positive \\nway.  Like working with non-profits to use their data in smarter ways, or working with all \\nthe data that cities are releasing now.  \\nOpening up public data is great, but there are not many cities that are using their data in \\na real, predictive way right now.  New York has done some really interesting predictive \\nthings. Chicago has released a lot of data, but Chicago hasn’t done a lot of interesting \\nanalytics with its data as a city. They just release data to the community and hope the \\ncommunity will do it.\\nI’m excited about future applications where data science is going to be seen as a positive \\nforce for good, because honestly I’m a little worried.  Right now, a lot of the applications \\nwe have with data have to do with targeted advertising, cookie collection, online \\noptimization of ad click rates, etc. That’s great, but I’m worried that, at some point, \\nthere’s going to be a backlash against collecting more and more data about people. \\nI’m hoping that before that happens or when that happens, there are enough positive \\nThere are lots of people who are writing tutorials \\nexplaining different techniques and different \\nprojects they’ve worked on.  None of that existed \\nwhen I was younger, and it’s awesome that you \\ncan go out, get that stuff, and get an idea of \\nwhat’s going on.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 214}, page_content='210MICHELANGELO D’AGOSTINO\\ncounter examples of ways data is being used to benefit people and society that it can \\nprevent some of that backlash.\\nI wish I could talk about this a little more specifically with the clients we’re working with \\nat Civis, because that’s something we’re really focused on.  Before I started here, one of \\nthe big engagements we had was with the College Board, the folks who administer the SAT \\nexam. We spent a very long time working with their data and helping them build models \\nto understand which kids weren’t going to colleges and universities commensurate with \\ntheir abilities.  Could we predict that?  If so, what are the implications for designing \\ninterventions to help those high school students? I’m hoping that we’ll have more and \\nmore examples of data science work like that, work that people feel good about rather \\nthan just seeing that companies are trying to collect data from them.\\nAlso, one of the data scientists from the campaign started a Data Science for Social Good \\nFellowship in Chicago, where I was a volunteer mentor. Some of the projects we worked \\non addressed really interesting social impact problems, and I’m hoping there will be \\nmore and more of these kinds of applications in the future. That’s what excites me about \\nthe future of data science.\\nWhen we spoke to Jace from Khan Academy, it was inspiring to see him apply his \\nknowledge from quantitative finance to education. How can we encourage more \\nof this in the nascent data science community?\\nI think people really want to do more and \\nmore of this kind of work. I think about \\nthis a lot. My wife is a lawyer, and almost \\nall lawyers do some amount of pro bono \\nwork in a given year. I think it would be \\nawesome if we could get some engineers \\nand computer scientists and data people to \\ndo a certain amount of pro bono hours every year working with a non-profit. A lot of \\npeople are already doing that as a volunteer thing, but if we could institutionalize that, \\nI think that would really be awesome for the field. \\nYour background as a science teacher and as a writer is different than most of the \\nother people we’ve interviewed.  As a science teacher and writer, how is data \\nscience doing on the PR side?  What is data science missing on the teaching and \\nwriting side? \\nI forgot to mention that earlier. I was briefly a science journalist. I took a summer off \\nand worked at The Economist and wrote about science and technology. I freelanced for \\nI do worry that there’s a little bit of \\nhype, but it’s undeniable that there’s \\na very solid grain of truth to the whole \\ndata science thing.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 215}, page_content='211MICHELANGELO D’AGOSTINO\\nthem for a while after I was in London for that summer. I actually think teaching and \\nwriting have helped me become a better data scientist because a lot of what I do is \\ninteract with my colleagues on a daily basis. I teach them new things all the time. They \\nteach me things. We sit in meetings and look at graphs and talk through algorithms and \\ntechniques, and we ask each other questions. We explain things to each other, and you \\ntell a story about the data.  That’s very similar to the things you do in a classroom when \\nyou’re teaching people something.  It’s very similar.  When you’re writing about science, \\nyou try to simplify things and explain them to people.  Those skills have been useful for \\nme as a data scientist. \\nAs a field, I think data science is doing a pretty good job. There are so many people who \\nare blogging about their work and telling stories about their work.  There are lots of \\npeople who are writing tutorials explaining different techniques and different projects \\nthey’ve worked on.  None of that existed when I was younger, and it’s awesome that \\nyou can go out, get that stuff, and get an idea of what’s going on.  I think that is really \\nawesome.\\nSometimes, when we talk with people who come from an academic background, \\nthey are suspicious of data science.  They think of it as a fad.  I’m thinking about \\nthe hype that might be behind that or how some people react to it.  What would \\nyou say to somebody who thinks it’s a fad?\\nFirst of all, I think it’s a valid concern. \\nI do worry that data science is being \\nsuper hyped up right now. Not by the \\npeople that are doing it or who know \\nwhat it’s really about, but there are \\nlots of companies who want to sell \\npeople things. A few journalists write \\nan article on something, and everyone \\nelse feels like they need to write an article too.  Then, it becomes this big giant thing.\\nI do worry that there’s a little bit of hype, but it’s undeniable that there’s a very solid \\ngrain of truth to the whole data science thing. We do have lots and lots of data, and we’re \\ncollecting more every day.  I can’t imagine that companies and organizations are going \\nto want to be less efficient in the future about how they reach out to people, about how \\nthey optimize their own operations. I think that trend is going to continue, and they’re \\ngoing to want people to help them analyze that data. The skills you need to do that just \\ndon’t come from a single discipline like statistics or computer science. They have all the \\ninterdisciplinary aspects of what people call data science.\\nThis is why I’m excited about more positive \\nexamples of data applications. I think the \\nmore positive examples of data science that \\nwe have, the more it will help counteract a \\nlot of the hype.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 216}, page_content='212MICHELANGELO D’AGOSTINO\\nThis is why I’m excited about more positive examples of data applications. I think the \\nmore positive examples of data science that we have, the more it will help counteract a \\nlot of the hype. I think all the hype has not just been around data science but about tools. \\nEveryone’s been talking about Hadoop. Hadoop is great, but it’s a tool. It’s not the most \\nimportant thing in the world, and not every organization needs to have a giant Hadoop \\ncluster, but, with the hype, the message is, “If you’re not running a Hadoop cluster, you’re \\nnot doing anything interesting with your data.” \\nThe term big data makes me want to throw up because it’s become an overused, overhyped \\nthing. To me, it’s not the amount of data you have. It’s what you do with the data you \\nhave and how you apply it to problems and what interesting things you’re doing with it. \\nThat’s so much more important.\\n \\nI actually don’t think that anything we did on the campaign, when you talk to someone \\nfrom Silicon Valley, counts as big data. We didn’t have a petabyte of data, but it was what \\nwe did with it, how we were changing the organization and the practices of the campaign \\nthat was really important.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 217}, page_content='MICHAEL HOCHSTER \\nDirector of Data Science at LinkedIn\\nYour background spans both pure mathematics at the undergraduate level, law \\nstudies and then a Ph.D. in statistics. How did that happen? Can you talk a little bit \\nabout that process?\\n \\nI have never been great at long-term planning for anything, so I’ve always followed my \\nnose. Even the decision to go into math in the first place — I’d decided at the end of high \\nschool that I was finished with math and that I didn’t really enjoy it that much. But I kept \\non taking just one more class in college. Then at a certain point, that was the only thing \\nI had taken enough classes in to have a major. So I ended up majoring in math. I did end \\nup liking it a lot, but that wasn’t a directed decision.\\n \\nI was mostly interested in the pure math. My dad is a mathematician so that might have \\nsomething to do with it. More than anything, I really liked the fields of abstract algebra, \\ntopology, logic, and set theory. I didn’t take any statistics courses as an undergraduate, \\nalthough I studied probability if that counts.\\nThen at the end of college, my thought was, “This is too abstract. This is fun, but I need to \\ndo something connected to the real world. ” At that time, I didn’t see math as something \\nMichael Hochster’s path into the field of data science \\ntook a series of winding turns. After graduating from high \\nschool, Michael believed himself to be done with math. Yet, \\nhe eventually received his bachelors in pure mathematics \\nfrom UC Berkeley.\\nAfter graduating and seeking something more practical, \\nMichael entering law school, but quickly learned that it \\nwasn’t for him. After leaving law school, he eventually \\nended up enrolling in the Statistics PhD program at \\nStanford, despite having minimal exposure to statistics.\\nAfter some time spent in industry, including stints at a pharmaceutical company, a web \\nstartup, Google and Microsoft, Michael became the Director of Data Science at LinkedIn.\\nWhile we interviewed Michael when he was in his role at LinkedIn, he has since become the \\nDirector of Research at the music company, Pandora.\\nThe Importance of Developing Data Sense'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 218}, page_content='MICHAEL HOCHSTER\\n214\\nthat was going to lead me to a connection with the real world. So I speculatively decided \\nto go off to law school with the reasoning: “ I’ll probably be able to find something useful \\nand interesting to do with this.”\\n \\nLaw seems to have a logical aspect, which is similar to math in some ways.\\n \\nI’m guessing that the logic part translated from math to law very well.\\n \\nWell, that’s what I thought. There’s a superficial similarity: it’s reasoning. It’s making \\nyour career out of reasoning. I always liked the reasoning part of math; it was one of \\nthe more appealing aspects. This was the story that I told myself when I went off to law \\nschool.\\n \\nSo I went to law school for a \\nyear and it was a bit of a mixed \\nbag. I did like law school; I \\nenjoyed the classes and liked \\nmy fellow students. But at a \\ncertain point, I started realizing \\nthat the “ I will probably find \\nsomething interesting to do with \\nthis” thinking wasn’t going to pan out if I didn’t have a real plan. It seemed like everybody \\nwas defaulting to corporate law. If you were taking the next step up the ladder, you went \\nto a good law school, you went to work at a good firm, and then you became a partner.\\n \\nSo there was a certain point during the summer when you were supposed to find a law \\nfirm for an internship. As I was sitting in these interviews explaining to the interviewers \\nwhy I wanted to work for their firm over the summer, I realized that I didn’t really want \\nto do that. I didn’t really know what I did want to do and it seemed misguided. I was just \\ngoing down a path that didn’t make sense.\\n \\nI didn’t know what I was going to do next, aside from not-law-school. I did have a friend \\nwho was doing a Ph.D. in statistics at Berkeley and I got in touch with her. She told me \\nabout some of the things she was working on (she’s now a professor of Biostatistics at \\nthe University of Florida). It just sounded interesting, at least more interesting than the \\nthings I was doing. Again, this was completely speculative. I didn’t know anything, but I \\njust thought, “I know some math so I’ll probably be able to pick this up.”\\n \\nSo I started applying to graduate schools in statistics and took some time off. I was a \\ntemp for a while. Eventually, I got into graduate school. It was funny because all I had \\nwas a general idea that I wanted to do something connected to the real world. I wanted \\nAt the end of college, my thought was, “This is too \\nabstract. This is fun, but I need to do something \\nconnected to the real world.” At that time, I didn’t \\nsee math as something that was going to lead me \\nto a connection with the real world.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 219}, page_content='MICHAEL HOCHSTER\\n215\\nto use my math background, but I didn’t know anything. I didn’t know what confidence \\ninterval was, I didn’t know what a t-test was. I didn’t know anything.\\n \\nDid you find the statistics graduate school experience to be more closely aligned \\nwith what you were expecting?\\n \\nGraduate school was rough for me, because of my lack of background going in. I didn’t \\nunderstand the point of a lot of things we were studying. In grad school, you immediately \\nlaunch into theoretical statistics; you don’t really have any idea about its applications. \\nUnbiased minimum variance estimator? Who cares?\\n \\nIt seems like you still had the question of, “what is this applied for?”\\n \\nYes, in the end, the “I want to do something connected to the real world” fell by the wayside, \\nin the sense that I was most comfortable doing math. Even though my math was a little \\nrusty at this point, my graduate school experience resulted in my being most comfortable \\nin the theoretical side of statistics where I could prove theorems and know I was getting \\nthe right answer. That’s the gratification you get from math.\\n \\nI ended up, first of all, being very far behind in understanding the point of statistics. \\nUltimately I fiddled around with it and tried to work out what to study. I ended up in \\nsomething that is very theoretical. Which I enjoyed in a way, but it didn’t have the \\nconnected-to-the-real-world feeling. It was very tenuous.\\n \\nIt wasn’t until I entered the workforce that I started understanding what statistics were \\nuseful for. It was a pleasant surprise that I actually like the job, and am well suited to \\nit. I’m more interested in working out how to do useful things with data than I am in \\nproving theorems. It was only after school was over that I started to figure out it was a \\nvery good fit for me. It was accidental.\\n \\nEven after having finished the Ph.D., I felt I was going up the next rung of the ladder. You \\nget your Ph.D. from a good school and then you want to get a postdoc at a good school \\nor a tenure track position, that’s the next step up. On top of that, both my parents are \\nacademics, so that path seemed natural to me. And I wasn’t too well-informed about \\nother options. But in the end, it was clear to me that I wasn’t passionate enough about \\nproving theorems in theoretical statistics to make that my livelihood.\\n \\nIt sounds like from your story that after you finished your Ph.D., you then evaluated \\nyour options and said, “I don’t really want to go down the full professor route.” Is \\nthat correct?\\n \\nIt was a mixture of things, that’s a somewhat nice revision of it. I applied for a few things,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 220}, page_content='MICHAEL HOCHSTER\\n216\\ndidn’t get anything. Then it became a question of, “ should I really press hard and apply \\nand go to a place where I may not really want to live? Or should I think about what else I can \\ndo?”\\nIt wasn’t that clear. This was a time when a lot of people were going into finance. You \\ncould go into the pharmaceutical industry. That seemed about it. It wasn’t like you \\ntype “data science” into a search engine and you get fifty million jobs. I was looking for \\nstatistician or quant, something or other. I applied for some finance jobs and I ended up \\nmeandering into this position as a biostatistician for a pharmaceutical company.\\n \\nWas that was the first time you were confronted with real data?\\n \\nIt was an interesting experience. Again, I was going in as with every step, very ignorant. I \\nstill think especially here in the Valley, people don’t appreciate the huge role traditional \\nstatistics plays in the pharmaceutical industry. These companies employ armies of \\nstatisticians who are really good people. All this A/B testing that’s so in vogue now \\nhas been thoroughly worked out in the pharmaceutical industry. All the philosophical \\nhand wringing: “can you peek at the data,”  “Bayesian versus frequentist” and looking at \\nsubgroups. Those people have really thought about this. So that was fun for me.\\n \\nI started out at Schering-Plough, \\na pharmaceutical company in \\nNew Jersey, where statisticians \\nwere divided into preclinical and \\na clinical side. I started in the \\npreclinical group at Schering-\\nPlough, which was statistical \\nconsulting for the scientists \\nresearching new treatments. That was the role. So it was very open-ended and some of \\nit was interesting. This was when gene microarray technology was first getting started. \\nThey had acquired a microarray company and there was some interesting data there.\\n \\nThe stuff didn’t work very well. The errors were huge and they needed some statisticians \\nto work it out. They may not have been aware of this, but they needed statisticians to \\nestimate the signal-to-noise ratio. There was a lot of explaining of t-tests to scientists \\nas well. It was a mixture of things.\\n \\nThe clinical side had way more statisticians, since it was all about the design of clinical \\ntrials that would ultimately end up as submissions to the FDA. That was the more serious \\nside of the business. The research scientists could get along without us to a large degree. \\nHowever, doing analysis that ends up as an FDA submission was a pretty big deal.\\nPharmaceuticals is such a heavily regulated \\nindustry. It’s not just about creatively doing \\nthe best analysis you can give. It’s doing the \\nbest analysis you can do within the constraints \\nof the regulations.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 221}, page_content='MICHAEL HOCHSTER\\n217\\nPharmaceuticals is such a heavily regulated industry. It’s not just about creatively \\ndoing the best analysis you can give. It’s doing the best analysis you can do within the \\nconstraints of the regulations. Some really clever Bayesian thing isn’t going to fly.\\n \\nThe thing that was a little bit unappealing about it was it can have a bit of a lawyerish \\nflavor. Yes, you are trying to do the best analysis. But it’s not like your employers don’t \\ncare which way it comes out. It’s almost impossible not to look at it as finding the best \\nstatistical case.\\n \\nThe methodology requires that it be rigorous in some sense. But there’s always a funny \\nspace of choosing what analysis to do and convincing yourself what’s the best.\\n \\nSo with that experience in hand, were you motivated to transition to the tech \\nindustry in the late 1990s when technology was becoming big?\\n \\nThat’s exactly what happened. I switched from Schering-Plough in 2000, which is when \\nthe web had arrived and it was the first dot-com boom. I was living in New York City \\nand had an opportunity to work at this dot-com start up in the city. I got on board with \\nthat and I started working for a company that was basically doing customer satisfaction \\nsurveys on the web. So I ended up having an analytical role. It was a startup that had \\nbeen acquired by a larger company so it wasn’t exactly a startup. That’s how I got started \\nin technology.\\n \\nWhat data questions were you asking at these web companies? What was the \\nnature of the analysis?\\n \\nThe idea was to do quick, popup customer satisfaction surveys that would be lightweight \\nenough so that people were willing to fill them out, so you could get a decent response \\nrate. That was the idea, rather than having an extensive survey where you would have to \\ngive people a lot of incentive to do it, and then have to deal with all the biases that you \\nincur by doing that. The goal was, you have a website that wants to know how it’s doing \\nand so it wants to ask its users some questions. This still exists today.\\n \\nWhat was interesting was doing some analysis such as which features of a website are \\ndriving overall satisfaction on the website. That’s an example of a question. The design \\nthat they had was each customer had a large set of questions and then to make the survey \\nshort, they’d take a short sample of the questions. So you’d have a list of 50 questions, \\nbut you’d only ask each user 5 of them.\\n \\nThen you have some data that’s massively missing, a survey that’s only one-tenth \\ncomplete for each user. Then you want to do some analysis with that data, where every \\nrow is mostly missing.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 222}, page_content='MICHAEL HOCHSTER\\n218\\nSo it’s a cool problem. There are also a few interesting methodological questions about \\nthe right way to do this sampling. One is how to make the popup random, whatever that \\nmeans. There was a lot of writing SQL and trying to keep the lights on as well. It wasn’t \\na huge fraction of methodologically sexy work but it was fun.\\n \\nIt’s very hard to answer these questions, but the goal was to get answers to questions \\nlike, “Which aspects of the site did customers get the most satisfaction from? ” So you’ve \\ngot a few problems here, one of which is that it’s all correlation. For instance, customer \\nsatisfaction appears to be highly correlated with appearance, but that’s because good-\\nlooking sites are also the most satisfying in other ways. So it’s not that if every crap site \\nmade itself look better then it would be more satisfying.\\n \\nDid any of your experience in grad school carry over to this area? Or were you \\nlearning on the fly?\\n \\nMost of the time the advanced stuff I learned at school did not directly apply in any of \\nmy jobs because most of the math I learned at school was very specialized. But in the first \\ncouple of years you get some understanding of how things like regression work. Then \\nwhen you come to a problem where you have missing data in every row you think, “ If I \\nwant to do linear regression that only depends on the first two moments of everything, I can \\nestimate those fairly well. Because it’s balanced in a particular way. If I just fit the regression \\nusing the first two moments of everything that might actually work, and not be too biased… \\nAnd well if the covariance matrix isn’t positive-definite then maybe I can fix that up.”\\n \\nSo there’s a little bit of basic math \\nthat you learn that gives you the \\nfoundations to feel comfortable \\nwhen you hit something strange. In \\nall these situations you’re always \\nhitting problems that are slightly \\nweird. In any real life work experience, you never hit anything that’s just a textbook \\nproblem. It always has some weird aspect. The more advanced your education and the \\nmore work experience you have, the more comfortable you are about hitting something \\nweird and figuring out how to adapt what you know.\\n \\nYou did metric design at several different companies including Google. Based on \\nthe different things you’ve seen, how do you approach the problem of metric \\nmeasuring and also experimental design and knowing what to collect?\\n \\nThat’s a pretty big question. Let’s take that one piece at a time. I’ll just make one point \\nabout experimental design which I think is a subtle point. Doing A/B testing is actually \\nreally hard to do well. One thing I learned at Google is you get huge value when you’re \\nIn any real life work experience, you never \\nhit anything that’s just a textbook problem. It \\nalways has some weird aspect.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 223}, page_content='MICHAEL HOCHSTER\\n219\\ntesting something if you can isolate the effect of your test as much as possible. So for \\nexample, if you’re making a change to Google’s ranking algorithm and you want to \\nevaluate it, and that change only affects a small number of queries, you need to look at \\nthe queries that are going to be affected. You may not know which those are in advance, \\nbut you have to focus on those, otherwise you’re not going to be able to see anything \\nsmall if you pull a random sample of queries.\\n \\nThat sounds obvious, but it’s not. Without being too specific, I’ll say that it has not \\nalways been done, that approach has not always been taken. But the whole notion of \\nisolating the treatment effect — that has a lot of ramifications that get complicated.\\n \\nFor example, you think it’s straightforward. You just want to compare A with B. Treatment \\nversus control, it’s very straightforward. Treatment on one side, control on the other and \\nonce you figure out your success metric and you measure both sides, you’re finished.\\n \\nYou can do that. But you might end up with a very noisy comparison if you do that — if \\nthe treatment is only targeted to a low number of samples. What you really want to do is \\ncompare those subjects that were exposed to the treatment, that were affected, to those \\nin the control group who would have been affected by the treatment.\\n \\nSo this counterfactual comparison is what you are really interested in. Because it means \\nthat if you’re doing things the right way, you need to be logging on the control side \\nwhether each subject would have been exposed to the treatment. This means that you \\ncan’t just use your standard production, unless your standard production involves \\nlogging counterfactually what treatments would have accomplished.\\n \\nIt’s often not so obvious how to identify, in the control, whether they would have received \\nthe treatment. So I’ve seen that people usually ignore this. That’s what I would have \\ndone starting out, it’s only because I’ve worked through these problems at Google that I \\nrealized we’re not seeing anything because we’re comparing the whole treatment to the \\nwhole control. It’s just swamped in noise.\\n \\nThis has been a running theme for me, trying to hammer home this point. There are a lot \\nof cases, even at Google (where experimentation is an extremely well-oiled machine), \\nwhere this kind of thinking is not carried as far as it could be.\\n \\nHow did you balance the theoretical rigor you were coming in with, given your \\nacademic training, with the practical demands of actually applying statistics in an \\nindustry setting? Were there tradeoffs you had to make?\\n \\nThat’s definitely a constant challenge.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 224}, page_content='MICHAEL HOCHSTER\\n220\\nThere’s a more basic thing, especially where there’s a division between engineering and \\nanalysis — then who decides what gets logged? From what I say it’s clear it matters a lot \\nwhat’s logged. You may need to log a lot of things to do it correctly and it might not be \\nobvious that the company needs to log it.\\n \\nThus, even if you want to do the basics, you ask engineering to do some work that’s not \\nvery interesting and a pain. There’s a reaction of, “ Really? I have to log that? Explain to \\nme why I need to do this.”\\n \\nThe more nuanced the reason, the harder it is to do. It’s hard to demonstrate the value of \\nit until it’s already in place and then you can say, “Look at this analysis that we were able \\nto do.” It’s 100x more informative than it would have been if you hadn’t done this extra \\nlogging. So yes, it’s a challenge.\\n \\nThe closer and better-aligned engineering and analysis is, the less friction you get.\\n \\nIt seems that analysis spans many different domains of the company. Not only do \\nyou have to work with engineering, but also once you update your analysis then \\nyou need to show it to someone who will act on it.\\n \\nI do think the communication needs of the data scientist role is one of the most important \\nthings. When I’m hiring, there are always some trade-offs between different skills, but \\nthe ability to communicate well is a given. Because it’s important in so many ways, \\nboth in negotiations with other teams and making your analysis have an impact on the \\norganization. You have to be able to talk to people and explain why it matters.\\n \\nThere are people who are good at \\nanalysis and people who are good at \\nwriting code. For some of these people, \\nthere’s such a strong temptation to \\npresent things as, “ I did this, and then I \\ndid this, and then I did this. And then I did \\nthis really smart thing and here are the \\nresults after I did all these really smart things.”\\n \\nNo one gives a shit about that. No one really cares how smart you are. This is why it’s \\ndifferent from graduate school. The subtext of “ I’m smart ” doesn’t matter anywhere \\noutside of graduate school. You have to start with: Here’s what I found and why you should \\ncare about it.\\n \\nSeeing as you’ve worked intensely with understanding metrics at numerous \\nThe subtext of “I’m smart” doesn’t matter \\nanywhere outside of graduate school. \\nYou have to start with: Here’s what I \\nfound and why you should care about it.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 225}, page_content='MICHAEL HOCHSTER\\n221\\ncompanies over the past few years, what have been some of your important \\ntakeaways?\\n \\nI have two main things to say about metrics.\\n \\nFirst, there are two very different angles of looking at metrics. There’s the overall \\nevaluation criterion idea, where you think of a metric that everybody agrees represents \\nprogress. Then you focus all your efforts on improving that metric with the understanding \\nthat this is our understanding of when progress is made.\\n \\nSo when I worked at Microsoft, this philosophy was very strongly advocated. “This is our \\noverall evaluation criterion, you have to move this. I’m sorry but if you can’t move this \\nthen it isn’t worth shipping. Too bad.”\\n \\nMy philosophy of metrics is almost the opposite of this. I think overall the evaluation \\ncriterion is good — you want something you can track. You want to have a number you \\ncan believe in that represents the overall health of your product. But generally, anything \\nthat’s accepted as the driving metric in this philosophy is going to be too broad and you’re \\nnot going to be able to move it. So you really have to make a conceptual distinction in \\nmy opinion between approximate metrics — that you use to decide whether a feature \\nis good, and which are going to be very fine-grained and specific to your feature — and \\nthese overall global metrics that you hope go up.\\nIt depends a little bit if you’re in a business that depends on small improvements or \\nwhether you’re at a stage where you’re making many big improvements. For example, in \\nGoogle search many of the improvements were small. If you’re improving the ranking, \\nit’s small. If you restrict yourself to these broad metrics you can never ship anything \\nbecause they don’t register on the global metrics.\\nOne example of a broad metric is searches per unique user. Using that you can do \\nsomething to ranking and your search engine gets better so people might use it more. \\nBut that’s really hard; you’re not going to be able to see that in most experiments.\\n \\nSo I am very big on thinking very hard about what a particular feature is trying to \\naccomplish, and how we can measure that as narrowly as possible. It’s good to have a \\nsmall number of metrics, but for shipping you want something that measures as closely \\nas possible the positive impact you expect that feature to have, and not think of it as an \\noverall evaluation criterion. So my philosophy is the opposite of what I saw at Microsoft.\\n \\nThe second thing about metrics is that you don’t have metrics on the metrics. You never \\nreally know what a good metric is. So you spend a lot of intellectual cycles trying to'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 226}, page_content='MICHAEL HOCHSTER\\n222\\ndevelop things that are useful. And these things are being used as a yardstick for other \\nthings. So you never have clear guidance about whether your metrics themselves are any \\ngood.\\n \\nIt comes back to getting a new metric established. How do you do that? You have to \\nlawyer it again. That’s tough. How do you do that? How do you go about convincing \\nyourself that a metric is good? And how do you go about selling it or convincing other \\npeople that it’s good?\\n \\nIt’s really hard. A lot of the time, at least in the domains I’ve worked in, you’re interested \\nin “is a particular feature good?” Or, “Is a particular change to a website good?” You \\ndon’t have access to seeing the electrodes in users’ brains to know if it’s good or not, so \\nyou end up inferring what’s a positive impact from behavioral data. While there are all \\nsorts of things you can do to try and quantify user behavior, the issue is that you never \\nreally have absolute truth about what’s good.\\n \\nSo one possibility is to try a lot of things that seem plausible. You don’t have absolute \\ntruth but you have correlation: lots of plausible approaches that seem to point in the \\nsame direction.\\n \\nIt’s not logically guaranteed, but if you start with some plausible things, a lot of them \\nmove together. Some seem much cleaner than the others. That’s how you proceed. \\nIt could be something else that’s making all these things move together, but it’s also \\nplausible that there’s underlying goodness that’s driving them all. So I start to believe \\nthat.\\n \\nThe other way, that’s somewhat of an empirical approach. You observe different possible \\nthings and the fact that they’ve all moved together gives you some interactive evidence \\nthat they’re all doing something reasonable.\\n \\nThis is a really good point. Could tell a brief story about one of these instances? I \\nunderstand the lesson in the general case, but, what was one thing that you tried \\nto measure that was hard to get at, and what were some things that you designed \\nto tackle this problem?\\n \\nI’m going to go back to the example of search. \\nLet’s say you want to use clicks on a search as a measure of accuracy of search results. \\nWell, a lot of that is based on a “more-clicks-is-better” principle — you start thinking \\nabout when more clicks are better. If I have a query, “What is the capital of Albania” \\nand I have a lot of clicks on that query, is that a good thing? Probably not. But if I have a'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 227}, page_content='MICHAEL HOCHSTER\\n223\\nquery such as “Best digital camera” and I have a lot of clicks for that kind of query, that \\nprobably is a good thing.\\n \\nFirst you take a proposal for a metric. Even without looking at any data, you start \\nthinking about under what circumstances the metric could point the opposite way that \\nit’s supposed to. Then you get some ideas; you see there are some major cases where \\nthe metric points the wrong way. Maybe we need some segmentation. Maybe there is no \\nsimple metric that is going to cover everything; maybe we have to consider navigational \\nqueries and more browsing queries separately to have any behavioral metric that makes \\nsense.\\n \\nYou can convince yourself by introspection. The story also becomes more convincing \\nwhen you observe how this new segmented metric compares in practice to just counting \\nclicks. Neither of those things is entirely satisfying. Because your empirical stuff isn’t \\nconclusive, your empirical evidence is never conclusive. Your thought experiments are \\njust thought experiments. So it’s not math. It’s not science.\\n \\nThis sounds like a deep distinction between academia and industry. How has \\nindustry changed your view of math?\\n \\nI still like doing math puzzles for fun. I still think math is beautiful. But in terms of when \\nI think about math as something on the job for me, I don’t consider myself any kind of \\nmathematician. It’s just there, it’s a tool.\\n \\nI’ll say something a little broader than that: math is just there as something that will help \\nme figure out my problem. I feel the same way about all the machinery of data science.\\n \\nFor me it’s the actual substantive questions. For me, there’s data, there are interesting \\nquestions. I want to answer the questions. There are interesting products you can make \\nthat require the data to be big and that’s cool. But the big data per se isn’t interesting. \\nMaybe I’ve been spoiled a little bit at Google where you have this massive infrastructure \\nand you don’t need to think about it that much. You just write a script and send it off and \\nGoogle’s massive infrastructure processes it, and you get your answer back.\\n \\nLet’s talk about your view on data science. How do you see the term, and the \\ndivision within the roles in the field?\\n \\nIt’s a good question. I think I will probably say something similar to what Pete Skomoroch \\nsays, although I’m pretty much all the way type A. For me, a type A data scientist is about \\nAnalysis. B is for Building. Of course there’s no dividing line between those things. A lot \\nof people do some of both.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 228}, page_content='MICHAEL HOCHSTER\\n224\\nAt LinkedIn, it’s divided up that way. There’s a team called Decision Sciences. They \\nare focused more, but not exclusively, on analysis, working with product teams, \\nexperimentation, some model building. But for the most part it’s far from putting stuff \\ninto production.\\n \\nAnd then there’s the data products team which uses data science techniques to build \\nthings. So I think that’s a reasonable distinction to make.\\n \\nSo why even have this term “data science”? What’s new here? Why don’t we just call type \\nthe A data science a “Statistician” and type B something else? Well, I do think there’s a \\nlittle bit more to say than just that. \\nThere’s a lot of practical work with data that is not covered, and it’s totally different \\nfrom the statistics curriculum. I’m talking about all the practicalities of data, all the \\nvisualization, the critical aspect of it and the communication piece that we talked about \\nearlier.\\n \\nStatistics as a field has focused itself very narrowly as a field on producing certain artifacts: \\nconfidence intervals, hypothesis tests, p-values etc. These are the work products of the \\nstatistician. In the pharmaceutical industry, that’s what it is. You have a report but at the \\nend of the day you’re saying, “Here’s my p-value and it’s less than .05.”\\n \\nHowever, for data science, there is so much more to it than that. Although I have to admit \\nthe term “data scientist” took me a while to get used to. I was a late adopter. I laughed when \\nmy friend sent me this meme that said: “Data scientist, is that like a hammer carpenter?” I \\nthought that was funny. But \\nI accept it now as a term that \\nencompasses much more \\nthan statistics.\\n \\nI think that the type B data \\nscientist — the data engineer \\n— I think that’s a reasonable \\ndistinction to make. It really amounts to: these people all have some mix of statistics \\nand analysis skills and coding. And then you can make a continuum or you can say you’re \\nmostly stats or you’re mostly engineering. Josh Wills defines a data scientist as someone \\nwho’s a better coder than every statistician and a better statistician than every coder.\\n \\nTo me there’s probably no-one in that category. At Google, the really strong coders who \\nknow a lot of statistics are software engineers. They don’t have a special title. They’re just \\nsoftware engineers who know a lot about machine learning. They might call themselves \\nI laughed when my friend sent me this meme that said: \\n“Data scientist, is that like a hammer carpenter?” I \\nthought that was funny. But I accept it now as a term \\nthat encompasses much more than statistics.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 229}, page_content='MICHAEL HOCHSTER\\n225\\na data scientist to get a job. I can see that point of view.\\n \\nSometimes you get people who are quite good coders, but they’re not all the way to being \\na software engineer. But they know a lot of machine learning. So they can implement \\nprototypes, but not all the way to production. That I think becomes a tricky place for \\ndata scientists because you’re in between things. But I still consider it to be a useful \\ndesignation.\\n \\nWith that designation in mind, when you are trying to hire people who are coming \\nout of school right now, what are the features you’re looking for? And then more \\ngenerally, how do you think when you’re building a data science team? What goes \\ninto that composition?\\n \\nI’m not sure I can answer the second question that well, since it depends on what you’re \\ntrying to do. At LinkedIn, I’m not exactly the person who built the team. I came into a \\nteam that was already there. When I think about hiring, I want people who can code \\nsomewhat, although I myself am not a particularly good coder. But we’re more focused \\non analysis. So when I’m looking for people, the most important qualities that a data \\nscientist should have include having a feeling of how to take a data set and answer a \\nquestion with it. Figuring out what should I compare? What’s the control? What’s the \\nway of transforming the things that I have available to me to make it reasonable? What \\nam I missing here that I need to go and collect?\\n \\nThis isn’t stuff you learn in school. Some people have it; it comes from experience too. It \\ndefinitely comes from working with data. So I look for people who have real experience \\nwith data – whether it’s in a hard science, a social science, computer science, or statistics. \\nJust understanding theory isn’t enough. You need data sense.\\n \\nI’m also really looking for the ability to \\ncommunicate well about things you’ve done, and \\ngood judgment. Understanding that when you’re \\nworking through a problem you have a series \\nof choices to make and being very aware of the \\nchoices you’re making and why you’re making them at every stage. That’s part of data \\nsense too. So these are somewhat intangible factors.\\n \\nI also look for some facility with coding — you need to be able to get your data and \\nmanipulate it. Therefore coding is required. I myself don’t look for super-heavy coding \\nskills because I feel like a lot things in my world have to be picked up. Also, I can’t \\nevaluate it myself when I talk to people.\\n \\nJust understanding theory isn’t \\nenough. You need data sense.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 230}, page_content='MICHAEL HOCHSTER\\n226\\nThen, the more formal statistical inference is the last thing that I look for. Not that it’s \\nunimportant, but it is probably last.\\n \\nFrom what you’ve said, it seems that what’s most important is to have real life \\nexperience working with data.\\n \\nNot everyone who has worked with data gets the data sense that I’m trying to pick out. \\nBut working with real data seems to help with that. It’s one of the factors.\\n \\nI spent so many years at Google inventing and asking people math brainteaser questions, \\nwhich is basically a “How smart are you?” type of gauge. I’ve totally given up on that stuff, \\nbecause although it measures something — people who can do all those things, they \\ntend to be smart people — there’s a job opening that I have and I don’t think an ability \\nto answer these questions is that strongly correlated with being able to do the job well.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 231}, page_content='KUNAL PUNERA Co-Founder/CTO at Bento Labs\\nLet’s start with where you are and where you came from. Starting from undergrad, \\nwhat was your journey? Why did you go into data?\\n \\nI did my undergraduate work in computer science in India. During that period I was \\nmore of a hacker, building things without being too worried about the theoretical side. \\nAt some point, towards the end of my undergraduate studies, I received all these offers \\nto work for some software companies and to just hack on things. I didn’t quite know \\nmuch about the Master’s or Ph.D. programs in other parts of the world. Then, one of \\nmy close friends was accepted into a Ph.D. program in the U.S., and I started hearing \\nthe vocabulary surrounding graduate schools in the U.S., GRE scores, the application \\nprocess, etc. That’s when I started considering the possibility of studying further.\\n \\nI was not really sure at first if I wanted to pursue further studies. So after finishing my \\nundergraduate studies, I took a year off from the software companies to work with a \\nprofessor and helping with his research; if I was going to commit many years of my life \\nto research, I wanted to first see if I would enjoy the work. And what I discovered was \\nthat I loved it. I loved research just as much as I loved ad hoc hacking. The professor, Dr. \\nSoumen Chakrabarti, and I wrote a couple of papers on data mining that ended up being \\npublished at the 2002 World Wide Web conference.  \\n \\nKunal Punera started hacking on computers at an early age \\nin India. Inspired by the way Google transformed internet \\nsearch through indexing and information retrieval, he \\ncame to the United States to do his PhD in data mining \\nand machine learning at UT Austin. \\nAfter for years at Yahoo Research working on diverse data \\nproblems, he joined Customer Relationship Management \\n(CRM) startup RelateIQ, as their fourth engineer and first \\ndata scientist. At RelateIQ, Kunal built the data mining \\nsystem from scratch — as well as many of the data products \\ndeployed.\\nRecently, Kunal recently left RelateIQ to start his own company, Bento Labs. RelateIQ was \\nacquired by Salesforce for $380M. In this interview, Kunal shares his experiences bridging \\nfrom research to data science, thoughtful lessons about data science engineering, and the \\nimportance of tool making. \\nData Mining, Data Products, and Entrepreneurship'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 232}, page_content='KUNAL PUNERA\\n228\\nThe way I got started on data mining was coincidental. From my hacking experience, \\nI was interested in databases and operating systems, but Soumen told me that OS and \\nDB research was already pretty mature, and that there was a new field of research that \\ninvolved combining artificial intelligence and data that he needed help with, so that is \\nhow I started working on data mining problems. Some of the first projects I worked on \\nwere on web mining and machine learning for the Web. I enjoyed thinking about those \\nproblems and really got into them. There was a sense that I could have a tangible effect \\non the lives of users through my research, which was pretty exciting.\\n \\nTo provide some context, this was back in 2001 and I had just discovered Google. It \\nprovided a real life example of “what data mining can accomplish.” The other search \\nengine at the time, AltaVista, was not nearly as strong as Google. You could clearly see \\nthe difference in search quality. This was one of the first times that I saw how data \\nmining could make a huge difference in the way people live their day-to-day lives, how \\nthey accessed information, and how they behaved online.\\n \\nAfter working with Soumen \\nfor a year, I applied and was \\naccepted into graduate school \\nat the University of Texas \\n(UT-Austin). My Ph.D. advisor \\nthere, Dr. Joydeep Ghosh, gave \\nme a lot of space to explore \\nvarious problems in data \\nmining and machine learning. \\nIt took me a little while to get \\ninto the academic mindset – I spent my first 2-3 years exploring the new country, with \\nroad trips across the U.S., and weeks spent in national parks. I also spent a lot of time at \\ninternships at industrial labs – IBM Almaden and Yahoo! Research. I finally got serious \\nabout research in my third year as a graduate student, and did some good work in my \\nfourth and fifth years to wrap up my Ph.D.\\n \\nWhat was your Ph.D. in?\\n \\nTopics in machine learning and data mining. The topic specifically was classification in \\nthe presence of structure in data. If you have structure in the data, could you use that \\nto make learning algorithms better by enforcing constraints? I was very motivated by \\nreal world problems. My last two years of Ph.D. were funded by Yahoo! so the problems \\nI tackled tended to be rooted in challenges Yahoo! was facing at the time: searching and \\nindexing, classifying web pages, and trying to model user preferences and behavior. I \\nsolved a bunch of real world problems, and the thing I found in common between the \\nThis was back in 2001 and I had just discovered \\nGoogle. It provided a real life example of “what \\ndata mining can accomplish....This was one of the \\nfirst times that I saw how data mining could make \\na huge difference in the way people live their day-\\nto-day lives, how they accessed information, and \\nhow they behaved online.”'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 233}, page_content='KUNAL PUNERA\\n229\\ndifferent solutions was that they always exploited the structure in the data – websites \\nare hierarchical structures, web pages as well, and people’s browsing could be modeled \\nas Directed Acyclic Graphs (DAGs).\\n \\nIn reflection, my Ph.D. thesis topic came about more from figuring out a common thread \\nin the different problems I worked on, as opposed to having a particular research agenda \\nand pursuing it. That’s been my approach to research since my Ph.D. as well. I don’t have \\na specific agenda or an area that I’d like to advance. I don’t really feel like pushing any \\none particular technology.  All I want to do is solve hard and interesting problems. After \\nmy Ph.D., I took a full-time position at Yahoo! Research which, in those days, was almost \\nan academic organization. It was basically a university department without the teaching \\nload. It was perfect because I basically went from being a graduate student to a similar \\nplace, but was paid significantly more. Plus, they had the benefit of having an immense \\namount of data as well as great infrastructure to work with.\\n \\nWhat kind of problems were you solving there? Were they motivated by Yahoo! \\nuser-facing business?   \\n \\nAt Yahoo! Research, we had a pretty open \\ncharter to help direct our work. 50% of our \\ntime was to be spent making an impact for \\nYahoo! and the remaining half could be \\nspent working on research problems that \\nmay not have much to do with the immediate \\nneeds of the company. That was an amazing \\nexperience because I got to touch pretty much \\nany problem I wanted to. Since I could code as \\nwell as do research, I got to work on a lot of different data mining problems – including \\ndesigning better CAPTCHAs, email spam detection, phishing detection, search engine \\nranking, targeting for the advertising systems, and new approaches to user modeling. \\nI spent four years at Yahoo! Research and worked on a wide variety of projects ranging \\nfrom short-term ones (3-6 months) to some engagements that lasted years.\\n \\nDid you focus mostly on the research aspect of coding, or did you also deploy your \\nresearch, such as spam filters, in production?\\n \\nResearch scientists at Yahoo! were judged based not only on the amount of internal \\nimpact that we had, but also on the number of research papers we wrote, the number \\nof external talks we gave, etc. Typically, Yahoo! Research did not own the projects I was \\nworking on, and so I had to work closely with the products teams responsible for them. \\nGiven the nature of the engagement, naturally, the product teams were hesitant to have \\nI don’t have a specific agenda or an \\narea that I’d like to advance. I don’t \\nreally feel like pushing any one \\nparticular technology.  All I want \\nto do is solve hard and interesting \\nproblems.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 234}, page_content='KUNAL PUNERA\\n230\\nresearchers make direct changes to the code base; the products teams had a focused \\nagenda while I had a broader agenda and different responsibilities. But I had a strong \\ndevelopment background and wanted to build/optimize the systems end-to-end, and \\ntherefore, I felt a little frustrated.\\n \\nAlso, after years in research, I realized that academic careers require one to be an expert \\nin a specific, narrow area. There’s a lot of pressure to become an expert at one thing, \\nso everyone would know Kunal Punera is an expert at so-and-so. My research agenda \\nhas always been “show me an interesting problem and I will work towards solving it.” \\nOver my four years at Yahoo! I moved across a lot of different types of problems and \\ndomains, ranking problems in search and ads to adversarial data mining in mail spam \\nand CAPTCHAs. That doesn’t mesh very well with how academia expects publications \\nand careers to progress. Eventually, I realized that a purely academic career wouldn’t \\nsustain my interest enough. Moreover, outside Yahoo! I was watching the emergence of \\nthese interesting companies that are using data to solve important problems for people, \\nand I really wanted to get involved with that.\\n \\nAt some point, I started \\nconsidering leaving Yahoo!, and \\nmaybe starting my own company. \\nDuring this process I realized that \\nI had been away from software \\ndevelopment for too long. During \\nthe five years of my Ph.D. work \\nand four years at Yahoo! Research, \\nI had written a lot of code, but code written for research doesn’t have to be production-\\nquality; it doesn’t have to be maintainable, it isn’t typically changed by anyone else. \\nAlso, the whole world of web development had undergone considerable change since \\nthe time I had been writing systems in cgi-perl. You probably don’t even know what that \\nis — it was the precursor to the modem web application frameworks. I realized that I had \\nto update my knowledge about software development, especially when it came to using \\nthe open source stack.\\n \\nSo I realized that I had much to learn before I could start my own company, and that I \\nwouldn’t be able to do it while at Yahoo! I had to go work at a place that would appreciate \\nthe fact that I had a very strong research background, but would give me the opportunity \\nto learn stuff beyond data mining, and RelateIQ fell right in the sweet spot. The match \\nwas amazing. The founders were interested in building a company that solved key pain \\npoints around relationship management using cutting-edge data mining. Furthermore, \\nsince I was to be the fourth engineer, I would have to build everything from scratch on \\nmy own, and consequently, would learn a lot from the experience.\\n \\nMoreover, outside Yahoo! I was watching the \\nemergence of these interesting companies that \\nare using data to solve important problems \\nfor people, and I really wanted to get involved \\nwith that.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 235}, page_content='KUNAL PUNERA\\n231\\nI spent two years at RelateIQ. I worked on building the data mining system from scratch \\n— and by the time I left I had built most of the data products deployed in RelateIQ. And \\nin the process I learnt a hell of a lot.  \\n \\nWow! How did you learn all of this on the job, and on the fly?\\n \\nMy data mining background was very \\ndeep and broad, so I didn’t really have \\nto learn any of the learning algorithms \\nor approaches on the fly. I picked up \\nNatural Language Processing (NLP) \\nas needed, but once you have a decent \\nstatistical modeling background, \\nthe rest of machine learning is just \\nvariations of the same thing. Those \\nwere not an issue. But, software development skills were something I had to learn a \\nlot about. For example, while I was a good coder, it is a different experience to work \\nwith engineers who had worked in production environments their entire careers. So, \\nwhile Maven (for dependency management) was obvious to them, it was new to me. \\nUsing Guice for dependency injection was normal to them, while it was something I was \\npicking up for the first time.\\n \\nDuring my time at RelateIQ, in terms of software engineering, I learnt a lot. Sometimes \\nI feel I didn’t learn nearly enough. [Laughs.] I think there’s a lot more I could have \\nworked on, but whatever I learnt, I learnt well. Whatever I know about machine learning \\nalgorithms, I learnt at Yahoo! Research. Whatever I know about software engineering, I \\nlearnt at RelateIQ.\\n \\nI had come to RelateIQ as a stepping stone to starting something on my own. But as two \\nyears passed, RelateIQ blew up, in the sense that it was doing extremely well. So, there \\nwas a strong temptation to stay because the stock options were going to be worth a lot at \\nsome point. But then I also had some confidence that I could make something valuable \\nof my own in the next few years. I loved the people at RelateIQ, but with a heavy heart, \\nI made a decision to leave. If I hadn’t left now I might never have had a chance to do my \\nown startup.\\n \\nI left RelateIQ to do my own startup. In the last two months, I’ve just been rebuilding \\nmany of the things that had always existed at RelateIQ. I’ve been building a backend \\nand figuring out how to get continuous deployment working, learning how to get the \\ndatabase to perform well — all these things which I didn’t have to do before. It’s been \\ninteresting.\\n \\nI spent two years at RelateIQ. I worked \\non building the data mining system from \\nscratch — and by the time I left I had \\nbuilt most of the data products deployed \\nin RelateIQ. And in the process I learnt a \\nhell of a lot.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 236}, page_content='KUNAL PUNERA\\n232\\nThat’s amazing. It seems like you’ve systematically identified areas of knowledge \\nyou wanted and found either employment or career opportunities where you could \\ngo and be paid to learn those things. Once you mastered those things, you can go \\nto other things. How did you do that?\\n \\nSilicon Valley is the place where, first of all, there’s a huge demand for the kinds of skills \\nwe have built up. I’m lucky that I’ve chosen to work on something that has a huge demand, \\nand companies are willing to let you learn on the job as long as you can contribute back. \\nRelateIQ, for the entire time I was there, did not have another data scientist, so I had to \\ncarry that whole load, but in return, I learnt a lot. Working in startups is always a give \\nand take, and I think good companies in Silicon Valley understand that the employees \\nthey are trying to hire are, in general, smart, and have their own long-term goals that \\nthey want to pursue. As long as they contribute a lot back to the company — and I like to \\nthink that I did — then the companies help further the goals of the employees.\\n \\nWhen I wanted to leave RelateIQ, \\neveryone, from Adam to Steve \\nto DJ, was very supportive. \\nSteve wanted to introduce me to \\ninvestors. DJ wanted me to come \\nby and get his advice on the \\nnew idea. The environment was \\nextremely supportive. We are \\nvery lucky to live in a business \\nenvironment where companies \\ndon’t even think about locking \\nemployees in. There’s no notion of an employee lock-in. There’s no notion of company \\nlock-in. There’s always flexibility.  Everyone wants to make the best possible use of their \\ntime. We all understand that we’re on Earth for a short time, and we all want to go \\nto a company or work on things which uniquely need us. Silicon Valley is unique, and \\namazing in that way. We’re lucky to be in this situation.\\n \\nBeing able to learn new things really quickly is one of the things we need today \\nmore than ever, but there’s an art to doing that. You need to have some sort of \\nfoundation, core programming skills, core modeling skills. If you were to decompose \\nthose down to the principle skills, what do you feel is most important?\\n \\nIn terms of programming skills, I’m not sure what the curriculum nowadays looks like, \\nbut in my undergraduate days, I started by learning C. Actually, I learnt Pascal first. Then, \\nI learnt C. These are pretty low-level languages with few rules and close interaction \\nwith the machine. So, I learnt from the very beginning how programming languages \\nmanage memory, what pointers are, what an execution stack looks like, etc. I think that \\nOnce you have a decent statistical modeling \\nbackground, the rest of machine learning is just \\nvariations of the same thing. ... But, software \\ndevelopment skills were something I had to \\nlearn a lot about. For example, while I was a \\ngood coder, it is a different experience to work \\nwith engineers who had worked in production \\nenvironments their entire careers.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 237}, page_content='KUNAL PUNERA\\n233\\nexperience was useful because now, if I have to learn new concepts, it’s easy for me to go \\nback and reconstruct them from the first principles in my head.  \\n \\nIn terms of programming, I would \\nthink learning about core programming \\nconcepts is important. You should start \\nlearning from there. I have a feeling that \\nif you started learning programming with \\nJavascript, it might be a little bit more \\ndifficult to know exactly what’s happening \\nin the background. I would encourage one \\nto learn what is happening at a low level, but also to not spend too much time on it. I \\nspent way too many years working with C and C++. Nowadays, I wouldn’t build systems \\nin those languages. Java, Scala, Ruby, Python have amazing framework support, open \\nsource libraries, and lots of solutions documented in sources like Stack Overflow.\\n \\nIn terms of data modeling, I think I was lucky that I took some good statistics courses. \\nIt’s useful to understand the underlying concepts of algorithms. I think a graduate-level \\noptimization course is important, as well.\\n \\nOne of the obstacles I sometimes see engineers running into is confusing the core problem \\nthat needs to be solved and the one particular solution to that problem. Sometimes \\npeople have one way of solving the problem already in their head, and they might not \\nsee that the core problem is not the same thing as their solution. As much as possible, \\nI would encourage people to constantly ask the question “What am I optimizing?” For \\nexample, if you want to obtain a clustering of data, it’s useful to first try to determine what \\nproperties you would want in a good solution, and then attempt to encode these criteria \\ninto a loss function. If one is not careful it is easy to think of clustering data in terms of \\nsteps the algorithm should take, or a series of methods that must be implemented. This \\ncan sometimes lead the engineer astray in that the preconceived solution might never \\nend up obtaining clusters with the desired properties. Of course, the time constraints in \\na startup don’t leave data scientists the luxury of carefully thinking of every problem. In \\nthese situations, experience helps.\\n \\nDo you have any specific examples for that? I know what you’re saying in the \\nabstract but it would be helpful to hear a concrete example.\\n \\nFor example, suppose you want to do classification. Say I have two classes, and I wanted \\nto learn a model that separates them. I can use one of the many algorithms out there: \\ndecision trees, support vector machines (SVM), random forests, etc. But one might come \\nto erroneously think that the classification problem is equal to learning decision trees — \\nwithout completely understanding what underlying problem is being solved.\\n \\nWhatever I know about machine \\nlearning algorithms, I learnt at Yahoo! \\nResearch. Whatever I know about \\nsoftware engineering, I learnt at \\nRelateIQ.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 238}, page_content='KUNAL PUNERA\\n234\\nBefore jumping into implementing a solution, one might want to consider some questions \\nabout  the nature of the problem. The core problem here is that there is a boundary, a \\nseparation between the two classes, that we need to find. Well, what does it mean to find a \\nboundary? What kind of boundaries do decision trees find? And what kind of boundaries \\ndo linear SVMs find? Will using a kernel method help? Is this a situation where I need \\nto worry about irrelevant features? Does that mean I need to regularize via a L 1 norm \\nor stick with L 2? These are fundamental questions that once answered can guide us to \\nthe appropriate approach and thus avoid a lot of  trial and error. Moreover, they help \\nin the following situation: once we have applied the first algorithm and it obtains 65% \\nclassification accuracy, what should we do next to improve the results? Carefully defining \\nthe parameters of the problems \\nand the characteristics of a good \\nsolution help us figure out what \\nthe next step to take is.\\n \\nSometimes when reading Hacker \\nNews, I get a sense that people feel \\nmachine learning is simply about \\ntaking open-source libraries and \\napplying them to data. In many \\ncases, this works okay as the first \\nstep, but, often, the next step to \\nfurther improve the model is difficult to figure out. But if one has a strong understanding \\nof what these libraries are trying to optimize for, what each core algorithm is good for, \\nhow the curse of dimensionality effects learnability, what the difference is between L1 \\nnorm and L2 norm, and other such kinds of things, then it becomes much easier to figure \\nout how best to apply these open source resources.\\n \\nSo is this the set of skills you are looking for when you are interviewing for the data \\nscientist position?\\n \\nWhen I am looking for data scientists, the most important thing I am looking for is \\nwhether their approach to machine learning is systematic. Sometimes I meet people who \\nknow what first step to take, and can do it pretty fast because they’re amazing coders, \\nbut the second step becomes a little harder. When I interview people, I don’t really want \\nthem to solve anything on the whiteboard, I don’t want them to code. The key thing I \\nwant to know is whether they get the underlying principles of what they are building. I’ll \\ntypically ask them about something they’ve previously built and then just delve deeper \\nand deeper into that same problem. I find this is a good way to evaluate candidates \\nbecause if they contributed significantly to the work and know their fundamentals, they \\nwould be able to defend their decisions from first principles and not just say, “Everyone \\nGood companies in Silicon Valley understand \\nthat the employees they are trying to hire \\nare, in general, smart, and have their own \\nlong-term goals that they want to pursue. \\nAs long as they contribute a lot back to the \\ncompany — and I like to think that I did — \\nthen the companies help further the goals of \\nthe employees.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 239}, page_content='KUNAL PUNERA\\n235\\nlikes SVMs so I used it.” They should say, “Well, the problem had the following properties, \\nthat’s why we needed a SVM”. Or “I also tried this other thing. It didn’t work well because \\nI believe... ” as opposed to “I just didn’t try it.”\\n \\nI think that’s a key thing to look for — \\nstrong fundamentals. If someone has \\nstrong fundamentals, but doesn’t know \\nwhat a random forest is, I don’t really \\ncare, because individual machine learning \\napproaches can be easily learnt.  Having \\na strong background and then picking up \\nrandom forests is way easier than having \\njust shallow knowledge of random forests \\nand then trying to debug them. People \\nwho are looking to work with data mining \\nalgorithms should take a systematic \\napproach to learning them. I think it’s difficult to do that nowadays because there’s so \\nmuch demand for the skill set. But I would urge them to get more fundamental skills \\nvia, maybe, a machine learning course which focuses less on the specific algorithms and \\nmore on the fundamentals, and then some core statistics, optimization, and algorithms \\ncourses. These will give them a good foundation for their work.\\n \\nWhen you were trying to build the data science team at RelateIQ, how big was the \\nteam?\\n \\nAt RelateIQ we were not building a data science team. One of the things I’m not fond \\nof is the kind of process I used to follow at Yahoo! Research, where the science team \\nbuilds the models and then passes them off to the engineers to implement or deploy. I \\nfeel like a lot gets lost in the translation. Sometimes the models that one builds assume \\nan environment that doesn’t really exist in production, and one doesn’t know that until \\nthe models are deployed. And in fact, when models get deployed and accuracy lags, it’s \\nvery difficult for engineers who didn’t build the models to convey back what’s exactly \\nhappening.\\n \\nI prefer that the scientists be closely involved in the implementation of the feature \\npipelines and the models in production. They should know how the model is deployed, \\neverything that happens to the data — filters, sampling — before it shows up as input \\ninto the model. If there’s a particular filter which takes out one particular type of data, \\nthe scientists should know about it. Moreover, in the first few months after a model is \\ndeployed, the scientists should be the ones maintaining it.\\n \\nSo, I learnt from the very beginning \\nhow programming languages manage \\nmemory, what pointers are, what \\nan execution stack looks like, etc. \\nI think that experience was useful \\nbecause now, if I have to learn new \\nconcepts, it’s easy for me to go back \\nand reconstruct them from the first \\nprinciples in my head.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 240}, page_content='KUNAL PUNERA\\n236\\nAt RelateIQ, we were following this principle and building a  data products engineering \\nteam. We didn’t call it data science at all. In the data products engineering team, we \\nlooked for people who had a very strong sense of data, who liked playing with data, but \\nalso had reasonable engineering skills so that they could actually touch production code \\ndirectly. We didn’t expect them to roll out their own hadoop infrastructure, though many \\nof our data product engineering people did. But we wanted them to be able to deploy \\ntheir own models, run them, write the feature extractor pipelines, etc. Apart from the \\nprinciple I mentioned earlier, a second reason for building the team this way was more \\npragmatic; we were a small team and we couldn’t spare engineers dedicated to taking \\nthe work done by data scientists to production.\\n \\nIt seems like you not only focused on people who can do data analysis but also on \\nthose who have a strong engineering background, people who started out hacking \\nor coding and then went to data science.\\n \\nI find that you can go both ways: start from \\nthe data side or software development side \\nof things. But in a startup, having people \\nwith both skill sets is critical. One thing that \\nyou never want in a startup is to have a data \\nscientist working alone with no established \\nprocess to get work into production. I’ve \\nseen many startups where data scientists \\nare six months ahead of production \\nsystems; they have done six months of \\nwork that hasn’t been deployed because \\nthe engineers that touch production are \\nbusy with their own work or fires. These \\ndata scientists have done the work in R or matlab and are not able to integrate it with \\nthe production backend system. You don’t want to have that situation.\\n \\nIn a slightly bigger startup, one may want to have small teams of two or three people \\n— one data scientist, one person with engineering system type skills, and one with \\nproduct management type skills — to build and maintain data products. They work as a \\nteam to build features as opposed to a data science person building a model alone, and \\nhoping that one day some engineer is going to step forward and bring those features to \\nproduction.  \\n \\nWhen RelateIQ was small we avoided this situation by having one person perform all \\nthree roles — data scientist, engineer, and product management. Now that we are larger \\nwe are building multi-skilled teams.\\n \\nAt RelateIQ, we were following this \\nprinciple and building a data products \\nengineering team. We didn’t call it \\ndata science at all. In the data products \\nengineering team, we looked for \\npeople who had a very strong sense \\nof data, who liked playing with data, \\nbut also had reasonable engineering \\nskills so that they could actually touch \\nproduction code directly.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 241}, page_content='KUNAL PUNERA\\n237\\nThis is a fantastic example of data science and product done right. You avoided \\nsome of the pitfalls of great, locked up models that you can’t deploy. Were there \\nother things you saw at RelateIQ that you felt were really good lessons in building \\ndata products?\\n \\nOther than the constitution of the team, \\nanother important aspect to keep in mind \\nis the cadence of development of data \\nproducts. Engineering the systems that \\ninvolve data mining is a little different in \\nthe sense that most times it is not clear how \\nmany engineering resources will be needed \\nbefore the models reach production quality, or even whether the desired quality can even \\nbe reached. This may not be a big problem at large companies, but it makes scheduling \\nand resourcing data products tasks problematic when resources are constrained, as in \\na startup. In a startup, one should want to break down data products work such that \\nvisible, measurable progress can be made in two-three weeks so that the engineers have \\nintermediate wins. This also prevents engineers from going too far down the wrong path. \\nOf course, the development cycles need to be long enough so that hard problems can be \\nattempted and solved; very short inflexible cycles typically lead to data products that \\nhave been patched together and are not robust.\\n \\nAnother important aspect relates to scheduling; if you want a data product deployed at \\nany point in time, you probably should give the data engineers a head start so that they \\ndefinitely have their models or features built before the front-end or back-end resources \\nbecome available. This is simply a consequence of the uncertainty around the pace of \\nprogress on data products.\\n \\nFor a long time after I joined RelateIQ, I was the only one working on data products. In \\nthese early days, scheduling was not that much of an issue since I was the only data, \\nbackend, and frontend resource. Moreover, I have a lot of experience with data mining \\nand was able to avoid going down bad paths, and was able to get most models deployed \\nin the first couple of iterations. As the team grew and I had more frontend and backend \\nresources that could help me, we had to work harder on scheduling and we applied the \\nprinciples I outlined earlier.\\n \\nAny other data product hacks from RelateIQ?\\n \\nThe other thing that we did a lot is we took shortcuts. We took shortcuts all over the \\nplace. At the beginning we were in a hurry and we didn’t even know whether the products \\nwould be received well by the users, and so we tried to get away with putting in as many \\nOne thing that you never want in \\na startup is to have a data scientist \\nworking alone with no established \\nprocess to get work into production.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 242}, page_content='KUNAL PUNERA\\n238\\nhacks as possible. We made our decisions on the hacks in this particular way:\\n \\nAnything that was fundamental, core-level, functionality, such the parsing of emails, we \\nmade sure it was extremely strong. There are many reasons why functionality gets put \\ninto this category: in the case of email parsing, first every email has to be parsed and the \\ncost to reparse is very high (I’ll have to go back and fetch every email and reparse it), and \\nsecond, a whole bunch of other features of the data system depend on accurate parsing \\nof email. Therefore, my system for parsing is very strong. It involves nice, sound models \\nbased on CRFs and SVMs that we learnt over large quantities of training data and that \\nare continuously trained as data changes; these models are sound.\\n \\nOther functionalities are higher \\nlevel, such as automatically \\nmaking a suggestion to follow-\\nup with a contact. There are \\nmany questions that need to be \\nanswered here that are difficult \\nto optimize using data since the \\ndegrees of freedom are too high or \\ntraining data is too noisy. When a \\nsuggestion has to be created, the \\nsystem has to determine if a follow-up to an email is warranted, whether the user has \\nalready done the follow-up, how long the system should wait before reminding the user \\nto follow-up, and if multiple users are referenced in the email that the suggestion to \\nfollow-up will be directed to. The dimensionality of this space of choices is so high that \\nthe first attempt to model this should involve using manual rules and hard thresholds.\\n \\nAnother example is trying to learn the effectiveness of our rules for follow-up \\nsuggestions via usage data, and using the feedback if a user rejects the suggestion. Even \\nthis is complicated since rejection is a very aggregate action and it’s not clear what the \\nuser is rejecting; maybe we made a mistake in parsing the email and no suggestion was \\nwarranted or maybe the user liked the suggestion but we made it too early, or the user \\ndoesn’t like the sender of the email, or even the user hates all suggestions in general. So \\neven here I shied away from modeling the entire problem and put in a lot of rules, a lot \\nof very simple models. The first cut solution involved counting the number of rejections \\nand rules for actions to be taken when certain thresholds are met. As the data product \\nimproved we used more advanced approaches to model user feedback.\\n \\nYet another important aspect is tools, and this is something that was driven home to me at \\nRelateIQ. Before working at RelateIQ, I had a very high threshold for tooling. Sometimes \\nI ended up doing the same thing 10 times without automating it because every time I did \\nThe other thing that we did a lot is we took \\nshortcuts. We took shortcuts all over the place. \\nAt the beginning we were in a hurry and we \\ndidn’t even know whether the products would \\nbe received well by the users, and so we tried \\nto get away with putting in as many hacks as \\npossible.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 243}, page_content='KUNAL PUNERA\\n239\\nit, I was not sure I would be doing it again. After RelateIQ I can safely say that if someone \\ndoes something 3 or 4 times, they will be doing it again in the future, so they should \\ntry to automate it; automate data cleaning scripts, automate model deployments, write \\ntools for re-training of models, don’t do it by hand. Write tools that will automatically \\ncreate a fresh data set, retrain the model, check its accuracy, and send you an email if the \\naccuracy is below a threshold, and, if the accuracy is good then deploy the model. This \\ntooling might seem excessive but is going to easily pay for itself in terms of saved time \\nin the long run.\\n \\nWas that a change of pace compared to when you were working in research?\\n \\nWell, I did a lot of work at Yahoo! \\nResearch. I worked on new projects \\nevery 3 to 6 months. I was writing \\nthree to four papers every year \\nand that’s a lot of work. I’m used \\nto working a lot of late hours. At \\nRelateIQ what changed was the emphasis. At Yahoo! Research, the emphasis was always \\non doing something innovative. It was all about asking, “ Last year Microsoft Research \\npublished this. The year before, Google did. What’s the new angle I can find and solve the \\nproblem?” Sometimes the problem being considered was not an immediate concern for \\nYahoo. Other times the problem could be solved using simpler means. At these points, \\nwe would consider more complex versions of the problem with additional hurdles, and \\nthen figure out how to solve them. The goal was to constantly push the envelope of what \\nwas possible with data mining, and not just to solve immediate practical problems. The \\ntask was as much to find new problems as to solve them.\\n \\nAt RelateIQ, I worked extremely hard as well. There, the problem to be solved was pretty \\nclear, and main question facing me was “ What is the minimum effort that I can put forth \\nand get something into the hands of the users so that I can test whether the solution is \\nuseful?” And from that feedback I can figure out how much more effort I want to put into \\nit in the future to improve the feature. Moreover, the solutions I tried out were chosen \\nnot just for their innovativeness, but using a tradeoff between effectiveness and the cost \\nof implementation and future maintenance.\\n \\nSo the main difference from the earlier days of research was not one of pace of work. It \\nwas a change in priorities.\\n \\nHow do you measure cost? Development effort or time?\\n \\nCost in this case involves implementation and future maintenance. In a startup you have \\nYet another important aspect is tools, and this \\nis something that was driven home to me at \\nRelateIQ.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 244}, page_content='KUNAL PUNERA\\n240\\nto constantly trade that off for accuracy of models. If one option is a complex model such \\nas a Conditional Random Field (CRF), but we can come up within 5% of the accuracy using \\na Naïve Bayes model, then we would choose to go with the Naïve Bayes. It is not just that \\nCRF models would be significantly harder to train within a typical project timeline in a \\nstartup, but as the data environment changes in the future, the CRF will break in non-\\nintuitive ways and it won’t be easy to debug. Whereas in the Naïve Bayes model, you can \\nlook at the parameters and try to see what might be happening.\\n \\nA big issue that impacts machine \\nlearning at startups is that \\nmanually labeled training data \\nmight be hard to come by. This \\nis why at RelateIQ a lot of the \\nmodels I had to build involved a \\nlot of manual intervention. I had \\nto be very careful about picking \\nthe right features that, based on my experience, would not cause me to overtrain; \\nbecause I knew my training data was so biased and so limited that I could not rely on \\ncross validation. I had to basically look at each feature and ask, “While using this feature \\ngives me a reduction in test error, what is the chance that this is simply because of the \\nway the data in the training set was selected?”\\n \\nAnother side effect of limited training data is that sometimes it is useful to closely \\nexamine and perhaps manually twiddle the model’s parameters, setting them to values \\n(or signs) that intuitively make sense. This intuition has to be balanced against the \\nparameters coming from the learning algorithms. As in most cases, extensive experience \\nwith learning algorithms in limited data situations helps.\\n \\nYet another impact of limited training data is the high likelihood that the training data \\nis from a different distribution as your deployment data. For example, at the beginning \\nthe startup might have 48 customers, and they are probably all friends of the CEO. The \\nmodels trained on data obtained from these customers are likely to be biased towards \\nthem. However, one year down the line, the startup might have 4,800 customers. If one \\nis not careful, the models created in those early days will fail miserably on the new \\ncustomers a year later.\\n \\nYou said that you’re building out your own tools that you took for granted at \\nRelateIQ. That is really interesting because when you work in data science at a \\ncompany, you have a lot of things that are taken care of for you. Deployment \\nusually is handled by other people as a day job. So how are you approaching that? \\nWhat are you rebuilding, and how do you know how to rebuild it?\\n \\nThere, the problem to be solved was pretty \\nclear, and main question facing me was “What is \\nthe minimum effort that I can put forth and get \\nsomething into the hands of the users so that I \\ncan test whether the solution is useful?”'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 245}, page_content='KUNAL PUNERA\\n241\\nI am playing around with some ideas on mobile, app re-engagement, and advertising.  \\nI am currently implementing the backend part. But since I learnt from RelateIQ that I \\nneed to invest in tools early, I am being careful in designing the backend “properly” from \\nthe very beginning. It plays nicely with my IntelliJ IDE; I am ensuring that I am able to \\nrun it entirely offline. When I push code to GitHub, the remote systems pick the code up, \\nautomatically compile/test it on the server, run the DB migration scripts, automatically \\ndeploy the APIs, etc. If we were to not invest in this now, then I would have to do this \\nentire process manually, every time I deploy some small bug-fix. Moreover, I would \\nprobably make mistakes in the deployment steps (forgetting to migrate the DB) and find \\nbugs that end up being simple deployment errors.\\n \\nHow do I learn all this? Some of this I worked on, but a lot of these technologies were \\njust words that I heard while at RelateIQ. I was working with these extremely talented \\nengineers, and I heard them talk about Docker or Maven or Guice all the time. So when I \\nleft and started working on my own company, I Googled all this stuff. Google, along with \\nsites like Stack Overflow, is a great resource for these things.\\n \\nAnd if all else fails, there’s GChat \\nso I can ping my ex-colleagues \\nwho are friends of mine. These \\nguys have so many years of \\nexperience that even without \\nmy completely describing the \\nsituation, they are able to point \\nme in the right direction. I did the \\nsame thing when I moved to RelateIQ and I was the only data scientist. Since I couldn’t \\ntalk to anyone at RelateIQ about some of the problems I was tackling, I would ping \\nmy friends from Yahoo! Research to ensure that I was thinking about the problem and \\nsolution the right way. In turn I would help them think through data mining problems \\nthey were thinking of. I have been pretty shameless about asking people for help, because \\nfor any topic I am working on, except maybe one or two topics, there is someone out \\nthere who knows it better than me.\\n \\nIf you want to start your own company, you have to build the first version of the product. \\nEventually, you’ll get funding and be able to hire amazing engineers, who are going to \\nscoff at my code and change everything, and I’m okay with that. But in the meantime, I \\nneed to build this. And there’s never been a better time to build things yourself – there \\nare a lot of good tools out there. You can use the Google App Engine for example, and \\nmany aspects of the backend are abstracted away. They have their own version of Task \\nQueue, their own databases. You don’t even know how your data is hosted. I didn’t want \\nto use Google App Engine because it abstracts way too much, and I felt like the lock-in \\nI have been pretty shameless about asking \\npeople for help, because for any topic I am \\nworking on, except maybe one or two topics, \\nthere is someone out there who knows it better \\nthan me.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 246}, page_content='KUNAL PUNERA\\n242\\nmight be rather severe. That’s why I am building the backend from scratch on Digital \\nOcean.\\n \\nThe other reason to build all this myself is that it helps me interview people. [Laughs.]\\n \\nOne day, I will have to interview someone who will help me with DevOps. It is significantly \\nharder to interview someone if I don’t know much about DevOps myself. My advice to \\nanyone who’s thinking of leaving a company and starting their own is that six months \\nbefore you plan to leave, talk to your CTO or your manager. Tell them what your career \\ngoals are, and that you want to do this. Have them put you in situations where you \\ncan learn some of this stuff because there’s nothing better than learning on the job. \\nSomeone’s paying you, and you’re learning while doing work for them. Like I said earlier, \\nSilicon Valley is good at giving you opportunities to learn and extend yourself.\\n \\nWhat are the opportunities you see in data science right now?\\n \\nThere are many different aspects of data \\nscience. One is data analysis, to support \\nbusiness decisions. There is of course a \\nhuge need for data analysts in all sorts \\nof businesses; at RelateIQ we need data \\nscientists to analyze our product usage and \\nSaaS business and suggest ways to improve the product or sales processes. But there is \\nalso a huge opportunity to actually build a layer between these data scientists and the \\ndata. These guys would prefer to use higher-level statistical languages such as R, but \\nthey want their analysis code to run on large-scale data on a distributed set of machines. \\nThere are a bunch of companies looking to provide this interface between the scientists \\nand data, so that they write their analysis in R and don’t have to worry about where it \\nruns, and how it runs. The interface might even contain features that might help data \\nscientists collaborate and make them much more productive. Mode Analytics and Sense \\nare two of the newer companies I have seen in this market.\\n \\nIn terms of products enabled by data mining and machine learning, there are huge \\nopportunities out there. Some are in the usual areas: Digital advertising, Search, and \\nRecommendation systems. There are some mature players in these areas, providing both \\none-off services and platforms, but there is plenty of novel work coming out of startups \\nas well.\\n \\nOne generic area that is seeing a lot of work is in trying to make sense of unstructured data. \\nIn the most straightforward cases, some startups are trying to automatically understand \\nweb pages and construct APIs over their data. However, at an abstract level this is what \\nIf you want to start your own company, \\nyou have to build the first version of \\nthe product.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 247}, page_content='KUNAL PUNERA\\n243\\nRelateIQ is doing as well. RelateIQ is trying to mine people’s communications data and \\ngive them insights about their own data. RelateIQ takes a mix of structured (phone call \\nmetadata) and unstructured information (email texts) and tries to extract structured \\nobjects that are of interest to the user (follow-up suggestions, new phone numbers for \\ncontacts, best connections to use to reach people etc).\\n \\nWhile RelateIQ is mining relationship data sitting within enterprises, there is a huge \\nopportunity to mine all sorts of unstructured data within enterprises and make it useful \\nto them. For example, data within emails, calendars, etc. could be used to help large \\nenterprises grow and maintain their talent; many startups are pursuing this.\\n \\nAnother area where data mining can help is by helping people deal with information \\noverload. Right now there is all this news just flying by me. I always feel like I’m missing \\nout on so much and so I need help consuming this. There are some companies trying to \\nhelp with this, trying to use machine learning to do that. Have you seen Prismatic?\\n \\nI’ve heard of them.\\n \\nI downloaded the app a little while ago, \\nand with some help from me it was able \\nto deliver some relevant stories to me. \\nHowever, it wasn’t quite as relevant as I \\nwould have liked and it wasn’t helping with \\nthe problem of me feeling that I’m missing \\nout on a lot of good content, and, recently, \\nI stopped using the app. Another potential \\nexample is Google that knows so much \\nabout me. If I was an Android user, they would know everything about my mobile use. I \\nuse Chrome, so they know about my browser use. I use Google Docs and Gmail so they \\nhave all my work data as well. I use a search tool heavily, so they have the set of things I \\nam interested in as well. Given all this information, Google is in a position to completely \\npersonalize the web for me. Have you seen the movie “ Her”? Other than the falling-in-\\nlove-with-a-robot part, why is the rest of that movie not a reality?\\n \\nI think the technology to build much of that is already here. The data is siloed so maybe \\nthat’s an issue. Maybe the user appetite to engage with the app in such a personal way is \\nnot there yet. I feel people may not be ready to give up that much control, but I think it \\nis headed there. I think the next big thing is going to be in that vein. The way RelateIQ \\nworks for salespeople, there will be digital services that help regular people live. There’s \\na soccer mom somewhere being driven insane by having to run her household, arrange \\nfor her kids to attend school and various activities, managing events for the entire family \\nGiven all this information, Google is in \\na position to completely personalize \\nthe web for me. Have you seen the \\nmovie “Her”? Other than the falling-\\nin-love-with-a-robot part, why is the \\nrest of that movie not a reality?'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 248}, page_content='KUNAL PUNERA\\n244\\nand interacting with her friends, all at the same time. Why is her phone not figuring all \\nthis out for her — making her life easier for her?\\n \\nA dominant trend in the world is the move towards mobile. A lot of the mobile world \\nright now is replicating what the desktop world did. On the desktop we have websites. \\nAnd so we have a notion of apps on mobile. We used to navigate between websites, often \\nthrough searches. So now we are devising a way to navigate across apps via deeplinks. \\nHowever, it seems to me that my usage of my mobile device is very different from my \\nusage of my laptop. I do most of my information access on my mobile device right \\nnow. I use my laptop for coding and for long-running information searches like buying \\nsomething. It seems like technologies that make my life on the laptop easier may not \\nnecessarily work on mobile devices. I don’t know the answers here yet, but I feel like data \\nmining has a large role to play. This interests me a lot and I am likely going to select a \\nproblem in this space for my startup: a mobile frontend with an intelligent backend.\\n \\nSo there are plenty of huge opportunities; though, I think they are very difficult to predict \\nand quantify.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 249}, page_content='SEAN GOURLEY Co-Founder and CTO at Quid\\nTo start off, can you tell us a little bit more about your background from your early \\ndays to now?\\nFor starters, I’m from New Zealand. Unlike many data scientists, I did not grow up doing \\nhuge amounts of mathematics, but I think this was probably a little bit of a conscious \\ndecision from my parents. When I was five or six years old, I used to stay awake all night \\nunder the bed covers with a flashlight, solving math problems . My parents thought, \\n“He’s probably doing more than enough math, so we don’t need to push him on this \\nskill.” As a result, at school, I never really focused on math. Instead I spent a lot more \\ntime learning psychology, English, politics and philosophy.\\nI enrolled in university as a law student, which I really loved. After a few semesters, I \\nalso realized that law was a lot of hard work, and it was simply easier for me to get the \\nbest grades in math and physics. So after one year of university, I switched out of law and \\nmade the decision that I should focus on what I excelled at. I changed my major, but I \\nmade a deal with myself that if I didn’t like it after a year of studying, I would go back and \\nbecome a lawyer. As it turns out, I loved it so much that I went on to get a PhD in Physics.\\nSo while I had a lot of mathematical abilities at a young age, I wasn’t pushed in that \\ndirection. Instead, I spent a lot of my time learning about law, philosophy, politics \\nand psychology. I truly believe that it gave me a better perspective on the world, \\nthan mathematics alone would have given. Although I didn’t know it at the time, the \\ncombination of physics and politics would allow me to make breakthroughs in a field of \\nmathematics that didn’t yet exist.\\nSean is a physicist, decathlete, political advisor, and TED \\nfellow. He is originally from New Zealand where he ran for \\nnational elected office and helped start New Zealand’s first \\nnanotech company. Sean studied at Oxford as a Rhodes \\nScholar, where he received a PhD for his research on the \\nmathematical patterns that underlie modern war. This \\nresearch has taken him all over the world, from the Pentagon, \\nto the United Nations and Iraq. Previously, Sean worked at \\nNASA on self-repairing nano-circuits and is a two-time New \\nZealand track and field champion. Sean is now based in San \\nFrancisco where he is the co-founder and CTO of Quid, an \\naugmented intelligence company.\\nFrom Modeling War to Augmenting Human Intelligence'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 250}, page_content='SEAN GOURLEY\\n246\\nI immersed myself in the world of physics and loved it. Mostly because it allowed me to ask \\nquestions about the world and come up with testable theories to explain it. With physics, \\nyou can explain why the sky is blue. It’s fascinating to just be able to do something as \\nsimple as that. Once I got in further and started doing nanotechnology and quantum \\nmechanics, I ended up pushing the boundaries of the world we experience. In nanotech, \\nfor example, you become obsessed with explaining the very small. The theories you \\ndevelop start to speak to a world of atoms and electrons. The interactions don’t make \\nsense on a human scale; they’re non-intuitive because you’re not really modeling our \\nhuman world anymore. \\nLikewise, in cosmology, the equations \\nyou build represent systems on a \\ngalactic scale. Again, at the edges \\nof modern physics, you’re modeling \\nworlds that are divorced from the \\neveryday human experience. It’s not \\nreally addressing the big questions \\nthat we face as humans. Questions like: “Why does the financial market move in a way \\nthat allows it to crash massively, while at other times remain stable?” “Why do wars \\nseem to start?” “How do epidemics spread?” “Where do ideas come from and how to they \\nevolve?”\\nThese were the questions about our world that I wanted to answer — and I believed \\nthat the tools and techniques from physics and mathematics might have something to \\ncontribute.\\nIt wasn’t until I got to Oxford, being very lucky to go on a Rhodes scholarship, that I \\nhad the freedom to explore these ideas. I was originally taking my PhD in biomolecular \\nmotors, which, like most physics projects, involved a lot of time spent in the lab. After \\nspending a couple of days in the lab, I thought, “I don’t really want to spend the next five \\nyears in these rooms.” I went looking around to see if there was a branch of physics that \\nwouldn’t involve time in a lab. As it happens, there was a really interesting professor \\nthere who was modeling the dynamics of human interactions, particularly financial \\nmarkets. I asked him if he would take me on as one of his students, and after a bit of \\nconvincing, he said yes.\\nMy supervisor’s name was Neil Johnson. He was a relatively young physicist who was \\nmaking a name for himself by publishing on a range of different topics, from quantum \\ncomputers to statistical physics. I worked with him, getting my initial start in the field, \\nby creating models for financial markets. For me, this felt like home. \\nAlthough I didn’t know it at the time, the \\ncombination of physics and politics would \\nallow me to make breakthroughs in a field \\nof mathematics that didn’t yet exist.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 251}, page_content='SEAN GOURLEY\\n247\\nThe first thing I started researching was the dynamics of ensembles of agents. Or, simply \\nput, what happens when a range of intelligent objects start to interact. We used this agent-\\nbased modeling approach to start to understand the dynamics of financial markets. Not \\nnecessarily to predict where the market was going, but rather, to understand the forces \\nthat are shaping and driving it. The work was pretty novel at the time, but it suffered \\nfrom the limitation that the computer simulations being used to model human behavior \\ncould not capture all the intricacies of our human psychology.\\nThis study raised some interesting thoughts. On one hand, there is the issue that we still \\ndon’t fully understand the complexities of human decision-making. On the other hand, \\nwe’re definitely more predictable than we think we are. What unfolded in the financial \\nworld was that humans got out of the market, and algorithms started trading. The \\nalgorithms looked exactly like our models. We had created pretty accurate simulations \\nof a market of competing non-human algorithms, along with some warnings about \\nvolatility when algorithms dominate a market. This modeling of financial markets led \\nme to my next line of research, and towards modeling the dynamics of insurgency. \\nWar was topical in 2003, as the US had just sent a massive deployment of troops to both \\nIraq and Afghanistan. In 2003, we also saw the information landscape change as we \\nstarted to get data sources, like blogs coming online, where reports of violence would be \\ntransmitted by many different sources, all of which could be read by machines. So not only \\ncould we create virtual models of insurgency, we could tune these models to precisely \\nreplicate the statistical signatures of the data that we were collecting in near real time. \\nAll of this required building machines that would read news and design algorithms that \\nwould extract events from these stories. This was a challenging proposition given the \\nstate of Natural Language Processing technology circa 2003. We used a lot of heuristic \\ntechniques combined with supervised machine learning models. They performed well \\nenough that we were able to assemble a very complete data set of violent events. We \\nanalysed this data set for any statistical patterns and built the agent-based models to \\ndescribe them.\\nYou’ve got everything from data coming in, looking for signals within the noise, building \\nmodels to replicate those dynamics, and being quite at the fringe of physics. In the \\nend, my PhD was in physics, modeling the dynamics of insurgency mixed with some \\nalgorithms, natural language processing, and political dynamics. \\nThat must have been a fascinating topic of study. In 2003, it sounds like it was quite \\nhard to get the data to actually conduct analysis.\\nYou could say that. The data that the U.S. military had was classified and as a foreigner, \\nyou weren’t going to get it or even know if they had it to give. It was this restriction that \\nactually drove us to use alternate data sources in the first place. We didn’t think that our'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 252}, page_content='SEAN GOURLEY\\n248\\nopen-source data was very good at the time. We thought that the classified data must be \\nmuch better. It was funny, the first time at the Pentagon, I said, “Look, I’ve got this data, \\nand this what we’re seeing. If you’ve guys have better data, can I have it now?” After a \\nfew minutes of talking amongst themselves, they came back to me and simply said, “No. \\nYour data is broadly in line with what we have. You don’t need ours.”  \\nAs it turns out, it wasn’t just broadly in line — it was better! That was just crazy!\\nThe idea that through open source \\nintelligence, you can beat the entire US \\nmilitary’s data collection about significant \\nevents in Iraq. When WikiLeaks released \\nthe Iraq significant events database, the \\ninformation was of a lower resolution than the data we had. Data that was already out \\nthere and available to the public if you just had the right algorithms to make sense of it. \\nThis trend of open-source intelligence dominating closed data collection is one we are \\nobserving again and again. We saw it with the financial markets. It used to be, ‘do you \\nknow the price and volume of stocks?’ This was the valuable information. Then, price \\ninformation becomes a commodity. So people switch to making sense of the data with \\nadvanced algorithms. You see this transition from data being valuable to algorithms \\nbeing valuable.\\nI went through all that. It was a challenging few years. I spent time in Iraq, the Pentagon \\nand the United Nations. I had enough war to last me a lifetime.\\nYou mentioned spending time in Iraq. Was this during your PhD?\\nI wasn’t in Iraq during my PhD. I went in 2008, after my PhD, but the events in the UN \\nand the Pentagon were during my PhD. A lot of it was knocking on doors. I was literally \\nin D.C. stating, “I’ve got this equation — all this useful data.”  I just showed it to a couple \\nof people I knew, who helped get me in touch with some of their connections. Over the \\ncourse of a week, I had impressed enough contacts that that I ended up in the Pentagon \\npresenting to four-star generals, the intelligence team from US central command, and \\nthe Iraqi ambassador to the U.S.\\nWhat was the reaction like? How did the folks from the US government respond to \\nyour presentation of your research?\\nI expected two or three people to show up, but instead, I was surrounded by 40 people, \\ncircling one of those classic war room tables that they have in the Pentagon. Reflecting \\nback, I would have prepared a more polished presentation if I had known exactly the \\nYou see this transition from data being \\nvaluable to algorithms being valuable.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 253}, page_content='SEAN GOURLEY\\n249\\nscale of my briefing. There were people who did not fully understand what the data was \\ntelling them, and were opposed to the findings. One of the main points of difference was \\nthat Pentagon analysts were insistent that there were six groups of insurgents in Iraq. \\nSince I could not make any of the mathematical models work with six groups, they simply \\nstated, “This is not how things are done. You don’t know anything about this space.” My \\nrebuttal was that if they didn’t like this theory, what was their theory to explain this \\ndata? They replied, “Our theory wasn’t designed to explain any data,” to which I replied, \\n“How is that even a theory?”\\nIt was as if I was talking to people who spent their whole lives avoiding numbers. They \\nstudied political science, and every decision they made along the way was so they didn’t \\nhave to deal with mathematics or statistics. But there was the small percentage of those in \\nthe room who had spent time on the ground in Iraq, and seen the reality of the situation. \\nWhen they saw the analysis, they understood what the numbers were saying and they \\nagreed, “this explains a lot of what is going on in Iraq.” The Iraqi ambassador to the US, \\nwho luckily had a degree in engineering, was able to see the power of the data driven \\napproach. He said, “It’s like the Wild West out there. There are hundreds of different \\ngroups fighting each other. We can’t just sit down and negotiate a truce when the group \\nmight not even exist tomorrow. The models you have show this.”\\nDid you find any allies amongst those you presented to?\\nYes. People on the ground: the soldiers and the Iraqi government. Those were two big \\nallies because they had the very real challenge of having to navigate this violence on a \\nday-to-day basis. Many of the officers from West Point asked, “What do I do? What does \\nthis mean for me? How do I operationalise this? I’ve got guys on the ground and I don’t \\nwant them harmed. What does this mean for getting them home safely?” You go through \\nthe dynamics with them; tell them what the basic statistical signatures are showing \\nyou, and what the models point to from a strategic perspective. Here is the probability \\nof attack. Here’s how the different insurgent groups coalesce. Here are the signals that \\nsuggest a group is starting to break apart, and operationally, they get it.\\nOn the flip side however, many of the Pentagon analysts weren’t moved. They would \\nstate, “We’ve got game theory.” I replied, “What does game theory mean when you have \\nhundreds of different groups constantly evolving and the estimated half-life of a group \\nis under 6 months? What does that mean for your game theory?” The insurgents don’t \\neven know what’s going on. How are they supposed to take the rational decisions needed \\nfor Game Theoretic models? Game theory is great if you’re in the Cold War and have a \\ngood understanding of your one or two enemies, but these guys are 40 years behind. This \\nis a different war.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 254}, page_content='SEAN GOURLEY\\n250\\nJust as game theory emerged out of the research from the RAND corporation \\ntrying to model the standoff in the Cold War, are you saying that complexity is the \\nnew model for human actors and chaotic warfare?\\nThat’s exactly right. But they were limited by the restrictive nature of the classified \\nworlds their analyst teams work in. If you were to ask them to look it up on Google, they \\nwould tell you, “I can’t open Google. We’ve got an encrypted system. We’ve got to go \\ninto that room outside of the building to use Google!” They couldn’t use any data that \\nhadn’t been approved. This limits their view of the world so much so that their analysis \\nbecomes dissociated from the activities on the ground.\\nThat said, things are slowly changing. You see General Petraeus moving the thinking of \\nthe military towards a more data centric approach. David Kilcullen, an Australian ally, \\nwas chief adviser to Petraeus, and they started to become more data oriented. What they \\nwere doing with the data was still pretty naïve — but it was a start.\\nI think it’s changed quite a bit over the last six or seven years, and it’s more accepted that \\nthis is the way it’s done. But the first time we submitted our research on the mathematical \\nstructure of insurgency to the top scientific journals, they said, “We don’t do politics.” To \\nwhich we replied, “It’s not politics, it’s mathematics.” Still, they were pretty closed to the \\nidea of publishing this type of research. It took a long time. The academic establishment \\ndidn’t want to know about it. The politicians didn’t want to know about it. No one \\nwanted to publish it. Not because it wasn’t any good — but mostly because it didn’t \\nbelong anywhere. So you had this new type of academic work that had no home. \\nIn many ways, TED played a pretty instrumental role in getting this research into the \\npublic eye. They put me on stage in 2009. At the time, I was only 28. I was the youngest \\nTED speaker from an academic background. Every other academic, who had been on the \\nstage, had a very well established name in their field. Yet here I am presenting this work, \\nI haven’t published, and I’ve just finished my PhD, so everyone is like, “Who is this guy?” \\nI was a nobody with some interesting ideas — nothing more. But that exposure (over 1 \\nmillion downloads of the lecture) did force people to stand up and take notice. When \\nwe submitted the research the second time, the editors at Nature realized that they had \\nto take a closer look at the work. The paper finally went out for peer review and was \\naccepted. Later that year, the research was on the cover of Nature. It was a huge win for \\nour work and for us. But it took three years to get to that place, after many of the world’s \\njournals said they wouldn’t have anything to do with it. \\nNow, we’ve evolved the theory and so on, but the world also became ready to look at conflict \\nin a way that was quantitative. The lesson is that you can have all the mathematics, you \\ncan have all the science, but you also need to bend the world. The world has to be ready,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 255}, page_content='SEAN GOURLEY\\n251\\nbut through telling great stories you can help it get there. The million plus viewers that \\ndownloaded the TED Talk, and the attention that it garnered, changed the conversation. \\nIt made people everywhere begin to think differently about war and mathematics.\\nFor those six months from the TED talk until \\nthe Nature paper was published, I encountered \\na lot of criticism. Wired magazine put a out \\na very critical article about my work, saying, \\n“This guy is naive. He’s saying he’s going to \\nmake war simple. But he doesn’t know what \\nhe is doing,” but they fundamentally didn’t \\nunderstand the research. At the time, I was surprised by the reaction to the research. I \\nthought that the research would be relatively straightforward, that the reaction would be \\nmore positive and open, but there was so much politics surrounding this kind of research, \\nit was always controversial. You can’t expect to analyze an ongoing conflict and not deal \\nwith politics. At the time, I guess I saw science and politics as being two different things. \\nOf course, fast forward a few years to today and the research is now widely accepted to \\nthe point of being ”obvious.” It’s obvious and accepted that when people kill each other, \\nit is done in a mathematically predictable way that doesn’t seem to be dependent on \\npolitics or religion.\\nI still think that experience taught me a few things. One is, if you really want to change \\nthe way the world looks at things, you have to be ready to be the first one through the \\nwall. You have to be ready to get the bloody nose that comes with breaking through \\nentrenched ideas, and know that you’re going to get beat up a little bit. The world won’t \\naccept a new idea without having you fight for it. The second is, that you get to write the \\nstory but you also have to be willing to tell the story. The third is, eventually, when the \\nidea does come to be accepted, it will seem so obvious that everyone will forget there \\nwas any struggle to start with.\\nI remember coming out of that time and needing a break from academia. I started \\napplying for jobs, not really knowing what I was looking to do, but wanting to explore \\nsome different options. I started looking for jobs in hedge funds, technology companies \\nand the big strategy, consulting firms. \\nYou did a stint at BCG — a consulting firm, right?\\nThat’s right. I spent a whole week there at the Chicago office. It was 2009 and during the \\nrecession. I felt like I needed a stable job, and I knew I wanted to get out of academia. \\nBut after a week I knew that it wasn’t for me and I quit the job to move to San Francisco.\\nThe lesson is that you can have all \\nthe mathematics, you can have all \\nthe science, but you also need to \\nbend the world.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 256}, page_content='SEAN GOURLEY\\n252\\nBefore we move on to the story, I want to point out that you didn’t have the usual \\ngraduate school experience, where you’re tucked away in basement number 2, \\nin building number 3, and you don’t see anyone. You were out there trying to \\nchampion and defend this new idea.\\nYes, and trying to get people to listen. That’s exactly right.\\nCould you  expand on the different ways in which your graduate experience was \\ndifferent? It’s amazing that you had the audacity to go to D.C. and began knocking \\non doors, when most researchers would rather sit behind their papers.\\nIn hindsight, I know that I was very lucky in that I managed to choose my supervisor \\nvery well. Neil Johnson gave me the freedom to succeed, and I think that was really \\nimportant. I didn’t have a predefined goal of what I was going to do when I started my \\nPhD. I knew I was going to follow what was interesting to me, and I had the ability to \\ndo that. I think that’s really important. You should pivot your research as you progress \\nin your PhD, because in your third year you are simply going to know a whole lot more \\nabout what is interesting than you are in your first 6 months. Be open to finding that \\nsidetrack that changes the direction of your path.\\nYou’re in a place, as a PhD student, to be able to think deeply about a problem and \\ncomment on things from a pretty unbiased angle. This is a very valuable thing, and \\nsomething that should be encouraged more..\\nI think the other piece was the total time I spent in the physics lab department, which \\nwould probably turn out to be less than a few days. I didn’t spend a lot of time in the \\nphysics department, but instead, I spent a lot of time talking to people in political \\nscience. I spent hours with the soldiers that were coming back from Iraq and starting \\ntheir Master’s in international relations. I spent a lot of time with people with a range of \\ndifferent ideas about how the world worked, and a lot of time reading interesting papers \\nthat were outside my discipline; collecting information and ideas from disparate places. \\nI then assimilated this information together to create a new set of theories about war.\\nThere are two very different strategies that I could have used to get my PhD. There was \\na strategy whereby I could work really hard in the physics lab, plugging away at a niche \\nproblem for 5 years and making an incremental gain. Or, I could expose myself to a range \\nof different ideas that no one else from the world of physics was seeing. I could connect \\nthe dots better than anyone, and then put a structure on it to make it relevant to the \\nworld. That was very much my philosophy. I spent five years of my life asking questions \\nand answering them, and if I’m going to spend that amount of time, the questions should \\nbe interesting to me.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 257}, page_content='SEAN GOURLEY\\n253\\nOnce you’ve taken care of your PhD requirements, you have a lot of freedom as a graduate \\nstudent — probably more freedom than anywhere. Get out and enjoy that. Be a part of \\nthe conversation and seek to answer the things on your mind while always seeking out \\nnew things. Take risks!\\nGiven everything you’ve just said, it actually seems like you had a great PhD \\nexperience, in contrast to other data scientists we’ve spoken with.\\nI loved it! \\nI ran track a lot; spending three hours a day training for a Decathlon, pole vaulting and \\nhurdling. I think it was really necessary to do that physical exercise because it cleared \\nmy head every day. I never went to the track and came back with the work on my mind. \\nIf you clear your head every day, it allows you to have fresher thoughts and filters out \\nideas. Sleep and exercise are two things that we now know removes weaker synaptic \\nconnections. As you can imagine, I did a lot of sleeping and running and filtering out all \\nthe weak connections that I would make during the day.\\nTo be honest, I think I only did maybe 2 hours of \\nwork a day during my PhD. But it was five years \\nof working for 2 hours a day. Everything else, \\nlike the conversations, the things outside of your \\nfield that you read, the random ideas you stumble \\nacross — these filled the rest of the day. You build \\na life around a space that will expose you to the maximum number of ideas, and you \\nbuild a pruning system in your life that allows the concrete ones to stay. In that regard, \\nyou build a lifestyle, as a PhD, that is less traditional. The other life you can build is \\nto show up at the lab, do your studies, and repeat. That’s a lifestyle that’s pretty well \\nproven, but there’s another, which is the one that’s going to create the new connections \\nbetween the dots. \\nI think that’s what really excites us about putting this book together. We feel like \\nthis whole data science thing is comprised of people, like yourself, who are in the \\nfield defining and fleshing out what it means to bring analytics to industries that \\nnever had analytics before, and being willing to fight that uphill battle. Despite \\nyour unique experience, you decided you didn’t want to stay in academia for the \\nrest of your life. What made you decide to switch to this other world that you were \\ncreating?\\nI made that decision before the Nature paper came out. I was frustrated that you couldn’t \\nget the resources from outside to solve the kinds of problems I wanted to solve. I knew \\nBe open to finding that sidetrack \\nthat changes the direction of \\nyour path.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 258}, page_content='SEAN GOURLEY\\n254\\nEveryone asks, “Does your theory work?” \\nand for me, I can tell you that it does, or I \\ncan show you it does. Showing is a much \\nbetter way of doing it.\\nwe needed to combine teams together from different backgrounds. I knew I needed \\npeople with expertise in Natural Language Processing; infrastructure people to store and \\nprocess large amounts of data. I would have loved to have had more marketing people to \\nhelp spread the ideas. \\nThere were all these things I knew \\nI needed, and in academia, all I had \\naccess to was grad students from the \\nPhysics Department. It was too limited. \\nI couldn’t get cross-departmental \\nteams, and I couldn’t run them on the \\nscale I needed. Maybe after tenure I \\ncould have run a small team of 5-6 PhDs, but it felt too long to get there, and the team \\nsize seemed too small to solve the problems I wanted to solve. Physicists can do a lot \\nof things, but they are not developers who are going to build a real time, self-updating \\ndatabase of Chinese television transcripts with high precision named-entity recognition \\nengines. It was never going to happen. You need a database guru from EMC to build that \\ntype of infrastructure for you.\\nSo academia was too constraining?\\nIt was. \\nI remember a particular instance in one of my days at the Pentagon. There were a couple \\nof guys from Lockheed Martin who were selling some sort of new radar tracking system. \\nWhile we were both waiting for our respective meetings, I remember thinking, ‘I’m on \\nthe wrong side of this equation. I’m here to give the Pentagon ideas. These guys are here \\nto sell them product. They’re going to get the money to build this — I’m going to have \\nto hope that someone listens to me.’ Somehow, the academics become the people that \\nare the advisors, but the money is spent with the people who are the builders. Everyone \\nasks, “Does your theory work?” and for me, I can tell you that it does, or I can show you \\nit does. Showing is a much better way of doing it. For me, I have to make this thing real. \\nI have to make this theory concrete. I had a real desire to build something that made use \\nof this research.\\nThe building side of it was key, and so I came out here to the Valley. That was a pretty big \\nmove. Honestly, I didn’t know anything about business. I didn’t even know what a Series \\nA was. I didn’t know anything about hiring, or legal, or product management and quality \\ncode. But despite all of that, I felt as though I was ready to start a tech company.\\nI think that’s a good first step. You’re starting at the bottom, but it’s all uphill from \\nthere.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 259}, page_content='SEAN GOURLEY\\n255\\nIt was a good first step, but I still had to convince myself that I could start a company \\nand take on this kind of risk. I remember coming out to San Francisco and sitting down \\nwith Max Levchin, talking about what it was like to start a company. He told me, “It’s \\nnever going to be easier to start a company. You might think it’s hard now and that’s fine \\n— but it will never be easier to start a company than when you’ve come out of graduate \\nschool, because you’re living on no money. You’ve got no one to support. If it all goes \\nsouth in a year, you’re still incredibly employable and you can roll the dice.”  That stuck \\nwith me — “It’s never going to be easier,” because in my mind, I thought, “If I can go to \\nMcKinsey and learn all about business, when I go back, it’s going to be easier.”  But that’s \\nnot the case. It’s never going to be easier to start a company than when you’ve just left \\ngrad school.\\nI think the second step was finding my co-founder, and without him I wouldn’t have been \\nable to make the jump into starting a company. He had been out in the Valley for about \\nfour years. He was the first employee of Yelp, and I thought he knew everything about \\nstartups and business. Of course, looking back, he didn’t know everything, he just knew \\nmore than me, which wasn’t hard, but the things he did understand were vital to our \\nearly progress and survival. He was instrumental in helping me build the infrastructure \\nfor the ideas and the product that I had. I could not have started the company by myself, \\nnor would I have wanted to. Starting a company is difficult and trying to do that alone is \\ntoo much responsibility, especially when it is the first company you have started. A co-\\nfounder makes it bearable. \\nWhat have been the biggest changes since grad school? I think you skipped the \\npart where you tried to be employable, and you just went straight to employing \\npeople.\\nWell, I did try to be employable. I went around to the consultancies, and I remember they \\nwere quite interested in me. I ended up working at BCG, but I found there was no way \\nfor me to apply the kinds of research and theories I had developed to the problems that \\nthey were solving. Working at BCG, I felt as though I had lost the talents that made me \\nunique.\\nIt’s like the Pentagon all over again, except you were going to be a part of the \\nPentagon!\\nThat’s right. I was looking at working there; trying to have it make sense for me, but \\nit really didn’t. The ironic thing is that now things have come full circle. We’re selling \\nsoftware to all the major consulting firms like McKinsey, BCG and Bain. BCG and \\nMcKinsey now use our software, which is a great result, but at the time, I felt like I was \\na losing a part of myself by working there. I had worked on all these cutting edge ideas'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 260}, page_content='SEAN GOURLEY\\n256\\nabout data, and I was asked to give them up so I could conform to the way things were \\nbeing done at consulting firms. I did it for a week, and I finally said, “I can’t do this.” It \\njust wasn’t a fit for me.\\nI remember being at the BCG training program in little country resort just outside of \\nBarcelona. It was a 3-week long immersion course for scientists and lawyers to give \\nthem business skills, or the “mini-MBA,” as it was called. It was half way during the first \\nweek and I had had a call with one of the senior government officials in Iraq about the \\nescalation of violence over there. The call ended at around 5am in the morning, as such I \\ndidn’t get much sleep and I was showing up a half an hour late to the 8am training session \\nin modern accounting practices for strategy, and the Partner running the training was \\nobviously not happy with me. “This is very important that you show up here on time.” \\nOf course, they wanted (and were paying me) to come here and learn important skills for \\nstrategy consulting, but that just didn’t seem to be so important as taking the late night \\nphone call from the Iraqi government to discuss IED modelling techniques. At this point \\nI was thinking that I might be in the wrong place. Right then I knew it wasn’t for me and \\ndecided to get out at the first opportunity.\\nI was disappointed. I didn’t want to be at BCG, but I didn’t know where I did belong. I \\nwanted to keep doing this research and push forward the data analysis techniques I had \\ndeveloped, but there wasn’t a place to do it. There was nowhere that would employ me \\nto do what I wanted to do. So, without any other options on the table, I decided that if I \\nwanted to make these ideas real then I would have to create a company myself. I didn’t \\nknow exactly how to do this, or what the company would look like, but ultimately I made \\nthe jump. I remember the day. It was a Sunday morning, and I was driving back from Los \\nAngeles up the pacific coast highway. Somewhere right around Big Sur it became very \\nclear to me , “I can’t get on the plane tomorrow and fly back to BCG in Chicago.”\\n \\nI rang them up then and left a voice message, “I can’t go back to work. I’m done.” It was \\nscary to do that, but it was also a rush to cut all the ties. I kept thinking, “I finally get to \\ndo this.” That was the transition.\\nWow. That’s amazing. So after that point, you ended up creating Quid. Can you tell \\nus about Quid?\\nSure! I ended up out here in San Francisco in the middle of the recession without a job, \\nwithout anywhere to stay, with only the last pay check from BCG in my bank account. \\nThat was when it all became real. I started to do some contracting work to pay the bills, \\njust talking to companies that I thought had interesting data and they paid me to start \\nplaying with it to see if there was any value. At one of these companies, I met my co-\\nfounder Bob. He was the CEO of a company with some very interesting data, and I said,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 261}, page_content='SEAN GOURLEY\\n257\\n“I can help you with that.”  We worked together for a few months, and it was a blast. So \\nI told him, “You have to help me start Quid. We’ve got to start Quid. You have to get out \\nof this company. Quit. You have to come to Quid!”.\\nSo we pitched the idea for Quid to Peter Thiel at a breakfast meeting at his house. He \\nliked it and came in to lead the first round.\\nWhat was the pitch at the time? Were you pitching a commercial version of your \\nresearch?\\nAt the time, I didn’t think my research was commercializable. I thought the military \\nmight buy it, but it wasn’t clear that companies would buy the idea of an intelligence \\nplatform. No one was banging down our door asking for a platform to allow unstructured \\ndata, collected from outside sources, to make their biggest strategic decisions. It didn’t \\nseem like there was an obvious market. Customers wanted the machines to predict what \\nto do next; to push a button and have the computer spit out an answer. But this wasn’t \\nwhat we were offering. We were saying that we could build an intelligence platform that \\nwould combine the best of the human brain with the best of the artificial, computer \\nbrain. We didn’t have a name for it then, but today it would be known as augmented \\nintelligence.\\nWe needed a first group of customers who would adopt this new way of making decisions. \\nWe needed a group in which the decisions were too difficult for a computer to make by \\nitself and a group in which the biological limitations of the human brain were running \\nup against the increasing complexity of the world. Silicon Valley, in 2010, provided us \\nwith just this environment. There were groups of people, working to figure out the right \\nM&A deals to make for big companies, like Microsoft and Google. Their task was almost \\nimpossible to do well, simply because of the time it takes to adequately understand an \\nemerging technology space, before the space has changed to the point where your analysis \\nis no longer accurate. This reminded us of the same challenges we had come across in \\nIraq. Trying to keep track of many small groups (startups), any of which could do damage \\nto a larger dominant force (Google, Microsoft, etc.). It seemed like you could apply these \\nsame research techniques, developed to understand insurgents, to the global technology \\nlandscape. If you did that, you could make better bets than were currently being made. \\nIt could move the market cap of companies by billions and create new winners in the \\nspace.\\nThat seemed like the right place to get started. In my mind, I thought, “I want to build \\nthis. I want to build a company that remotely monitors the globe and allows analysts to \\nplug in and see structures, like I did in my PhD.” By rolling out this technology to the \\ncorporate M&A market, it allowed us to begin the project with a clear business case on \\nwhich to focus our development.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 262}, page_content='SEAN GOURLEY\\n258\\nThat’s how we got our start, but in the back of my mind I was always thinking, “I have to \\nhack this venture capital financing structure to do some really cool science fiction stuff. \\nWhat I really want to do will take a long time, but as I go through this process, I’ll be able \\nto do it. First, I have to make money. Once you make money, you can do anything you \\nwant.” This was the hack.\\nThat being said, venture capital is not \\nreally set up to do this. For the most \\npart it is easier to arbitrage market \\nopportunities than it is to create \\nscience fiction type products. Even if \\nyou do get money for this, there’s no \\nguarantee that it is even possible to \\nbuild the things you are imagining. \\nLooking back now, 2009 was too early \\nfor this intelligence platform to exist. \\nThere were just too many technology \\nsolutions missing from the equation; \\ntoo many things that we would have to build ourselves. The right time to make this \\nfor venture capital would have been at the start of 2012. I think if I wanted to start the \\ncompany, I should have started in 2012, but the problem would not have been nearly \\nas interesting to work on. This is the issue with venture capital — if you want to really \\npush the limits of what science can do, there just might not be any business applications \\nready and waiting for you, once you’ve done it.\\nWhen things come to market, they are not as interesting as they were five years earlier, \\nand when you live in academia, you’re 10 years ahead of the market. You think a certain \\nthing is possible, and of course, it’s not possible for 10 years. One of the heuristics is \\nthat whenever a group of papers are published, it will take 10 years for any academic \\nbreakthroughs to become commercial realities.\\nYou learn to appreciate that timeframe. You can’t port your research straight into \\nventure- at least not with the current financial tools that we have. If you’ve finished your \\nPhD, and you can immediately start a company, then your PhD wasn’t any good, because \\nyou should be far enough ahead of the world that there isn’t a market for what you’re \\nbuilding. On the flip side, you’re going to be at a place where you’re the first to market, \\nand you’ve already made all the mistakes, and now others can copy your breakthroughs. \\nThat’s a difficult place to be. It’s an exciting place, but a difficult place from a business \\nperspective.\\nIn many ways you have to constrain your science aspirations by business realities. We \\nhad done this war stuff, and we were going to create a platform to improve private equity \\nThat’s how we got our start, but in the back \\nof my mind I was always thinking, “I have to \\nhack this venture capital financing structure \\nto do some really cool science fiction stuff. \\nWhat I really want to do will take a long \\ntime, but as I go through this process, \\nI’ll be able to do it. First, I have to make \\nmoney. Once you make money, you can do \\nanything you want.”'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 263}, page_content='SEAN GOURLEY\\n259\\ninvestment decisions. It’s not quite revolutionary, but you also have to keep in mind that \\nit is the first step, and venture capital is all about levelling up. If you make the first step, \\nthen you move from $2.5M in funding to $10M. Make the next step and you get $50M to \\nplay with. You have to keep the grand vision, and at the same time execute on the day-\\nto-day elements of creating product market fit.\\nMy vision with Quid is to have an intelligence platform that monitors the world through \\nopen data sources, so that anyone can plug into the platform and see the patterns that \\nshape the world. From that vantage point, everyone can make better decisions in their \\nworld that will ultimately impact our world. Users can see further, see deeper, leveraging \\ndeep intuitive AI combined with immersive visualizations. To ultimately amplify \\nintelligence through software — that’s where I want to go with this. I want to have a \\nsystem that makes us smarter, that is distributed as widely as possible, and to as many \\npeople as possible.\\nWe’re talking about augmenting human cognition across the planet. I think we’re maybe \\n10 years away from having a complete working version of this. There’s certainly another \\nbillion dollars of investment here. Whether we get there or not, no one knows. But I \\nthink something to take away is that with science, you hold a piece of the puzzle, you \\ndirect the field, and you get to shape it a little bit.\\nHere, the traditional thinking is that if you don’t win financially, you haven’t won. But \\nI know that by even being here, I’ve shaped the direction of the technological vector. I \\nwill continue to shape it as long as I keep playing. Even if I don’t win the money at end \\nof the game, I’ll do very well, but the direction is going to be shaped because of me. In \\nscience, we know that we play a part in a bigger human endeavor and in the Valley its all \\nabout me — and did I win.\\nThis is why we need to be in this game, because these things that are happening are \\nshaping all of us, and if it’s just a monetary grab, we’re a little off. Science brings in the \\naspect of having a sense to do something worthwhile and good.\\nIn 2006, you were working on this paper and Nature wasn’t ready, the Pentagon \\ndefinitely wasn’t ready. Now, it’s almost 10 years later, and now we see the \\nmovement in industry towards making strategy decisions. Relative to your paper \\nin 2006, do you think that within that 10-year deadline, we’re going to get to the \\nplace where your vision is?\\nThe paper came out in 2009, so there’s probably still a few years left before we see \\ncommercializations. Based on the work from 2006, we are definitely going to see this \\nin the commercial world. In the last 6 months, since Quid released the second version'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 264}, page_content='SEAN GOURLEY\\n260\\nof our Intelligence Platform, we have seen a great uptake in all types of people using \\nit; from hedge funds, to strategy consultants and advertising creatives. Fast forward \\nanother 18 months, I think that we will have thousands of strategy consultants running \\nQuid software. I’m very confident that we’re putting the elements in place to make this \\nhappen: the relationships, the technology, and the algorithms. We’re getting our first \\ncourse at the University College of London’s management science class and the entire \\nclass is getting Quid accounts. They’re plugging in. They’re training on it. The first \\nMcKinsey teams and the first BCG teams are spinning up. We just signed a major deal \\nwith a group of publicists to roll this out to their creative strategists across the entire \\nfirm.\\nWe’ve got small, boutique consultancies that are winning massive contracts because \\nthey’re running Quid software. They’re getting great results and even moving into new \\noffices based on all the new business they’re winning. Consulting used to be a case where \\nyou arbitrage smart PhD students and then you plug them in to BCG. You throw people at \\nthe problem. Now, these same people can drive the kinds of software Quid is pioneering. \\nThe AI behind the Quid engine can do a lot of the heavy lifting, saving literally, weeks \\nof work. The analysts can spend time \\ndoing the things that matter — which \\nis figuring out the implications of the \\nstrategy in front of them. Hopefully, \\nif nothing else, I’ve given some of our \\nusers a bit of their life back instead \\nof spending it doing those tedious \\nthings.\\nThe strategy part of the problem is well on the way towards being solved, and I think \\nthe next step is to start integrating more of our Artificial Intelligence capabilities into \\nthe system. Scientists talk about the brain having a neural circuitry for intuition. Expert \\nintuition comes from two parts of the brain: the precuneus and the caudate nucleus. The \\nprecuneus is the pattern recognition engine that identifies patterns to extract signals, \\nwhere most of us non-experts would only see noise. I think we’ve built a lot of that in the \\ncurrent release of the Quid platform. We’ve built a lot of pretty good pattern recognition \\nengines, to allow users to see structure in news, science, Twitter etc.\\nThe next phase of the Quid project is to build the AI version of the caudate nucleus. \\nThis is the part of the brain associated with the learned response function. I think in \\nthe next couple of years, we will have built a good, learned response function into the \\nQuid platform. At the moment, humans are learning the patterns and figuring out what \\nthey should do next based on their experience. We can start hinting at things that have \\nhappened in the past. That’s not to say that we should replicate them, but we can build \\nA lot of the process, for me, is continuously \\nlearning to let go of the things that I have \\nbuilt and let other people in the company \\ntake ownership of them.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 265}, page_content='SEAN GOURLEY\\n261\\non that functionality so they can see what an artificial caudate nucleus would look like \\non top of these data streams. It’s a kind of simulation that would project the current \\nworld forward in time to explore different scenarios. I think that’s going to be really \\npowerful.\\nI think what the Quid platform ultimately does is allow people that are good at \\nrecognizing patterns, and knowing what to do about them, to jump between different \\nareas of expertise. You should be able to jump into the world of material science and see \\nall the papers written in that field, and then jump into the world of swarm robotics for \\nUAVs, and to then into the world of Ukrainian politics. You should be able to leverage the \\nintelligence engines of Quid to give you a deep understanding, across all these fields, in \\njust a few hours.\\nI think when we put that tool in front of people, they will begin to broaden their \\nknowledge. They will see further and they will see new things. I want to try and replicate \\nthe experience I had in grad school, where I was able to jump between things but to give \\nthat in a tool to other people, and I think that will change the way people will see the \\nworld. I think it will also allow things to be thought and to be built in ways that otherwise \\nwouldn’t have happened. I’m more confident now than ever of getting that right. \\nA lot of the process, for me, is continuously learning to let go of the things that I have \\nbuilt and let other people in the company take ownership of them. It seems obvious, but \\nit’s a continual process of letting go. You build the first versions and then you have to \\nstep back and give it to the other team members. You might not like how they choose \\nto update your solution, but the point is that it’s no longer just yours anymore. The \\nchallenge then becomes knowing when to let go and when to step back in to make sure \\nthe essential parts of the project are still being maintained.\\nFor example, one of the key features of the product is the animated transition between \\ndata spaces. When building this, I was adamant that we had to have transitions. Some \\nother members of the team rightfully challenged this because it’s an expensive part of \\nthe product to build. They would ask, “Why do you need transitions?” There’s no real \\nempirical evidence as to why we need this feature, but it somehow just feels right. So \\nI replied, “We’ve got to have transitions. The data has to move between a timeline and \\na network. People need to orientate themselves”. Other members of the team again \\nobjected stating, “No one wants to have that.”  Until I finally stated, “I hear you, but \\nwe’re doing it.”\\nFast forward a few weeks, and one of the engineers says that a cylindrical coordinate \\ntransformation would be better. I said, “You know what? I never thought of that. I’m not \\nsure it does.” Then I looked at it, and they were right; it does. A cylindrical transformation'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 266}, page_content='SEAN GOURLEY\\n262\\n— translating between two points using cylindrical coordinates; I never would have \\nthought of that. I had nothing more to add. Their understanding of this problem was \\nbeyond me. That was the right time to let go.\\nYou have things that are important and then at some point, you realize, “I have nothing \\nto add to this.” That’s the continual balance when you create things that are pushing the \\nboundaries of what is possible. It’s important to know what matters and what doesn’t.\\nThat’s the beautiful lesson in leadership. It must have been a hard lesson to learn. \\nI feel like there’s so much investment involved. Not only have you carried this, you \\nalso fought for it for so long, and then, at the very end, you give it away to others \\ntorchbearers. \\nThat’s right, and it can only be done with thousands of people building this. It’s fighting \\nthe battles that need to be fought and letting go of the ones that don’t. Now, for me, it’s \\ntrusting in the machinery that I’ve set up, and it’s also going out and helping the world \\nto learn to use this. With a team, you can keep making the products better. \\nIn life, it’s always 0 to 1, and you’re either a one person or a 1 to 1.1 person. I think a lot \\nof things we do in life are 0 to 1, and that’s also important to recognize. That means that \\nwhen you’re the first one through the wall, you have to fight for it. No one wants to listen \\nto you, and by the time the idea gets accepted, you’re bored with it. You move on to the \\nnext thing.\\nThe nice thing about startups is there’s always a next thing. Everything you do is \\nsomething you’re doing for the first time and not something you’re very good at. It’s \\nsomething you’re unqualified to be doing.\\nNow at this point in your life, I have to say that you have a lot of credibility in doing \\nthings you’re unqualified for.\\nThat’s how you learn about your strength. My strength is consistently doing things I’m \\nnot very good at and quickly becoming reasonably competent. My hope for grad students \\ncoming out of their PhD is to pick whatever job you want in a way that takes advantage of \\nthe skills you have as a graduate student. In data science, if you feel you have to conform \\ntoo much in a box and don’t get the freedom, that job is not for you. Find a place where \\nyou can shape a little bit of the world and keep doing that, which will probably involve \\ndoing a lot of things that you’re unqualified for and not very good at.\\nI think we’ve got a very narrow view of what data science is, which has largely been \\nshaped by data analysts working in the big social networks, like Facebook and Linkedin.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 267}, page_content='SEAN GOURLEY\\n263\\nSo for many of us, data science seems concerned with things like A/B testing to optimize \\npersonalized ad recommendations. But data science can be so much more than this. \\nWe must recognizing what data can do, what data can’t do, recognizing that it’s messy, \\nthat it’s biased, and understanding that it needs a human layer — that it needs stories. \\nRecognizing that it can solve a certain degree of complexity, but it can’t solve any \\nfurther. Remember that humans have \\nbiases and they absolutely need data. \\nWe don’t want to move towards \\nnaive empiricism — that’s not what \\ndata science should be. It’s not what \\nscience teaches us, but, at the same \\ntime, we don’t need to throw data out \\nthe window just because it can’t push \\na button to solve an equation.\\nI think a lot of that will come together. Data science will evolve. I think the second \\npiece is data scientists have an obligation to do good things in this world with that data. \\nIt’s not enough to just not be evil; it can fundamentally be good. If you come out of \\nscience, you are contributing to the world’s knowledge. When you come to the business \\nworld, you should also be contributing towards building the tools that help us to live and \\nfunction in society.\\nThis is an imperative that should be fought for very hard. This should be one of the \\ndecisions you make in the jobs that you do. We have a set of technologies that can and \\nwill shape our world in ways that are positive and potentially very negative. It ultimately \\ncomes down to the mentality of the people that are building the technologies. We can \\nwash our hands and say, “I can’t do anything about it. It’s not in my control.” But we \\nreally need to challenge this assumption. You can do something about it! You’re making \\nthis or your company is making this stuff. You’re the data scientists that are building this \\nstuff. Of course you can do something about it, and of course you have that responsibility.\\nIf you choose to do it in a different way, you are the one shaping the world. We are \\nthe people who are creating this technology, so you can’t just wash your hands and say \\nyou’re not part of it. We saw what happened when a bunch of quants on Wall Street, with \\nlittle regard for the consequences said, “I’m just going to use these algorithms to make \\nmoney.”  This is not good enough. You can’t arbitrage a system and make money for \\nyourself without also having the responsibility to make it better.\\nSo much of data science has been concerned with equations for the optimization of an \\nexisting world. But we need to use data science to build and engineer a better world, \\nand that’s where it starts to move beyond black box predictions and basic statistical \\nIn life, it’s always 0 to 1, and you’re either a \\none person or a 1 to 1.1 person. I think a lot \\nof things we do in life are 0 to 1, and that’s \\nalso important to recognize. That means \\nthat when you’re the first one through the \\nwall, you have to fight for it.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 268}, page_content='SEAN GOURLEY\\n264\\ntools and moves into design. One of the big things for data scientists is to understand \\nthat their role is also one of design. If you create algorithms, you shape the behavior of \\npeople who interact with these algorithms. So what kind of behavior are you designing?\\nI think data science is really going to become more of a product design process; actually \\nan algorithm design process. Algorithms take information and direct us; whether it’s the \\ninformation we read, the music we listen to, the places we drink coffee, the friends we \\nmeet, or the updates in our lives. \\nYou are designing algorithms that \\nfundamentally shape humanity, and \\nwe do it in on a population scale in \\nthe billions. So how we choose to \\nshape this world certainly has a lot \\nof challenges. We can’t just hide \\nbehind the imperative to optimize an \\nalgorithm for maximum revenue. You designed an algorithm that created a certain kind \\nof behavior — for better or worse — and now this algorithm is potentially impacting the \\nlives of billions of people you have never met. What kind of behavior do we want? I think \\nyou need to fall on the line of making humans more human, making them see further, \\nmaking them see deeper, making them understand and appreciate the nuance. Don’t try \\nto hide the complexity from them, but instead, make them more conscious. Make them \\nsmarter. Help make them smarter. I think that’s what you design for. That’s what you use \\ndata science for.\\nThat is amazing. I love that vision, the imperative you stated for people that want \\nto work in data science.\\nI think most of the data scientists I meet are pretty good people. It’s been refreshing to \\nsee this culture emerge from the community that we built up over the years. It’s one of \\nthe things we started in 2009, DDG (Data Drinking Group), which was Pete Skomoroch, \\nMike Driscoll, DJ Patil, Bradford Cross, and me. There were five or six of us that would just \\nget together and drink and talk about this stuff. These were some of the most creative \\ntimes. The ideas we discussed, the questions we would ask, and the technology we would \\nshare. I think this really influenced how the discipline is unfolding today.\\nData science is its own philosophy. We’re not the same as the production engineers of \\nthe world. We’re not product people. We’re our own kind of group with our own set of \\nvalues. Data scientists have a distinct kind of DNA that is measurably different from a lot \\nof the other groups. As this culture emerges and develops, I think good things will come \\nfrom it. I’ve always been very impressed by the data science people I’ve met. They have \\nthis nice coupling between the real word and the computer world. They know data and \\nData scientists have an obligation to do \\ngood things in this world with that data. \\nIt’s not enough to just not be evil; it can \\nfundamentally be good.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 269}, page_content='SEAN GOURLEY\\n265\\nthey know engineering. They value the beauty in their algorithms and the beauty in their \\ndesign. They span a lot of traditional disciplines and can combine their experiences to \\ncreate new things. I think we’re going to see this group of data scientists solve many of \\nthe bigger problems we are facing in the world, and that’s pretty exciting.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 270}, page_content='JONATHAN GOLDMAN \\nDirector of Data Science and Analytics at Intuit\\nCan you give us a sense of the background and the path that you’ve taken to get \\nwhere you are today?\\n \\nI completed my Bachelors in Physics at MIT. I just absolutely love math and physics. \\nI actually loved a lot of other fields as well, but knew I wanted to stay with math and \\nphysics in particular. I also absolutely loved MIT — it was the perfect place for me. When \\nit came to graduation, however, I still didn’t know what I wanted to do with my future. I \\nknew I wanted to do something more in science, but I didn’t know if I definitely wanted \\nto be a professor. I ended up applying to Ph.D. programs but still wasn’t certain if that \\nwas what I wanted to do.\\nI also applied for a few jobs, but was just not excited about any of the jobs I saw, and how \\nthey would leverage my skills. In comparison, grad school was exciting since I would get \\nto work on fundamental research there. At the time, I was really excited about what was \\nhappening in the world of quantum computing.\\n \\nI got into Stanford, and I found an advisor who was specifically working on quantum \\ncomputing. So I came out to Stanford and liked it for a while, but towards the later \\npart of my Ph.D. recognized I wanted to something else. Research was hard and not as \\nrewarding in the short-term — it took me seven years to get the results that I needed to \\ngraduate. It was in my fifth or sixth year that I thought, “I want to do something that has \\na little bit more immediate impact.”\\n \\nJonathan is currently Director of Data Science and \\nAnalytics at Intuit. He co-founded Level Up Analytics, a \\npremier data science consulting company focused on data \\nscience, big data and analytics which Intuit acquired in \\n2013. From 2006–09 he led the product analytics team \\nat LinkedIn which was responsible for creating new data-\\ndriven products. While at LinkedIn he invented the “People \\nYou May Know” product and algorithm which was directly \\nresponsible for getting millions of users connected and \\nmore engaged with LinkedIn. \\nHe received a Ph.D. in physics in 2005 from Stanford where \\nhe worked on quantum computing and a B.S. in physics from MIT.\\nHow to Build Novel Data Products and Companies'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 271}, page_content='JONATHAN GOLDMAN 267\\nThe parts of the Ph.D. program I loved most were when I was actually getting the data, \\nanalyzing it, and iterating very fast. I had these experiments I’d have to run for 30 \\nhours, and basically after that, the system would shut down, restart my experiment, and \\nit would take a day or two to get the system to reset. It was during this period that I \\nwas getting this amazing data, make a hypothesis then and test it. I loved the actual \\nthinking, the theoretical aspects of it, what that told me to do with the experiment, and \\nwhat parameters to explore.\\nTowards the end of my program, I got involved in some entrepreneurship activities at \\nStanford. I got involved in this organization called a nanotechnology forum, where Steve \\nChu, Stanford physics professor and later the Secretary of Energy came to speak. A lot \\nwas happening back in the early 2000s in that area. I was trying to go into that area, \\nlooking at solar energy technologies — I was very excited about that. But then I looked at \\na few of the solar technology companies, and the basic approach that they had was, “Hey, \\nyou get to work on this technology as a postdoc, and if it works, you’ll get a full-time job. \\nIf not, that’s a nice postdoc for a year or two.” That just didn’t seem appealing to me.\\nAt the end of graduate school, I was looking for a job, and I knew at that point I just did \\nnot want to stay and do a postdoc. I ended up going to the consulting firm Accenture, and \\nI was excited about going to work in energy. I had been working on energy-related stuff, \\nand I was getting more excited \\nand interested in that. I wanted to \\nwork in strategy for Accenture — \\nthe focus was in the utility/energy \\nsector, especially in the natural gas \\nmarket.\\nSo, I was working for a little while \\non natural gas strategy for one of \\nthe partners, and that was fun. I got \\nput on a project to work at a utility \\ncompany, and it was good to get that exposure — to find out what the corporate world \\nis like. What is it like to do consulting? What’s it like to work in this company? How do \\nthey operate? I actually learned a lot about how to communicate and how they work; it’s \\nsuch a different world from academia. \\nCan you tell us a bit more about what you did at Accenture? What were you \\ninvolved in there?\\nI was in the supply chain project for a utility company, and we did a lot of work on \\nsupply and demand, and other sorts of optimizations. When should the utility company \\nAcademia becomes a very competitive world \\nsince you have to make a name for yourself \\nto succeed. The business world is also \\ncompetitive, but in my experience, teamwork \\nis more highly valued there because it really \\ndoes take a significant effort from many people \\nto make something interesting happen.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 272}, page_content='JONATHAN GOLDMAN\\n268\\nbuy? How much inventory should they have and what do they have to plan for? They’re \\ninteresting problems because you need math and analytics to figure out the optimizations. \\nIn the case of a utility company, it’s different because you have to plan for worst-case \\nscenarios. If there’s a storm, I need to be able to repair everything quickly enough so \\npeople have enough power. There’s demand and supply planning, as well as strategic \\nsourcing — there’s a whole bunch of interesting problems.\\nCan you tell us more about your transition from Accenture to LinkedIn?\\nAt that point where I was thinking, “Let me see if I can do something a little more \\ntechnical.” I felt like I learned what I needed to learn so I was trying to find new projects. \\nI started looking around to new places, including LinkedIn. Initially it seemed like it \\nwas a recruiting platform and I wasn’t that excited about it, but after I went and met \\nwith various people there, learned about their data, and learned about what they were \\nthinking about, I thought “Wow, this is awesome.” \\n \\nWhat was it about LinkedIn that hooked you?  \\n \\nWell, what really excited me was thinking, “Well, look, you have this data about people’s \\ncareers, where they went to school, where they are now working, what they have done \\nin their careers, and descriptions of their past jobs. So how do I help people get the right \\njob?” It’s a problem that actually felt very personal. While I’m trying to find the right \\ncareer for me, I could help work on solving that problem for others at scale.  \\n \\nThe data was all there, and I could ask questions about the data very quickly. It was \\nexactly the part of the Ph.D. program that I liked. Suddenly I didn’t have to deal with \\nthe experimental apparatus which took me two years to build. It was like, boom, I have \\nthe data, and it’s actually very interesting. I was learning all these new techniques and \\nit was great.\\nWithin two weeks of starting, I had already felt that this was my dream job. It was \\nawesome, and I totally loved it. I found people even more collaborative in companies \\nthan they were in university research — we were all working to help the company do \\nwell and make a dent in the universe. In academia you also try to make a dent, but it \\nwas very often your own dent. Academia becomes a very competitive world since you \\nhave to make a name for yourself to succeed. The business world is also competitive, \\nbut in my experience, teamwork is more highly valued there because it really does take a \\nsignificant effort from many people to make something interesting happen.\\nIt sounds like you really enjoyed your time at LinkedIn. What did you do there?\\nI was trying to figure out what I could do with the data to improve things. One project I'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 273}, page_content='JONATHAN GOLDMAN\\n269\\nworked on involved sending invites on LinkedIn. I looked at questions such as whether \\nor not the click-through-rates changed depending on the level of the person who sent \\nit to you (more senior than you, more junior to you, a peer). Something else I thought \\nof and looked at was the reminder emails that we send a week or two later after you \\nhaven’t accepted an invite. I looked into the best time to send such a reminder, and \\ndiscovered neat facts such as 80% of invites go to people in the same time zone. This \\nmeans that even though I don’t know what time zone you’re in, I can guess pretty well \\nfrom the time-zone of the person who sent you the invite. We optimized the time of day \\nthat the email went out and saw boosts of 2-3% in click-through rate. This improvement \\ncompounds and the result can be massive.\\nBasically, we were trying to look for all these little knobs to turn to understand the \\nLinkedIn dynamic and to understand LinkedIn at a fundamental, physical level. I thought \\nof it as a physics problem involving people and invites. I was asking myself — who’s \\nconnected to whom, and how can I get more people to join? How can I get more people \\nconnected? When you understand the system, you try to think of it not just as these \\ndisparate things but more as an overall global pattern that you want to understand — an \\nengine that you want to get to move faster.\\nI started thinking about some of the dynamics \\ninvolved in what gets people to sign up, and \\nthen I also started looking at the data. I found \\nthat a lot of people didn’t even have that many \\nconnections. And people were not going to \\nreally get the value of LinkedIn until they had \\na good network — until they had ten, twenty \\nor thirty connections. Most people only had \\none, two, even zero. I observed these things in the data, and realized that we really need \\nto just work on getting people connected. I asked myself — how can we get more people \\nconnected? Well, we can make it easier for you to find people to connect with. Back then, \\nthere was Friendster, MySpace, and the beginnings of Facebook, and no one had been \\nworking on recommending people you might know.\\nSteve Stegman (Steve was what we would call a data scientist today) and I, within the \\nspan of one day, conceived the beginnings of the “ Viewers of this profile also viewed… ” \\nfeature. We could quickly get stuff out onto the site, test it, and see the click-through \\nrates, so that was awesome. I had this idea of trying to recommend people you know and \\nwe ultimately called it “People You May Know”. I was working on the heuristics, mostly \\nat night, just iterating and iterating, and asking, “What are the things that can work?” And \\nwe ended up using a lot of stuff like company and school, and also the graph structure \\nof how connected they are. The initial click-through rates were amazing — and then \\nWe optimized the time of day that \\nthe email went out and saw boosts \\nof 2-3% in click-through rate. This \\nimprovement compounds and the \\nresult can be massive.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 274}, page_content='JONATHAN GOLDMAN\\n270\\nmachine learning helped increase click-through rates another 2- to 3-fold. This work \\nwas spearheaded by Monica Rogati who I hired onto my team.\\nThis was not a product that was on \\nany roadmap — I think that’s an \\nimportant thing to point out. I pitched \\n“People You May Know” to a few \\nproduct managers and they were all \\nlukewarm about the idea. It was hard \\nfinding people who really bought into \\nthe idea at the beginning, but we ran tests and had data we could go back to and show \\npeople. Once we had data, no-one stopped us from expanding and doing more but it \\nstill took some time to get the proper engineering investment we needed. Because of \\nthe viral nature of “People You May Know”, we demonstrated with data that this feature \\ngot millions of users back to the site who otherwise would not have visited the site. \\nWe showed this to Jeff Weiner in 2009, and he was like, “Yes, we’ve got to go on and do \\nmore.” At that point there was lots more engineering investment put in place across \\nLinkedIn and fortunately PYMK got significant additional investment.\\n \\nThis was a great example of a data product that was never actually on the product roadmap. \\nIt’s the impact that a data scientist can have on a business, because you can observe \\nsome pattern in the data, build something, and start doing some pretty sophisticated \\nstuff with all these different signals. You end up transforming the trajectory of growth.\\n“People You May Know” started as my original work. I did basically all of it initially, \\nincluding the algorithm and the product, but ultimately, as it grew and grew, many more \\npeople became involved. Monica and Steve Stegman made contributions to some of the \\nalgorithm, and DJ helped with getting it onto mobile and getting it faster. Other product \\nmanagers, like Janet, were also involved.\\nLater on in your career, you started your own company with your wife and a \\nthird co-founder, Lucian Lita — can you tell us more about this? What was it like \\ntransitioning from a role as a data scientist at a large company to running your \\nown?\\n \\nThe three of us saw this opportunity — the demand for data science and building \\ntechnology that would help solve data science problems. We saw a huge need that was \\njust constant, and thought we could build a premier consulting firm and we would go to \\nthese companies and help them transform their businesses, while hiring people that we \\nreally liked working with. \\nBasically, we were trying to look for all \\nthese little knobs to turn to understand \\nthe LinkedIn dynamic and to understand \\nLinkedIn at a fundamental, physical level.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 275}, page_content='JONATHAN GOLDMAN\\n271\\nThe amazing thing was that we were able to get really good talent, get really good \\nclients, and work on really challenging problems. There weren’t that many people doing \\nexactly what we were doing — no-one else did the full end-to-end, including “What’s the \\nbusiness problem you’re facing? Where’s the place we can have the most impact? What \\ntechnology might need to be built or deployed? What algorithms and analysis need to be \\ndone? We could do the full stack — I think a lot of companies really liked that approach.  \\n \\nOne of our clients, Intuit, after we got to know them and they got to know us, approached \\nus about getting our entire company focused on Intuit — namely they wanted to acquire \\nus. We really liked the problem they were working on. They were fundamentally changing \\npeople’s lives by making it easier to manage their finances, do their taxes and run a small \\nbusiness. It’s actually quite an interesting problem because they see so much of the \\neconomy. They are really truly one of the few companies that I think is mapping the \\nworld’s economy. You could say that LinkedIn is mapping the talent economy, but Intuit \\nis actually mapping the real transactions that are happening. I don’t know any other \\ncompany that has such interesting data. The impact on the economy and economic \\nwealth is profound.  To me, it was a good mission to be a part of, and I really liked the \\nculture and the people. \\nGiven your own experiences in a PhD program, what advice do you have for our \\nreaders who are in a PhD, or just recently finished one, and are looking to start \\ntheir career in data science?\\n \\nFind the companies that are aligned with \\nyour values, where you get to work on things \\nthat are impactful and making a dent in the \\nuniverse. There’s never going to be a shortage \\nof interesting problems to work on that are \\nmassive and impactful. When you’re at that kind of company, it’s easier to take that data \\nand turn the data into transformational business impact.  \\nI think one of the most important things is to learn to be curious. You see something that \\nmight spark new questions for future projects. Once you’re curious about something \\nwith the data, you’ll figure out how to go solve and answer those questions, regardless \\nof the technique. You need to be able to go back and forth in an iterative manner as \\nbusinesses don’t always have well-defined problems. \\nI think one of the most important \\nthings is to learn to be curious.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 276}, page_content='WILLIAM CHEN Data Scientist at Quora\\nCan you tell us about your journey transitioning into data science?\\nI started my freshman year at Harvard wanting to study math, but then took Stat 110 \\nwith Joe Blitzstein. The class changed the way I thought about uncertainty and everyday \\nevents, while teaching me how to value intuition and communication. The class \\ninfluenced me to declare statistics as my major in my sophomore year.\\nIn my sophomore year, I started looking around for internships that would use some of \\nmy probability and statistics background. My knowledge was mostly theoretical then \\nwith little experience in application, so I was pleasantly surprised when Etsy invited \\nme to intern with them as a data analyst. This was my introduction to using data to \\nimprove business — every facet of my internship helped me grow and develop my skills \\nas a budding data scientist.\\nEtsy is a very metrics-driven company and I was able to see and understand the heart \\nof how Etsy makes decisions with A/B testing. The frequent statistics discussions on \\nthe mailing list were engaging and I was able to learn about common techniques and \\npotential pitfalls in metrics-driven tech companies.\\nThe presentation of data at Etsy was beautiful (with d3 dashboards and highly polished \\nslide decks). In that kind of environment and attention to visuals, I taught myself ggplot2 \\nand started making my own plots and graphics. I was able to learn a lot during that \\ninternship — it was the start of my career in data science.\\nAfter my internship at Etsy ended, I started my junior year. That year, I returned to being \\na teaching fellow (the equivalent of an undergraduate teaching assistant) for Stat 110. \\nWilliam Chen is a data scientist at Quora, where he helps \\ngrow and share the world’s knowledge. He became a data \\nscientist after finishing his joint degree in Statistics and \\nApplied Math at Harvard, and is part of the first wave of \\ncollege undergraduates who took data science courses and \\nsought data science jobs straight after graduation. Prior to \\njoining Quora full time, he interned at Quora and Etsy as \\ndata interns. He has a passion for telling stories with data, \\nand shares his knowledge extensively on Quora.\\nWilliam is one of the co-authors of this book.\\nFrom Undergraduate to Data Scientist'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 277}, page_content='WILLIAM CHEN 273\\nIn helping people with their probability problems, I realized that teaching probability \\nhelped me improve both my communication and storytelling capabilities. It was also \\nvery enjoyable and I got more in the habit of trying to share and teach whatever I could.\\nMy junior year, I also started \\nto take a lot more CS classes \\nas I realized their importance \\nin a data science role. Not \\nhaving enough programming \\nbackground to implement \\nyour statistics knowledge can \\nseverely limit the number of \\nthings you can do. I realized that having both was imperative to succeeding in a data \\nscience career, so I worked to excel at their intersection by taking classes that I felt \\nwould augment my skills.\\nI was also applying for internships my junior year, with the mindset that I wanted to \\nuse my statistical and programming skills to help companies make better decisions. I \\nreceived an internship offer from Quora and decided to take it, even though I was still \\nfairly new to the product at the time.\\nAt Quora, I touched a lot more of the codebase and learned much more about software \\nengineering. There was a sense of dynamism and importance to my project. It involved \\nnew growth initiatives, and I appreciated the level of freedom and trust that Quora gave \\nme. I enjoyed my time there working with both the people and the product a lot, so I \\ndecided to go back full-time.\\nIn my senior year, I continued developing my statistical and programming toolkit while \\nworking on my thesis.\\nWhy did you choose to major in statistics instead of computer science?\\nI put a lot of time into Stat 110 and a whole bunch of other statistics classes — I enjoyed \\nthose classes so much that it would have been unreasonable for me to major in anything \\nelse!\\nDuring my internship at Etsy, I saw first-hand how limited my abilities would be if I \\ncould only do statistics and not code. I put a lot of effort that summer into developing \\nmy abilities to analyze data in R.\\nMy junior and senior years I took an equal load of statistics and computer science courses. \\nNot having enough programming background \\nto implement your statistics knowledge can \\nseverely limit the number of things you can do. \\nI took computer science courses so I could more \\neffectively do statistics.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 278}, page_content='WILLIAM CHEN\\n274\\nI took computer science courses so I could more effectively do statistics. I took classes \\nto make me better at applying statistics (Machine Learning, Parallel Programming, Web \\nDevelopment, Data Science) or just because they were fun mathematical topics (Data \\nStructures and Algorithms, Economics and Computer Science).\\nMy primary interest is still statistics, but I heavily value computer science since it \\nempowers me to do more complicated analyses, generate visualizations, deal with \\nmassive amounts of data, and automate away a lot of my work so I can focus on what’s \\nreally interesting.\\nThat being said, I actually declared a secondary (aka minor) in Computer Science my \\nSenior Spring. I fulfilled its requirements (accidentally) and pursued the secondary \\nbecause it would require no extra effort on my part, just some paperwork.\\nCan you tell us more about what you felt that your main challenge was during your \\ndata internships?\\nOne exciting thing about working for a tech \\ncompany where data is central is that there’s \\nso many potential projects to tackle. There’s \\nso much data that can be analyzed and never \\nenough data scientists to really look deeply \\ninto every single thing. My main challenge \\nduring my internships, especially at Quora, was figuring out how to prioritize all the \\npossible things I could be doing, especially since I took on many projects in parallel.\\nAt Quora, I realized I couldn’t replicate what I did at school by working on everything \\nat the same time. I realized that I needed to prioritize things that would have the most \\nimpact for the company. I spent a bit too much time working on certain tools and not \\nenough time focusing on researching growth initiatives that would have potentially \\nhigher impact.\\nHow do you see data science in terms of it being the intersection of math, statistics \\nand computer science? What weight would you give each in terms of importance?\\nI would say that the programming and software engineering part is very important \\nbecause you may be expected to implement models, write dashboards, and pull out data \\nin creative ways. You’ll be the one in charge of hauling your own data. You’ll be the one \\nwho owns the end-to-end and the full execution, from pulling out the data to presenting \\nit to the company.\\nI realized that I needed to prioritize \\nthings that would have the most \\nimpact for the company.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 279}, page_content='WILLIAM CHEN\\n275\\nThe Pareto principle is in full effect here. Eighty percent of the time is spent pulling the \\ndata, cleaning the data, and writing the code for your analysis. I found this true during \\nmy internships (especially because I was new to everything). A good coding background \\nis particularly important here, and can save you a lot of time and frustration.\\nTo emphasize: pulling the data and figuring out what to do with it takes an enormous \\namount of time, and often doesn’t require any statistics knowledge. A lot of this is \\nsoftware engineering and writing efficient queries or efficient ways to move around and \\nanalyze your data. Programming is important here.\\nOne interesting thing to note is that the statistics used day-to-day in data science is really \\ndifferent than the kind of statistics you’d read about in a recent research paper. There’s \\na bias towards methods that are fast, interpretable, and reliable instead of theoretically \\nperfect.\\nWhile the statistics and math may not be that complicated, a strong background in \\nmath and statistics is still important to gather the intuition you need to distinguish \\nreal insights from fake insights. Also, \\na strong background and experience \\nwill give you better intuition on how to \\nsolve some of your company’s harder \\nproblems. You may have a better \\nintuition on why a certain metric might \\nbe falling or why people are suddenly \\nmore engaged in your product.\\nAnother benefit of a strong statistics and math background is the contribution to \\ncommunication. The better you understand the theoretical bases around a certain idea \\nor concept, the better you can articulate what you’re doing and communicate it with \\nthe rest of your team. As a data scientist, a large portion of your work is presenting an \\naction that you feel would have an impact. Communication is very important to make \\nthat happen.  \\nSome data science roles require a very strong statistical or machine learning background. \\nYou might be working on a feed or recommendation engine. Or dealing with problems \\nwhere you need to know time series analysis, basic machine learning techniques, linear \\nregressions, and causal inference. There are lots of kinds of data for which you’d need a \\nmore advanced statistics background to be able to analyze.\\nFiguring out the balance between computer science, statistics and math will really \\ndepend on the role you take, so these are just some of my general observations.\\nThe better you understand the theoretical \\nbases around a certain idea or concept, \\nthe better you can articulate what you’re \\ndoing and communicate it with the rest \\nof your team.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 280}, page_content='WILLIAM CHEN\\n276\\nWhy do you think so many people entering data science have Ph.D.s?\\nData science is a new field now, and employers are looking for people with the qualifications \\nto become a data scientist. Because it’s such a new field, not that many people have \\nmuch industry experience in this, so you have to find people who show some other signal \\nthat they’d be qualified for the position. Having a Ph.D. in a computational/quantitative \\nbackground is a great choice usually, since they’ve already done plenty of research and \\ndata work. Ph.D. and Master’s students with data experience often have qualities that \\nare great for data science: learning quickly, asking questions, and being resilient.\\nI think companies will start hiring \\nmore and more undergrads to fill data \\nscience roles in 5-10 years as there will \\nbe more people coming out with the \\nright data science background. There \\nare a ton more Sophomores at Harvard, \\nfor instance who want to become data \\nscientists, then there were when I was a Sophomore. I think they view it as a promising \\nand exciting career opportunity, of which I wholly agree.\\nRight now, there are plenty of MOOCs (Massive Open Online Courses) offering classes \\nand certificates, and universities all over the world are offering their first data science \\nclass. For example, Harvard’s first data science class and first predictive modeling class \\nshowed up in the 2013-2014 school year. These classes are perfect for undergrads who \\nwant to work on data.\\nIf you’re trying to hire data scientists and there are very few people with experience, \\nthose with Phds and Master’s are good candidates. That will probably change in 5 to 10 \\nyears as there will be more undergraduates who come out with the right data science \\nbackground.  \\nRight now on Coursera, there’s already a data science specialization, and at Harvard \\nthere’s a new class called Data Science taught by Joe Blitzstein and Hanspeter Pfister. Joe \\nis the same professor who taught the statistics class I loved. \\nIn Spring 2014, a predictive modeling class started at Harvard. This is a class that focuses \\non Kaggle competitions. This kind of class is perfect for undergrads who want to work \\nwith data.  \\nIf you had to go back to when you were just starting out, what would you have \\nfocused on more, and what would you have focused on less?\\nPh.D. and Master’s students with data \\nexperience often have qualities that are \\ngreat for data science: learning quickly, \\nasking questions, and being resilient.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 281}, page_content='WILLIAM CHEN\\n277\\nI think my big regret in course selection in college was not taking programming classes \\nmy freshman year. Programming is so vital in data science — there’s not that many roles \\nfor pure statisticians who don’t code unless it’s a giant company like Google or Amazon \\nthat might be specialized enough to need research statisticians. Programming is so \\nessential that you can’t get away with not doing it well.\\nWhen it comes to this term “data science”, a lot of people are worried or claim \\nthere’s a lot of hype around the field in that it’s overblown. What’s your take \\naround this hype and craze around big data and data science?\\nIt’s definitely a bit overhyped right now, just like cloud computing and the mobile / local \\n/ social craze. However, just because it’s overhyped doesn’t mean it’s not important. I \\nthink over the next few years, the hype will die down but the importance of data science \\nwill not.\\nDo you think that the need for data scientists will die down as tools get better?\\nPersonally, I appreciate the new tools a lot. I think the job of the data scientist will \\nchange a lot over the next few years as the tool kit gets better. \\nHowever, I don’t think the need for data \\nscientists will decrease because we’re \\nalways going to need people who can \\ninterpret results and distill insights into \\nactionable plans to improve business. Data \\nscience is never going to run out of hard \\nproblems — there will always be the need \\nfor people to interpret results and communicate ideas. That’s what I think data science \\nis — it’s distilling the data into actionable insights to improve product and business.\\nTools will make what some data scientists do outdated, as some startups provide \\nenterprise solutions and commoditize certain tasks. Even with the new enterprise tools, \\nthere will be a need for data scientists to be able to use the tools intelligently. You’re \\ngoing to want your data scientists to look at the results and think about how they can \\nhelp the company directly.\\nHow much domain expertise do you need in order to be a good data scientist? \\nHow much do you need to know about people’s behaviors online, and does that \\ndrive the products to be built?\\nAt Quora, I worked on a project that involved understanding user engagement. I was in \\na unique position while trying to understand that problem since I was an avid user of \\nWe’re always going to need people \\nwho can interpret results and distill \\ninsights into actionable plans to \\nimprove business.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 282}, page_content='WILLIAM CHEN\\n278\\nQuora myself. When you have domain knowledge, you have an advantage in that you \\ncan make better hypotheses on what you’re curious about before you even look at the \\ndata. You can then look at the data to gain a better intuition on why you were right or \\nwrong. Domain expertise and the intuition that comes coupled with that can help a lot, \\nespecially if your models are complicated or you need to present them to an internal \\naudience. The domain expertise facilitates \\nthe sharing of insightful stories that help \\nexplain the drivers of human behavior in \\nyour product. This is really different than \\nsome data sets on Kaggle where you aren’t \\neven given the column names (because of \\nprivacy) and don’t really understand the \\ndata you’re working with.\\nYou were choosing between quantitative finance and data science and eventually \\nchose data science. Why did that happen, and what were the considerations when \\nyou were making that decision?\\nI think quantitative finance and data science are both really good options. I’m pretty \\nsure that data science was the right option for me because I am just so excited to see \\nhow technology can change the way the world works and make everything work better. I \\nfelt like I wanted to be a part of that. I decided that in order for me to do this properly, I \\nneeded to be part of a consumer or enterprise technology firm where I was able to help \\nmake a product that empowered people to do things.\\nI also really like the teaching and communication aspects of data science — I found out \\nthat I enjoyed it when I got to help teach Statistics 110 at Harvard. Data Science has a lot \\nmore of this teaching and communication going on — often in quantitative finance all \\nyou need are your back-testing results.\\nI want to be some sort of evangelist for data, and convince people that data is useful. I feel \\nthat there’s a lot more potential to do this in the tech sector. For tech, data is very new, \\nwhile for finance, data is very old. I just found it exciting to be part of something where \\ndata was just getting a foothold. I wanted to be a part of something where technology is \\nused to empower people and make the world better.\\nWhen you have domain knowledge, \\nyou have an advantage in that you \\ncan make better hypotheses on what \\nyou’re curious about before you even \\nlook at the data.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 283}, page_content='ABOUT THE AUTHORS\\nCARL SHAN is a Data Science for Social Good Fellow in \\nChicago, where he works with President Obama’s former \\nChief Scientist on applying machine learning and data \\nscience to pressing policy issues. He’s written extensively \\non his website  about his experiences in applying machine \\nlearning to social issues. An avid reader, he co-authored \\nThe Data Science Handbook to help bring stories and \\nwisdom from pioneering data scientists into the lives of as \\nmany readers as possible. When not mired in data, Carl can \\nbe found at a pool table, or pretending to know the lyrics of \\nthe latest hit pop song. \\nCarl holds an honors degree in Statistics from UC Berkeley.\\nHENRY WANG  is an investment analyst with New \\nZealand’s sovereign wealth fund, where he focuses on \\nprivate investments in alternative energy technologies. He is \\ninterested in the intersection of data science and traditional \\ncapital intensive industries, where data driven techniques \\ncan be used to better inform operational and investment \\ndecisions. Henry is a simple guy who enjoys simple things \\nlike traveling, reading, and making delicious instant ramen.\\nHenry holds a Bachelors in Statistics from UC Berkeley.\\nWILLIAM CHEN  is a data scientist at Quora, where he \\nhelps grow and share the world’s knowledge. He is also \\nan avid writer on Quora, where he answers questions on \\ndata science, statistics, machine learning, probability, and \\nmore. William co-authored this book to share the stories \\nof data scientists and help others who want to enter the \\nprofession. For fun, he enjoys speed-solving Rubik’s cubes, \\nbuilding K’NEX ball machines, and breaking out from \\n“escape rooms”. Check out his recent projects (like The Only \\nProbability Cheatsheet You’ll Ever Need) on his website.\\nWilliam holds a Bachelors in Statistics and a Masters in \\nApplied Mathematics from Harvard.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\sarfarazuddin.s\\\\Downloads\\\\The Data Science Handbook.pdf', 'page': 284}, page_content='280\\nMAX SONG  is a data scientist currently working on \\nsecret projects in Paris. Previously, he was the youngest \\ndata scientist at DARPA-backed startup Ayasdi, where he \\nused topological data analysis and machine learning to \\nbuild predictive models. He wrote a popular post about his \\njourney to become a data scientist  on Medium, and enjoys \\nthe craft of writing.  He co-authored the Data Science \\nHandbook to share the the wisdom of pioneers for those \\nlooking to trailblaze their own data science journeys. When \\nnot feverishly coding, he can be found playing improv games \\nand seeding an intellectual gathering ( Salon) in far-flung \\ncorners of the world. \\nAt the time of writing, he is on leave from Applied \\nMathematics-Biology at Brown. \\nBRITTANY CHENG is an Associate Product Manager at \\nYelp who recently launched Yelp in Taiwan. She created the \\nlayout design of The Data Science Handbook and has also \\nworked on layout designs for 120 Data Science Interview \\nQuestions and The Product Manager Handbook . When \\nshe isn’t designing handbooks, she likes to eat, talk about \\neating, drink tea, and rant about umbrellas. Read her Yelp \\nreviews to see what she’s been eating recently.\\nBrittany holds a degree in Electrical Engineering and \\nComputer Science from UC Berkeley.\\nABOUT THE AUTHORS')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd767f6-1eb8-432b-a0df-0be6d73d9379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47000edf-8a87-418a-9d11-0236bbcbde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sangmini/msmarco-cotmae-MiniLM-L12_en-ko-ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d28409f-adaa-4eed-bf22-2e8217f66098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma vector database\n",
    "persist_directory = r\"D:\\vectorstore\"  # Replace with your actual persistence directory path\n",
    "db = Chroma.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9746ac5f-a573-4e77-8d13-b5920511d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chroma retriever\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Initialize the RetrievalQA chain with your LLM and the Chroma retriever\n",
    "db_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # You can use 'stuff', 'map_reduce', or 'refine' depending on your needs\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8ee37b-929e-49a9-917c-ce698257deee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  What is Data Science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarfarazuddin.s\\AppData\\Local\\Temp\\ipykernel_20172\\3641891934.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  db_context = db_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: According to The Data Science Handbook, Data Science is a unique discipline that combines elements of applied mathematics, computer science, business consulting, and new product development. It is considered a permanent feature of the business landscape, requiring a strong foundation in advanced statistics, machine learning, SQL, Hadoop, and a mainstream programming language like Java. Data Science is not just about analyzing data, but also about being able to communicate effectively between business and technical domains, and serving as a trusted advisor to business leaders.\n"
     ]
    }
   ],
   "source": [
    "def retrieve_from_db(query: str) -> str:\n",
    "    try:\n",
    "        db_context = db_chain(query)\n",
    "        db_context = db_context['result'].strip()\n",
    "        # print(f\"Debug: SQL Query Result - {db_context}\")\n",
    "        return db_context\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"An error occurred while retrieving data from the database.\"\n",
    "\n",
    "def generate(query: str) -> str:\n",
    "    db_context = retrieve_from_db(query)\n",
    "    \n",
    "    system_message = system_message = \"\"\"You are a professional representative of The Data Science Handbook.\n",
    "        Answer questions related to data science topics, methodologies, and insights from the book. Provide concise and accurate information based on the content of the book.\n",
    "        If question is asked which is not related to Data Science dont give answer and reply that you are not allowed to give the answers which are not related\n",
    "        to Data Science.\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "    human_qry_template = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"Input:\n",
    "        {human_input}\n",
    "        \n",
    "        Context:\n",
    "        {db_context}\n",
    "        \n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        SystemMessage(content=system_message),\n",
    "        human_qry_template.format(human_input=query, db_context=db_context)\n",
    "    ]\n",
    "    try:\n",
    "        # Get the response from the LLM using the invoke method\n",
    "        response = llm.invoke(messages).content\n",
    "        return response\n",
    "    except Exception as e: \n",
    "        print(f\"Error: {e}\")\n",
    "        return \"An error occurred while generating the response.\"\n",
    "\n",
    "# Example of usage\n",
    "query_input = input(\"Enter your query: \")\n",
    "\n",
    "response_data = generate(query_input)\n",
    "print(f\"Response: {response_data}\")\n",
    "\n",
    "\n",
    "#     try:\n",
    "#         response = llm.invoke(messages).content\n",
    "#         print(f\"LLM Response - {response}\")\n",
    "#         return response\n",
    "#     except Exception as e: \n",
    "#         print(f\"Error: {e}\")\n",
    "#         return \"An error occurred while generating the response.\"\n",
    "\n",
    "# # Example of usage\n",
    "# query_input = input(\"Enter your query: \")\n",
    "\n",
    "# if query_input.lower() in ['hi', 'hello', 'hey']:\n",
    "#     print(\"Hello! How can I assist you with information about data science?\")\n",
    "# else:\n",
    "#     response_data = generate(query_input)\n",
    "#     print(f\"Response: {response_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe9c531-b186-4abd-a5da-36094454b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  What is Physics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I am not allowed to give answers which are not related to Data Science.\n"
     ]
    }
   ],
   "source": [
    "# Example of usage\n",
    "query_input = input(\"Enter your query: \")\n",
    "\n",
    "response_data = generate(query_input)\n",
    "print(f\"Response: {response_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899db46-b07f-482e-9d9f-1c529ea37782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
